
====================
		return err

	}

	return nil

}

func powershell(args ...string) (string, string, error) {

	ps, err := exec.LookPath("powershell.exe")

	if err != nil {

		return "", "", err

	}

	args = append([]string{"-NoProfile", "-NonInteractive"}, args...)

	cmd := exec.Command(ps, args...)

	var stdout bytes.Buffer

	var stderr bytes.Buffer

	cmd.Stdout = &stdout

	cmd.Stderr = &stderr

	err = cmd.Run()

	if err != nil {

		return "", "", err

	}

	return stdout.String(), stderr.String(), err


====================
	var parser = &docopt.Parser{

		HelpHandler:   docopt.PrintHelpOnly,

		OptionsFirst:  true,

		SkipHelpFlags: false,

	}

	arguments, err := parser.ParseArgs(doc, nil, commands.VERSION_SUMMARY)

	if err != nil {

		if _, ok := err.(*docopt.UserError); ok {

			// the user gave us bad input

			fmt.Printf("Invalid option: '%s'. Use flag '--help' to read about a specific subcommand.\n", strings.Join(os.Args[1:], " "))

		}

		os.Exit(1)

	}

	if logLevel := arguments["--log-level"]; logLevel != nil {

		parsedLogLevel, err := log.ParseLevel(logLevel.(string))

		if err != nil {

			fmt.Printf("Unknown log level: %s, expected one of: \n"+

				"panic, fatal, error, warn, info, debug.\n", logLevel)

			os.Exit(1)

		} else {


====================
	}

	arguments, err := parser.ParseArgs(doc, nil, commands.VERSION_SUMMARY)

	if err != nil {

		if _, ok := err.(*docopt.UserError); ok {

			// the user gave us bad input

			fmt.Printf("Invalid option: '%s'. Use flag '--help' to read about a specific subcommand.\n", strings.Join(os.Args[1:], " "))

		}

		os.Exit(1)

	}

	if logLevel := arguments["--log-level"]; logLevel != nil {

		parsedLogLevel, err := log.ParseLevel(logLevel.(string))

		if err != nil {

			fmt.Printf("Unknown log level: %s, expected one of: \n"+

				"panic, fatal, error, warn, info, debug.\n", logLevel)

			os.Exit(1)

		} else {

			log.SetLevel(parsedLogLevel)

			log.Infof("Log level set to %v", parsedLogLevel)

		}

	}


====================
		if err != nil {

			fmt.Printf("Unknown log level: %s, expected one of: \n"+

				"panic, fatal, error, warn, info, debug.\n", logLevel)

			os.Exit(1)

		} else {

			log.SetLevel(parsedLogLevel)

			log.Infof("Log level set to %v", parsedLogLevel)

		}

	}

	if context := arguments["--context"]; context != nil {

		os.Setenv("K8S_CURRENT_CONTEXT", context.(string))

	}

	if arguments["<command>"] != nil {

		command := arguments["<command>"].(string)

		args := append([]string{command}, arguments["<args>"].([]string)...)

		// Propagate the '--allow-version-mismatch' arg to override version mismatch checking.

		if allowMismatch, _ := arguments["--allow-version-mismatch"].(bool); allowMismatch {

			args = append(args, "--allow-version-mismatch")

		}

		var err error


====================
			log.Infof("Log level set to %v", parsedLogLevel)

		}

	}

	if context := arguments["--context"]; context != nil {

		os.Setenv("K8S_CURRENT_CONTEXT", context.(string))

	}

	if arguments["<command>"] != nil {

		command := arguments["<command>"].(string)

		args := append([]string{command}, arguments["<args>"].([]string)...)

		// Propagate the '--allow-version-mismatch' arg to override version mismatch checking.

		if allowMismatch, _ := arguments["--allow-version-mismatch"].(bool); allowMismatch {

			args = append(args, "--allow-version-mismatch")

		}

		var err error

		switch command {

		case "create":

			err = commands.Create(args)

		case "replace":

			err = commands.Replace(args)

		case "apply":


====================
		}

	}

	if context := arguments["--context"]; context != nil {

		os.Setenv("K8S_CURRENT_CONTEXT", context.(string))

	}

	if arguments["<command>"] != nil {

		command := arguments["<command>"].(string)

		args := append([]string{command}, arguments["<args>"].([]string)...)

		// Propagate the '--allow-version-mismatch' arg to override version mismatch checking.

		if allowMismatch, _ := arguments["--allow-version-mismatch"].(bool); allowMismatch {

			args = append(args, "--allow-version-mismatch")

		}

		var err error

		switch command {

		case "create":

			err = commands.Create(args)

		case "replace":

			err = commands.Replace(args)

		case "apply":

			err = commands.Apply(args)


====================
	}

	if context := arguments["--context"]; context != nil {

		os.Setenv("K8S_CURRENT_CONTEXT", context.(string))

	}

	if arguments["<command>"] != nil {

		command := arguments["<command>"].(string)

		args := append([]string{command}, arguments["<args>"].([]string)...)

		// Propagate the '--allow-version-mismatch' arg to override version mismatch checking.

		if allowMismatch, _ := arguments["--allow-version-mismatch"].(bool); allowMismatch {

			args = append(args, "--allow-version-mismatch")

		}

		var err error

		switch command {

		case "create":

			err = commands.Create(args)

		case "replace":

			err = commands.Replace(args)

		case "apply":

			err = commands.Apply(args)

		case "patch":


====================
  # Delete a policy based on the type and name in the YAML passed into stdin.

  cat policy.yaml | <BINARY_NAME> delete -f -

  # Delete policies with names "foo" and "bar"

  <BINARY_NAME> delete policy foo bar

Options:

  -h --help                    Show this screen.

  -s --skip-not-exists         Skip over and treat as successful, resources that

                               don't exist.

  -f --filename=<FILENAME>     Filename to use to delete the resource.  If set to

                               "-" loads from stdin. If filename is a directory, this command is

                               invoked for each .json .yaml and .yml file within that directory,

                               terminating after the first failure.

  -R --recursive               Process the filename specified in -f or --filename recursively.

     --skip-empty              Do not error if any files or directory specified using -f or --filename contain no

                               data.

  -c --config=<CONFIG>         Path to the file containing connection

                               configuration in YAML or JSON format.

                               [default: ` + constants.DefaultConfigPath + `]

  -n --namespace=<NS>          Namespace of the resource.

                               Only applicable to NetworkPolicy and WorkloadEndpoint.


====================
  The resources are deleted in the order they are specified.  In the event of a

  failure deleting a specific resource it is possible to work out which

  resource failed based on the number of resources successfully deleted.

`

	// Replace all instances of BINARY_NAME with the name of the binary.

	name, _ := util.NameAndDescription()

	doc = strings.ReplaceAll(doc, "<BINARY_NAME>", name)

	parsedArgs, err := docopt.ParseArgs(doc, args, "")

	if err != nil {

		return fmt.Errorf("Invalid option: 'calicoctl %s'. Use flag '--help' to read about a specific subcommand.", strings.Join(args, " "))

	}

	if len(parsedArgs) == 0 {

		return nil

	}

	if context := parsedArgs["--context"]; context != nil {

		os.Setenv("K8S_CURRENT_CONTEXT", context.(string))

	}

	results := common.ExecuteConfigCommand(parsedArgs, common.ActionDelete)

	log.Infof("results: %+v", results)

	if results.FileInvalid {


====================
	name, _ := util.NameAndDescription()

	doc = strings.ReplaceAll(doc, "<BINARY_NAME>", name)

	parsedArgs, err := docopt.ParseArgs(doc, args, "")

	if err != nil {

		return fmt.Errorf("Invalid option: 'calicoctl %s'. Use flag '--help' to read about a specific subcommand.", strings.Join(args, " "))

	}

	if len(parsedArgs) == 0 {

		return nil

	}

	if context := parsedArgs["--context"]; context != nil {

		os.Setenv("K8S_CURRENT_CONTEXT", context.(string))

	}

	results := common.ExecuteConfigCommand(parsedArgs, common.ActionDelete)

	log.Infof("results: %+v", results)

	if results.FileInvalid {

		return fmt.Errorf("Failed to execute command: %v", results.Err)

	} else if results.NumResources == 0 {

		// No resources specified. If there is an associated error use that, otherwise print message with no error.

		if results.Err != nil {

			return results.Err


====================
                [--output=<OUTPUT>] [--ignore-validation] [--allow-version-mismatch]

Examples:

  # Convert the contents of policy.yaml to a Calico v3 policy.

  <BINARY_NAME> convert -f ./policy.yaml -o yaml

  # Convert a policy based on the JSON passed into stdin.

  cat policy.json | <BINARY_NAME> convert -f -

Options:

  -h --help                     Show this screen.

  -f --filename=<FILENAME>      Filename to use to create the resource. If set to

                                "-" loads from stdin.

  -o --output=<OUTPUT FORMAT>   Output format. One of: yaml or json.

                                [Default: yaml]

     --ignore-validation        Skip validation on the converted manifest.

     --allow-version-mismatch   Allow client and cluster versions mismatch.

Description:

  Convert config files from Calico v1 or Kubernetes to Calico v3 API versions. Both YAML and JSON formats are accepted.

  The default output will be printed to stdout in YAML format.

`

	// Replace all instances of BINARY_NAME with the name of the binary.

	name, _ := util.NameAndDescription()


====================
Description:

  Convert config files from Calico v1 or Kubernetes to Calico v3 API versions. Both YAML and JSON formats are accepted.

  The default output will be printed to stdout in YAML format.

`

	// Replace all instances of BINARY_NAME with the name of the binary.

	name, _ := util.NameAndDescription()

	doc = strings.ReplaceAll(doc, "<BINARY_NAME>", name)

	parsedArgs, err := docopt.ParseArgs(doc, args, "")

	if err != nil {

		return fmt.Errorf("Invalid option: 'calicoctl %s'. Use flag '--help' to read about a specific subcommand.", strings.Join(args, " "))

	}

	if len(parsedArgs) == 0 {

		return nil

	}

	// Note: Intentionally not check version mismatch for this command

	var rp common.ResourcePrinter

	output := parsedArgs["--output"].(string)

	// Only supported output formats are yaml (default) and json.

	switch output {

	case "yaml", "yml":


====================
	parsedArgs, err := docopt.ParseArgs(doc, args, "")

	if err != nil {

		return fmt.Errorf("Invalid option: 'calicoctl %s'. Use flag '--help' to read about a specific subcommand.", strings.Join(args, " "))

	}

	if len(parsedArgs) == 0 {

		return nil

	}

	// Note: Intentionally not check version mismatch for this command

	var rp common.ResourcePrinter

	output := parsedArgs["--output"].(string)

	// Only supported output formats are yaml (default) and json.

	switch output {

	case "yaml", "yml":

		rp = common.ResourcePrinterYAML{}

	case "json":

		rp = common.ResourcePrinterJSON{}

	default:

		return fmt.Errorf("unrecognized output format '%s'", output)

	}

	filename := argutils.ArgStringOrBlank(parsedArgs, "--filename")


====================
	// Only supported output formats are yaml (default) and json.

	switch output {

	case "yaml", "yml":

		rp = common.ResourcePrinterYAML{}

	case "json":

		rp = common.ResourcePrinterJSON{}

	default:

		return fmt.Errorf("unrecognized output format '%s'", output)

	}

	filename := argutils.ArgStringOrBlank(parsedArgs, "--filename")

	// Load the resource from file and convert to a slice

	// of resources for easier handling.

	convRes, err := resourceloader.CreateResourcesFromFile(filename)

	if err != nil {

		return fmt.Errorf("Failed to create resources from file: %w", err)

	}

	// Unpack list resources (if any) into the slice

	convRes, err = unpackResourceLists(convRes)

	if err != nil {

		return fmt.Errorf("Failed to unpack lists: %w", err)


====================
			return fmt.Errorf("Failed to convert resource: %w", err)

		}

		// Remove any extra metadata the object might have.

		rom := v3Resource.(v1.ObjectMetaAccessor).GetObjectMeta()

		rom.SetUID("")

		rom.SetResourceVersion("")

		rom.SetCreationTimestamp(v1.Time{})

		rom.SetDeletionTimestamp(nil)

		rom.SetDeletionGracePeriodSeconds(nil)

		ignoreValidation := argutils.ArgBoolOrFalse(parsedArgs, "--ignore-validation")

		if !ignoreValidation {

			if err := validator.Validate(v3Resource); err != nil {

				return fmt.Errorf("Converted manifest resource(s) failed validation: %s"+

					"Re-run the command with '--ignore-validation' flag to see the converted output.\n", err)

			}

		}

		results = append(results, v3Resource)

	}

	log.Infof("results: %+v", results)

	if len(results) > 1 {


====================
		rom.SetUID("")

		rom.SetResourceVersion("")

		rom.SetCreationTimestamp(v1.Time{})

		rom.SetDeletionTimestamp(nil)

		rom.SetDeletionGracePeriodSeconds(nil)

		ignoreValidation := argutils.ArgBoolOrFalse(parsedArgs, "--ignore-validation")

		if !ignoreValidation {

			if err := validator.Validate(v3Resource); err != nil {

				return fmt.Errorf("Converted manifest resource(s) failed validation: %s"+

					"Re-run the command with '--ignore-validation' flag to see the converted output.\n", err)

			}

		}

		results = append(results, v3Resource)

	}

	log.Infof("results: %+v", results)

	if len(results) > 1 {

		results, err = createV1List(results)

		if err != nil {

			return fmt.Errorf("Failed to create v1.List: %w", err)

		}


====================
	name, _ := util.NameAndDescription()

	doc = strings.ReplaceAll(doc, "<BINARY_NAME>", name)

	var parser = &docopt.Parser{

		HelpHandler:   docopt.PrintHelpAndExit,

		OptionsFirst:  true,

		SkipHelpFlags: false,

	}

	arguments, err := parser.ParseArgs(doc, args, "")

	if err != nil {

		return fmt.Errorf("Invalid option: 'calicoctl %s'. Use flag '--help' to read about a specific subcommand.", strings.Join(args, " "))

	}

	if arguments["<command>"] == nil {

		return nil

	}

	command := arguments["<command>"].(string)

	args = append([]string{"ipam", command}, arguments["<args>"].([]string)...)

	switch command {

	case "check":

		return ipam.Check(args, VERSION)

	case "release":


====================
                    [--config=<CONFIG>] [--namespace=<NS>] [--context=<context>] [--allow-version-mismatch]

Examples:

  # Replace a policy using the data in policy.yaml.

  <BINARY_NAME> replace -f ./policy.yaml

  # Replace a policy based on the JSON passed into stdin.

  cat policy.json | <BINARY_NAME> replace -f -

Options:

  -h --help                    Show this screen.

  -f --filename=<FILENAME>     Filename to use to replace the resource.  If set

                               to "-" loads from stdin. If filename is a directory, this command is

                               invoked for each .json .yaml and .yml file within that directory,

                               terminating after the first failure.

  -R --recursive               Process the filename specified in -f or --filename recursively.

     --skip-empty              Do not error if any files or directory specified using -f or --filename contain no

                               data.

  -c --config=<CONFIG>         Path to the file containing connection

                               configuration in YAML or JSON format.

                               [default: ` + constants.DefaultConfigPath + `]

  -n --namespace=<NS>          Namespace of the resource.

                               Only applicable to NetworkPolicy, NetworkSet, and WorkloadEndpoint.


====================
  resource failed based on the number of resources successfully replaced.

  When replacing a resource, the complete resource spec must be provided, it is

  not sufficient to supply only the fields that are being updated.

`

	// Replace all instances of BINARY_NAME with the name of the binary.

	name, _ := util.NameAndDescription()

	doc = strings.ReplaceAll(doc, "<BINARY_NAME>", name)

	parsedArgs, err := docopt.ParseArgs(doc, args, "")

	if err != nil {

		return fmt.Errorf("Invalid option: 'calicoctl %s'. Use flag '--help' to read about a specific subcommand.", strings.Join(args, " "))

	}

	if len(parsedArgs) == 0 {

		return nil

	}

	if context := parsedArgs["--context"]; context != nil {

		os.Setenv("K8S_CURRENT_CONTEXT", context.(string))

	}

	results := common.ExecuteConfigCommand(parsedArgs, common.ActionUpdate)

	log.Infof("results: %+v", results)

	if results.FileInvalid {


====================
	name, _ := util.NameAndDescription()

	doc = strings.ReplaceAll(doc, "<BINARY_NAME>", name)

	parsedArgs, err := docopt.ParseArgs(doc, args, "")

	if err != nil {

		return fmt.Errorf("Invalid option: 'calicoctl %s'. Use flag '--help' to read about a specific subcommand.", strings.Join(args, " "))

	}

	if len(parsedArgs) == 0 {

		return nil

	}

	if context := parsedArgs["--context"]; context != nil {

		os.Setenv("K8S_CURRENT_CONTEXT", context.(string))

	}

	results := common.ExecuteConfigCommand(parsedArgs, common.ActionUpdate)

	log.Infof("results: %+v", results)

	if results.FileInvalid {

		return fmt.Errorf("Failed to execute command: %v", results.Err)

	} else if results.NumResources == 0 {

		// No resources specified. If there is an associated error use that, otherwise print message with no error.

		if results.Err != nil {

			return results.Err


====================
     --allow-version-mismatch  Allow client and cluster versions mismatch.

Description:

  Display the version of <BINARY_NAME>.

`

	// Replace all instances of BINARY_NAME with the name of the binary.

	name, _ := util.NameAndDescription()

	doc = strings.ReplaceAll(doc, "<BINARY_NAME>", name)

	parsedArgs, err := docopt.ParseArgs(doc, args, "")

	if err != nil {

		return fmt.Errorf("Invalid option: 'calicoctl %s'. Use flag '--help' to read about a specific subcommand.", strings.Join(args, " "))

	}

	if len(parsedArgs) == 0 {

		return nil

	}

	// Note: Intentionally not check version mismatch for this command

	// Parse the poll duration.

	var pollDuration time.Duration

	var ci *v3.ClusterInformation

	if poll := argutils.ArgStringOrBlank(parsedArgs, "--poll"); poll != "" {

		if pollDuration, err = time.ParseDuration(poll); err != nil {


====================
		return fmt.Errorf("Invalid option: 'calicoctl %s'. Use flag '--help' to read about a specific subcommand.", strings.Join(args, " "))

	}

	if len(parsedArgs) == 0 {

		return nil

	}

	// Note: Intentionally not check version mismatch for this command

	// Parse the poll duration.

	var pollDuration time.Duration

	var ci *v3.ClusterInformation

	if poll := argutils.ArgStringOrBlank(parsedArgs, "--poll"); poll != "" {

		if pollDuration, err = time.ParseDuration(poll); err != nil {

			return fmt.Errorf("Invalid poll duration specified: %s", pollDuration)

		}

	}

	fmt.Println("Client Version:   ", VERSION)

	fmt.Println("Git commit:       ", GIT_REVISION)

	// Load the client config and connect.

	cf := parsedArgs["--config"].(string)

	client, err := clientmgr.NewClient(cf)

	if err != nil {


====================
	var ci *v3.ClusterInformation

	if poll := argutils.ArgStringOrBlank(parsedArgs, "--poll"); poll != "" {

		if pollDuration, err = time.ParseDuration(poll); err != nil {

			return fmt.Errorf("Invalid poll duration specified: %s", pollDuration)

		}

	}

	fmt.Println("Client Version:   ", VERSION)

	fmt.Println("Git commit:       ", GIT_REVISION)

	// Load the client config and connect.

	cf := parsedArgs["--config"].(string)

	client, err := clientmgr.NewClient(cf)

	if err != nil {

		if derr, ok := err.(errors.ErrorDatastoreError); ok {

			log.Debugf("Client config error: %s", derr.Error())

			fmt.Println("Unable to detect installed Calico version")

			return nil

		}

		return err

	}

	ctx := context.Background()


====================
                  [--config=<CONFIG>] [--namespace=<NS>] [--context=<context>] [--allow-version-mismatch]

Examples:

  # Apply a policy using the data in policy.yaml.

  <BINARY_NAME> apply -f ./policy.yaml

  # Apply a policy based on the JSON passed into stdin.

  cat policy.json | <BINARY_NAME> apply -f -

Options:

  -h --help                    Show this screen.

  -f --filename=<FILENAME>     Filename to use to apply the resource.  If set to

                               "-" loads from stdin. If filename is a directory, this command is

                               invoked for each .json .yaml and .yml file within that directory,

                               terminating after the first failure.

  -R --recursive               Process the filename specified in -f or --filename recursively.

     --skip-empty              Do not error if any files or directory specified using -f or --filename contain no

                               data.

  -c --config=<CONFIG>         Path to the file containing connection

                               configuration in YAML or JSON format.

                               [default: ` + constants.DefaultConfigPath + `]

  -n --namespace=<NS>          Namespace of the resource.

                               Only applicable to NetworkPolicy, NetworkSet, and WorkloadEndpoint.


====================
  When applying a resource to perform an update, the complete resource spec

  must be provided, it is not sufficient to supply only the fields that are

  being updated.

`

	// Replace all instances of BINARY_NAME with the name of the binary.

	name, _ := util.NameAndDescription()

	doc = strings.ReplaceAll(doc, "<BINARY_NAME>", name)

	parsedArgs, err := docopt.ParseArgs(doc, args, "")

	if err != nil {

		return fmt.Errorf("Invalid option: 'calicoctl %s'. Use flag '--help' to read about a specific subcommand.", strings.Join(args, " "))

	}

	if len(parsedArgs) == 0 {

		return nil

	}

	if context := parsedArgs["--context"]; context != nil {

		os.Setenv("K8S_CURRENT_CONTEXT", context.(string))

	}

	results := common.ExecuteConfigCommand(parsedArgs, common.ActionApply)

	log.Infof("results: %+v", results)

	if results.FileInvalid {


====================
	name, _ := util.NameAndDescription()

	doc = strings.ReplaceAll(doc, "<BINARY_NAME>", name)

	parsedArgs, err := docopt.ParseArgs(doc, args, "")

	if err != nil {

		return fmt.Errorf("Invalid option: 'calicoctl %s'. Use flag '--help' to read about a specific subcommand.", strings.Join(args, " "))

	}

	if len(parsedArgs) == 0 {

		return nil

	}

	if context := parsedArgs["--context"]; context != nil {

		os.Setenv("K8S_CURRENT_CONTEXT", context.(string))

	}

	results := common.ExecuteConfigCommand(parsedArgs, common.ActionApply)

	log.Infof("results: %+v", results)

	if results.FileInvalid {

		return fmt.Errorf("Failed to execute command: %v", results.Err)

	} else if results.NumResources == 0 {

		// No resources specified. If there is an associated error use that, otherwise print message with no error.

		if results.Err != nil {

			return results.Err


====================
  When labeling a resource on an existing key:

  - gets an error if option --overwrite is not provided.

  - value of the key updates to specified value if option --overwrite is provided.

  `

	// Replace all instances of BINARY_NAME with the name of the binary.

	binaryName, _ := util.NameAndDescription()

	doc = strings.ReplaceAll(doc, "<BINARY_NAME>", binaryName)

	parsedArgs, err := docopt.ParseArgs(doc, args, "")

	if err != nil {

		return fmt.Errorf("Invalid option: 'calicoctl %s'. Use flag '--help' to read about a specific subcommand.", strings.Join(args, " "))

	}

	if len(parsedArgs) == 0 {

		return nil

	}

	if context := parsedArgs["--context"]; context != nil {

		os.Setenv("K8S_CURRENT_CONTEXT", context.(string))

	}

	log.Debugf("parse args: %+v\n", parsedArgs)

	// get results.

	kind := parsedArgs["<KIND>"].(string)


====================
	binaryName, _ := util.NameAndDescription()

	doc = strings.ReplaceAll(doc, "<BINARY_NAME>", binaryName)

	parsedArgs, err := docopt.ParseArgs(doc, args, "")

	if err != nil {

		return fmt.Errorf("Invalid option: 'calicoctl %s'. Use flag '--help' to read about a specific subcommand.", strings.Join(args, " "))

	}

	if len(parsedArgs) == 0 {

		return nil

	}

	if context := parsedArgs["--context"]; context != nil {

		os.Setenv("K8S_CURRENT_CONTEXT", context.(string))

	}

	log.Debugf("parse args: %+v\n", parsedArgs)

	// get results.

	kind := parsedArgs["<KIND>"].(string)

	name := parsedArgs["<NAME>"].(string)

	// TODO: convert kind into the formal format

	// parse key/value.

	var key, value string

	remove := parsedArgs["--remove"].(bool)


====================
		os.Setenv("K8S_CURRENT_CONTEXT", context.(string))

	}

	log.Debugf("parse args: %+v\n", parsedArgs)

	// get results.

	kind := parsedArgs["<KIND>"].(string)

	name := parsedArgs["<NAME>"].(string)

	// TODO: convert kind into the formal format

	// parse key/value.

	var key, value string

	remove := parsedArgs["--remove"].(bool)

	if remove {

		key = parsedArgs["<key>"].(string)

	} else {

		kv := strings.Split(parsedArgs["<key>=<value>"].(string), "=")

		if len(kv) != 2 {

			return fmt.Errorf("invalid label %s", parsedArgs["<key>=<value>"])

		}

		key = kv[0]

		value = kv[1]

	}


====================
		return fmt.Errorf("Failed to execute command: %v", results.Err)

	} else if results.Err != nil {

		return fmt.Errorf("failed to get %s %s, error %v",

			kind, name, results.Err)

	} else if len(results.Resources) == 0 {

		return fmt.Errorf("%s %s not found", kind, name)

	}

	resource := results.Resources[0].(resourcemgr.ResourceObject)

	labels := resource.GetObjectMeta().GetLabels()

	overwrite := parsedArgs["--overwrite"].(bool)

	overwritten := false

	client := results.Client

	if labels == nil {

		labels = make(map[string]string)

	}

	if remove {

		// remove label.

		_, ok := labels[key]

		if !ok {

			// raise error if the key does not exist.


====================
		}

	} else {

		// add or update label.

		oldValue, ok := labels[key]

		if ok {

			if overwrite || value == oldValue {

				labels[key] = value

				overwritten = true

			} else {

				return fmt.Errorf("failed to update label of %s %s, key %s is already present. please use '--overwrite' to set a new value.",

					kind, name, key)

			}

		} else {

			labels[key] = value

		}

	}

	resource.GetObjectMeta().SetLabels(labels)

	_, err = common.ExecuteResourceAction(parsedArgs, client, resource, common.ActionUpdate)

	if err != nil {

		return fmt.Errorf("failed to update %s %s, label not changed", kind, name)


====================
	name, _ := util.NameAndDescription()

	doc = strings.ReplaceAll(doc, "<BINARY_NAME>", name)

	var parser = &docopt.Parser{

		HelpHandler:   docopt.PrintHelpAndExit,

		OptionsFirst:  true,

		SkipHelpFlags: false,

	}

	arguments, err := parser.ParseArgs(doc, args, "")

	if err != nil {

		return fmt.Errorf("Invalid option: 'calicoctl %s'. Use flag '--help' to read about a specific subcommand.", strings.Join(args, " "))

	}

	if arguments["<command>"] == nil {

		return nil

	}

	command := arguments["<command>"].(string)

	args = append([]string{"node", command}, arguments["<args>"].([]string)...)

	switch command {

	case "status":

		return node.Status(args)

	case "diags":


====================
  When patching resources by type, only a single type may be specified at a

  time.  The name is required along with any and other identifiers required to

  uniquely identify a resource of the specified type.

`

	// Replace all instances of BINARY_NAME with the name of the binary.

	name, _ := util.NameAndDescription()

	doc = strings.ReplaceAll(doc, "<BINARY_NAME>", name)

	parsedArgs, err := docopt.ParseArgs(doc, args, "")

	if err != nil {

		return fmt.Errorf("Invalid option: 'calicoctl %s'. Use flag '--help' to read about a specific subcommand.", strings.Join(args, " "))

	}

	if len(parsedArgs) == 0 {

		return nil

	}

	if context := parsedArgs["--context"]; context != nil {

		os.Setenv("K8S_CURRENT_CONTEXT", context.(string))

	}

	results := common.ExecuteConfigCommand(parsedArgs, common.ActionPatch)

	log.Infof("results: %+v", results)

	if results.NumResources == 0 {


====================
	name, _ := util.NameAndDescription()

	doc = strings.ReplaceAll(doc, "<BINARY_NAME>", name)

	parsedArgs, err := docopt.ParseArgs(doc, args, "")

	if err != nil {

		return fmt.Errorf("Invalid option: 'calicoctl %s'. Use flag '--help' to read about a specific subcommand.", strings.Join(args, " "))

	}

	if len(parsedArgs) == 0 {

		return nil

	}

	if context := parsedArgs["--context"]; context != nil {

		os.Setenv("K8S_CURRENT_CONTEXT", context.(string))

	}

	results := common.ExecuteConfigCommand(parsedArgs, common.ActionPatch)

	log.Infof("results: %+v", results)

	if results.NumResources == 0 {

		// No resources specified. If there is an associated error use that, otherwise print message with no error.

		if results.Err != nil {

			return results.Err

		}

		return fmt.Errorf("No resources specified")


====================
	name, _ := util.NameAndDescription()

	doc = strings.ReplaceAll(doc, "<BINARY_NAME>", name)

	var parser = &docopt.Parser{

		HelpHandler:   docopt.PrintHelpAndExit,

		OptionsFirst:  true,

		SkipHelpFlags: false,

	}

	arguments, err := parser.ParseArgs(doc, args, "")

	if err != nil {

		return fmt.Errorf("Invalid option: 'calicoctl %s'. Use flag '--help' to read about a specific subcommand.", strings.Join(args, " "))

	}

	if arguments["<command>"] == nil {

		return nil

	}

	command := arguments["<command>"].(string)

	args = append([]string{"datastore", command}, arguments["<args>"].([]string)...)

	switch command {

	case "migrate":

		return datastore.Migrate(args)

	default:


====================
                   [--skip-exists] [--config=<CONFIG>] [--namespace=<NS>] [--context=<context>] [--allow-version-mismatch]

Examples:

  # Create a policy using the data in policy.yaml.

  <BINARY_NAME> create -f ./policy.yaml

  # Create a policy based on the JSON passed into stdin.

  cat policy.json | <BINARY_NAME> create -f -

Options:

  -h --help                    Show this screen.

  -f --filename=<FILENAME>     Filename to use to create the resource.  If set to

                               "-" loads from stdin. If filename is a directory, this command is

                               invoked for each .json .yaml and .yml file within that directory,

                               terminating after the first failure.

  -R --recursive               Process the filename specified in -f or --filename recursively.

     --skip-empty              Do not error if any files or directory specified using -f or --filename contain no

                               data.

     --skip-exists             Skip over and treat as successful any attempts to

                               create an entry that already exists.

  -c --config=<CONFIG>         Path to the file containing connection

                               configuration in YAML or JSON format.

                               [default: ` + constants.DefaultConfigPath + `]


====================
  The resources are created in the order they are specified.  In the event of a

  failure creating a specific resource it is possible to work out which

  resource failed based on the number of resources successfully created.

`

	// Replace all instances of BINARY_NAME with the name of the binary.

	name, _ := util.NameAndDescription()

	doc = strings.ReplaceAll(doc, "<BINARY_NAME>", name)

	parsedArgs, err := docopt.ParseArgs(doc, args, "")

	if err != nil {

		return fmt.Errorf("Invalid option: 'calicoctl %s'. Use flag '--help' to read about a specific subcommand.", strings.Join(args, " "))

	}

	if len(parsedArgs) == 0 {

		return nil

	}

	if context := parsedArgs["--context"]; context != nil {

		os.Setenv("K8S_CURRENT_CONTEXT", context.(string))

	}

	results := common.ExecuteConfigCommand(parsedArgs, common.ActionCreate)

	log.Infof("results: %+v", results)

	if results.FileInvalid {


====================
	name, _ := util.NameAndDescription()

	doc = strings.ReplaceAll(doc, "<BINARY_NAME>", name)

	parsedArgs, err := docopt.ParseArgs(doc, args, "")

	if err != nil {

		return fmt.Errorf("Invalid option: 'calicoctl %s'. Use flag '--help' to read about a specific subcommand.", strings.Join(args, " "))

	}

	if len(parsedArgs) == 0 {

		return nil

	}

	if context := parsedArgs["--context"]; context != nil {

		os.Setenv("K8S_CURRENT_CONTEXT", context.(string))

	}

	results := common.ExecuteConfigCommand(parsedArgs, common.ActionCreate)

	log.Infof("results: %+v", results)

	if results.FileInvalid {

		return fmt.Errorf("Failed to execute command: %v", results.Err)

	} else if results.NumResources == 0 {

		// No resources specified. If there is an associated error use that, otherwise print message with no error.

		if results.Err != nil {

			return results.Err


====================
                [--output=<OUTPUT>] [--config=<CONFIG>] [--namespace=<NS>] [--all-namespaces] [--export] [--context=<context>] [--allow-version-mismatch]

Examples:

  # List all policy in default output format.

  <BINARY_NAME> get policy

  # List specific policies in YAML format

  <BINARY_NAME> get -o yaml policy my-policy-1 my-policy-2

Options:

  -h --help                    Show this screen.

  -f --filename=<FILENAME>     Filename to use to get the resource.  If set to

                               "-" loads from stdin. If filename is a directory, this command is

                               invoked for each .json .yaml and .yml file within that directory,

                               terminating after the first failure.

  -R --recursive               Process the filename specified in -f or --filename recursively.

     --skip-empty              Do not error if any files or directory specified using -f or --filename contain no

                               data.

  -o --output=<OUTPUT FORMAT>  Output format.  One of: yaml, json, ps, wide,

                               custom-columns=..., go-template=...,

                               go-template-file=...   [Default: ps]

  -c --config=<CONFIG>         Path to the file containing connection

                               configuration in YAML or JSON format.


====================
  the output formats, including example outputs, resource structure (required

  for the golang template definitions) and the valid column names (required for

  the custom-columns option).

`

	// Replace all instances of BINARY_NAME with the name of the binary.

	name, _ := util.NameAndDescription()

	doc = strings.ReplaceAll(doc, "<BINARY_NAME>", name)

	// -a option Backward compatibility

	for k, v := range args {

		if v == "-a" {

			args[k] = "-A"

		}

	}

	parsedArgs, err := docopt.ParseArgs(doc, args, "")

	if err != nil {

		return fmt.Errorf("Invalid option: 'calicoctl %s'. Use flag '--help' to read about a specific subcommand.", strings.Join(args, " "))

	}

	if len(parsedArgs) == 0 {

		return nil

	}


====================
  for the golang template definitions) and the valid column names (required for

  the custom-columns option).

`

	// Replace all instances of BINARY_NAME with the name of the binary.

	name, _ := util.NameAndDescription()

	doc = strings.ReplaceAll(doc, "<BINARY_NAME>", name)

	// -a option Backward compatibility

	for k, v := range args {

		if v == "-a" {

			args[k] = "-A"

		}

	}

	parsedArgs, err := docopt.ParseArgs(doc, args, "")

	if err != nil {

		return fmt.Errorf("Invalid option: 'calicoctl %s'. Use flag '--help' to read about a specific subcommand.", strings.Join(args, " "))

	}

	if len(parsedArgs) == 0 {

		return nil

	}

	if context := parsedArgs["--context"]; context != nil {


====================
	doc = strings.ReplaceAll(doc, "<BINARY_NAME>", name)

	// -a option Backward compatibility

	for k, v := range args {

		if v == "-a" {

			args[k] = "-A"

		}

	}

	parsedArgs, err := docopt.ParseArgs(doc, args, "")

	if err != nil {

		return fmt.Errorf("Invalid option: 'calicoctl %s'. Use flag '--help' to read about a specific subcommand.", strings.Join(args, " "))

	}

	if len(parsedArgs) == 0 {

		return nil

	}

	if context := parsedArgs["--context"]; context != nil {

		os.Setenv("K8S_CURRENT_CONTEXT", context.(string))

	}

	printNamespace := false

	if argutils.ArgBoolOrFalse(parsedArgs, "--all-namespaces") || argutils.ArgStringOrBlank(parsedArgs, "--namespace") != "" {

		printNamespace = true


====================
		}

	}

	parsedArgs, err := docopt.ParseArgs(doc, args, "")

	if err != nil {

		return fmt.Errorf("Invalid option: 'calicoctl %s'. Use flag '--help' to read about a specific subcommand.", strings.Join(args, " "))

	}

	if len(parsedArgs) == 0 {

		return nil

	}

	if context := parsedArgs["--context"]; context != nil {

		os.Setenv("K8S_CURRENT_CONTEXT", context.(string))

	}

	printNamespace := false

	if argutils.ArgBoolOrFalse(parsedArgs, "--all-namespaces") || argutils.ArgStringOrBlank(parsedArgs, "--namespace") != "" {

		printNamespace = true

	}

	var rp common.ResourcePrinter

	output := parsedArgs["--output"].(string)

	switch output {

	case "yaml", "yml":


====================
		return fmt.Errorf("Invalid option: 'calicoctl %s'. Use flag '--help' to read about a specific subcommand.", strings.Join(args, " "))

	}

	if len(parsedArgs) == 0 {

		return nil

	}

	if context := parsedArgs["--context"]; context != nil {

		os.Setenv("K8S_CURRENT_CONTEXT", context.(string))

	}

	printNamespace := false

	if argutils.ArgBoolOrFalse(parsedArgs, "--all-namespaces") || argutils.ArgStringOrBlank(parsedArgs, "--namespace") != "" {

		printNamespace = true

	}

	var rp common.ResourcePrinter

	output := parsedArgs["--output"].(string)

	switch output {

	case "yaml", "yml":

		rp = common.ResourcePrinterYAML{}

	case "json":

		rp = common.ResourcePrinterJSON{}

	case "ps":


====================
	}

	if context := parsedArgs["--context"]; context != nil {

		os.Setenv("K8S_CURRENT_CONTEXT", context.(string))

	}

	printNamespace := false

	if argutils.ArgBoolOrFalse(parsedArgs, "--all-namespaces") || argutils.ArgStringOrBlank(parsedArgs, "--namespace") != "" {

		printNamespace = true

	}

	var rp common.ResourcePrinter

	output := parsedArgs["--output"].(string)

	switch output {

	case "yaml", "yml":

		rp = common.ResourcePrinterYAML{}

	case "json":

		rp = common.ResourcePrinterJSON{}

	case "ps":

		rp = common.ResourcePrinterTable{Wide: false, PrintNamespace: printNamespace}

	case "wide":

		rp = common.ResourcePrinterTable{Wide: true, PrintNamespace: printNamespace}

	default:


====================
		df2name2 = strings.TrimPrefix(df2name2, "./")

		df2name3 = strings.TrimPrefix(df2name3, "./")

	})

	AfterEach(func() {

		Expect(os.Remove(fname)).ToNot(HaveOccurred())

		Expect(os.RemoveAll(dname)).ToNot(HaveOccurred())

	})

	runTest := func(filename string, recursive bool, expected []string) error {

		args := map[string]interface{}{

			"--abc": 1,

			"--def": "hello",

		}

		if filename != "" {

			args["--filename"] = filename

		}

		if recursive {

			args["--recursive"] = true

		}

		err := file.Iter(args, func(updated map[string]interface{}) error {

			invocations = append(invocations, updated)


====================
		df2name3 = strings.TrimPrefix(df2name3, "./")

	})

	AfterEach(func() {

		Expect(os.Remove(fname)).ToNot(HaveOccurred())

		Expect(os.RemoveAll(dname)).ToNot(HaveOccurred())

	})

	runTest := func(filename string, recursive bool, expected []string) error {

		args := map[string]interface{}{

			"--abc": 1,

			"--def": "hello",

		}

		if filename != "" {

			args["--filename"] = filename

		}

		if recursive {

			args["--recursive"] = true

		}

		err := file.Iter(args, func(updated map[string]interface{}) error {

			invocations = append(invocations, updated)

			return testError


====================
		Expect(os.Remove(fname)).ToNot(HaveOccurred())

		Expect(os.RemoveAll(dname)).ToNot(HaveOccurred())

	})

	runTest := func(filename string, recursive bool, expected []string) error {

		args := map[string]interface{}{

			"--abc": 1,

			"--def": "hello",

		}

		if filename != "" {

			args["--filename"] = filename

		}

		if recursive {

			args["--recursive"] = true

		}

		err := file.Iter(args, func(updated map[string]interface{}) error {

			invocations = append(invocations, updated)

			return testError

		})

		Expect(invocations).To(HaveLen(len(expected)))

		for i := range invocations {


====================
	runTest := func(filename string, recursive bool, expected []string) error {

		args := map[string]interface{}{

			"--abc": 1,

			"--def": "hello",

		}

		if filename != "" {

			args["--filename"] = filename

		}

		if recursive {

			args["--recursive"] = true

		}

		err := file.Iter(args, func(updated map[string]interface{}) error {

			invocations = append(invocations, updated)

			return testError

		})

		Expect(invocations).To(HaveLen(len(expected)))

		for i := range invocations {

			var count int

			if filename == "" {

				Expect(invocations[i]).NotTo(HaveKey("--filename"))


====================
		}

		err := file.Iter(args, func(updated map[string]interface{}) error {

			invocations = append(invocations, updated)

			return testError

		})

		Expect(invocations).To(HaveLen(len(expected)))

		for i := range invocations {

			var count int

			if filename == "" {

				Expect(invocations[i]).NotTo(HaveKey("--filename"))

				count = 2

			} else {

				Expect(invocations[i]).To(HaveKey("--filename"))

				// Trim leading ./ (if any) for easier comparison.

				fn := invocations[i]["--filename"].(string)

				fn = strings.TrimPrefix(fn, "./")

				Expect(fn).To(BeElementOf(expected))

				count = 3

			}

			if recursive {


====================
			return testError

		})

		Expect(invocations).To(HaveLen(len(expected)))

		for i := range invocations {

			var count int

			if filename == "" {

				Expect(invocations[i]).NotTo(HaveKey("--filename"))

				count = 2

			} else {

				Expect(invocations[i]).To(HaveKey("--filename"))

				// Trim leading ./ (if any) for easier comparison.

				fn := invocations[i]["--filename"].(string)

				fn = strings.TrimPrefix(fn, "./")

				Expect(fn).To(BeElementOf(expected))

				count = 3

			}

			if recursive {

				count++

			}

			Expect(invocations[i]).To(HaveLen(count))


====================
		Expect(invocations).To(HaveLen(len(expected)))

		for i := range invocations {

			var count int

			if filename == "" {

				Expect(invocations[i]).NotTo(HaveKey("--filename"))

				count = 2

			} else {

				Expect(invocations[i]).To(HaveKey("--filename"))

				// Trim leading ./ (if any) for easier comparison.

				fn := invocations[i]["--filename"].(string)

				fn = strings.TrimPrefix(fn, "./")

				Expect(fn).To(BeElementOf(expected))

				count = 3

			}

			if recursive {

				count++

			}

			Expect(invocations[i]).To(HaveLen(count))

			Expect(invocations[i]).To(HaveKey("--abc"))

			Expect(invocations[i]["--abc"]).To(Equal(1))


====================
				fn := invocations[i]["--filename"].(string)

				fn = strings.TrimPrefix(fn, "./")

				Expect(fn).To(BeElementOf(expected))

				count = 3

			}

			if recursive {

				count++

			}

			Expect(invocations[i]).To(HaveLen(count))

			Expect(invocations[i]).To(HaveKey("--abc"))

			Expect(invocations[i]["--abc"]).To(Equal(1))

			Expect(invocations[i]["--def"]).To(Equal("hello"))

		}

		return err

	}

	It("should handle no filename", func() {

		err := runTest("", false, []string{""})

		Expect(err).NotTo(HaveOccurred())

	})

	It("should handle stdin", func() {


====================
				fn = strings.TrimPrefix(fn, "./")

				Expect(fn).To(BeElementOf(expected))

				count = 3

			}

			if recursive {

				count++

			}

			Expect(invocations[i]).To(HaveLen(count))

			Expect(invocations[i]).To(HaveKey("--abc"))

			Expect(invocations[i]["--abc"]).To(Equal(1))

			Expect(invocations[i]["--def"]).To(Equal("hello"))

		}

		return err

	}

	It("should handle no filename", func() {

		err := runTest("", false, []string{""})

		Expect(err).NotTo(HaveOccurred())

	})

	It("should handle stdin", func() {

		err := runTest("-", false, []string{"-"})


====================
				Expect(fn).To(BeElementOf(expected))

				count = 3

			}

			if recursive {

				count++

			}

			Expect(invocations[i]).To(HaveLen(count))

			Expect(invocations[i]).To(HaveKey("--abc"))

			Expect(invocations[i]["--abc"]).To(Equal(1))

			Expect(invocations[i]["--def"]).To(Equal("hello"))

		}

		return err

	}

	It("should handle no filename", func() {

		err := runTest("", false, []string{""})

		Expect(err).NotTo(HaveOccurred())

	})

	It("should handle stdin", func() {

		err := runTest("-", false, []string{"-"})

		Expect(err).NotTo(HaveOccurred())


====================
			Expect(invocations[i]["--def"]).To(Equal("hello"))

		}

		return err

	}

	It("should handle no filename", func() {

		err := runTest("", false, []string{""})

		Expect(err).NotTo(HaveOccurred())

	})

	It("should handle stdin", func() {

		err := runTest("-", false, []string{"-"})

		Expect(err).NotTo(HaveOccurred())

	})

	It("should handle non-existent file", func() {

		err := runTest("this-file-should-not-exist", false, []string{"this-file-should-not-exist"})

		Expect(err).NotTo(HaveOccurred())

	})

	It("should handle error", func() {

		testError = errors.New("test")

		err := runTest("-", false, []string{"-"})

		Expect(err).To(HaveOccurred())


====================
		err := runTest("-", false, []string{"-"})

		Expect(err).NotTo(HaveOccurred())

	})

	It("should handle non-existent file", func() {

		err := runTest("this-file-should-not-exist", false, []string{"this-file-should-not-exist"})

		Expect(err).NotTo(HaveOccurred())

	})

	It("should handle error", func() {

		testError = errors.New("test")

		err := runTest("-", false, []string{"-"})

		Expect(err).To(HaveOccurred())

	})

	It("should handle file", func() {

		err := runTest(fname, false, []string{fname})

		Expect(err).NotTo(HaveOccurred())

	})

	It("should handle directory and different file extensions", func() {

		err := runTest(dname, false, []string{dfname1, dfname2, dfname3})

		Expect(err).NotTo(HaveOccurred())

	})


====================
//     directory (updating the arguments to include the specific file)

//   - otherwise just invoke the callback with the unmodified arguments.

func Iter(parsedArgs map[string]interface{}, cb func(map[string]interface{}) error) error {

	// File name is specified.

	f, ok := parsedArgs["--filename"].(string)

	if !ok {

		// Handle invalid or missing filename by invoking standard processing.

		return cb(parsedArgs)

	}

	if f == "-" {

		// Handle stdin filename by invoking standard processing.

		return cb(parsedArgs)

	}

	if !isDir(f) {

		// Handle non-directory by invoking standard processing.

		return cb(parsedArgs)

	}

	// Determine if we are following directories recursively.

	recursive := argutils.ArgBoolOrFalse(parsedArgs, "--recursive")

	// Handle directory by walking the directory contents and performing the action on each manifest file.


====================
	if f == "-" {

		// Handle stdin filename by invoking standard processing.

		return cb(parsedArgs)

	}

	if !isDir(f) {

		// Handle non-directory by invoking standard processing.

		return cb(parsedArgs)

	}

	// Determine if we are following directories recursively.

	recursive := argutils.ArgBoolOrFalse(parsedArgs, "--recursive")

	// Handle directory by walking the directory contents and performing the action on each manifest file.

	return filepath.Walk(f,

		func(path string, info os.FileInfo, err error) error {

			if err != nil {

				return err

			}

			if info.IsDir() {

				// Return nil or SkipDir dpending on whether or not we are recursively following directories (note that

				// we need to explicitly handle the root directory to ensure we do at least one layer of directory

				// walking by default).


====================
		return info.IsDir()

	}

}

// newParsedArgs returns an updated set of arguments which include the specified filename.

func newParsedArgs(original map[string]interface{}, newFilename string) map[string]interface{} {

	out := make(map[string]interface{})

	for k, v := range original {

		out[k] = v

	}

	out["--filename"] = newFilename

	return out

}

// Copyright (c) 2016 Tigera, Inc. All rights reserved.

// Licensed under the Apache License, Version 2.0 (the "License");

// you may not use this file except in compliance with the License.

// You may obtain a copy of the License at

//

//     http://www.apache.org/licenses/LICENSE-2.0

//

// Unless required by applicable law or agreed to in writing, software


====================
     --allow-version-mismatch           Allow client and cluster versions mismatch.

Description:

  Check the compatibility of this compute host to run a Calico node instance.

`

	// Replace all instances of BINARY_NAME with the name of the binary.

	name, _ := util.NameAndDescription()

	doc = strings.ReplaceAll(doc, "<BINARY_NAME>", name)

	parsedArgs, err := docopt.ParseArgs(doc, args, "")

	if err != nil {

		return fmt.Errorf("Invalid option: 'calicoctl %s'. Use flag '--help' to read about a specific subcommand.", strings.Join(args, " "))

	}

	if len(parsedArgs) == 0 {

		return nil

	}

	// Note: Intentionally not check version mismatch for this command

	if parsedArgs["--kernel-config"] != nil {

		overrideBootFile = parsedArgs["--kernel-config"].(string)

	}

	// Make sure the command is run with super user privileges

	enforceRoot()


====================
	doc = strings.ReplaceAll(doc, "<BINARY_NAME>", name)

	parsedArgs, err := docopt.ParseArgs(doc, args, "")

	if err != nil {

		return fmt.Errorf("Invalid option: 'calicoctl %s'. Use flag '--help' to read about a specific subcommand.", strings.Join(args, " "))

	}

	if len(parsedArgs) == 0 {

		return nil

	}

	// Note: Intentionally not check version mismatch for this command

	if parsedArgs["--kernel-config"] != nil {

		overrideBootFile = parsedArgs["--kernel-config"].(string)

	}

	// Make sure the command is run with super user privileges

	enforceRoot()

	systemOk := true

	fmt.Print("Checking kernel version...\n")

	err = checkKernelVersion()

	if err != nil {

		systemOk = false

	}


====================
	parsedArgs, err := docopt.ParseArgs(doc, args, "")

	if err != nil {

		return fmt.Errorf("Invalid option: 'calicoctl %s'. Use flag '--help' to read about a specific subcommand.", strings.Join(args, " "))

	}

	if len(parsedArgs) == 0 {

		return nil

	}

	// Note: Intentionally not check version mismatch for this command

	if parsedArgs["--kernel-config"] != nil {

		overrideBootFile = parsedArgs["--kernel-config"].(string)

	}

	// Make sure the command is run with super user privileges

	enforceRoot()

	systemOk := true

	fmt.Print("Checking kernel version...\n")

	err = checkKernelVersion()

	if err != nil {

		systemOk = false

	}

	fmt.Print("Checking kernel modules...\n")


====================
	// If any of the checks fail, print a message and exit

	if !systemOk {

		return fmt.Errorf("System doesn't meet one or more minimum systems requirements to run Calico")

	}

	fmt.Printf("System meets minimum system requirements to run Calico!\n")

	return nil

}

// checkKernelVersion checks for minimum required kernel version

func checkKernelVersion() error {

	kernelVersion, err := exec.Command("uname", "-r").Output()

	if err != nil {

		printResult("", "FAIL")

		fmt.Printf("Error executing command: %s\n", err)

		return err

	}

	// To strip the trailing `\n`

	kernelVersionStr := strings.TrimSpace(string(kernelVersion))

	// Goversion normalizes the versions and compares them returns `true` if

	// running version is >= minimum version

	if !goversion.CompareNormalized(kernelVersionStr, minKernelVersion, ">=") {


====================
		fmt.Printf("Minimum kernel version to run Calico is %s. Detected kernel version: %s", minKernelVersion, string(kernelVersion))

		return errors.New("Kernel version mismatch")

	}

	// Prints "OK" if current version is >= minimum required version

	printResult(kernelVersionStr, "OK")

	return nil

}

// checkKernelModules checks for all the required kernel modules in the system

func checkKernelModules() error {

	kernelVersion, err := exec.Command("uname", "-r").Output()

	if err != nil {

		fmt.Printf("Error executing command: %s\n", err)

		return err

	}

	// To strip the trailing `\n`

	kernelVersionStr := strings.TrimSpace(string(kernelVersion))

	// File path to Loadable kernel modules

	modulesLoadablePath := fmt.Sprintf("/lib/modules/%s/modules.dep", kernelVersionStr)

	// File path to Builtin kernel modules

	modulesBuiltinPath := fmt.Sprintf("/lib/modules/%s/modules.builtin", kernelVersionStr)


====================
  This command is used to start a calico/node container instance which provides

  Calico networking and network policy on your compute host.

`

	// Replace all instances of BINARY_NAME with the name of the binary.

	binaryName, _ := util.NameAndDescription()

	doc = strings.ReplaceAll(doc, "<BINARY_NAME>", binaryName)

	arguments, err := docopt.ParseArgs(doc, args, "")

	if err != nil {

		log.Info(err)

		return fmt.Errorf("Invalid option: 'calicoctl %s'. Use flag '--help' to read about a specific subcommand.", strings.Join(args, " "))

	}

	if len(arguments) == 0 {

		return nil

	}

	// Note: Intentionally not check version mismatch for this command

	// Extract all the parameters.

	ipv4 := argutils.ArgStringOrBlank(arguments, "--ip")

	ipv6 := argutils.ArgStringOrBlank(arguments, "--ip6")

	ipv4ADMethod := argutils.ArgStringOrBlank(arguments, "--ip-autodetection-method")

	ipv6ADMethod := argutils.ArgStringOrBlank(arguments, "--ip6-autodetection-method")


====================
	if err != nil {

		log.Info(err)

		return fmt.Errorf("Invalid option: 'calicoctl %s'. Use flag '--help' to read about a specific subcommand.", strings.Join(args, " "))

	}

	if len(arguments) == 0 {

		return nil

	}

	// Note: Intentionally not check version mismatch for this command

	// Extract all the parameters.

	ipv4 := argutils.ArgStringOrBlank(arguments, "--ip")

	ipv6 := argutils.ArgStringOrBlank(arguments, "--ip6")

	ipv4ADMethod := argutils.ArgStringOrBlank(arguments, "--ip-autodetection-method")

	ipv6ADMethod := argutils.ArgStringOrBlank(arguments, "--ip6-autodetection-method")

	logDir := argutils.ArgStringOrBlank(arguments, "--log-dir")

	asNumber := argutils.ArgStringOrBlank(arguments, "--as")

	img := argutils.ArgStringOrBlank(arguments, "--node-image")

	backend := argutils.ArgStringOrBlank(arguments, "--backend")

	dryrun := argutils.ArgBoolOrFalse(arguments, "--dryrun")

	name := argutils.ArgStringOrBlank(arguments, "--name")

	nopools := argutils.ArgBoolOrFalse(arguments, "--no-default-ippools")


====================
		log.Info(err)

		return fmt.Errorf("Invalid option: 'calicoctl %s'. Use flag '--help' to read about a specific subcommand.", strings.Join(args, " "))

	}

	if len(arguments) == 0 {

		return nil

	}

	// Note: Intentionally not check version mismatch for this command

	// Extract all the parameters.

	ipv4 := argutils.ArgStringOrBlank(arguments, "--ip")

	ipv6 := argutils.ArgStringOrBlank(arguments, "--ip6")

	ipv4ADMethod := argutils.ArgStringOrBlank(arguments, "--ip-autodetection-method")

	ipv6ADMethod := argutils.ArgStringOrBlank(arguments, "--ip6-autodetection-method")

	logDir := argutils.ArgStringOrBlank(arguments, "--log-dir")

	asNumber := argutils.ArgStringOrBlank(arguments, "--as")

	img := argutils.ArgStringOrBlank(arguments, "--node-image")

	backend := argutils.ArgStringOrBlank(arguments, "--backend")

	dryrun := argutils.ArgBoolOrFalse(arguments, "--dryrun")

	name := argutils.ArgStringOrBlank(arguments, "--name")

	nopools := argutils.ArgBoolOrFalse(arguments, "--no-default-ippools")

	config := argutils.ArgStringOrBlank(arguments, "--config")


====================
		return fmt.Errorf("Invalid option: 'calicoctl %s'. Use flag '--help' to read about a specific subcommand.", strings.Join(args, " "))

	}

	if len(arguments) == 0 {

		return nil

	}

	// Note: Intentionally not check version mismatch for this command

	// Extract all the parameters.

	ipv4 := argutils.ArgStringOrBlank(arguments, "--ip")

	ipv6 := argutils.ArgStringOrBlank(arguments, "--ip6")

	ipv4ADMethod := argutils.ArgStringOrBlank(arguments, "--ip-autodetection-method")

	ipv6ADMethod := argutils.ArgStringOrBlank(arguments, "--ip6-autodetection-method")

	logDir := argutils.ArgStringOrBlank(arguments, "--log-dir")

	asNumber := argutils.ArgStringOrBlank(arguments, "--as")

	img := argutils.ArgStringOrBlank(arguments, "--node-image")

	backend := argutils.ArgStringOrBlank(arguments, "--backend")

	dryrun := argutils.ArgBoolOrFalse(arguments, "--dryrun")

	name := argutils.ArgStringOrBlank(arguments, "--name")

	nopools := argutils.ArgBoolOrFalse(arguments, "--no-default-ippools")

	config := argutils.ArgStringOrBlank(arguments, "--config")

	felixConfig := argutils.ArgStringOrBlank(arguments, "--felix-config")


====================
	}

	if len(arguments) == 0 {

		return nil

	}

	// Note: Intentionally not check version mismatch for this command

	// Extract all the parameters.

	ipv4 := argutils.ArgStringOrBlank(arguments, "--ip")

	ipv6 := argutils.ArgStringOrBlank(arguments, "--ip6")

	ipv4ADMethod := argutils.ArgStringOrBlank(arguments, "--ip-autodetection-method")

	ipv6ADMethod := argutils.ArgStringOrBlank(arguments, "--ip6-autodetection-method")

	logDir := argutils.ArgStringOrBlank(arguments, "--log-dir")

	asNumber := argutils.ArgStringOrBlank(arguments, "--as")

	img := argutils.ArgStringOrBlank(arguments, "--node-image")

	backend := argutils.ArgStringOrBlank(arguments, "--backend")

	dryrun := argutils.ArgBoolOrFalse(arguments, "--dryrun")

	name := argutils.ArgStringOrBlank(arguments, "--name")

	nopools := argutils.ArgBoolOrFalse(arguments, "--no-default-ippools")

	config := argutils.ArgStringOrBlank(arguments, "--config")

	felixConfig := argutils.ArgStringOrBlank(arguments, "--felix-config")

	initSystem := argutils.ArgBoolOrFalse(arguments, "--init-system")


====================
	if len(arguments) == 0 {

		return nil

	}

	// Note: Intentionally not check version mismatch for this command

	// Extract all the parameters.

	ipv4 := argutils.ArgStringOrBlank(arguments, "--ip")

	ipv6 := argutils.ArgStringOrBlank(arguments, "--ip6")

	ipv4ADMethod := argutils.ArgStringOrBlank(arguments, "--ip-autodetection-method")

	ipv6ADMethod := argutils.ArgStringOrBlank(arguments, "--ip6-autodetection-method")

	logDir := argutils.ArgStringOrBlank(arguments, "--log-dir")

	asNumber := argutils.ArgStringOrBlank(arguments, "--as")

	img := argutils.ArgStringOrBlank(arguments, "--node-image")

	backend := argutils.ArgStringOrBlank(arguments, "--backend")

	dryrun := argutils.ArgBoolOrFalse(arguments, "--dryrun")

	name := argutils.ArgStringOrBlank(arguments, "--name")

	nopools := argutils.ArgBoolOrFalse(arguments, "--no-default-ippools")

	config := argutils.ArgStringOrBlank(arguments, "--config")

	felixConfig := argutils.ArgStringOrBlank(arguments, "--felix-config")

	initSystem := argutils.ArgBoolOrFalse(arguments, "--init-system")

	// Validate parameters.


====================
		return nil

	}

	// Note: Intentionally not check version mismatch for this command

	// Extract all the parameters.

	ipv4 := argutils.ArgStringOrBlank(arguments, "--ip")

	ipv6 := argutils.ArgStringOrBlank(arguments, "--ip6")

	ipv4ADMethod := argutils.ArgStringOrBlank(arguments, "--ip-autodetection-method")

	ipv6ADMethod := argutils.ArgStringOrBlank(arguments, "--ip6-autodetection-method")

	logDir := argutils.ArgStringOrBlank(arguments, "--log-dir")

	asNumber := argutils.ArgStringOrBlank(arguments, "--as")

	img := argutils.ArgStringOrBlank(arguments, "--node-image")

	backend := argutils.ArgStringOrBlank(arguments, "--backend")

	dryrun := argutils.ArgBoolOrFalse(arguments, "--dryrun")

	name := argutils.ArgStringOrBlank(arguments, "--name")

	nopools := argutils.ArgBoolOrFalse(arguments, "--no-default-ippools")

	config := argutils.ArgStringOrBlank(arguments, "--config")

	felixConfig := argutils.ArgStringOrBlank(arguments, "--felix-config")

	initSystem := argutils.ArgBoolOrFalse(arguments, "--init-system")

	// Validate parameters.

	if ipv4 != "" && ipv4 != "autodetect" {


====================
	}

	// Note: Intentionally not check version mismatch for this command

	// Extract all the parameters.

	ipv4 := argutils.ArgStringOrBlank(arguments, "--ip")

	ipv6 := argutils.ArgStringOrBlank(arguments, "--ip6")

	ipv4ADMethod := argutils.ArgStringOrBlank(arguments, "--ip-autodetection-method")

	ipv6ADMethod := argutils.ArgStringOrBlank(arguments, "--ip6-autodetection-method")

	logDir := argutils.ArgStringOrBlank(arguments, "--log-dir")

	asNumber := argutils.ArgStringOrBlank(arguments, "--as")

	img := argutils.ArgStringOrBlank(arguments, "--node-image")

	backend := argutils.ArgStringOrBlank(arguments, "--backend")

	dryrun := argutils.ArgBoolOrFalse(arguments, "--dryrun")

	name := argutils.ArgStringOrBlank(arguments, "--name")

	nopools := argutils.ArgBoolOrFalse(arguments, "--no-default-ippools")

	config := argutils.ArgStringOrBlank(arguments, "--config")

	felixConfig := argutils.ArgStringOrBlank(arguments, "--felix-config")

	initSystem := argutils.ArgBoolOrFalse(arguments, "--init-system")

	// Validate parameters.

	if ipv4 != "" && ipv4 != "autodetect" {

		ip := argutils.ValidateIP(ipv4)


====================
	// Note: Intentionally not check version mismatch for this command

	// Extract all the parameters.

	ipv4 := argutils.ArgStringOrBlank(arguments, "--ip")

	ipv6 := argutils.ArgStringOrBlank(arguments, "--ip6")

	ipv4ADMethod := argutils.ArgStringOrBlank(arguments, "--ip-autodetection-method")

	ipv6ADMethod := argutils.ArgStringOrBlank(arguments, "--ip6-autodetection-method")

	logDir := argutils.ArgStringOrBlank(arguments, "--log-dir")

	asNumber := argutils.ArgStringOrBlank(arguments, "--as")

	img := argutils.ArgStringOrBlank(arguments, "--node-image")

	backend := argutils.ArgStringOrBlank(arguments, "--backend")

	dryrun := argutils.ArgBoolOrFalse(arguments, "--dryrun")

	name := argutils.ArgStringOrBlank(arguments, "--name")

	nopools := argutils.ArgBoolOrFalse(arguments, "--no-default-ippools")

	config := argutils.ArgStringOrBlank(arguments, "--config")

	felixConfig := argutils.ArgStringOrBlank(arguments, "--felix-config")

	initSystem := argutils.ArgBoolOrFalse(arguments, "--init-system")

	// Validate parameters.

	if ipv4 != "" && ipv4 != "autodetect" {

		ip := argutils.ValidateIP(ipv4)

		if ip.Version() != 4 {


====================
	// Extract all the parameters.

	ipv4 := argutils.ArgStringOrBlank(arguments, "--ip")

	ipv6 := argutils.ArgStringOrBlank(arguments, "--ip6")

	ipv4ADMethod := argutils.ArgStringOrBlank(arguments, "--ip-autodetection-method")

	ipv6ADMethod := argutils.ArgStringOrBlank(arguments, "--ip6-autodetection-method")

	logDir := argutils.ArgStringOrBlank(arguments, "--log-dir")

	asNumber := argutils.ArgStringOrBlank(arguments, "--as")

	img := argutils.ArgStringOrBlank(arguments, "--node-image")

	backend := argutils.ArgStringOrBlank(arguments, "--backend")

	dryrun := argutils.ArgBoolOrFalse(arguments, "--dryrun")

	name := argutils.ArgStringOrBlank(arguments, "--name")

	nopools := argutils.ArgBoolOrFalse(arguments, "--no-default-ippools")

	config := argutils.ArgStringOrBlank(arguments, "--config")

	felixConfig := argutils.ArgStringOrBlank(arguments, "--felix-config")

	initSystem := argutils.ArgBoolOrFalse(arguments, "--init-system")

	// Validate parameters.

	if ipv4 != "" && ipv4 != "autodetect" {

		ip := argutils.ValidateIP(ipv4)

		if ip.Version() != 4 {

			return fmt.Errorf("Error executing command: --ip is wrong IP version")


====================
	ipv4 := argutils.ArgStringOrBlank(arguments, "--ip")

	ipv6 := argutils.ArgStringOrBlank(arguments, "--ip6")

	ipv4ADMethod := argutils.ArgStringOrBlank(arguments, "--ip-autodetection-method")

	ipv6ADMethod := argutils.ArgStringOrBlank(arguments, "--ip6-autodetection-method")

	logDir := argutils.ArgStringOrBlank(arguments, "--log-dir")

	asNumber := argutils.ArgStringOrBlank(arguments, "--as")

	img := argutils.ArgStringOrBlank(arguments, "--node-image")

	backend := argutils.ArgStringOrBlank(arguments, "--backend")

	dryrun := argutils.ArgBoolOrFalse(arguments, "--dryrun")

	name := argutils.ArgStringOrBlank(arguments, "--name")

	nopools := argutils.ArgBoolOrFalse(arguments, "--no-default-ippools")

	config := argutils.ArgStringOrBlank(arguments, "--config")

	felixConfig := argutils.ArgStringOrBlank(arguments, "--felix-config")

	initSystem := argutils.ArgBoolOrFalse(arguments, "--init-system")

	// Validate parameters.

	if ipv4 != "" && ipv4 != "autodetect" {

		ip := argutils.ValidateIP(ipv4)

		if ip.Version() != 4 {

			return fmt.Errorf("Error executing command: --ip is wrong IP version")

		}


====================
	ipv6 := argutils.ArgStringOrBlank(arguments, "--ip6")

	ipv4ADMethod := argutils.ArgStringOrBlank(arguments, "--ip-autodetection-method")

	ipv6ADMethod := argutils.ArgStringOrBlank(arguments, "--ip6-autodetection-method")

	logDir := argutils.ArgStringOrBlank(arguments, "--log-dir")

	asNumber := argutils.ArgStringOrBlank(arguments, "--as")

	img := argutils.ArgStringOrBlank(arguments, "--node-image")

	backend := argutils.ArgStringOrBlank(arguments, "--backend")

	dryrun := argutils.ArgBoolOrFalse(arguments, "--dryrun")

	name := argutils.ArgStringOrBlank(arguments, "--name")

	nopools := argutils.ArgBoolOrFalse(arguments, "--no-default-ippools")

	config := argutils.ArgStringOrBlank(arguments, "--config")

	felixConfig := argutils.ArgStringOrBlank(arguments, "--felix-config")

	initSystem := argutils.ArgBoolOrFalse(arguments, "--init-system")

	// Validate parameters.

	if ipv4 != "" && ipv4 != "autodetect" {

		ip := argutils.ValidateIP(ipv4)

		if ip.Version() != 4 {

			return fmt.Errorf("Error executing command: --ip is wrong IP version")

		}

	}


====================
	ipv4ADMethod := argutils.ArgStringOrBlank(arguments, "--ip-autodetection-method")

	ipv6ADMethod := argutils.ArgStringOrBlank(arguments, "--ip6-autodetection-method")

	logDir := argutils.ArgStringOrBlank(arguments, "--log-dir")

	asNumber := argutils.ArgStringOrBlank(arguments, "--as")

	img := argutils.ArgStringOrBlank(arguments, "--node-image")

	backend := argutils.ArgStringOrBlank(arguments, "--backend")

	dryrun := argutils.ArgBoolOrFalse(arguments, "--dryrun")

	name := argutils.ArgStringOrBlank(arguments, "--name")

	nopools := argutils.ArgBoolOrFalse(arguments, "--no-default-ippools")

	config := argutils.ArgStringOrBlank(arguments, "--config")

	felixConfig := argutils.ArgStringOrBlank(arguments, "--felix-config")

	initSystem := argutils.ArgBoolOrFalse(arguments, "--init-system")

	// Validate parameters.

	if ipv4 != "" && ipv4 != "autodetect" {

		ip := argutils.ValidateIP(ipv4)

		if ip.Version() != 4 {

			return fmt.Errorf("Error executing command: --ip is wrong IP version")

		}

	}

	if ipv6 != "" && ipv6 != "autodetect" {


====================
	ipv6ADMethod := argutils.ArgStringOrBlank(arguments, "--ip6-autodetection-method")

	logDir := argutils.ArgStringOrBlank(arguments, "--log-dir")

	asNumber := argutils.ArgStringOrBlank(arguments, "--as")

	img := argutils.ArgStringOrBlank(arguments, "--node-image")

	backend := argutils.ArgStringOrBlank(arguments, "--backend")

	dryrun := argutils.ArgBoolOrFalse(arguments, "--dryrun")

	name := argutils.ArgStringOrBlank(arguments, "--name")

	nopools := argutils.ArgBoolOrFalse(arguments, "--no-default-ippools")

	config := argutils.ArgStringOrBlank(arguments, "--config")

	felixConfig := argutils.ArgStringOrBlank(arguments, "--felix-config")

	initSystem := argutils.ArgBoolOrFalse(arguments, "--init-system")

	// Validate parameters.

	if ipv4 != "" && ipv4 != "autodetect" {

		ip := argutils.ValidateIP(ipv4)

		if ip.Version() != 4 {

			return fmt.Errorf("Error executing command: --ip is wrong IP version")

		}

	}

	if ipv6 != "" && ipv6 != "autodetect" {

		ip := argutils.ValidateIP(ipv6)


====================
	logDir := argutils.ArgStringOrBlank(arguments, "--log-dir")

	asNumber := argutils.ArgStringOrBlank(arguments, "--as")

	img := argutils.ArgStringOrBlank(arguments, "--node-image")

	backend := argutils.ArgStringOrBlank(arguments, "--backend")

	dryrun := argutils.ArgBoolOrFalse(arguments, "--dryrun")

	name := argutils.ArgStringOrBlank(arguments, "--name")

	nopools := argutils.ArgBoolOrFalse(arguments, "--no-default-ippools")

	config := argutils.ArgStringOrBlank(arguments, "--config")

	felixConfig := argutils.ArgStringOrBlank(arguments, "--felix-config")

	initSystem := argutils.ArgBoolOrFalse(arguments, "--init-system")

	// Validate parameters.

	if ipv4 != "" && ipv4 != "autodetect" {

		ip := argutils.ValidateIP(ipv4)

		if ip.Version() != 4 {

			return fmt.Errorf("Error executing command: --ip is wrong IP version")

		}

	}

	if ipv6 != "" && ipv6 != "autodetect" {

		ip := argutils.ValidateIP(ipv6)

		if ip.Version() != 6 {


====================
		envs["ETCD_CERT_FILE"] = ETCD_CERT_NODE_FILE

		vols = append(vols, vol{hostPath: etcdcfg.EtcdCertFile, containerPath: ETCD_CERT_NODE_FILE})

	}

	// Create the Docker command to execute (or display).  Start with the

	// fixed parts.  If this is not for an init system, we'll include the

	// detach flag (to prevent the command blocking), and use Dockers built

	// in restart mechanism.  If this is for an init-system we want the

	// command to remain attached and for Docker to remove the dead

	// container so that it can be restarted by the init system.

	cmd := []string{"docker", "run", "--net=host", "--privileged",

		"--name=calico-node"}

	if initSystem {

		cmd = append(cmd, "--rm")

	} else {

		cmd = append(cmd, "-d", "--restart=always")

	}

	// Add the environment variable pass-through.

	for k, v := range envs {

		cmd = append(cmd, "-e", fmt.Sprintf("%s=%s", k, v))

	}


====================
		vols = append(vols, vol{hostPath: etcdcfg.EtcdCertFile, containerPath: ETCD_CERT_NODE_FILE})

	}

	// Create the Docker command to execute (or display).  Start with the

	// fixed parts.  If this is not for an init system, we'll include the

	// detach flag (to prevent the command blocking), and use Dockers built

	// in restart mechanism.  If this is for an init-system we want the

	// command to remain attached and for Docker to remove the dead

	// container so that it can be restarted by the init system.

	cmd := []string{"docker", "run", "--net=host", "--privileged",

		"--name=calico-node"}

	if initSystem {

		cmd = append(cmd, "--rm")

	} else {

		cmd = append(cmd, "-d", "--restart=always")

	}

	// Add the environment variable pass-through.

	for k, v := range envs {

		cmd = append(cmd, "-e", fmt.Sprintf("%s=%s", k, v))

	}

	// Add the volume mounts.


====================
	// Create the Docker command to execute (or display).  Start with the

	// fixed parts.  If this is not for an init system, we'll include the

	// detach flag (to prevent the command blocking), and use Dockers built

	// in restart mechanism.  If this is for an init-system we want the

	// command to remain attached and for Docker to remove the dead

	// container so that it can be restarted by the init system.

	cmd := []string{"docker", "run", "--net=host", "--privileged",

		"--name=calico-node"}

	if initSystem {

		cmd = append(cmd, "--rm")

	} else {

		cmd = append(cmd, "-d", "--restart=always")

	}

	// Add the environment variable pass-through.

	for k, v := range envs {

		cmd = append(cmd, "-e", fmt.Sprintf("%s=%s", k, v))

	}

	// Add the volume mounts.

	for _, v := range vols {

		cmd = append(cmd, "-v", fmt.Sprintf("%s:%s", v.hostPath, v.containerPath))


====================
	// detach flag (to prevent the command blocking), and use Dockers built

	// in restart mechanism.  If this is for an init-system we want the

	// command to remain attached and for Docker to remove the dead

	// container so that it can be restarted by the init system.

	cmd := []string{"docker", "run", "--net=host", "--privileged",

		"--name=calico-node"}

	if initSystem {

		cmd = append(cmd, "--rm")

	} else {

		cmd = append(cmd, "-d", "--restart=always")

	}

	// Add the environment variable pass-through.

	for k, v := range envs {

		cmd = append(cmd, "-e", fmt.Sprintf("%s=%s", k, v))

	}

	// Add the volume mounts.

	for _, v := range vols {

		cmd = append(cmd, "-v", fmt.Sprintf("%s:%s", v.hostPath, v.containerPath))

	}

	// Add the container image name


====================
	cmd := []string{"docker", "run", "--net=host", "--privileged",

		"--name=calico-node"}

	if initSystem {

		cmd = append(cmd, "--rm")

	} else {

		cmd = append(cmd, "-d", "--restart=always")

	}

	// Add the environment variable pass-through.

	for k, v := range envs {

		cmd = append(cmd, "-e", fmt.Sprintf("%s=%s", k, v))

	}

	// Add the volume mounts.

	for _, v := range vols {

		cmd = append(cmd, "-v", fmt.Sprintf("%s:%s", v.hostPath, v.containerPath))

	}

	// Add the container image name

	cmd = append(cmd, img)

	if dryrun {

		fmt.Println("Use the following command to start the calico/node container:")

		fmt.Printf("\n%s\n\n", strings.Join(cmd, " "))


====================
	} else {

		cmd = append(cmd, "-d", "--restart=always")

	}

	// Add the environment variable pass-through.

	for k, v := range envs {

		cmd = append(cmd, "-e", fmt.Sprintf("%s=%s", k, v))

	}

	// Add the volume mounts.

	for _, v := range vols {

		cmd = append(cmd, "-v", fmt.Sprintf("%s:%s", v.hostPath, v.containerPath))

	}

	// Add the container image name

	cmd = append(cmd, img)

	if dryrun {

		fmt.Println("Use the following command to start the calico/node container:")

		fmt.Printf("\n%s\n\n", strings.Join(cmd, " "))

		if !initSystem {

			fmt.Println("If you are running calico/node in an init system, use the --init-system flag")

			fmt.Println("to display the appropriate start and stop commands.")

		} else {


====================
		loadModules()

		if err := setupIPForwarding(); err != nil {

			return err

		}

		setNFConntrackMax()

	}

	// Make sure the calico-node is not already running before we attempt

	// to start the node.

	fmt.Println("Removing old calico-node container (if running).")

	err = exec.Command("docker", "rm", "-f", "calico-node").Run()

	if err != nil {

		log.WithError(err).Debug("Unable to remove calico-node container (ok if container was not running)")

	}

	// Run the docker command.

	fmt.Println("Running the following command to start calico-node:")

	fmt.Printf("\n%s\n\n", strings.Join(cmd, " "))

	fmt.Println("Image may take a short time to download if it is not available locally.")

	// Now execute the actual Docker run command and check for the

	// unable to find image message.

	runCmd := exec.Command(cmd[0], cmd[1:]...)


====================
	if output, err := runCmd.CombinedOutput(); err != nil {

		errStr := fmt.Sprintf("Error executing command: %v\n", err)

		for _, line := range strings.Split(string(output), "/n") {

			errStr += fmt.Sprintf(" | %s/n", line)

		}

		return fmt.Errorf(errStr)

	}

	// Create the command to follow the docker logs for the calico/node

	fmt.Print("Container started, checking progress logs.\n\n")

	logCmd := exec.Command("docker", "logs", "--follow", "calico-node")

	// Get the stdout pipe

	outPipe, err := logCmd.StdoutPipe()

	if err != nil {

		return fmt.Errorf("Error executing command:  unable to check calico/node logs: %v", err)

	}

	outScanner := bufio.NewScanner(outPipe)

	// Start following the logs.

	err = logCmd.Start()

	if err != nil {

		return fmt.Errorf("Error executing command:  unable to check calico/node logs: %v", err)


====================
	}

	return nil

}

// runningInContainer returns whether we are running calicoctl within a container.

func runningInContainer() bool {

	v := os.Getenv("CALICO_CTL_CONTAINER")

	return v != ""

}

func loadModules() {

	cmd := []string{"modprobe", "-a", "xt_set", "ip6_tables"}

	fmt.Printf("Running command to load modules: %s\n", strings.Join(cmd, " "))

	err := exec.Command(cmd[0], cmd[1:]...).Run()

	if err != nil {

		log.Warning(err)

	}

}

func setupIPForwarding() error {

	fmt.Println("Enabling IPv4 forwarding")

	err := os.WriteFile("/proc/sys/net/ipv4/ip_forward",

		[]byte("1"), 0)


====================
  your Calico network.

  This command must be run on the specific Calico node that you are gathering

  diagnostics for.

`

	// Replace all instances of BINARY_NAME with the name of the binary.

	name, _ := util.NameAndDescription()

	doc = strings.ReplaceAll(doc, "<BINARY_NAME>", name)

	arguments, err := docopt.ParseArgs(doc, args, "")

	if err != nil {

		return fmt.Errorf("Invalid option: 'calicoctl %s'. Use flag '--help' to read about a specific subcommand.", strings.Join(args, " "))

	}

	if len(arguments) == 0 {

		return nil

	}

	// Note: Intentionally not check version mismatch for this command

	return runDiags(arguments["--log-dir"].(string))

}

// runDiags takes logDir and runs a sequence of commands to collect diagnostics

func runDiags(logDir string) error {

	// Note: in for the cmd field in this struct, it  can't handle args quoted with space in it


====================
	doc = strings.ReplaceAll(doc, "<BINARY_NAME>", name)

	arguments, err := docopt.ParseArgs(doc, args, "")

	if err != nil {

		return fmt.Errorf("Invalid option: 'calicoctl %s'. Use flag '--help' to read about a specific subcommand.", strings.Join(args, " "))

	}

	if len(arguments) == 0 {

		return nil

	}

	// Note: Intentionally not check version mismatch for this command

	return runDiags(arguments["--log-dir"].(string))

}

// runDiags takes logDir and runs a sequence of commands to collect diagnostics

func runDiags(logDir string) error {

	// Note: in for the cmd field in this struct, it  can't handle args quoted with space in it

	// For example, you can't add cmd "do this", since after the `strings.Fields` it will become `"do` and `this"`

	cmds := []diagCmd{

		{"", "date", "date"},

		{"", "hostname", "hostname"},

		{"Dumping netstat", "netstat -a -n", "netstat"},

		{"Dumping routes (IPv4)", "ip -4 route", "ipv4_route"},


====================
		{"Dumping ipsets", "ipset list", "ipsets"},

		{"Dumping ipsets (container)", "docker run --rm --privileged --net=host calico/node ipset list", "ipset_container"},

		{"Copying journal for calico-node.service", "journalctl -u calico-node.service --no-pager", "journalctl_calico_node"},

		{"Dumping felix stats", "pkill -SIGUSR1 felix", ""},

	}

	// Make sure the command is run with super user privileges

	enforceRoot()

	fmt.Println("Collecting diagnostics")

	// Create a temp directory in /tmp

	tmpDir, err := os.MkdirTemp("", "calico")

	if err != nil {

		return fmt.Errorf("Error creating temp directory to dump logs: %v", err)

	}

	fmt.Println("Using temp dir:", tmpDir)

	err = os.Chdir(tmpDir)

	if err != nil {

		return fmt.Errorf("Error changing directory to temp directory to dump logs: %v", err)

	}

	err = os.Mkdir("diagnostics", os.ModeDir)

	if err != nil {


====================
		return fmt.Errorf("Error creating diagnostics directory: %v\n", err)

	}

	diagsTmpDir := filepath.Join(tmpDir, "diagnostics")

	for _, v := range cmds {

		err = writeDiags(v, diagsTmpDir)

		// sometimes socket information is not collected as netstat tool

		// is obsolete and removed in Ubuntu and other distros. so when

		// "netstat -a -n " fails, we should use "ss -a -n" instead of it

		if err != nil && v.cmd == "netstat -a -n" {

			parts := []string{"ss", "-a", "-n"}

			content, err := exec.Command(parts[0], parts[1], parts[2]).CombinedOutput()

			if err != nil {

				fmt.Printf("Failed to run command: %s\nError: %s\n", strings.Join(parts, " "), string(content))

			}

			fp := filepath.Join(diagsTmpDir, parts[0])

			if err := os.WriteFile(fp, content, 0666); err != nil {

				log.Errorf("Error writing diags to file: %s\n", err)

			}

		}

	}


====================
	err = exec.Command("tar", "-zcvf", tarFile, "diagnostics").Run()

	if err != nil {

		fmt.Printf("Error compressing the diagnostics: %v\n", err)

	}

	tarFilePath := filepath.Join(tmpDir, tarFile)

	fmt.Printf("\nDiags saved to %s\n", tarFilePath)

	fmt.Println("If required, you can upload the diagnostics bundle to a file sharing service.")

	return nil

}

// getNodeContainerLogs will attempt to grab logs for any "calico" named containers for hosted installs.

func getNodeContainerLogs(logDir string) {

	err := os.Mkdir(logDir, os.ModeDir)

	if err != nil {

		fmt.Printf("Error creating log directory: %v\n", err)

		return

	}

	// Get a list of Calico containers running on this Node.

	result, err := exec.Command("docker", "ps", "-a", "--filter", "name=calico", "--format", "{{.Names}}: {{.CreatedAt}}").CombinedOutput()

	if err != nil {

		fmt.Printf("Could not run docker command: %s\n", string(result))


====================
}

// getNodeContainerLogs will attempt to grab logs for any "calico" named containers for hosted installs.

func getNodeContainerLogs(logDir string) {

	err := os.Mkdir(logDir, os.ModeDir)

	if err != nil {

		fmt.Printf("Error creating log directory: %v\n", err)

		return

	}

	// Get a list of Calico containers running on this Node.

	result, err := exec.Command("docker", "ps", "-a", "--filter", "name=calico", "--format", "{{.Names}}: {{.CreatedAt}}").CombinedOutput()

	if err != nil {

		fmt.Printf("Could not run docker command: %s\n", string(result))

		return

	}

	// No Calico containers found.

	if string(result) == "" {

		log.Debug("Did not find any Calico containers")

		return

	}

	// Remove any containers that have "k8s_POD" in them.


====================
Description:

  Check the status of the Calico node instance.  This includes the status and

  uptime of the node instance, and BGP peering states.

`

	// Replace all instances of BINARY_NAME with the name of the binary.

	name, _ := util.NameAndDescription()

	doc = strings.ReplaceAll(doc, "<BINARY_NAME>", name)

	parsedArgs, err := docopt.ParseArgs(doc, args, "")

	if err != nil {

		return fmt.Errorf("Invalid option: 'calicoctl %s'. Use flag '--help' to read about a specific subcommand.", strings.Join(args, " "))

	}

	if len(parsedArgs) == 0 {

		return nil

	}

	// Note: Intentionally not check version mismatch for this command

	// Must run this command as root to be able to connect to BIRD sockets

	enforceRoot()

	// Go through running processes and check if `calico-felix` processes is not running

	processes, err := process.Processes()

	if err != nil {


====================
	// Note: Intentionally not check version mismatch for this command

	// Must run this command as root to be able to connect to BIRD sockets

	enforceRoot()

	// Go through running processes and check if `calico-felix` processes is not running

	processes, err := process.Processes()

	if err != nil {

		fmt.Println(err)

	}

	// For older versions of calico/node, the process was called `calico-felix`. Newer ones use `calico-node -felix`.

	if !psContains([]string{"calico-felix"}, processes) && !psContains([]string{"calico-node", "-felix"}, processes) {

		// Return and print message if calico-node is not running

		return fmt.Errorf("Calico process is not running.")

	}

	fmt.Printf("Calico process is running.\n")

	if psContains([]string{"bird"}, processes) || psContains([]string{"bird6"}, processes) {

		// Check if birdv4 process is running, print the BGP peer table if it is, else print a warning

		if psContains([]string{"bird"}, processes) {

			if err := printBIRDPeers("4"); err != nil {

				return err

			}


====================
			return nil, err

		}

	}

	log.Infof("Unpacked: %+v", unpacked)

	return unpacked, nil

}

// Create the Resource from the specified file f.

//   - The file format may be JSON or YAML encoding of either a single resource or list of

//     resources as defined by the API objects in /api.

//   - A filename of "-" means "Read from stdin".

//

// The returned Resource will either be a single Resource or a List containing zero or more

// Resources.  If the file does not contain any valid Resources this function returns an error.

func CreateResourcesFromFile(f string) ([]unversioned.Resource, error) {

	// Load the bytes from file or from stdin.

	var reader io.Reader

	var err error

	if f == "-" {

		reader = os.Stdin

	} else {


====================
//     resources as defined by the API objects in /api.

//   - A filename of "-" means "Read from stdin".

//

// The returned Resource will either be a single Resource or a List containing zero or more

// Resources.  If the file does not contain any valid Resources this function returns an error.

func CreateResourcesFromFile(f string) ([]unversioned.Resource, error) {

	// Load the bytes from file or from stdin.

	var reader io.Reader

	var err error

	if f == "-" {

		reader = os.Stdin

	} else {

		reader, err = os.Open(f)

	}

	if err != nil {

		return nil, err

	}

	var resources []unversioned.Resource

	separator := yamlsep.NewYAMLDocumentSeparator(reader)

	for {


====================
		"bird=felix,e..."),

	Entry("map with non string", map[string]int{"a": 1}, ",", 0, "a=1"),

	Entry("map with non string", map[string]int{"a": -1}, ",", 0, "a=-1"),

	Entry("map with non string", map[int]int{123: 1}, ",", 0, "123=1"),

	Entry("map with non string, truncated", map[int]int{123: 4567}, ",", 3, "..."),

	Entry("nil slice", nilSlice, ",", 0, ""),

	Entry("empty slice", []int{}, ",", 0, ""),

	Entry("slice with one value", []int{1}, ",", 0, "1"),

	Entry("slice with multiple value", []string{"one", "two", "three", "four"}, ",", 0, "one,two,three,four"),

	Entry("slice with multiple value different separator", []string{"one", "two", "three", "four"}, "-", 0, "one-two-three-four"),

	Entry("slice with multiple value, truncate", []string{"otorhinolaryngological", "psychophysicotherapeutics", "hepaticocholangiogastrostomy"}, ",", 10,

		"otorhin..."),

	Entry("slice truncate", []int{12345, 67890}, ",", 6, "123..."),

	Entry("slice truncate", []int{1234567}, ",", 6, "123..."),

	Entry("slice no truncate", []int{123456}, ",", 6, "123456"),

	Entry("string", "HelloWorld", ",", 0, "HelloWorld"),

)

// Copyright (c) 2021 Tigera, Inc. All rights reserved.

// Licensed under the Apache License, Version 2.0 (the "License");

// you may not use this file except in compliance with the License.


====================
		}

		return fmt.Errorf("Unable to get Cluster Information to verify version mismatch: %w\nUse --allow-version-mismatch to override.\n", err)

	}

	clusterv := ci.Spec.CalicoVersion

	if clusterv == "" {

		// CalicoVersion field not specified in the cluster, so skip check.

		log.Infof("Skip version mismatch checking due to CalicoVersion not being set")

		return nil

	}

	clusterv = strings.Split(strings.TrimPrefix(clusterv, "v"), "-")[0]

	clientv := strings.Split(strings.TrimPrefix(VERSION, "v"), "-")[0]

	if clusterv != clientv {

		return fmt.Errorf("Version mismatch.\nClient Version:   %s\nCluster Version:  %s\nUse --allow-version-mismatch to override.\n", VERSION, clusterv)

	}

	return nil

}

// Copyright (c) 2016-2018 Tigera, Inc. All rights reserved.

// Licensed under the Apache License, Version 2.0 (the "License");

// you may not use this file except in compliance with the License.

// You may obtain a copy of the License at


====================
		return fmt.Errorf("Unable to get Cluster Information to verify version mismatch: %w\nUse --allow-version-mismatch to override.\n", err)

	}

	clusterv := ci.Spec.CalicoVersion

	if clusterv == "" {

		// CalicoVersion field not specified in the cluster, so skip check.

		log.Infof("Skip version mismatch checking due to CalicoVersion not being set")

		return nil

	}

	clusterv = strings.Split(strings.TrimPrefix(clusterv, "v"), "-")[0]

	clientv := strings.Split(strings.TrimPrefix(VERSION, "v"), "-")[0]

	if clusterv != clientv {

		return fmt.Errorf("Version mismatch.\nClient Version:   %s\nCluster Version:  %s\nUse --allow-version-mismatch to override.\n", VERSION, clusterv)

	}

	return nil

}

// Copyright (c) 2016-2018 Tigera, Inc. All rights reserved.

// Licensed under the Apache License, Version 2.0 (the "License");

// you may not use this file except in compliance with the License.

// You may obtain a copy of the License at

//


====================
//   - Load resources from file (or if not specified determine the resource from

//     the command line options).

//   - Convert the loaded resources into a list of resources (easier to handle)

//   - Process each resource individually, fanning out to the appropriate methods on

//     the client interface, collate results and exit on the first error.

func ExecuteConfigCommand(args map[string]interface{}, action action) CommandResults {

	var resources []resourcemgr.ResourceObject

	singleKind := false

	log.Info("Executing config command")

	err := CheckVersionMismatch(args["--config"], args["--allow-version-mismatch"])

	if err != nil {

		return CommandResults{Err: err}

	}

	errorOnEmpty := !argutils.ArgBoolOrFalse(args, "--skip-empty")

	if filename := args["--filename"]; filename != nil {

		// Filename is specified.  Use the file iterator to handle the fact that this may be a directory rather than a

		// single file. For each file load the resources from the file and convert to a single slice of resources for

		// easier handling.

		err := file.Iter(args, func(modifiedArgs map[string]interface{}) error {

			modifiedFilename := modifiedArgs["--filename"].(string)


====================
//     the client interface, collate results and exit on the first error.

func ExecuteConfigCommand(args map[string]interface{}, action action) CommandResults {

	var resources []resourcemgr.ResourceObject

	singleKind := false

	log.Info("Executing config command")

	err := CheckVersionMismatch(args["--config"], args["--allow-version-mismatch"])

	if err != nil {

		return CommandResults{Err: err}

	}

	errorOnEmpty := !argutils.ArgBoolOrFalse(args, "--skip-empty")

	if filename := args["--filename"]; filename != nil {

		// Filename is specified.  Use the file iterator to handle the fact that this may be a directory rather than a

		// single file. For each file load the resources from the file and convert to a single slice of resources for

		// easier handling.

		err := file.Iter(args, func(modifiedArgs map[string]interface{}) error {

			modifiedFilename := modifiedArgs["--filename"].(string)

			r, err := resourcemgr.CreateResourcesFromFile(modifiedFilename)

			if err != nil {

				return fileError{err}

			}


====================
func ExecuteConfigCommand(args map[string]interface{}, action action) CommandResults {

	var resources []resourcemgr.ResourceObject

	singleKind := false

	log.Info("Executing config command")

	err := CheckVersionMismatch(args["--config"], args["--allow-version-mismatch"])

	if err != nil {

		return CommandResults{Err: err}

	}

	errorOnEmpty := !argutils.ArgBoolOrFalse(args, "--skip-empty")

	if filename := args["--filename"]; filename != nil {

		// Filename is specified.  Use the file iterator to handle the fact that this may be a directory rather than a

		// single file. For each file load the resources from the file and convert to a single slice of resources for

		// easier handling.

		err := file.Iter(args, func(modifiedArgs map[string]interface{}) error {

			modifiedFilename := modifiedArgs["--filename"].(string)

			r, err := resourcemgr.CreateResourcesFromFile(modifiedFilename)

			if err != nil {

				return fileError{err}

			}

			converted, err := convertToSliceOfResources(r)


====================
	if err != nil {

		return CommandResults{Err: err}

	}

	errorOnEmpty := !argutils.ArgBoolOrFalse(args, "--skip-empty")

	if filename := args["--filename"]; filename != nil {

		// Filename is specified.  Use the file iterator to handle the fact that this may be a directory rather than a

		// single file. For each file load the resources from the file and convert to a single slice of resources for

		// easier handling.

		err := file.Iter(args, func(modifiedArgs map[string]interface{}) error {

			modifiedFilename := modifiedArgs["--filename"].(string)

			r, err := resourcemgr.CreateResourcesFromFile(modifiedFilename)

			if err != nil {

				return fileError{err}

			}

			converted, err := convertToSliceOfResources(r)

			if err != nil {

				return fileError{err}

			}

			if len(converted) == 0 && errorOnEmpty {

				// We should fail on empty files.


====================
			log.Debugf("Resource: %s", v.GetObjectKind().GroupVersionKind().String())

		}

		d, err := yaml.Marshal(resources)

		if err != nil {

			return CommandResults{Err: err}

		}

		log.Debugf("Data: %s", string(d))

	}

	// Load the client config and connect.

	cf := args["--config"].(string)

	cclient, err := clientmgr.NewClient(cf)

	if err != nil {

		fmt.Printf("Failed to create Calico API client: %s\n", err)

		os.Exit(1)

	}

	log.Infof("Client: %v", cclient)

	// Initialise the command results with the number of resources and the name of the

	// kind of resource (if only dealing with a single resource).

	results := CommandResults{Client: cclient}

	var kind string


====================
		kind = r.GetObjectKind().GroupVersionKind().Kind

		count[kind] = count[kind] + 1

		results.NumResources = results.NumResources + 1

	}

	if len(count) == 1 || singleKind {

		results.SingleKind = kind

	}

	// Now execute the command on each resource in order, exiting as soon as we hit an

	// error.

	export := argutils.ArgBoolOrFalse(args, "--export")

	nameSpecified := false

	emptyName := false

	switch a := args["<NAME>"].(type) {

	case string:

		nameSpecified = len(a) > 0

		_, ok := args["<NAME>"]

		emptyName = !ok || !nameSpecified

	case []string:

		nameSpecified = len(a) > 0

		for _, v := range a {


====================
		if err != nil {

			switch action {

			case ActionApply, ActionCreate, ActionDelete, ActionGetOrList:

				results.ResErrs = append(results.ResErrs, err)

				continue

			default:

				results.Err = err

			}

		}

		// Remove the cluster specific metadata if the "--export" flag is specified

		// Skip removing cluster specific metadata if this is is called as a "list"

		// operation (no specific name is specified).

		if export && nameSpecified {

			for i := range res {

				rom := res[i].(v1.ObjectMetaAccessor).GetObjectMeta()

				rom.SetNamespace("")

				rom.SetUID("")

				rom.SetResourceVersion("")

				rom.SetCreationTimestamp(v1.Time{})

				rom.SetDeletionTimestamp(nil)


====================
	case ActionCreate:

		resOut, err = rm.Create(ctx, client, resource)

	case ActionUpdate:

		resOut, err = rm.Update(ctx, client, resource)

	case ActionDelete:

		resOut, err = rm.Delete(ctx, client, resource)

	case ActionGetOrList:

		resOut, err = rm.GetOrList(ctx, client, resource)

	case ActionPatch:

		patch := args["--patch"].(string)

		resOut, err = rm.Patch(ctx, client, resource, patch)

	}

	// Skip over some errors depending on command line options.

	if err != nil {

		skip := false

		switch err.(type) {

		case calicoErrors.ErrorResourceAlreadyExists:

			skip = argutils.ArgBoolOrFalse(args, "--skip-exists")

		case calicoErrors.ErrorResourceDoesNotExist:

			skip = argutils.ArgBoolOrFalse(args, "--skip-not-exists")


====================
	case ActionPatch:

		patch := args["--patch"].(string)

		resOut, err = rm.Patch(ctx, client, resource, patch)

	}

	// Skip over some errors depending on command line options.

	if err != nil {

		skip := false

		switch err.(type) {

		case calicoErrors.ErrorResourceAlreadyExists:

			skip = argutils.ArgBoolOrFalse(args, "--skip-exists")

		case calicoErrors.ErrorResourceDoesNotExist:

			skip = argutils.ArgBoolOrFalse(args, "--skip-not-exists")

		}

		if skip {

			resOut = resource

			err = nil

		}

	}

	return []runtime.Object{resOut}, err

}


====================
		resOut, err = rm.Patch(ctx, client, resource, patch)

	}

	// Skip over some errors depending on command line options.

	if err != nil {

		skip := false

		switch err.(type) {

		case calicoErrors.ErrorResourceAlreadyExists:

			skip = argutils.ArgBoolOrFalse(args, "--skip-exists")

		case calicoErrors.ErrorResourceDoesNotExist:

			skip = argutils.ArgBoolOrFalse(args, "--skip-not-exists")

		}

		if skip {

			resOut = resource

			err = nil

		}

	}

	return []runtime.Object{resOut}, err

}

// handleNamespace fills in the namespace information in the resource (if required),

// and validates the namespace depending on whether or not a namespace should be


====================
			err = nil

		}

	}

	return []runtime.Object{resOut}, err

}

// handleNamespace fills in the namespace information in the resource (if required),

// and validates the namespace depending on whether or not a namespace should be

// provided based on the resource kind.

func handleNamespace(resource resourcemgr.ResourceObject, rm resourcemgr.ResourceManager, args map[string]interface{}) error {

	allNs := argutils.ArgBoolOrFalse(args, "--all-namespaces")

	cliNs := argutils.ArgStringOrBlank(args, "--namespace")

	resNs := resource.GetObjectMeta().GetNamespace()

	if rm.IsNamespaced() {

		switch {

		case allNs && cliNs != "":

			// Check if --namespace and --all-namespaces flags are used together.

			return fmt.Errorf("cannot use both --namespace and --all-namespaces flags at the same time")

		case resNs == "" && cliNs != "":

			// If resource doesn't have a namespace specified

			// but it's passed in through the -n flag then use that one.


====================
		}

	}

	return []runtime.Object{resOut}, err

}

// handleNamespace fills in the namespace information in the resource (if required),

// and validates the namespace depending on whether or not a namespace should be

// provided based on the resource kind.

func handleNamespace(resource resourcemgr.ResourceObject, rm resourcemgr.ResourceManager, args map[string]interface{}) error {

	allNs := argutils.ArgBoolOrFalse(args, "--all-namespaces")

	cliNs := argutils.ArgStringOrBlank(args, "--namespace")

	resNs := resource.GetObjectMeta().GetNamespace()

	if rm.IsNamespaced() {

		switch {

		case allNs && cliNs != "":

			// Check if --namespace and --all-namespaces flags are used together.

			return fmt.Errorf("cannot use both --namespace and --all-namespaces flags at the same time")

		case resNs == "" && cliNs != "":

			// If resource doesn't have a namespace specified

			// but it's passed in through the -n flag then use that one.

			resource.GetObjectMeta().SetNamespace(cliNs)


====================
Description:

  The ipam show command prints information about a given IP address, or about

  overall IP usage.

`

	// Replace all instances of BINARY_NAME with the name of the binary.

	name, _ := util.NameAndDescription()

	doc = strings.ReplaceAll(doc, "<BINARY_NAME>", name)

	parsedArgs, err := docopt.ParseArgs(doc, args, "")

	if err != nil {

		return fmt.Errorf("Invalid option: 'calicoctl %s'. Use flag '--help' to read about a specific subcommand.", strings.Join(args, " "))

	}

	if len(parsedArgs) == 0 {

		return nil

	}

	err = common.CheckVersionMismatch(parsedArgs["--config"], parsedArgs["--allow-version-mismatch"])

	if err != nil {

		return err

	}

	ctx := context.Background()

	// Create a new backend client from env vars.


====================
	name, _ := util.NameAndDescription()

	doc = strings.ReplaceAll(doc, "<BINARY_NAME>", name)

	parsedArgs, err := docopt.ParseArgs(doc, args, "")

	if err != nil {

		return fmt.Errorf("Invalid option: 'calicoctl %s'. Use flag '--help' to read about a specific subcommand.", strings.Join(args, " "))

	}

	if len(parsedArgs) == 0 {

		return nil

	}

	err = common.CheckVersionMismatch(parsedArgs["--config"], parsedArgs["--allow-version-mismatch"])

	if err != nil {

		return err

	}

	ctx := context.Background()

	// Create a new backend client from env vars.

	cf := parsedArgs["--config"].(string)

	client, err := clientmgr.NewClient(cf)

	if err != nil {

		return err

	}


====================
	if len(parsedArgs) == 0 {

		return nil

	}

	err = common.CheckVersionMismatch(parsedArgs["--config"], parsedArgs["--allow-version-mismatch"])

	if err != nil {

		return err

	}

	ctx := context.Background()

	// Create a new backend client from env vars.

	cf := parsedArgs["--config"].(string)

	client, err := clientmgr.NewClient(cf)

	if err != nil {

		return err

	}

	ipamClient := client.IPAM()

	ippoolClient := client.IPPools()

	// Get the backend client.

	type accessor interface {

		Backend() bapi.Client

	}


====================
		return err

	}

	ipamClient := client.IPAM()

	ippoolClient := client.IPPools()

	// Get the backend client.

	type accessor interface {

		Backend() bapi.Client

	}

	bc := client.(accessor).Backend()

	passedIP := parsedArgs["--ip"]

	showBlocks := parsedArgs["--show-blocks"].(bool)

	showBorrowed := parsedArgs["--show-borrowed"].(bool)

	configuration := parsedArgs["--show-configuration"].(bool)

	if passedIP != nil {

		return showIP(ctx, ipamClient, passedIP)

	} else if showBlocks {

		return showBlockUtilization(ctx, ipamClient, true)

	} else if showBorrowed {

		return showBorrowedDetails(ctx, ippoolClient, bc)

	} else if configuration {


====================
	}

	ipamClient := client.IPAM()

	ippoolClient := client.IPPools()

	// Get the backend client.

	type accessor interface {

		Backend() bapi.Client

	}

	bc := client.(accessor).Backend()

	passedIP := parsedArgs["--ip"]

	showBlocks := parsedArgs["--show-blocks"].(bool)

	showBorrowed := parsedArgs["--show-borrowed"].(bool)

	configuration := parsedArgs["--show-configuration"].(bool)

	if passedIP != nil {

		return showIP(ctx, ipamClient, passedIP)

	} else if showBlocks {

		return showBlockUtilization(ctx, ipamClient, true)

	} else if showBorrowed {

		return showBorrowedDetails(ctx, ippoolClient, bc)

	} else if configuration {

		return showConfiguration(ctx, ipamClient)


====================
	ipamClient := client.IPAM()

	ippoolClient := client.IPPools()

	// Get the backend client.

	type accessor interface {

		Backend() bapi.Client

	}

	bc := client.(accessor).Backend()

	passedIP := parsedArgs["--ip"]

	showBlocks := parsedArgs["--show-blocks"].(bool)

	showBorrowed := parsedArgs["--show-borrowed"].(bool)

	configuration := parsedArgs["--show-configuration"].(bool)

	if passedIP != nil {

		return showIP(ctx, ipamClient, passedIP)

	} else if showBlocks {

		return showBlockUtilization(ctx, ipamClient, true)

	} else if showBorrowed {

		return showBorrowedDetails(ctx, ippoolClient, bc)

	} else if configuration {

		return showConfiguration(ctx, ipamClient)

	}


====================
	ippoolClient := client.IPPools()

	// Get the backend client.

	type accessor interface {

		Backend() bapi.Client

	}

	bc := client.(accessor).Backend()

	passedIP := parsedArgs["--ip"]

	showBlocks := parsedArgs["--show-blocks"].(bool)

	showBorrowed := parsedArgs["--show-borrowed"].(bool)

	configuration := parsedArgs["--show-configuration"].(bool)

	if passedIP != nil {

		return showIP(ctx, ipamClient, passedIP)

	} else if showBlocks {

		return showBlockUtilization(ctx, ipamClient, true)

	} else if showBorrowed {

		return showBorrowedDetails(ctx, ippoolClient, bc)

	} else if configuration {

		return showConfiguration(ctx, ipamClient)

	}

	return showBlockUtilization(ctx, ipamClient, false)


====================
     --allow-version-mismatch  Allow client and cluster versions mismatch.

Description:

  The ipam check command checks the integrity of the IPAM datastructures against Kubernetes.

`

	// Replace all instances of BINARY_NAME with the name of the binary.

	name, _ := util.NameAndDescription()

	doc = strings.ReplaceAll(doc, "<BINARY_NAME>", name)

	parsedArgs, err := docopt.ParseArgs(doc, args, version)

	if err != nil {

		return fmt.Errorf("Invalid option: 'calicoctl %s'. Use flag '--help' to read about a specific subcommand.", strings.Join(args, " "))

	}

	if len(parsedArgs) == 0 {

		return nil

	}

	err = common.CheckVersionMismatch(parsedArgs["--config"], parsedArgs["--allow-version-mismatch"])

	if err != nil {

		return err

	}

	ctx := context.Background()

	// Create a new backend client from env vars.


====================
	name, _ := util.NameAndDescription()

	doc = strings.ReplaceAll(doc, "<BINARY_NAME>", name)

	parsedArgs, err := docopt.ParseArgs(doc, args, version)

	if err != nil {

		return fmt.Errorf("Invalid option: 'calicoctl %s'. Use flag '--help' to read about a specific subcommand.", strings.Join(args, " "))

	}

	if len(parsedArgs) == 0 {

		return nil

	}

	err = common.CheckVersionMismatch(parsedArgs["--config"], parsedArgs["--allow-version-mismatch"])

	if err != nil {

		return err

	}

	ctx := context.Background()

	// Create a new backend client from env vars.

	cf := parsedArgs["--config"].(string)

	client, err := clientmgr.NewClient(cf)

	if err != nil {

		return err

	}


====================
	if len(parsedArgs) == 0 {

		return nil

	}

	err = common.CheckVersionMismatch(parsedArgs["--config"], parsedArgs["--allow-version-mismatch"])

	if err != nil {

		return err

	}

	ctx := context.Background()

	// Create a new backend client from env vars.

	cf := parsedArgs["--config"].(string)

	client, err := clientmgr.NewClient(cf)

	if err != nil {

		return err

	}

	// Get the backend client.

	type accessor interface {

		Backend() bapi.Client

	}

	bc := client.(accessor).Backend()

	// Get a kube-client. If this is a kdd cluster, we can pull this from the backend.


====================
	// Otherwise, we need to build one ourselves.

	var kubeClient *kubernetes.Clientset

	if kc, ok := bc.(*k8s.KubeClient); ok {

		// Pull from the kdd client.

		kubeClient = kc.ClientSet

	}

	// TODO: Support etcd mode. For now, this is OK since we don't actually

	// use the kubeClient yet. But we will do so eventually.

	// Pull out CLI args.

	showAllIPs := parsedArgs["--show-all-ips"].(bool)

	showProblemIPs := showAllIPs || parsedArgs["--show-problem-ips"].(bool)

	var outFile string = ""

	if arg := parsedArgs["--output"]; arg != nil {

		outFile = arg.(string)

	}

	// Build the checker.

	checker := NewIPAMChecker(kubeClient, client, bc, showAllIPs, showProblemIPs, outFile, version)

	return checker.checkIPAM(ctx)

}

func NewIPAMChecker(k8sClient kubernetes.Interface,


====================
	var kubeClient *kubernetes.Clientset

	if kc, ok := bc.(*k8s.KubeClient); ok {

		// Pull from the kdd client.

		kubeClient = kc.ClientSet

	}

	// TODO: Support etcd mode. For now, this is OK since we don't actually

	// use the kubeClient yet. But we will do so eventually.

	// Pull out CLI args.

	showAllIPs := parsedArgs["--show-all-ips"].(bool)

	showProblemIPs := showAllIPs || parsedArgs["--show-problem-ips"].(bool)

	var outFile string = ""

	if arg := parsedArgs["--output"]; arg != nil {

		outFile = arg.(string)

	}

	// Build the checker.

	checker := NewIPAMChecker(kubeClient, client, bc, showAllIPs, showProblemIPs, outFile, version)

	return checker.checkIPAM(ctx)

}

func NewIPAMChecker(k8sClient kubernetes.Interface,

	v3Client clientv3.Interface,


====================
		// Pull from the kdd client.

		kubeClient = kc.ClientSet

	}

	// TODO: Support etcd mode. For now, this is OK since we don't actually

	// use the kubeClient yet. But we will do so eventually.

	// Pull out CLI args.

	showAllIPs := parsedArgs["--show-all-ips"].(bool)

	showProblemIPs := showAllIPs || parsedArgs["--show-problem-ips"].(bool)

	var outFile string = ""

	if arg := parsedArgs["--output"]; arg != nil {

		outFile = arg.(string)

	}

	// Build the checker.

	checker := NewIPAMChecker(kubeClient, client, bc, showAllIPs, showProblemIPs, outFile, version)

	return checker.checkIPAM(ctx)

}

func NewIPAMChecker(k8sClient kubernetes.Interface,

	v3Client clientv3.Interface,

	backendClient bapi.Client,

	showAllIPs bool,


====================
	}

	return ip.String(), nil

}

// Allocation represents an IP that is allocated in Calico IPAM, augmented with data

// from cross referencing with WorkloadEndpoints, etc.

type Allocation struct {

	// The actual address.

	IP string `json:"ip"`

	// Access to the block.

	Block   *model.AllocationBlock `json:"-"`

	Ordinal int                    `json:"-"`

	Handle         string  `json:"handle,omitempty"`

	SequenceNumber *uint64 `json:"sequenceNumber,omitempty"`

	// Metadata for the Allocation.

	Pod               string `json:"pod,omitempty"`

	Namespace         string `json:"namespace,omitempty"`

	Node              string `json:"node,omitempty"`

	Type              string `json:"type,omitempty"`

	CreationTimestamp string `json:"creationTimestamp,omitempty"`

	// InUse is true when this Allocation is currently being used by a running


====================
	return ip.String(), nil

}

// Allocation represents an IP that is allocated in Calico IPAM, augmented with data

// from cross referencing with WorkloadEndpoints, etc.

type Allocation struct {

	// The actual address.

	IP string `json:"ip"`

	// Access to the block.

	Block   *model.AllocationBlock `json:"-"`

	Ordinal int                    `json:"-"`

	Handle         string  `json:"handle,omitempty"`

	SequenceNumber *uint64 `json:"sequenceNumber,omitempty"`

	// Metadata for the Allocation.

	Pod               string `json:"pod,omitempty"`

	Namespace         string `json:"namespace,omitempty"`

	Node              string `json:"node,omitempty"`

	Type              string `json:"type,omitempty"`

	CreationTimestamp string `json:"creationTimestamp,omitempty"`

	// InUse is true when this Allocation is currently being used by a running

	// workload / node / etc. It is false if this address is not active and should be cleaned up.


====================
     --allow-version-mismatch      Allow client and cluster versions mismatch.

Description:

 Modify configuration for Calico IP address management.

`

	// Replace all instances of BINARY_NAME with the name of the binary.

	name, _ := util.NameAndDescription()

	doc = strings.ReplaceAll(doc, "<BINARY_NAME>", name)

	parsedArgs, err := docopt.ParseArgs(doc, args, "")

	if err != nil {

		return fmt.Errorf("Invalid option: 'calicoctl %s'. Use flag '--help' to read about a specific subcommand.", strings.Join(args, " "))

	}

	if len(parsedArgs) == 0 {

		return nil

	}

	err = common.CheckVersionMismatch(parsedArgs["--config"], parsedArgs["--allow-version-mismatch"])

	if err != nil {

		return err

	}

	ctx := context.Background()

	// Create a new backend client from env vars.


====================
	name, _ := util.NameAndDescription()

	doc = strings.ReplaceAll(doc, "<BINARY_NAME>", name)

	parsedArgs, err := docopt.ParseArgs(doc, args, "")

	if err != nil {

		return fmt.Errorf("Invalid option: 'calicoctl %s'. Use flag '--help' to read about a specific subcommand.", strings.Join(args, " "))

	}

	if len(parsedArgs) == 0 {

		return nil

	}

	err = common.CheckVersionMismatch(parsedArgs["--config"], parsedArgs["--allow-version-mismatch"])

	if err != nil {

		return err

	}

	ctx := context.Background()

	// Create a new backend client from env vars.

	cf := parsedArgs["--config"].(string)

	client, err := clientmgr.NewClient(cf)

	if err != nil {

		return err

	}


====================
	if len(parsedArgs) == 0 {

		return nil

	}

	err = common.CheckVersionMismatch(parsedArgs["--config"], parsedArgs["--allow-version-mismatch"])

	if err != nil {

		return err

	}

	ctx := context.Background()

	// Create a new backend client from env vars.

	cf := parsedArgs["--config"].(string)

	client, err := clientmgr.NewClient(cf)

	if err != nil {

		return err

	}

	ipamClient := client.IPAM()

	passedValue := parsedArgs["--strictaffinity"].(string)

	enabled, err := strconv.ParseBool(passedValue)

	if err != nil {

		return fmt.Errorf("Invalid value. Use true or false to set strictaffinity")

	}


====================
	}

	ctx := context.Background()

	// Create a new backend client from env vars.

	cf := parsedArgs["--config"].(string)

	client, err := clientmgr.NewClient(cf)

	if err != nil {

		return err

	}

	ipamClient := client.IPAM()

	passedValue := parsedArgs["--strictaffinity"].(string)

	enabled, err := strconv.ParseBool(passedValue)

	if err != nil {

		return fmt.Errorf("Invalid value. Use true or false to set strictaffinity")

	}

	return updateIPAMStrictAffinity(ctx, ipamClient, enabled)

}

// Copyright (c) 2016-2021 Tigera, Inc. All rights reserved.

// Licensed under the Apache License, Version 2.0 (the "License");

// you may not use this file except in compliance with the License.

// You may obtain a copy of the License at


====================
  Note that this does not remove the IP from any existing endpoints that may be

  using it, so only use this command to clean up addresses from endpoints that

  were not cleanly removed from Calico.

`

	// Replace all instances of BINARY_NAME with the name of the binary.

	name, _ := util.NameAndDescription()

	doc = strings.ReplaceAll(doc, "<BINARY_NAME>", name)

	parsedArgs, err := docopt.ParseArgs(doc, args, "")

	if err != nil {

		return fmt.Errorf("Invalid option: 'calicoctl %s'. Use flag '--help' to read about a specific subcommand.", strings.Join(args, " "))

	}

	if len(parsedArgs) == 0 {

		return nil

	}

	err = common.CheckVersionMismatch(parsedArgs["--config"], parsedArgs["--allow-version-mismatch"])

	if err != nil {

		return err

	}

	ctx := context.Background()

	// Load config.


====================
	name, _ := util.NameAndDescription()

	doc = strings.ReplaceAll(doc, "<BINARY_NAME>", name)

	parsedArgs, err := docopt.ParseArgs(doc, args, "")

	if err != nil {

		return fmt.Errorf("Invalid option: 'calicoctl %s'. Use flag '--help' to read about a specific subcommand.", strings.Join(args, " "))

	}

	if len(parsedArgs) == 0 {

		return nil

	}

	err = common.CheckVersionMismatch(parsedArgs["--config"], parsedArgs["--allow-version-mismatch"])

	if err != nil {

		return err

	}

	ctx := context.Background()

	// Load config.

	cf := parsedArgs["--config"].(string)

	cfg, err := clientmgr.LoadClientConfig(cf)

	if err != nil {

		return err

	}


====================
	if len(parsedArgs) == 0 {

		return nil

	}

	err = common.CheckVersionMismatch(parsedArgs["--config"], parsedArgs["--allow-version-mismatch"])

	if err != nil {

		return err

	}

	ctx := context.Background()

	// Load config.

	cf := parsedArgs["--config"].(string)

	cfg, err := clientmgr.LoadClientConfig(cf)

	if err != nil {

		return err

	}

	// Set QPS - we want to increase this because we may need to send many IPAM requests

	// in a short period of time in order to release a large number of addresses.

	cfg.Spec.K8sClientQPS = float32(100)

	// Create a new backend client.

	client, err := clientmgr.NewClientFromConfig(cfg)

	if err != nil {


====================
	// Set QPS - we want to increase this because we may need to send many IPAM requests

	// in a short period of time in order to release a large number of addresses.

	cfg.Spec.K8sClientQPS = float32(100)

	// Create a new backend client.

	client, err := clientmgr.NewClientFromConfig(cfg)

	if err != nil {

		return err

	}

	ipamClient := client.IPAM()

	if report := parsedArgs["--from-report"]; report != nil {

		reportFiles := parsedArgs["--from-report"].([]string)

		if len(reportFiles) > 0 {

			force := false

			if parsedArgs["--force"] != nil {

				force = parsedArgs["--force"].(bool)

			}

			err = releaseFromReports(ctx, client, force, reportFiles, version)

			if err != nil {

				return err

			}


====================
	// in a short period of time in order to release a large number of addresses.

	cfg.Spec.K8sClientQPS = float32(100)

	// Create a new backend client.

	client, err := clientmgr.NewClientFromConfig(cfg)

	if err != nil {

		return err

	}

	ipamClient := client.IPAM()

	if report := parsedArgs["--from-report"]; report != nil {

		reportFiles := parsedArgs["--from-report"].([]string)

		if len(reportFiles) > 0 {

			force := false

			if parsedArgs["--force"] != nil {

				force = parsedArgs["--force"].(bool)

			}

			err = releaseFromReports(ctx, client, force, reportFiles, version)

			if err != nil {

				return err

			}

			fmt.Println("You may now unlock the data store.")


====================
	client, err := clientmgr.NewClientFromConfig(cfg)

	if err != nil {

		return err

	}

	ipamClient := client.IPAM()

	if report := parsedArgs["--from-report"]; report != nil {

		reportFiles := parsedArgs["--from-report"].([]string)

		if len(reportFiles) > 0 {

			force := false

			if parsedArgs["--force"] != nil {

				force = parsedArgs["--force"].(bool)

			}

			err = releaseFromReports(ctx, client, force, reportFiles, version)

			if err != nil {

				return err

			}

			fmt.Println("You may now unlock the data store.")

			return nil

		}

	}


====================
	if err != nil {

		return err

	}

	ipamClient := client.IPAM()

	if report := parsedArgs["--from-report"]; report != nil {

		reportFiles := parsedArgs["--from-report"].([]string)

		if len(reportFiles) > 0 {

			force := false

			if parsedArgs["--force"] != nil {

				force = parsedArgs["--force"].(bool)

			}

			err = releaseFromReports(ctx, client, force, reportFiles, version)

			if err != nil {

				return err

			}

			fmt.Println("You may now unlock the data store.")

			return nil

		}

	}

	if ip := parsedArgs["--ip"]; ip != nil {


====================
			}

			err = releaseFromReports(ctx, client, force, reportFiles, version)

			if err != nil {

				return err

			}

			fmt.Println("You may now unlock the data store.")

			return nil

		}

	}

	if ip := parsedArgs["--ip"]; ip != nil {

		passedIP := parsedArgs["--ip"].(string)

		ip := argutils.ValidateIP(passedIP)

		opt := libipam.ReleaseOptions{Address: ip.IP.String()}

		// Call ReleaseIPs releases the IP and returns an empty slice as unallocatedIPs if

		// release was successful else it returns back the slice with the IP passed in.

		unallocatedIPs, err := ipamClient.ReleaseIPs(ctx, opt)

		if err != nil {

			return fmt.Errorf("Error: %v", err)

		}

		// Couldn't release the IP if the slice is not empty or IP might already be released/unassigned.


====================
			err = releaseFromReports(ctx, client, force, reportFiles, version)

			if err != nil {

				return err

			}

			fmt.Println("You may now unlock the data store.")

			return nil

		}

	}

	if ip := parsedArgs["--ip"]; ip != nil {

		passedIP := parsedArgs["--ip"].(string)

		ip := argutils.ValidateIP(passedIP)

		opt := libipam.ReleaseOptions{Address: ip.IP.String()}

		// Call ReleaseIPs releases the IP and returns an empty slice as unallocatedIPs if

		// release was successful else it returns back the slice with the IP passed in.

		unallocatedIPs, err := ipamClient.ReleaseIPs(ctx, opt)

		if err != nil {

			return fmt.Errorf("Error: %v", err)

		}

		// Couldn't release the IP if the slice is not empty or IP might already be released/unassigned.

		// This is not exactly an error, so not returning it to the caller.


====================
Examples:

  # Split the IP pool specified by 172.0.0.0/8 into 2 smaller pools

  <BINARY_NAME> ipam split --cidr=172.0.0.0/8 2

`

	// Replace all instances of BINARY_NAME with the name of the binary.

	name, _ := util.NameAndDescription()

	doc = strings.ReplaceAll(doc, "<BINARY_NAME>", name)

	parsedArgs, err := docopt.ParseArgs(doc, args, "")

	if err != nil {

		return fmt.Errorf("Invalid option: 'calicoctl %s'. Use flag '--help' to read about a specific subcommand.", strings.Join(args, " "))

	}

	if len(parsedArgs) == 0 {

		return nil

	}

	err = common.CheckVersionMismatch(parsedArgs["--config"], parsedArgs["--allow-version-mismatch"])

	if err != nil {

		return err

	}

	// Validate that a name or CIDR is provided to search for the IP pool.

	var oldPoolCIDR, oldPoolName string


====================
	name, _ := util.NameAndDescription()

	doc = strings.ReplaceAll(doc, "<BINARY_NAME>", name)

	parsedArgs, err := docopt.ParseArgs(doc, args, "")

	if err != nil {

		return fmt.Errorf("Invalid option: 'calicoctl %s'. Use flag '--help' to read about a specific subcommand.", strings.Join(args, " "))

	}

	if len(parsedArgs) == 0 {

		return nil

	}

	err = common.CheckVersionMismatch(parsedArgs["--config"], parsedArgs["--allow-version-mismatch"])

	if err != nil {

		return err

	}

	// Validate that a name or CIDR is provided to search for the IP pool.

	var oldPoolCIDR, oldPoolName string

	if cidr := parsedArgs["--cidr"]; cidr != nil {

		oldPoolCIDR = parsedArgs["--cidr"].(string)

	}

	if name := parsedArgs["--name"]; name != nil {

		oldPoolName = parsedArgs["--name"].(string)


====================
	if len(parsedArgs) == 0 {

		return nil

	}

	err = common.CheckVersionMismatch(parsedArgs["--config"], parsedArgs["--allow-version-mismatch"])

	if err != nil {

		return err

	}

	// Validate that a name or CIDR is provided to search for the IP pool.

	var oldPoolCIDR, oldPoolName string

	if cidr := parsedArgs["--cidr"]; cidr != nil {

		oldPoolCIDR = parsedArgs["--cidr"].(string)

	}

	if name := parsedArgs["--name"]; name != nil {

		oldPoolName = parsedArgs["--name"].(string)

	}

	if oldPoolCIDR == "" && oldPoolName == "" {

		return fmt.Errorf("No name or CIDR provided. Provide a name or CIDR to denote the IP pool to split.")

	}

	cf := parsedArgs["--config"].(string)

	// Get the backend client.


====================
		return nil

	}

	err = common.CheckVersionMismatch(parsedArgs["--config"], parsedArgs["--allow-version-mismatch"])

	if err != nil {

		return err

	}

	// Validate that a name or CIDR is provided to search for the IP pool.

	var oldPoolCIDR, oldPoolName string

	if cidr := parsedArgs["--cidr"]; cidr != nil {

		oldPoolCIDR = parsedArgs["--cidr"].(string)

	}

	if name := parsedArgs["--name"]; name != nil {

		oldPoolName = parsedArgs["--name"].(string)

	}

	if oldPoolCIDR == "" && oldPoolName == "" {

		return fmt.Errorf("No name or CIDR provided. Provide a name or CIDR to denote the IP pool to split.")

	}

	cf := parsedArgs["--config"].(string)

	// Get the backend client.

	client, err := clientmgr.NewClient(cf)


====================
	err = common.CheckVersionMismatch(parsedArgs["--config"], parsedArgs["--allow-version-mismatch"])

	if err != nil {

		return err

	}

	// Validate that a name or CIDR is provided to search for the IP pool.

	var oldPoolCIDR, oldPoolName string

	if cidr := parsedArgs["--cidr"]; cidr != nil {

		oldPoolCIDR = parsedArgs["--cidr"].(string)

	}

	if name := parsedArgs["--name"]; name != nil {

		oldPoolName = parsedArgs["--name"].(string)

	}

	if oldPoolCIDR == "" && oldPoolName == "" {

		return fmt.Errorf("No name or CIDR provided. Provide a name or CIDR to denote the IP pool to split.")

	}

	cf := parsedArgs["--config"].(string)

	// Get the backend client.

	client, err := clientmgr.NewClient(cf)

	if err != nil {

		return err


====================
	if err != nil {

		return err

	}

	// Validate that a name or CIDR is provided to search for the IP pool.

	var oldPoolCIDR, oldPoolName string

	if cidr := parsedArgs["--cidr"]; cidr != nil {

		oldPoolCIDR = parsedArgs["--cidr"].(string)

	}

	if name := parsedArgs["--name"]; name != nil {

		oldPoolName = parsedArgs["--name"].(string)

	}

	if oldPoolCIDR == "" && oldPoolName == "" {

		return fmt.Errorf("No name or CIDR provided. Provide a name or CIDR to denote the IP pool to split.")

	}

	cf := parsedArgs["--config"].(string)

	// Get the backend client.

	client, err := clientmgr.NewClient(cf)

	if err != nil {

		return err

	}


====================
	if cidr := parsedArgs["--cidr"]; cidr != nil {

		oldPoolCIDR = parsedArgs["--cidr"].(string)

	}

	if name := parsedArgs["--name"]; name != nil {

		oldPoolName = parsedArgs["--name"].(string)

	}

	if oldPoolCIDR == "" && oldPoolName == "" {

		return fmt.Errorf("No name or CIDR provided. Provide a name or CIDR to denote the IP pool to split.")

	}

	cf := parsedArgs["--config"].(string)

	// Get the backend client.

	client, err := clientmgr.NewClient(cf)

	if err != nil {

		return err

	}

	// Check that the datastore is locked

	ctx := context.Background()

	locked, err := common.CheckLocked(ctx, client)

	if err != nil {

		return fmt.Errorf("Error while checking if datastore was locked: %s", err)


====================
  The following resources are not exported:

    - WorkloadEndpoints

    - Profiles

`

	// Replace all instances of BINARY_NAME with the name of the binary.

	name, _ := util.NameAndDescription()

	doc = strings.ReplaceAll(doc, "<BINARY_NAME>", name)

	parsedArgs, err := docopt.ParseArgs(doc, args, "")

	if err != nil {

		return fmt.Errorf("Invalid option: 'calicoctl %s'. Use flag '--help' to read about a specific subcommand.", strings.Join(args, " "))

	}

	if len(parsedArgs) == 0 {

		return nil

	}

	err = common.CheckVersionMismatch(parsedArgs["--config"], parsedArgs["--allow-version-mismatch"])

	if err != nil {

		return err

	}

	cf := parsedArgs["--config"].(string)

	// Get the backend client.


====================
	name, _ := util.NameAndDescription()

	doc = strings.ReplaceAll(doc, "<BINARY_NAME>", name)

	parsedArgs, err := docopt.ParseArgs(doc, args, "")

	if err != nil {

		return fmt.Errorf("Invalid option: 'calicoctl %s'. Use flag '--help' to read about a specific subcommand.", strings.Join(args, " "))

	}

	if len(parsedArgs) == 0 {

		return nil

	}

	err = common.CheckVersionMismatch(parsedArgs["--config"], parsedArgs["--allow-version-mismatch"])

	if err != nil {

		return err

	}

	cf := parsedArgs["--config"].(string)

	// Get the backend client.

	client, err := clientmgr.NewClient(cf)

	if err != nil {

		return err

	}

	// Check that the datastore is locked.


====================
		return fmt.Errorf("Invalid option: 'calicoctl %s'. Use flag '--help' to read about a specific subcommand.", strings.Join(args, " "))

	}

	if len(parsedArgs) == 0 {

		return nil

	}

	err = common.CheckVersionMismatch(parsedArgs["--config"], parsedArgs["--allow-version-mismatch"])

	if err != nil {

		return err

	}

	cf := parsedArgs["--config"].(string)

	// Get the backend client.

	client, err := clientmgr.NewClient(cf)

	if err != nil {

		return err

	}

	// Check that the datastore is locked.

	ctx := context.Background()

	locked, err := common.CheckLocked(ctx, client)

	if err != nil {

		return fmt.Errorf("Error while checking if datastore was locked: %s", err)


====================
		return fmt.Errorf("Invalid datastore type: %s to export from for datastore migration. Datastore type must be etcdv3", cfg.Spec.DatastoreType)

	}

	rp := common.ResourcePrinterYAML{}

	etcdToKddNodeMap := make(map[string]string)

	// Loop through all the resource types to retrieve every resource available by the v3 API.

	for _, r := range allV3Resources {

		mockArgs := map[string]interface{}{

			"<KIND>":   r,

			"<NAME>":   []string{},

			"--config": cf,

			"--export": true,

			"--output": "yaml",

			"get":      true,

		}

		// Add options for pulling resources from all namespaces for namespaced resources.

		if r == "networksets" || r == "networkpolicies" {

			mockArgs["--all-namespaces"] = true

		}

		results := common.ExecuteConfigCommand(mockArgs, common.ActionGetOrList)

		if len(results.ResErrs) > 0 {


====================
	}

	rp := common.ResourcePrinterYAML{}

	etcdToKddNodeMap := make(map[string]string)

	// Loop through all the resource types to retrieve every resource available by the v3 API.

	for _, r := range allV3Resources {

		mockArgs := map[string]interface{}{

			"<KIND>":   r,

			"<NAME>":   []string{},

			"--config": cf,

			"--export": true,

			"--output": "yaml",

			"get":      true,

		}

		// Add options for pulling resources from all namespaces for namespaced resources.

		if r == "networksets" || r == "networkpolicies" {

			mockArgs["--all-namespaces"] = true

		}

		results := common.ExecuteConfigCommand(mockArgs, common.ActionGetOrList)

		if len(results.ResErrs) > 0 {

			var errStr string


====================
	rp := common.ResourcePrinterYAML{}

	etcdToKddNodeMap := make(map[string]string)

	// Loop through all the resource types to retrieve every resource available by the v3 API.

	for _, r := range allV3Resources {

		mockArgs := map[string]interface{}{

			"<KIND>":   r,

			"<NAME>":   []string{},

			"--config": cf,

			"--export": true,

			"--output": "yaml",

			"get":      true,

		}

		// Add options for pulling resources from all namespaces for namespaced resources.

		if r == "networksets" || r == "networkpolicies" {

			mockArgs["--all-namespaces"] = true

		}

		results := common.ExecuteConfigCommand(mockArgs, common.ActionGetOrList)

		if len(results.ResErrs) > 0 {

			var errStr string

			for i, err := range results.ResErrs {


====================
			"<KIND>":   r,

			"<NAME>":   []string{},

			"--config": cf,

			"--export": true,

			"--output": "yaml",

			"get":      true,

		}

		// Add options for pulling resources from all namespaces for namespaced resources.

		if r == "networksets" || r == "networkpolicies" {

			mockArgs["--all-namespaces"] = true

		}

		results := common.ExecuteConfigCommand(mockArgs, common.ActionGetOrList)

		if len(results.ResErrs) > 0 {

			var errStr string

			for i, err := range results.ResErrs {

				errStr += err.Error()

				if (i + 1) != len(results.ResErrs) {

					errStr += "\n"

				}

			}


====================
Description:

  Import the contents of the etcdv3 datastore from the file created by the

  export command.

`

	// Replace all instances of BINARY_NAME with the name of the binary.

	name, _ := util.NameAndDescription()

	doc = strings.ReplaceAll(doc, "<BINARY_NAME>", name)

	parsedArgs, err := docopt.ParseArgs(doc, args, "")

	if err != nil {

		return fmt.Errorf("Invalid option: 'calicoctl %s'. Use flag '--help' to read about a specific subcommand.", strings.Join(args, " "))

	}

	if len(parsedArgs) == 0 {

		return nil

	}

	// Note: Intentionally not check version mismatch for this command

	cf := parsedArgs["--config"].(string)

	cfg, err := clientmgr.LoadClientConfig(cf)

	if err != nil {

		log.Info("Error loading config")

		return err


====================
	doc = strings.ReplaceAll(doc, "<BINARY_NAME>", name)

	parsedArgs, err := docopt.ParseArgs(doc, args, "")

	if err != nil {

		return fmt.Errorf("Invalid option: 'calicoctl %s'. Use flag '--help' to read about a specific subcommand.", strings.Join(args, " "))

	}

	if len(parsedArgs) == 0 {

		return nil

	}

	// Note: Intentionally not check version mismatch for this command

	cf := parsedArgs["--config"].(string)

	cfg, err := clientmgr.LoadClientConfig(cf)

	if err != nil {

		log.Info("Error loading config")

		return err

	}

	// Set the Kubernetes client QPS to 50 if not explicitly set.

	if cfg.Spec.K8sClientQPS == float32(0) {

		cfg.Spec.K8sClientQPS = float32(50)

	}

	// Get the backend client for updating cluster info and migrating IPAM.


====================
	for _, r := range extendedV3Resources {

		// Skip nodes since they are backed by the Kubernetes node resource

		if r == "nodes" {

			continue

		}

		// Create mocked args in order to retrieve Get resources.

		mockArgs := map[string]interface{}{

			"<KIND>":   r,

			"<NAME>":   []string{},

			"--config": args["--config"].(string),

			"--export": false,

			"--output": "ps",

			"get":      true,

		}

		if _, ok := namespacedResources[r]; ok {

			mockArgs["--all-namespaces"] = true

		}

		// Get resources

		results := common.ExecuteConfigCommand(mockArgs, common.ActionGetOrList)

		// Loop through the result lists and see if anything exists


====================
		// Skip nodes since they are backed by the Kubernetes node resource

		if r == "nodes" {

			continue

		}

		// Create mocked args in order to retrieve Get resources.

		mockArgs := map[string]interface{}{

			"<KIND>":   r,

			"<NAME>":   []string{},

			"--config": args["--config"].(string),

			"--export": false,

			"--output": "ps",

			"get":      true,

		}

		if _, ok := namespacedResources[r]; ok {

			mockArgs["--all-namespaces"] = true

		}

		// Get resources

		results := common.ExecuteConfigCommand(mockArgs, common.ActionGetOrList)

		// Loop through the result lists and see if anything exists

		for _, resource := range results.Resources {


====================
		if r == "nodes" {

			continue

		}

		// Create mocked args in order to retrieve Get resources.

		mockArgs := map[string]interface{}{

			"<KIND>":   r,

			"<NAME>":   []string{},

			"--config": args["--config"].(string),

			"--export": false,

			"--output": "ps",

			"get":      true,

		}

		if _, ok := namespacedResources[r]; ok {

			mockArgs["--all-namespaces"] = true

		}

		// Get resources

		results := common.ExecuteConfigCommand(mockArgs, common.ActionGetOrList)

		// Loop through the result lists and see if anything exists

		for _, resource := range results.Resources {

			if meta.LenList(resource) > 0 {


====================
		mockArgs := map[string]interface{}{

			"<KIND>":   r,

			"<NAME>":   []string{},

			"--config": args["--config"].(string),

			"--export": false,

			"--output": "ps",

			"get":      true,

		}

		if _, ok := namespacedResources[r]; ok {

			mockArgs["--all-namespaces"] = true

		}

		// Get resources

		results := common.ExecuteConfigCommand(mockArgs, common.ActionGetOrList)

		// Loop through the result lists and see if anything exists

		for _, resource := range results.Resources {

			if meta.LenList(resource) > 0 {

				if r == "networkpolicies" {

					// For networkpolicies, having K8s network policies should not throw an error

					objs, err := meta.ExtractList(resource)

					if err != nil {


====================
  Lock the datastore to prepare it for migration. This prevents any new

  Calico resources from affecting the cluster but does not prevent updating

  or creating new Calico resources.

`

	// Replace all instances of BINARY_NAME with the name of the binary.

	name, _ := util.NameAndDescription()

	doc = strings.ReplaceAll(doc, "<BINARY_NAME>", name)

	parsedArgs, err := docopt.ParseArgs(doc, args, "")

	if err != nil {

		return fmt.Errorf("Invalid option: 'calicoctl %s'. Use flag '--help' to read about a specific subcommand.", strings.Join(args, " "))

	}

	if len(parsedArgs) == 0 {

		return nil

	}

	err = common.CheckVersionMismatch(parsedArgs["--config"], parsedArgs["--allow-version-mismatch"])

	if err != nil {

		return err

	}

	cf := parsedArgs["--config"].(string)

	client, err := clientmgr.NewClient(cf)


====================
	name, _ := util.NameAndDescription()

	doc = strings.ReplaceAll(doc, "<BINARY_NAME>", name)

	parsedArgs, err := docopt.ParseArgs(doc, args, "")

	if err != nil {

		return fmt.Errorf("Invalid option: 'calicoctl %s'. Use flag '--help' to read about a specific subcommand.", strings.Join(args, " "))

	}

	if len(parsedArgs) == 0 {

		return nil

	}

	err = common.CheckVersionMismatch(parsedArgs["--config"], parsedArgs["--allow-version-mismatch"])

	if err != nil {

		return err

	}

	cf := parsedArgs["--config"].(string)

	client, err := clientmgr.NewClient(cf)

	if err != nil {

		return err

	}

	// Ensure that the cluster information resource is initialized.

	ctx := context.Background()


====================
		return fmt.Errorf("Invalid option: 'calicoctl %s'. Use flag '--help' to read about a specific subcommand.", strings.Join(args, " "))

	}

	if len(parsedArgs) == 0 {

		return nil

	}

	err = common.CheckVersionMismatch(parsedArgs["--config"], parsedArgs["--allow-version-mismatch"])

	if err != nil {

		return err

	}

	cf := parsedArgs["--config"].(string)

	client, err := clientmgr.NewClient(cf)

	if err != nil {

		return err

	}

	// Ensure that the cluster information resource is initialized.

	ctx := context.Background()

	if err := client.EnsureInitialized(ctx, "", ""); err != nil {

		return fmt.Errorf("Unable to initialize cluster information for the datastore migration: %s", err)

	}

	// Get the cluster information resource


====================
Description:

  Unlock the datastore to complete migration. This once again allows

  Calico resources to take effect in the cluster.

`

	// Replace all instances of BINARY_NAME with the name of the binary.

	name, _ := util.NameAndDescription()

	doc = strings.ReplaceAll(doc, "<BINARY_NAME>", name)

	parsedArgs, err := docopt.ParseArgs(doc, args, "")

	if err != nil {

		return fmt.Errorf("Invalid option: 'calicoctl %s'. Use flag '--help' to read about a specific subcommand.", strings.Join(args, " "))

	}

	if len(parsedArgs) == 0 {

		return nil

	}

	err = common.CheckVersionMismatch(parsedArgs["--config"], parsedArgs["--allow-version-mismatch"])

	if err != nil {

		return err

	}

	cf := parsedArgs["--config"].(string)

	client, err := clientmgr.NewClient(cf)


====================
	name, _ := util.NameAndDescription()

	doc = strings.ReplaceAll(doc, "<BINARY_NAME>", name)

	parsedArgs, err := docopt.ParseArgs(doc, args, "")

	if err != nil {

		return fmt.Errorf("Invalid option: 'calicoctl %s'. Use flag '--help' to read about a specific subcommand.", strings.Join(args, " "))

	}

	if len(parsedArgs) == 0 {

		return nil

	}

	err = common.CheckVersionMismatch(parsedArgs["--config"], parsedArgs["--allow-version-mismatch"])

	if err != nil {

		return err

	}

	cf := parsedArgs["--config"].(string)

	client, err := clientmgr.NewClient(cf)

	if err != nil {

		return err

	}

	// Get the cluster information resource

	ctx := context.Background()


====================
		return fmt.Errorf("Invalid option: 'calicoctl %s'. Use flag '--help' to read about a specific subcommand.", strings.Join(args, " "))

	}

	if len(parsedArgs) == 0 {

		return nil

	}

	err = common.CheckVersionMismatch(parsedArgs["--config"], parsedArgs["--allow-version-mismatch"])

	if err != nil {

		return err

	}

	cf := parsedArgs["--config"].(string)

	client, err := clientmgr.NewClient(cf)

	if err != nil {

		return err

	}

	// Get the cluster information resource

	ctx := context.Background()

	clusterinfo, err := client.ClusterInformation().Get(ctx, "default", options.GetOptions{})

	if err != nil {

		return fmt.Errorf("Error retrieving ClusterInformation for unlocking: %s", err)

	}


====================
// and modified to use the Ginkgo testing framework

var _ = Describe("Test splitYAMLDocument", func() {

	It("should not split up full documents without separators", func() {

		ValidateSplitYAMLDocument("foo", true, "foo", 3)

	})

	It("should not return anything without a separator and not at the EOF", func() {

		ValidateSplitYAMLDocument("fo", false, "", 0)

	})

	It("should return part of YAML separator at EOF", func() {

		ValidateSplitYAMLDocument("---", true, "---", 3)

	})

	It("should return something similar to YAML separator with newline at EOF", func() {

		ValidateSplitYAMLDocument("---\n", true, "---\n", 4)

	})

	It("should not return something similar to YAML separator if not at EOF", func() {

		ValidateSplitYAMLDocument("---\n", false, "", 0)

	})

	It("should not return yaml separator before EOF but advance the bytes read", func() {

		ValidateSplitYAMLDocument("\n---\n", false, "", 5)

	})


====================
		ValidateSplitYAMLDocument("foo", true, "foo", 3)

	})

	It("should not return anything without a separator and not at the EOF", func() {

		ValidateSplitYAMLDocument("fo", false, "", 0)

	})

	It("should return part of YAML separator at EOF", func() {

		ValidateSplitYAMLDocument("---", true, "---", 3)

	})

	It("should return something similar to YAML separator with newline at EOF", func() {

		ValidateSplitYAMLDocument("---\n", true, "---\n", 4)

	})

	It("should not return something similar to YAML separator if not at EOF", func() {

		ValidateSplitYAMLDocument("---\n", false, "", 0)

	})

	It("should not return yaml separator before EOF but advance the bytes read", func() {

		ValidateSplitYAMLDocument("\n---\n", false, "", 5)

	})

	It("should not return yaml separator at EOF but advance the bytes read", func() {

		ValidateSplitYAMLDocument("\n---\n", true, "", 5)

	})


====================
		ValidateSplitYAMLDocument("fo", false, "", 0)

	})

	It("should return part of YAML separator at EOF", func() {

		ValidateSplitYAMLDocument("---", true, "---", 3)

	})

	It("should return something similar to YAML separator with newline at EOF", func() {

		ValidateSplitYAMLDocument("---\n", true, "---\n", 4)

	})

	It("should not return something similar to YAML separator if not at EOF", func() {

		ValidateSplitYAMLDocument("---\n", false, "", 0)

	})

	It("should not return yaml separator before EOF but advance the bytes read", func() {

		ValidateSplitYAMLDocument("\n---\n", false, "", 5)

	})

	It("should not return yaml separator at EOF but advance the bytes read", func() {

		ValidateSplitYAMLDocument("\n---\n", true, "", 5)

	})

	It("should split out and read the first document in multiple documents", func() {

		ValidateSplitYAMLDocument("abc\n---\ndef", true, "abc", 8)

	})


====================
	switch args[argname].(type) {

	case string:

		name := argutils.ArgStringOrBlank(args, argname)

		names = append(names, name)

	case []string:

		names = argutils.ArgStringsOrBlank(args, argname)

	default:

		panic(fmt.Errorf("Wrong name format, unexpected type: %T", args[argname]))

	}

	namespace := argutils.ArgStringOrBlank(args, "--namespace")

	var ret []ResourceObject

	for _, name := range names {

		res, ok := kindToRes[strings.ToLower(kind)]

		if !ok {

			return nil, fmt.Errorf("resource type '%s' is not supported", kind)

		}

		res = res.DeepCopyObject().(ResourceObject)

		res.GetObjectMeta().SetName(name)

		// Set the namespace if the object kind is namespaced.

		if helpers[res.GetObjectKind().GroupVersionKind()].isNamespaced {


====================
	if err := yaml.UnmarshalStrict(b, &unpacked); err != nil {

		return nil, err

	}

	log.Infof("Unpacked: %+v", unpacked)

	return unpacked, nil

}

// CreateResourcesFromFile creates the Resource from the specified file f.

//   - The file format may be JSON or YAML encoding of either a single resource or list of

//     resources as defined by the API objects in /api.

//   - A filename of "-" means "Read from stdin".

//

// The returned Resource will either be a single Resource or a List containing zero or more

// Resources.  If the file does not contain any valid Resources this function returns an error.

func CreateResourcesFromFile(f string) ([]runtime.Object, error) {

	// Load the bytes from file or from stdin.

	logCxt := log.WithField("source", f)

	var reader io.Reader

	var err error

	if f == "-" {

		reader = os.Stdin


====================
//   - A filename of "-" means "Read from stdin".

//

// The returned Resource will either be a single Resource or a List containing zero or more

// Resources.  If the file does not contain any valid Resources this function returns an error.

func CreateResourcesFromFile(f string) ([]runtime.Object, error) {

	// Load the bytes from file or from stdin.

	logCxt := log.WithField("source", f)

	var reader io.Reader

	var err error

	if f == "-" {

		reader = os.Stdin

	} else {

		reader, err = os.Open(f)

		if err != nil {

			logCxt.WithError(err).Error("Failed to open file")

			return nil, err

		}

	}

	logCxt.Debug("Creating document separator")

	var resources []runtime.Object


====================
	// Validate with the appropriate 'ipam show' commands

	// ipam show, pools only.

	out = Calicoctl(true, "ipam", "show")

	Expect(out).To(ContainSubstring("IPS IN USE"))

	Expect(out).To(ContainSubstring("10.65.0.0/16"))

	Expect(out).To(ContainSubstring("5 (0%)"))

	Expect(out).To(ContainSubstring("65531 (100%)"))

	Expect(out).To(ContainSubstring("fd5f:abcd:64::/48"))

	// ipam show, including blocks.

	out = Calicoctl(true, "ipam", "show", "--show-blocks")

	Expect(out).To(ContainSubstring("Block"))

	Expect(out).To(ContainSubstring("5 (8%)"))

	Expect(out).To(ContainSubstring("59 (92%)"))

	// Find out the allocation block.

	var allocatedIP string

	r, err := regexp.Compile(`(10\.65\.[0-9]+\.)([0-9]+)/26`)

	Expect(err).NotTo(HaveOccurred())

	for _, line := range strings.Split(out, "\n") {

		sm := r.FindStringSubmatch(line)

		if len(sm) > 0 {


====================
		if len(sm) > 0 {

			ordinalBase, err := strconv.Atoi(sm[2])

			Expect(err).NotTo(HaveOccurred())

			allocatedIP = sm[1] + strconv.Itoa(ordinalBase+2)

			break

		}

	}

	Expect(allocatedIP).NotTo(BeEmpty())

	// ipam show with specific IP that is now allocated.

	out = Calicoctl(false, "ipam", "show", "--ip="+allocatedIP)

	Expect(out).To(ContainSubstring(allocatedIP + " is in use"))

	Expect(out).To(ContainSubstring("Attributes:"))

	Expect(out).To(ContainSubstring("note: reserved by migrate_ipam_test.go"))

	// ipam show, including blocks.

	//

	// Example output here:

	// +----------+-------------------------------------------+------------+------------+-------------------+

	// | GROUPING |                   CIDR                    | IPS TOTAL  | IPS IN USE |     IPS FREE      |

	// +----------+-------------------------------------------+------------+------------+-------------------+

	// | IP Pool  | 10.65.0.0/16                              |      65536 | 5 (0%)     | 65531 (100%)      |


====================
	// +----------+-------------------------------------------+------------+------------+-------------------+

	// | IP Pool  | 10.65.0.0/16                              |      65536 | 5 (0%)     | 65531 (100%)      |

	// | Block    | 10.65.79.0/26                             |         64 | 5 (8%)     | 59 (92%)          |

	// | IP Pool  | 10.66.0.0/16                              |      65536 | 11 (0%)    | 65525 (100%)      |

	// | Block    | 10.66.137.224/29                          |          8 | 8 (100%)   | 0 (0%)            |

	// | Block    | 10.66.137.232/29                          |          8 | 3 (38%)    | 5 (62%)           |

	// | IP Pool  | fd5f:abcd:64::/48                         | 1.2089e+24 | 7 (0%)     | 1.2089e+24 (100%) |

	// | Block    | fd5f:abcd:64:4f2c:ec1b:27b9:1989:77c0/122 |         64 | 7 (11%)    | 57 (89%)          |

	// +----------+-------------------------------------------+------------+------------+-------------------+

	outLines := strings.Split(Calicoctl(false, "ipam", "show", "--show-blocks"), "\n")

	Expect(outLines).To(ContainElement(And(ContainSubstring("Block"), ContainSubstring("10.66"), ContainSubstring("8 (100%)"), ContainSubstring("0 (0%)"))))

	Expect(outLines).To(ContainElement(And(ContainSubstring("IP Pool"), ContainSubstring("fd5f"), ContainSubstring("7 (0%)"))))

	// Clean up resources

	cidrs := append(v4, v4More...)

	cidrs = append(cidrs, v6...)

	cidrs = append(cidrs, v6More...)

	var ips []ipam.ReleaseOptions

	for _, cidr := range cidrs {

		err = client.IPAM().ReleaseAffinity(ctx, cidr, "node4", false)

		Expect(err).NotTo(HaveOccurred())


====================
		Expect(err).NotTo(HaveOccurred())

		// Create a Node resource for this host.

		cleanupNode := createNodeForLocalhost(t, ctx, client)

		defer cleanupNode()

		// Set Calico version in ClusterInformation

		out, err := SetCalicoVersion(kdd)

		Expect(err).ToNot(HaveOccurred())

		Expect(out).To(ContainSubstring("Calico version set to"))

		// ipam show with specific unallocated IP.

		out = Calicoctl(kdd, "ipam", "show", "--ip=10.65.0.2")

		Expect(out).To(ContainSubstring("10.65.0.2 is not assigned"))

		// ipam show, with no allocations yet.

		out = Calicoctl(kdd, "ipam", "show")

		Expect(out).To(ContainSubstring("IPS IN USE"))

		// Assign some IPs.

		var v4, v6 []cnet.IPNet

		v4Assignments, v6Assignments, err := client.IPAM().AutoAssign(ctx, ipam.AutoAssignArgs{

			Num4:        5,

			Num6:        7,

			Attrs:       map[string]string{"note": "reserved by ipam_test.go"},


====================
		}

		// ipam show, pools only.

		out = Calicoctl(kdd, "ipam", "show")

		Expect(out).To(ContainSubstring("IPS IN USE"))

		Expect(out).To(ContainSubstring("10.65.0.0/16"))

		Expect(out).To(ContainSubstring("5 (0%)"))

		Expect(out).To(ContainSubstring("65531 (100%)"))

		Expect(out).To(ContainSubstring("fd5f:abcd:64::/48"))

		// ipam show, including blocks.

		out = Calicoctl(kdd, "ipam", "show", "--show-blocks")

		Expect(out).To(ContainSubstring("Block"))

		Expect(out).To(ContainSubstring("5 (8%)"))

		Expect(out).To(ContainSubstring("59 (92%)"))

		// Find out the allocation block.

		var allocatedIP string

		r, err := regexp.Compile(`(10\.65\.[0-9]+\.)([0-9]+)/26`)

		Expect(err).NotTo(HaveOccurred())

		for _, line := range strings.Split(out, "\n") {

			sm := r.FindStringSubmatch(line)

			if len(sm) > 0 {


====================
			if len(sm) > 0 {

				ordinalBase, err := strconv.Atoi(sm[2])

				Expect(err).NotTo(HaveOccurred())

				allocatedIP = sm[1] + strconv.Itoa(ordinalBase+2)

				break

			}

		}

		Expect(allocatedIP).NotTo(BeEmpty())

		// ipam show with specific IP that is now allocated.

		out = Calicoctl(kdd, "ipam", "show", "--ip="+allocatedIP)

		Expect(out).To(ContainSubstring(allocatedIP + " is in use"))

		Expect(out).To(ContainSubstring("Attributes:"))

		Expect(out).To(ContainSubstring("note: reserved by ipam_test.go"))

		// ipam show with an invalid IP.

		out, err = CalicoctlMayFail(kdd, "ipam", "show", "--ip=10.240.0.300")

		Expect(err).To(HaveOccurred())

		Expect(out).To(ContainSubstring("invalid IP address"))

		// Create a pool with blocksize 29, so we can easily allocate

		// an entire block.

		pool = v3.NewIPPool()


====================
			}

		}

		Expect(allocatedIP).NotTo(BeEmpty())

		// ipam show with specific IP that is now allocated.

		out = Calicoctl(kdd, "ipam", "show", "--ip="+allocatedIP)

		Expect(out).To(ContainSubstring(allocatedIP + " is in use"))

		Expect(out).To(ContainSubstring("Attributes:"))

		Expect(out).To(ContainSubstring("note: reserved by ipam_test.go"))

		// ipam show with an invalid IP.

		out, err = CalicoctlMayFail(kdd, "ipam", "show", "--ip=10.240.0.300")

		Expect(err).To(HaveOccurred())

		Expect(out).To(ContainSubstring("invalid IP address"))

		// Create a pool with blocksize 29, so we can easily allocate

		// an entire block.

		pool = v3.NewIPPool()

		pool.Name = "ipam-test-v4-b29"

		pool.Spec.CIDR = "10.66.0.0/16"

		pool.Spec.BlockSize = 29

		_, err = client.IPPools().Create(ctx, pool, options.SetOptions{})

		Expect(err).NotTo(HaveOccurred())


====================
		// +----------+-------------------------------------------+------------+------------+-------------------+

		// | IP Pool  | 10.65.0.0/16                              |      65536 | 5 (0%)     | 65531 (100%)      |

		// | Block    | 10.65.79.0/26                             |         64 | 5 (8%)     | 59 (92%)          |

		// | IP Pool  | 10.66.0.0/16                              |      65536 | 11 (0%)    | 65525 (100%)      |

		// | Block    | 10.66.137.224/29                          |          8 | 8 (100%)   | 0 (0%)            |

		// | Block    | 10.66.137.232/29                          |          8 | 3 (38%)    | 5 (62%)           |

		// | IP Pool  | fd5f:abcd:64::/48                         | 1.2089e+24 | 7 (0%)     | 1.2089e+24 (100%) |

		// | Block    | fd5f:abcd:64:4f2c:ec1b:27b9:1989:77c0/122 |         64 | 7 (11%)    | 57 (89%)          |

		// +----------+-------------------------------------------+------------+------------+-------------------+

		outLines := strings.Split(Calicoctl(kdd, "ipam", "show", "--show-blocks"), "\n")

		Expect(outLines).To(ContainElement(And(ContainSubstring("Block"), ContainSubstring("10.66"), ContainSubstring("8 (100%)"), ContainSubstring("0 (0%)"))))

		Expect(outLines).To(ContainElement(And(ContainSubstring("IP Pool"), ContainSubstring("fd5f"), ContainSubstring("7 (0%)"))))

		// Clean up resources

		cidrs := append(v4, v4More...)

		cidrs = append(cidrs, v6...)

		cidrs = append(cidrs, v6More...)

		nodename, err := os.Hostname()

		Expect(err).NotTo(HaveOccurred())

		var ips []ipam.ReleaseOptions

		for _, cidr := range cidrs {


====================
					},

					Deleted: false,

				},

			})

			Expect(err).NotTo(HaveOccurred())

			return kv

		}

		createLeakedHandle()

		// Run calicoctl ipam check and parse the resulting report.

		out = Calicoctl(kdd, "ipam", "check", "--show-all-ips", "-o", "/tmp/ipam_report.json")

		t.Log("IPAM check output:", out)

		reportFile, err := os.ReadFile("/tmp/ipam_report.json")

		Expect(err).NotTo(HaveOccurred())

		t.Log("IPAM check report (raw JSON):", string(reportFile))

		var report ipamcmd.Report

		err = json.Unmarshal(reportFile, &report)

		Expect(err).NotTo(HaveOccurred())

		// Check that handles were reported correctly.

		Expect(out).To(ContainSubstring("Found 1 handles with no matching IPs (and 1 handles with matches)."))

		Expect(report.LeakedHandles).To(HaveLen(1))


====================
		Expect(err).NotTo(HaveOccurred())

		// Check that handles were reported correctly.

		Expect(out).To(ContainSubstring("Found 1 handles with no matching IPs (and 1 handles with matches)."))

		Expect(report.LeakedHandles).To(HaveLen(1))

		Expect(report.LeakedHandles[0].ID).To(Equal("leaked-handle"))

		Expect(report.LeakedHandles[0].Revision).ToNot(BeEmpty())

		if kdd {

			Expect(report.LeakedHandles[0].UID).ToNot(BeNil())

		}

		out, err = CalicoctlMayFail(kdd, "ipam", "release", "--from-report=/tmp/ipam_report.json")

		Expect(err).To(HaveOccurred(), "calicoctl ipam release should fail if datastore is not locked")

		Expect(out).To(ContainSubstring("not locked"))

		out, err = CalicoctlMayFail(kdd, "ipam", "release", "--from-report=/tmp/ipam_report.json", "--force")

		Expect(err).NotTo(HaveOccurred(), fmt.Sprintf("failed to run calicoctl ipam release: %s", out))

		t.Log("calicoctl ipam release output:", out)

		Expect(out).To(ContainSubstring("Released 1 IPs successfully"))

		Expect(out).To(ContainSubstring("Released 1 handles; 0 skipped; 0 errors."))

		// Both handles should now be gone.

		handles, err := bc.List(ctx, model.IPAMHandleListOptions{}, "")

		Expect(err).NotTo(HaveOccurred())


====================
		Expect(report.LeakedHandles).To(HaveLen(1))

		Expect(report.LeakedHandles[0].ID).To(Equal("leaked-handle"))

		Expect(report.LeakedHandles[0].Revision).ToNot(BeEmpty())

		if kdd {

			Expect(report.LeakedHandles[0].UID).ToNot(BeNil())

		}

		out, err = CalicoctlMayFail(kdd, "ipam", "release", "--from-report=/tmp/ipam_report.json")

		Expect(err).To(HaveOccurred(), "calicoctl ipam release should fail if datastore is not locked")

		Expect(out).To(ContainSubstring("not locked"))

		out, err = CalicoctlMayFail(kdd, "ipam", "release", "--from-report=/tmp/ipam_report.json", "--force")

		Expect(err).NotTo(HaveOccurred(), fmt.Sprintf("failed to run calicoctl ipam release: %s", out))

		t.Log("calicoctl ipam release output:", out)

		Expect(out).To(ContainSubstring("Released 1 IPs successfully"))

		Expect(out).To(ContainSubstring("Released 1 handles; 0 skipped; 0 errors."))

		// Both handles should now be gone.

		handles, err := bc.List(ctx, model.IPAMHandleListOptions{}, "")

		Expect(err).NotTo(HaveOccurred())

		for _, kv := range handles.KVPairs {

			hk := kv.Key.(model.IPAMHandleKey)

			Expect(hk.HandleID).NotTo(Equal("leaked-handle"))


====================
		handles, err := bc.List(ctx, model.IPAMHandleListOptions{}, "")

		Expect(err).NotTo(HaveOccurred())

		for _, kv := range handles.KVPairs {

			hk := kv.Key.(model.IPAMHandleKey)

			Expect(hk.HandleID).NotTo(Equal("leaked-handle"))

			Expect(hk.HandleID).NotTo(Equal(myHandle))

		}

		// Recreate the handle and try running the same report again.  Should skip that handle due to change of revision.

		createLeakedHandle()

		out, err = CalicoctlMayFail(kdd, "ipam", "release", "--from-report=/tmp/ipam_report.json", "--force")

		Expect(err).NotTo(HaveOccurred(), fmt.Sprintf("failed to run calicoctl ipam release: %s", out))

		t.Log("calicoctl ipam release output:", out)

		Expect(out).ToNot(MatchRegexp(`.*Released \d+ IPs.*`), "No IPs should be released")

		Expect(out).To(ContainSubstring("Released 0 handles; 1 skipped; 0 errors."))

		// Run with missing handle, should skip.

		out, err = CalicoctlMayFail(kdd, "ipam", "release", "--from-report=/tmp/ipam_report.json", "--force")

		Expect(err).NotTo(HaveOccurred(), fmt.Sprintf("failed to run calicoctl ipam release: %s", out))

		t.Log("calicoctl ipam release output:", out)

		Expect(out).To(ContainSubstring("Released 0 handles; 1 skipped; 0 errors."))

	})


====================
		}

		// Recreate the handle and try running the same report again.  Should skip that handle due to change of revision.

		createLeakedHandle()

		out, err = CalicoctlMayFail(kdd, "ipam", "release", "--from-report=/tmp/ipam_report.json", "--force")

		Expect(err).NotTo(HaveOccurred(), fmt.Sprintf("failed to run calicoctl ipam release: %s", out))

		t.Log("calicoctl ipam release output:", out)

		Expect(out).ToNot(MatchRegexp(`.*Released \d+ IPs.*`), "No IPs should be released")

		Expect(out).To(ContainSubstring("Released 0 handles; 1 skipped; 0 errors."))

		// Run with missing handle, should skip.

		out, err = CalicoctlMayFail(kdd, "ipam", "release", "--from-report=/tmp/ipam_report.json", "--force")

		Expect(err).NotTo(HaveOccurred(), fmt.Sprintf("failed to run calicoctl ipam release: %s", out))

		t.Log("calicoctl ipam release output:", out)

		Expect(out).To(ContainSubstring("Released 0 handles; 1 skipped; 0 errors."))

	})

}

func createNodeForLocalhost(t *testing.T, ctx context.Context, client clientv3.Interface) (cleanup func()) {

	type accessor interface {

		Backend() bapi.Client

	}

	bc := client.(accessor).Backend()


====================
	Expect(err).NotTo(HaveOccurred())

	defer func() {

		_, err = client.NetworkPolicies().Delete(ctx, "secondns", "policy2", options.DeleteOptions{})

		Expect(err).NotTo(HaveOccurred())

	}()

	// Set Calico version in ClusterInformation

	out, err := SetCalicoVersion(false)

	Expect(err).ToNot(HaveOccurred())

	Expect(out).To(ContainSubstring("Calico version set to"))

	out, err = CalicoctlMayFail(false, "get", "ippool", "-A")

	Expect(err).To(HaveOccurred())

	Expect(out).To(Equal("IPPool is not namespaced\n"))

	out, err = CalicoctlMayFail(false, "get", "ippool", "-a")

	Expect(err).To(HaveOccurred())

	Expect(out).To(Equal("IPPool is not namespaced\n"))

	out = Calicoctl(false, "get", "networkPolicy", "-A")

	Expect(out).To(Equal("NAMESPACE   NAME      \nfirstns     policy1   \nsecondns    policy2   \n\n"))

	out = Calicoctl(false, "get", "networkPolicy", "-a")

	Expect(out).To(Equal("NAMESPACE   NAME      \nfirstns     policy1   \nsecondns    policy2   \n\n"))

}


====================
		Expect(err).NotTo(HaveOccurred())

	}()

	// Set Calico version in ClusterInformation

	out, err := SetCalicoVersion(false)

	Expect(err).ToNot(HaveOccurred())

	Expect(out).To(ContainSubstring("Calico version set to"))

	out, err = CalicoctlMayFail(false, "get", "ippool", "-A")

	Expect(err).To(HaveOccurred())

	Expect(out).To(Equal("IPPool is not namespaced\n"))

	out, err = CalicoctlMayFail(false, "get", "ippool", "-a")

	Expect(err).To(HaveOccurred())

	Expect(out).To(Equal("IPPool is not namespaced\n"))

	out = Calicoctl(false, "get", "networkPolicy", "-A")

	Expect(out).To(Equal("NAMESPACE   NAME      \nfirstns     policy1   \nsecondns    policy2   \n\n"))

	out = Calicoctl(false, "get", "networkPolicy", "-a")

	Expect(out).To(Equal("NAMESPACE   NAME      \nfirstns     policy1   \nsecondns    policy2   \n\n"))

}

// Copyright (c) 2019 Tigera, Inc. All rights reserved.

// Licensed under the Apache License, Version 2.0 (the "License");

// you may not use this file except in compliance with the License.


====================
	out, err := SetCalicoVersion(false)

	Expect(err).ToNot(HaveOccurred())

	Expect(out).To(ContainSubstring("Calico version set to"))

	out, err = CalicoctlMayFail(false, "get", "ippool", "-A")

	Expect(err).To(HaveOccurred())

	Expect(out).To(Equal("IPPool is not namespaced\n"))

	out, err = CalicoctlMayFail(false, "get", "ippool", "-a")

	Expect(err).To(HaveOccurred())

	Expect(out).To(Equal("IPPool is not namespaced\n"))

	out = Calicoctl(false, "get", "networkPolicy", "-A")

	Expect(out).To(Equal("NAMESPACE   NAME      \nfirstns     policy1   \nsecondns    policy2   \n\n"))

	out = Calicoctl(false, "get", "networkPolicy", "-a")

	Expect(out).To(Equal("NAMESPACE   NAME      \nfirstns     policy1   \nsecondns    policy2   \n\n"))

}

// Copyright (c) 2019 Tigera, Inc. All rights reserved.

// Licensed under the Apache License, Version 2.0 (the "License");

// you may not use this file except in compliance with the License.

// You may obtain a copy of the License at

//

//     http://www.apache.org/licenses/LICENSE-2.0


====================
	Expect(out).To(ContainSubstring("Calico version set to"))

	out, err = CalicoctlMayFail(false, "get", "ippool", "-A")

	Expect(err).To(HaveOccurred())

	Expect(out).To(Equal("IPPool is not namespaced\n"))

	out, err = CalicoctlMayFail(false, "get", "ippool", "-a")

	Expect(err).To(HaveOccurred())

	Expect(out).To(Equal("IPPool is not namespaced\n"))

	out = Calicoctl(false, "get", "networkPolicy", "-A")

	Expect(out).To(Equal("NAMESPACE   NAME      \nfirstns     policy1   \nsecondns    policy2   \n\n"))

	out = Calicoctl(false, "get", "networkPolicy", "-a")

	Expect(out).To(Equal("NAMESPACE   NAME      \nfirstns     policy1   \nsecondns    policy2   \n\n"))

}

// Copyright (c) 2019 Tigera, Inc. All rights reserved.

// Licensed under the Apache License, Version 2.0 (the "License");

// you may not use this file except in compliance with the License.

// You may obtain a copy of the License at

//

//     http://www.apache.org/licenses/LICENSE-2.0

//

// Unless required by applicable law or agreed to in writing, software


====================
	defer unpatchEnv()

	// Set Calico version in ClusterInformation for both contexts

	out, err := SetCalicoVersion(true, "--context", "main")

	Expect(err).ToNot(HaveOccurred())

	Expect(out).To(ContainSubstring("Calico version set to"))

	out, err = SetCalicoVersion(true, "--context", "second")

	Expect(err).ToNot(HaveOccurred())

	Expect(out).To(ContainSubstring("Calico version set to"))

	// This check will Fail, kubectl-config.yaml file that we are using for this only contains "main" context.

	out, err = CalicoctlMayFail(true, "--allow-version-mismatch", "get", "node", "--context", "fake")

	Expect(err).To(HaveOccurred())

	Expect(out).To(ContainSubstring("Failed"))

	// This check should Pass

	out = Calicoctl(true, "get", "node", "--context", "main")

	Expect(out).To(ContainSubstring("node4"))

	out = Calicoctl(true, "get", "node", "--context", "second")

	Expect(out).To(ContainSubstring("node8"))

	// This check should Pass proving --context works regardless of its position

	out = Calicoctl(true, "--context", "main", "get", "node")

	Expect(out).To(ContainSubstring("node4"))


====================
  --context=<context>       The name of the kubeconfig context to use.

Description:

  Set CalicoVersion in ClusterInformation.

`

	parsedArgs, err := docopt.ParseDoc(doc)

	if err != nil {

		fmt.Printf("Could not parse arguments: %s, err: %v\n", strings.Join(os.Args[1:], " "), err)

		os.Exit(1)

	}

	if context := parsedArgs["--context"]; context != nil {

		os.Setenv("K8S_CURRENT_CONTEXT", context.(string))

	}

	cf, _ := parsedArgs["--config"].(string)

	cfg, err := clientmgr.LoadClientConfig(cf)

	if err != nil {

		fmt.Printf("Could not load client config: %v\n", err)

		os.Exit(1)

	}

	// Get the backend client for updating cluster info and migrating IPAM.

	client, err := clientv3.New(*cfg)


====================
`

	parsedArgs, err := docopt.ParseDoc(doc)

	if err != nil {

		fmt.Printf("Could not parse arguments: %s, err: %v\n", strings.Join(os.Args[1:], " "), err)

		os.Exit(1)

	}

	if context := parsedArgs["--context"]; context != nil {

		os.Setenv("K8S_CURRENT_CONTEXT", context.(string))

	}

	cf, _ := parsedArgs["--config"].(string)

	cfg, err := clientmgr.LoadClientConfig(cf)

	if err != nil {

		fmt.Printf("Could not load client config: %v\n", err)

		os.Exit(1)

	}

	// Get the backend client for updating cluster info and migrating IPAM.

	client, err := clientv3.New(*cfg)

	if err != nil {

		fmt.Printf("Could not create client: %v\n", err)

		os.Exit(1)


====================
		os.Exit(1)

	}

	// Get the backend client for updating cluster info and migrating IPAM.

	client, err := clientv3.New(*cfg)

	if err != nil {

		fmt.Printf("Could not create client: %v\n", err)

		os.Exit(1)

	}

	ctx := context.Background()

	calicoVersion, _ := parsedArgs["--version"].(string)

	if err := client.EnsureInitialized(ctx, calicoVersion, ""); err != nil {

		fmt.Printf("Could not set calico version to %s: %v\n", calicoVersion, err)

		os.Exit(1)

	}

	fmt.Printf("Calico version set to %s\n", calicoVersion)

}

// Copyright (c) 2019 Tigera, Inc. All rights reserved.

// Licensed under the Apache License, Version 2.0 (the "License");

// you may not use this file except in compliance with the License.

// You may obtain a copy of the License at


====================
	routeKeyPrefix    = "/calico/staticroutes/"

	rejectKeyPrefix   = "/calico/rejectcidrs/"

	routeKeyPrefixV6  = "/calico/staticroutesv6/"

	rejectKeyPrefixV6 = "/calico/rejectcidrsv6/"

)

func (c *client) addRoutesLockHeld(prefixV4, prefixV6 string, cidrs []string) {

	for _, cidr := range cidrs {

		var k string

		if strings.Contains(cidr, ":") {

			k = prefixV6 + strings.Replace(cidr, "/", "-", 1)

		} else {

			k = prefixV4 + strings.Replace(cidr, "/", "-", 1)

		}

		// Update the cache and increment the reference count for this key.

		c.cache[k] = cidr

		c.programmedRouteRefCount[k]++

		c.keyUpdated(k)

	}

}

func (c *client) deleteRoutesLockHeld(prefixV4, prefixV6 string, cidrs []string) {


====================
	routeKeyPrefixV6  = "/calico/staticroutesv6/"

	rejectKeyPrefixV6 = "/calico/rejectcidrsv6/"

)

func (c *client) addRoutesLockHeld(prefixV4, prefixV6 string, cidrs []string) {

	for _, cidr := range cidrs {

		var k string

		if strings.Contains(cidr, ":") {

			k = prefixV6 + strings.Replace(cidr, "/", "-", 1)

		} else {

			k = prefixV4 + strings.Replace(cidr, "/", "-", 1)

		}

		// Update the cache and increment the reference count for this key.

		c.cache[k] = cidr

		c.programmedRouteRefCount[k]++

		c.keyUpdated(k)

	}

}

func (c *client) deleteRoutesLockHeld(prefixV4, prefixV6 string, cidrs []string) {

	for _, cidr := range cidrs {

		var k string


====================
		c.cache[k] = cidr

		c.programmedRouteRefCount[k]++

		c.keyUpdated(k)

	}

}

func (c *client) deleteRoutesLockHeld(prefixV4, prefixV6 string, cidrs []string) {

	for _, cidr := range cidrs {

		var k string

		if strings.Contains(cidr, ":") {

			k = prefixV6 + strings.Replace(cidr, "/", "-", 1)

		} else {

			k = prefixV4 + strings.Replace(cidr, "/", "-", 1)

		}

		if c.programmedRouteRefCount[k] <= 1 {

			// This is the last reference for this route. We can remove it.

			// We only delete from the cache if there are no other users of this route.

			delete(c.cache, k)

			delete(c.programmedRouteRefCount, k)

			c.keyUpdated(k)

		} else {


====================
		c.keyUpdated(k)

	}

}

func (c *client) deleteRoutesLockHeld(prefixV4, prefixV6 string, cidrs []string) {

	for _, cidr := range cidrs {

		var k string

		if strings.Contains(cidr, ":") {

			k = prefixV6 + strings.Replace(cidr, "/", "-", 1)

		} else {

			k = prefixV4 + strings.Replace(cidr, "/", "-", 1)

		}

		if c.programmedRouteRefCount[k] <= 1 {

			// This is the last reference for this route. We can remove it.

			// We only delete from the cache if there are no other users of this route.

			delete(c.cache, k)

			delete(c.programmedRouteRefCount, k)

			c.keyUpdated(k)

		} else {

			// Just decrement the ref counter.

			c.programmedRouteRefCount[k]--


====================
				Expect(rg.client.cache).ToNot(HaveKey("/calico/staticroutes/127.0.0.1-32"))

			})

		})

		Context("On BGP configuration changes from the syncer", func() {

			It("should only advertise external IPs within the configured ranges", func() {

				// Simulate an event from the syncer which sets the External IP range containing the first IP.

				rg.client.onExternalIPsUpdate([]string{externalIPRange1})

				rg.resyncKnownRoutes()

				// We should now advertise the first external IP, but not the second.

				Expect(rg.client.cache["/calico/staticroutes/"+externalIP1+"-32"]).To(Equal(externalIP1 + "/32"))

				Expect(rg.client.cache["/calico/staticroutes/"+externalIP2+"-32"]).To(BeEmpty())

				// It should also reject the full range into the data plane.

				Expect(rg.client.cache["/calico/rejectcidrs/"+strings.Replace(externalIPRange1, "/", "-", -1)]).To(Equal(externalIPRange1))

				// Simulate an event from the syncer which updates to use the second range (removing the first)

				rg.client.onExternalIPsUpdate([]string{externalIPRange2})

				rg.resyncKnownRoutes()

				// We should now advertise the second external IP, but not the first.

				Expect(rg.client.cache["/calico/staticroutes/"+externalIP1+"-32"]).To(BeEmpty())

				Expect(rg.client.cache["/calico/staticroutes/"+externalIP2+"-32"]).To(Equal(externalIP2 + "/32"))

				// It should now allow the range in the data plane.


====================
			})

		})

		Context("On BGP configuration changes from the syncer", func() {

			It("should only advertise external IPs within the configured ranges", func() {

				// Simulate an event from the syncer which sets the External IP range containing the first IP.

				rg.client.onExternalIPsUpdate([]string{externalIPRange1})

				rg.resyncKnownRoutes()

				// We should now advertise the first external IP, but not the second.

				Expect(rg.client.cache["/calico/staticroutes/"+externalIP1+"-32"]).To(Equal(externalIP1 + "/32"))

				Expect(rg.client.cache["/calico/staticroutes/"+externalIP2+"-32"]).To(BeEmpty())

				// It should also reject the full range into the data plane.

				Expect(rg.client.cache["/calico/rejectcidrs/"+strings.Replace(externalIPRange1, "/", "-", -1)]).To(Equal(externalIPRange1))

				// Simulate an event from the syncer which updates to use the second range (removing the first)

				rg.client.onExternalIPsUpdate([]string{externalIPRange2})

				rg.resyncKnownRoutes()

				// We should now advertise the second external IP, but not the first.

				Expect(rg.client.cache["/calico/staticroutes/"+externalIP1+"-32"]).To(BeEmpty())

				Expect(rg.client.cache["/calico/staticroutes/"+externalIP2+"-32"]).To(Equal(externalIP2 + "/32"))

				// It should now allow the range in the data plane.

				Expect(rg.client.cache["/calico/rejectcidrs/"+strings.Replace(externalIPRange1, "/", "-", -1)]).To(BeEmpty())


====================
		Context("On BGP configuration changes from the syncer", func() {

			It("should only advertise external IPs within the configured ranges", func() {

				// Simulate an event from the syncer which sets the External IP range containing the first IP.

				rg.client.onExternalIPsUpdate([]string{externalIPRange1})

				rg.resyncKnownRoutes()

				// We should now advertise the first external IP, but not the second.

				Expect(rg.client.cache["/calico/staticroutes/"+externalIP1+"-32"]).To(Equal(externalIP1 + "/32"))

				Expect(rg.client.cache["/calico/staticroutes/"+externalIP2+"-32"]).To(BeEmpty())

				// It should also reject the full range into the data plane.

				Expect(rg.client.cache["/calico/rejectcidrs/"+strings.Replace(externalIPRange1, "/", "-", -1)]).To(Equal(externalIPRange1))

				// Simulate an event from the syncer which updates to use the second range (removing the first)

				rg.client.onExternalIPsUpdate([]string{externalIPRange2})

				rg.resyncKnownRoutes()

				// We should now advertise the second external IP, but not the first.

				Expect(rg.client.cache["/calico/staticroutes/"+externalIP1+"-32"]).To(BeEmpty())

				Expect(rg.client.cache["/calico/staticroutes/"+externalIP2+"-32"]).To(Equal(externalIP2 + "/32"))

				// It should now allow the range in the data plane.

				Expect(rg.client.cache["/calico/rejectcidrs/"+strings.Replace(externalIPRange1, "/", "-", -1)]).To(BeEmpty())

			})

			It("should not advertise cluster IPs unless a range is specified", func() {


====================
				// We should now advertise the first external IP, but not the second.

				Expect(rg.client.cache["/calico/staticroutes/"+externalIP1+"-32"]).To(Equal(externalIP1 + "/32"))

				Expect(rg.client.cache["/calico/staticroutes/"+externalIP2+"-32"]).To(BeEmpty())

				// It should also reject the full range into the data plane.

				Expect(rg.client.cache["/calico/rejectcidrs/"+strings.Replace(externalIPRange1, "/", "-", -1)]).To(Equal(externalIPRange1))

				// Simulate an event from the syncer which updates to use the second range (removing the first)

				rg.client.onExternalIPsUpdate([]string{externalIPRange2})

				rg.resyncKnownRoutes()

				// We should now advertise the second external IP, but not the first.

				Expect(rg.client.cache["/calico/staticroutes/"+externalIP1+"-32"]).To(BeEmpty())

				Expect(rg.client.cache["/calico/staticroutes/"+externalIP2+"-32"]).To(Equal(externalIP2 + "/32"))

				// It should now allow the range in the data plane.

				Expect(rg.client.cache["/calico/rejectcidrs/"+strings.Replace(externalIPRange1, "/", "-", -1)]).To(BeEmpty())

			})

			It("should not advertise cluster IPs unless a range is specified", func() {

				// Show cluster CIDRs are advertised.

				rg.onSvcAdd(svc)

				rg.onEPAdd(ep)

				Expect(rg.client.cache["/calico/staticroutes/127.0.0.1-32"]).To(Equal("127.0.0.1/32"))

				// Withdraw the cluster CIDR from the syncer.


====================
				Expect(rg.client.cache["/calico/staticroutes/"+externalIP1+"-32"]).To(Equal(externalIP1 + "/32"))

				Expect(rg.client.cache["/calico/staticroutes/"+externalIP2+"-32"]).To(BeEmpty())

				// It should also reject the full range into the data plane.

				Expect(rg.client.cache["/calico/rejectcidrs/"+strings.Replace(externalIPRange1, "/", "-", -1)]).To(Equal(externalIPRange1))

				// Simulate an event from the syncer which updates to use the second range (removing the first)

				rg.client.onExternalIPsUpdate([]string{externalIPRange2})

				rg.resyncKnownRoutes()

				// We should now advertise the second external IP, but not the first.

				Expect(rg.client.cache["/calico/staticroutes/"+externalIP1+"-32"]).To(BeEmpty())

				Expect(rg.client.cache["/calico/staticroutes/"+externalIP2+"-32"]).To(Equal(externalIP2 + "/32"))

				// It should now allow the range in the data plane.

				Expect(rg.client.cache["/calico/rejectcidrs/"+strings.Replace(externalIPRange1, "/", "-", -1)]).To(BeEmpty())

			})

			It("should not advertise cluster IPs unless a range is specified", func() {

				// Show cluster CIDRs are advertised.

				rg.onSvcAdd(svc)

				rg.onEPAdd(ep)

				Expect(rg.client.cache["/calico/staticroutes/127.0.0.1-32"]).To(Equal("127.0.0.1/32"))

				// Withdraw the cluster CIDR from the syncer.

				rg.client.onClusterIPsUpdate([]string{})


====================
				// It should also reject the full range into the data plane.

				Expect(rg.client.cache["/calico/rejectcidrs/"+strings.Replace(externalIPRange1, "/", "-", -1)]).To(Equal(externalIPRange1))

				// Simulate an event from the syncer which updates to use the second range (removing the first)

				rg.client.onExternalIPsUpdate([]string{externalIPRange2})

				rg.resyncKnownRoutes()

				// We should now advertise the second external IP, but not the first.

				Expect(rg.client.cache["/calico/staticroutes/"+externalIP1+"-32"]).To(BeEmpty())

				Expect(rg.client.cache["/calico/staticroutes/"+externalIP2+"-32"]).To(Equal(externalIP2 + "/32"))

				// It should now allow the range in the data plane.

				Expect(rg.client.cache["/calico/rejectcidrs/"+strings.Replace(externalIPRange1, "/", "-", -1)]).To(BeEmpty())

			})

			It("should not advertise cluster IPs unless a range is specified", func() {

				// Show cluster CIDRs are advertised.

				rg.onSvcAdd(svc)

				rg.onEPAdd(ep)

				Expect(rg.client.cache["/calico/staticroutes/127.0.0.1-32"]).To(Equal("127.0.0.1/32"))

				// Withdraw the cluster CIDR from the syncer.

				rg.client.onClusterIPsUpdate([]string{})

				rg.resyncKnownRoutes()

				// We should no longer see cluster CIDRs to be advertised.


====================
				// We should no longer see cluster CIDRs to be advertised.

				Expect(rg.client.cache["/calico/staticroutes/127.0.0.1-32"]).To(BeEmpty())

			})

			// This test simulates a situation where BGPConfiguration has a /32 route that exactly matches

			// a Service route, resulting in two references to said route. It asserts that when the BGPConfiguration

			// is modified to remove that route, the service entry is still properly advertised.

			It("should handle duplicate prefixes BGPConfiguration and Service generated routes", func() {

				// Create a /32 CIDR for the services first externalIP.

				externalIPRangeSingle := fmt.Sprintf("%s/32", externalIP1)

				key := "/calico/staticroutes/" + externalIP1 + "-32"

				// Trigger programming of valid routes from the route generator for any known services.

				// We don't have a BGPConfiguration update yet, so we shouldn't receive any routes.

				By("Resyncing routes at start of test")

				rg.resyncKnownRoutes()

				Expect(rg.client.cache[key]).To(Equal(""))

				Expect(rg.client.programmedRouteRefCount[key]).To(Equal(0))

				// Simulate an event from the syncer which sets the External IP range containing only the service's externalIP.

				By("onExternalIPsUpdate to include /32 route")

				rg.client.onExternalIPsUpdate([]string{externalIPRangeSingle})

				// Expect that we advertise the /32 given to us via BGPConfiguration.


====================
			It("should handle /32 routes for LoadBalancerIPs", func() {

				// BeforeEach creates a service. Remove it before the test, since we want to start

				// this test without the service in place. svc3 is a LoadBalancer service with external traffic

				// policy of Local.

				err := rg.epIndexer.Delete(ep3)

				Expect(err).NotTo(HaveOccurred())

				err = rg.svcIndexer.Delete(svc3)

				Expect(err).NotTo(HaveOccurred())

				// The key we expect to be used for the LB IP.

				key := "/calico/staticroutes/" + loadBalancerIP1 + "-32"

				// Trigger programming of valid routes from the route generator for any known services.

				// We don't have a BGPConfiguration update or services yet, so we shouldn't receive any routes.

				By("Resyncing routes at start of test")

				rg.resyncKnownRoutes()

				Expect(rg.client.cache[key]).To(Equal(""))

				Expect(rg.client.programmedRouteRefCount[key]).To(Equal(0))

				// Simulate an event from the syncer which sets the LoadBalancer IP range containing only the service's loadBalancerIP.

				// We use a /32 route to trigger the situation under test.

				loadBalancerIPRangeSingle := fmt.Sprintf("%s/32", loadBalancerIP1)

				By("onLoadBalancerIPsUpdate to include /32 route")


====================
	data["src"] = t.StageFile.Name()

	tmpl, err := template.New("checkcmd").Parse(t.CheckCmd)

	if err != nil {

		return err

	}

	if err := tmpl.Execute(&cmdBuffer, data); err != nil {

		return err

	}

	log.Debug("Running checkcmd: " + cmdBuffer.String())

	c := exec.Command(t.shellCmd, "-c", cmdBuffer.String())

	output, err := c.CombinedOutput()

	if err != nil {

		log.Errorf("Error from checkcmd %q: %q", cmdBuffer.String(), string(output))

		return err

	}

	log.Debug(fmt.Sprintf("Output from checkcmd: %q", string(output)))

	return nil

}

// reload executes the reload command.

// It returns nil if the reload command returns 0.


====================
		return err

	}

	log.Debug(fmt.Sprintf("Output from checkcmd: %q", string(output)))

	return nil

}

// reload executes the reload command.

// It returns nil if the reload command returns 0.

func (t *TemplateResource) reload() error {

	log.Debug("Running reloadcmd: " + t.ReloadCmd)

	c := exec.Command(t.shellCmd, "-c", t.ReloadCmd)

	output, err := c.CombinedOutput()

	if err != nil {

		log.Error(fmt.Sprintf("Error from reloadcmd: %q", string(output)))

		return err

	}

	log.Debug(fmt.Sprintf("Output from reloadcmd: %q", string(output)))

	return nil

}

// process is a convenience function that wraps calls to the three main tasks

// required to keep local configuration files in sync. First we gather vars


====================
)

// VERSION is filled out during the build process (using git describe output)

var VERSION string

func main() {

	// Use the name of the binary to determine which routine to run.

	_, filename := filepath.Split(os.Args[0])

	switch filename {

	case "calico", "calico.exe":

		plugin.Main(VERSION)

	case "calico-ipam", "calico-ipam.exe":

		ipamplugin.Main(VERSION)

	case "install":

		err := install.Install()

		if err != nil {

			logrus.WithError(err).Fatal("Error installing CNI plugin")

		}

	default:

		panic("Unknown binary name: " + filename)

	}

}


====================
var VERSION string

func main() {

	// Use the name of the binary to determine which routine to run.

	_, filename := filepath.Split(os.Args[0])

	switch filename {

	case "calico", "calico.exe":

		plugin.Main(VERSION)

	case "calico-ipam", "calico-ipam.exe":

		ipamplugin.Main(VERSION)

	case "install":

		err := install.Install()

		if err != nil {

			logrus.WithError(err).Fatal("Error installing CNI plugin")

		}

	default:

		panic("Unknown binary name: " + filename)

	}

}

// Copyright (c) 2018 Tigera, Inc. All rights reserved.

// Licensed under the Apache License, Version 2.0 (the "License");


====================
		return

	}

	// Call the plugin. Will force a test failure if it hangs longer than 5s.

	session.Wait(5)

	exitCode = session.ExitCode()

	return

}

func Cmd(cmd string) string {

	_, _ = ginkgo.GinkgoWriter.Write([]byte(fmt.Sprintf("Running command [%s]\n", cmd)))

	out, err := exec.Command("bash", "-c", cmd).Output()

	if err != nil {

		_, writeErr := ginkgo.GinkgoWriter.Write(out)

		if writeErr != nil {

			panic(writeErr)

		}

		_, writeErr = ginkgo.GinkgoWriter.Write(err.(*exec.ExitError).Stderr)

		if writeErr != nil {

			panic(writeErr)

		}

		ginkgo.Fail("Command failed")


====================
	}

	log.Debugf("Set ClusterInformation: %v %v", ci, *ci.Spec.DatastoreReady)

}

// MustCreateNewIPPool creates a new Calico IPAM IP Pool.

func MustCreateNewIPPool(c client.Interface, cidr string, ipip, natOutgoing, ipam bool) string {

	return MustCreateNewIPPoolBlockSize(c, cidr, ipip, natOutgoing, ipam, 0)

}

// MustCreateNewIPPoolBlockSize creates a new Calico IPAM IP Pool with support for setting the block size.

func MustCreateNewIPPoolBlockSize(c client.Interface, cidr string, ipip, natOutgoing, ipam bool, blockSize int) string {

	name := strings.Replace(cidr, ".", "-", -1)

	name = strings.Replace(name, ":", "-", -1)

	name = strings.Replace(name, "/", "-", -1)

	var mode api.IPIPMode

	if ipip {

		mode = api.IPIPModeAlways

	} else {

		mode = api.IPIPModeNever

	}

	pool := api.NewIPPool()

	pool.Name = name


====================
	log.Debugf("Set ClusterInformation: %v %v", ci, *ci.Spec.DatastoreReady)

}

// MustCreateNewIPPool creates a new Calico IPAM IP Pool.

func MustCreateNewIPPool(c client.Interface, cidr string, ipip, natOutgoing, ipam bool) string {

	return MustCreateNewIPPoolBlockSize(c, cidr, ipip, natOutgoing, ipam, 0)

}

// MustCreateNewIPPoolBlockSize creates a new Calico IPAM IP Pool with support for setting the block size.

func MustCreateNewIPPoolBlockSize(c client.Interface, cidr string, ipip, natOutgoing, ipam bool, blockSize int) string {

	name := strings.Replace(cidr, ".", "-", -1)

	name = strings.Replace(name, ":", "-", -1)

	name = strings.Replace(name, "/", "-", -1)

	var mode api.IPIPMode

	if ipip {

		mode = api.IPIPModeAlways

	} else {

		mode = api.IPIPModeNever

	}

	pool := api.NewIPPool()

	pool.Name = name

	pool.Spec.CIDR = cidr


====================
}

// MustCreateNewIPPool creates a new Calico IPAM IP Pool.

func MustCreateNewIPPool(c client.Interface, cidr string, ipip, natOutgoing, ipam bool) string {

	return MustCreateNewIPPoolBlockSize(c, cidr, ipip, natOutgoing, ipam, 0)

}

// MustCreateNewIPPoolBlockSize creates a new Calico IPAM IP Pool with support for setting the block size.

func MustCreateNewIPPoolBlockSize(c client.Interface, cidr string, ipip, natOutgoing, ipam bool, blockSize int) string {

	name := strings.Replace(cidr, ".", "-", -1)

	name = strings.Replace(name, ":", "-", -1)

	name = strings.Replace(name, "/", "-", -1)

	var mode api.IPIPMode

	if ipip {

		mode = api.IPIPModeAlways

	} else {

		mode = api.IPIPModeNever

	}

	pool := api.NewIPPool()

	pool.Name = name

	pool.Spec.CIDR = cidr

	pool.Spec.NATOutgoing = natOutgoing


====================
	pool.Spec.IPIPMode = mode

	pool.Spec.BlockSize = blockSize

	_, err := c.IPPools().Create(context.Background(), pool, options.SetOptions{})

	if err != nil {

		panic(err)

	}

	return pool.Name

}

func MustDeleteIPPool(c client.Interface, cidr string) {

	name := strings.Replace(cidr, ".", "-", -1)

	name = strings.Replace(name, ":", "-", -1)

	name = strings.Replace(name, "/", "-", -1)

	_, err := c.IPPools().Delete(context.Background(), name, options.DeleteOptions{})

	if err != nil {

		panic(err)

	}

}

// Used for passing arguments to the CNI plugin.

type cniArgs struct {

	Env []string


====================
	pool.Spec.BlockSize = blockSize

	_, err := c.IPPools().Create(context.Background(), pool, options.SetOptions{})

	if err != nil {

		panic(err)

	}

	return pool.Name

}

func MustDeleteIPPool(c client.Interface, cidr string) {

	name := strings.Replace(cidr, ".", "-", -1)

	name = strings.Replace(name, ":", "-", -1)

	name = strings.Replace(name, "/", "-", -1)

	_, err := c.IPPools().Delete(context.Background(), name, options.DeleteOptions{})

	if err != nil {

		panic(err)

	}

}

// Used for passing arguments to the CNI plugin.

type cniArgs struct {

	Env []string

}


====================
	_, err := c.IPPools().Create(context.Background(), pool, options.SetOptions{})

	if err != nil {

		panic(err)

	}

	return pool.Name

}

func MustDeleteIPPool(c client.Interface, cidr string) {

	name := strings.Replace(cidr, ".", "-", -1)

	name = strings.Replace(name, ":", "-", -1)

	name = strings.Replace(name, "/", "-", -1)

	_, err := c.IPPools().Delete(context.Background(), name, options.DeleteOptions{})

	if err != nil {

		panic(err)

	}

}

// Used for passing arguments to the CNI plugin.

type cniArgs struct {

	Env []string

}

func (c *cniArgs) AsEnv() []string {


====================
}

// DeleteIPAM calls IPAM plugin to release the IP address.

// It also contains IPAM plugin specific logic based on the configured plugin,

// and is the logical counterpart to AddIPAM.

func DeleteIPAM(conf types.NetConf, args *skel.CmdArgs, logger *logrus.Entry) error {

	logger.Info("Calico CNI releasing IP address")

	logger.WithFields(logrus.Fields{"paths": os.Getenv("CNI_PATH"),

		"type": conf.IPAM.Type}).Debug("Looking for IPAM plugin in paths")

	var ae *azure.AzureEndpoint

	if conf.IPAM.Type == "host-local" {

		// We need to replace "usePodCidr" with a valid, but dummy podCidr string with "host-local" IPAM.

		// host-local IPAM releases the IP by ContainerID, so podCidr isn't really used to release the IP.

		// It just needs a valid CIDR, but it doesn't have to be the CIDR associated with the host.

		dummyPodCidrv4 := "0.0.0.0/0"

		dummyPodCidrv6 := "::/0"

		var stdinData map[string]interface{}

		err := json.Unmarshal(args.StdinData, &stdinData)

		if err != nil {

			return err

		}


====================
// DeleteIPAM calls IPAM plugin to release the IP address.

// It also contains IPAM plugin specific logic based on the configured plugin,

// and is the logical counterpart to AddIPAM.

func DeleteIPAM(conf types.NetConf, args *skel.CmdArgs, logger *logrus.Entry) error {

	logger.Info("Calico CNI releasing IP address")

	logger.WithFields(logrus.Fields{"paths": os.Getenv("CNI_PATH"),

		"type": conf.IPAM.Type}).Debug("Looking for IPAM plugin in paths")

	var ae *azure.AzureEndpoint

	if conf.IPAM.Type == "host-local" {

		// We need to replace "usePodCidr" with a valid, but dummy podCidr string with "host-local" IPAM.

		// host-local IPAM releases the IP by ContainerID, so podCidr isn't really used to release the IP.

		// It just needs a valid CIDR, but it doesn't have to be the CIDR associated with the host.

		dummyPodCidrv4 := "0.0.0.0/0"

		dummyPodCidrv6 := "::/0"

		var stdinData map[string]interface{}

		err := json.Unmarshal(args.StdinData, &stdinData)

		if err != nil {

			return err

		}

		logger.WithFields(logrus.Fields{"podCidrv4": dummyPodCidrv4,


====================
//

// To make sure that unknown fields are round-tripped, we manipulate the JSON as maps and slices rather than by

// unmarshaling it into a struct.  The structure of the JSON is as follows; we support replacing usePodCidr in

// either the "ipam" dict or its nested ranges section:

//

//	{

//	  "cniVersion": "%s",

//	  ...

//	  "ipam": {

//	    "type": "host-local",

//	    "subnet": "usePodCidr",

//	    "ranges": [

//	      [

//	         {

//	           "subnet": "usePodCidr"

//	         }

//	      ]

//	    ]

//	  }

//	  ...


====================
	}

	defer k.Close()

	// CreateKey creates a key named path under open key k.

	// CreateKey returns the new key and a boolean flag that reports whether the key already existed.

	tigeraK, _, err := registry.CreateKey(k, "tigera", registry.CREATE_SUB_KEY)

	if err != nil {

		return err

	}

	defer tigeraK.Close()

	calicoK, _, err := registry.CreateKey(tigeraK, "calico", registry.CREATE_SUB_KEY)

	if err != nil {

		return err

	}

	defer calicoK.Close()

	return nil

}

// Create key for deletion timestamps if not exists.

// Remove obsolete entries.

func maintainWepDeletionTimestamps(timeout int) error {

	if timeout == 0 {


====================
	})

	cniVersion := os.Getenv("CNI_SPEC_VERSION")

	Context("l2bridge network::using host-local IPAM", func() {

		var nsName, name string

		var clientset *kubernetes.Clientset

		netconf := fmt.Sprintf(`

	   		{

	   			"cniVersion": "%s",

	   			"name": "%s",

	   			"type": "calico",

	   			"etcd_endpoints": "%s",

	   			"datastore_type": "%s",

	   			"windows_use_single_network":true,

	   			"ipam": {

	   				"type": "host-local",

	   				"subnet": "10.254.112.0/20"

	   			},

	   			"kubernetes": {

	   				"k8s_api_root": "%s",

					"kubeconfig": "C:\\k\\config"


====================
		netconf := fmt.Sprintf(`

	   		{

	   			"cniVersion": "%s",

	   			"name": "%s",

	   			"type": "calico",

	   			"etcd_endpoints": "%s",

	   			"datastore_type": "%s",

	   			"windows_use_single_network":true,

	   			"ipam": {

	   				"type": "host-local",

	   				"subnet": "10.254.112.0/20"

	   			},

	   			"kubernetes": {

	   				"k8s_api_root": "%s",

					"kubeconfig": "C:\\k\\config"

	   			},

	   			"policy": {"type": "k8s"},

	   			"nodename_file_optional": true,

	   			"log_level":"debug"

	   		}`, cniVersion, networkName, os.Getenv("ETCD_ENDPOINTS"), os.Getenv("DATASTORE_TYPE"), os.Getenv("KUBERNETES_MASTER"))


====================
				Expect(containerEP.VirtualNetworkName).Should(Equal(hnsNetwork.Name))

				// Create network with new subnet

				podIP, subnet, _ := net.ParseCIDR("20.0.0.20/8")

				result.IPs[0].Address = *subnet

				result.IPs[0].Address.IP = podIP

				netconf2 := fmt.Sprintf(`

	   				{

	   					"cniVersion": "%s",

	   					"name": "%s",

	   					"type": "calico",

	   					"etcd_endpoints": "%s",

	   					"datastore_type": "%s",

	   					"windows_use_single_network":true,

	   					"ipam": {

	   						"type": "host-local",

	   						"subnet": "20.0.0.0/8"

	   					},

	   					"kubernetes": {

	   						"k8s_api_root": "%s",

							"kubeconfig": "C:\\k\\config"


====================
				netconf2 := fmt.Sprintf(`

	   				{

	   					"cniVersion": "%s",

	   					"name": "%s",

	   					"type": "calico",

	   					"etcd_endpoints": "%s",

	   					"datastore_type": "%s",

	   					"windows_use_single_network":true,

	   					"ipam": {

	   						"type": "host-local",

	   						"subnet": "20.0.0.0/8"

	   					},

	   					"kubernetes": {

	   						"k8s_api_root": "%s",

							"kubeconfig": "C:\\k\\config"

	   					},

	   					"policy": {"type": "k8s"},

	   					"nodename_file_optional": true,

	   					"log_level":"debug"

	   				}`, cniVersion, networkName, os.Getenv("ETCD_ENDPOINTS"), os.Getenv("DATASTORE_TYPE"), os.Getenv("KUBERNETES_MASTER"))


====================
				Expect(containerEP.VirtualNetworkName).Should(Equal(hnsNetwork.Name))

				// Create network with new subnet again

				podIP, subnet, _ = net.ParseCIDR("30.0.0.30/8")

				result.IPs[0].Address = *subnet

				result.IPs[0].Address.IP = podIP

				netconf3 := fmt.Sprintf(`

	   				{

	   					"cniVersion": "%s",

	   					"name": "%s",

	   					"type": "calico",

	   					"etcd_endpoints": "%s",

	   					"datastore_type": "%s",

	   					"windows_use_single_network":true,

	   					"ipam": {

	   						"type": "host-local",

	   						"subnet": "30.0.0.0/8"

	   					},

	   					"kubernetes": {

	   						"k8s_api_root": "%s",

							"kubeconfig": "C:\\k\\config"


====================
				netconf3 := fmt.Sprintf(`

	   				{

	   					"cniVersion": "%s",

	   					"name": "%s",

	   					"type": "calico",

	   					"etcd_endpoints": "%s",

	   					"datastore_type": "%s",

	   					"windows_use_single_network":true,

	   					"ipam": {

	   						"type": "host-local",

	   						"subnet": "30.0.0.0/8"

	   					},

	   					"kubernetes": {

	   						"k8s_api_root": "%s",

							"kubeconfig": "C:\\k\\config"

	   					},

	   					"policy": {"type": "k8s"},

	   					"nodename_file_optional": true,

	   					"log_level":"debug"

	   				}`, cniVersion, networkName, os.Getenv("ETCD_ENDPOINTS"), os.Getenv("DATASTORE_TYPE"), os.Getenv("KUBERNETES_MASTER"))


====================
		}{

			{

				description: "old-style inline subnet",

				cniVersion:  cniVersion,

				config: `

	   				{

	   					"cniVersion": "%s",

	   					"name": "%s",

	   					"nodename_file_optional": true,

	   					"type": "calico",

	   					"etcd_endpoints": "%s",

	   					"windows_use_single_network":true,

	   					"datastore_type": "%s",

	   					"ipam": {

	   						"type": "host-local",

	   						"subnet": "usePodCidr"

	   					},

	   					"kubernetes": {

	   						"k8s_api_root": "%s",

							"kubeconfig": "C:\\k\\config"


====================
	   				{

	   					"cniVersion": "%s",

	   					"name": "%s",

	   					"nodename_file_optional": true,

	   					"type": "calico",

	   					"etcd_endpoints": "%s",

	   					"windows_use_single_network":true,

	   					"datastore_type": "%s",

	   					"ipam": {

	   						"type": "host-local",

	   						"subnet": "usePodCidr"

	   					},

	   					"kubernetes": {

	   						"k8s_api_root": "%s",

							"kubeconfig": "C:\\k\\config"

	   					},

	   					"policy": {"type": "k8s"},

	   					"log_level":"debug"

	   				}`,

			},


====================
				log.Debugf("container IPs: %v", pod2IP)

				Expect(pod2IP).Should(Equal(expectedIP))

			})

		})

		Context("With DNS capability in CNI conf", func() {

			netconf = fmt.Sprintf(`

	   			{

	   				"cniVersion": "%s",

	   				"name": "%s",

	   				"type": "calico",

	   				"etcd_endpoints": "%s",

	   				"datastore_type": "%s",

	   				"windows_use_single_network":true,

	   				"ipam": {

	   					"type": "host-local",

	   					"subnet": "10.254.112.0/20"

	   				},

	   				"kubernetes": {

	   					"k8s_api_root": "%s",

						"kubeconfig": "C:\\k\\config"


====================
			netconf = fmt.Sprintf(`

	   			{

	   				"cniVersion": "%s",

	   				"name": "%s",

	   				"type": "calico",

	   				"etcd_endpoints": "%s",

	   				"datastore_type": "%s",

	   				"windows_use_single_network":true,

	   				"ipam": {

	   					"type": "host-local",

	   					"subnet": "10.254.112.0/20"

	   				},

	   				"kubernetes": {

	   					"k8s_api_root": "%s",

						"kubeconfig": "C:\\k\\config"

	   				},

	   				"policy": {"type": "k8s"},

	   				"nodename_file_optional": true,

	   				"log_level":"debug",

	   				"DNS":  {


====================
			ExpectWithOffset(1, ipamIPs[0].String()+"/32").To(Equal(endpointSpec.IPNetworks[0]))

		}

		var nsName string

		var clientset *kubernetes.Clientset

		BeforeEach(func() {

			// Create a network config.

			nc = types.NetConf{

				CNIVersion:              cniVersion,

				Name:                    networkName,

				Type:                    "calico",

				EtcdEndpoints:           os.Getenv("ETCD_ENDPOINTS"),

				DatastoreType:           os.Getenv("DATASTORE_TYPE"),

				Kubernetes:              types.Kubernetes{K8sAPIRoot: os.Getenv("KUBERNETES_MASTER"), Kubeconfig: "C:\\k\\config"},

				Policy:                  types.Policy{PolicyType: "k8s"},

				NodenameFileOptional:    true,

				LogLevel:                "info",

				WindowsUseSingleNetwork: true,

			}

			nc.IPAM.Type = "calico-ipam"

			ncb, err := json.Marshal(nc)


====================
				Type:                    "calico",

				EtcdEndpoints:           os.Getenv("ETCD_ENDPOINTS"),

				DatastoreType:           os.Getenv("DATASTORE_TYPE"),

				Kubernetes:              types.Kubernetes{K8sAPIRoot: os.Getenv("KUBERNETES_MASTER"), Kubeconfig: "C:\\k\\config"},

				Policy:                  types.Policy{PolicyType: "k8s"},

				NodenameFileOptional:    true,

				LogLevel:                "info",

				WindowsUseSingleNetwork: true,

			}

			nc.IPAM.Type = "calico-ipam"

			ncb, err := json.Marshal(nc)

			if err != nil {

				panic(err)

			}

			netconf = string(ncb)

			testutils.WipeK8sPods(netconf)

			conf := types.NetConf{}

			if err := json.Unmarshal([]byte(netconf), &conf); err != nil {

				panic(err)

			}


====================
		})

	})

	Context("l2bridge network::With a /29 IPAM blockSize", func() {

		var nsName string

		var clientset *kubernetes.Clientset

		netconf := fmt.Sprintf(`

		{

			"cniVersion": "%s",

			"name": "%s",

			"type": "calico",

			"etcd_endpoints": "%s",

			"datastore_type": "%s",

			"nodename_file_optional": true,

			"windows_use_single_network":true,

			"log_level": "debug",

			"ipam": {

				"type": "calico-ipam"

			},

			"kubernetes": {

				"k8s_api_root": "%s",


====================
			"cniVersion": "%s",

			"name": "%s",

			"type": "calico",

			"etcd_endpoints": "%s",

			"datastore_type": "%s",

			"nodename_file_optional": true,

			"windows_use_single_network":true,

			"log_level": "debug",

			"ipam": {

				"type": "calico-ipam"

			},

			"kubernetes": {

				"k8s_api_root": "%s",

				"kubeconfig": "C:\\k\\config"

			},

			"policy": {"type": "k8s"}

		}`, cniVersion, networkName, os.Getenv("ETCD_ENDPOINTS"), os.Getenv("DATASTORE_TYPE"), os.Getenv("KUBERNETES_MASTER"))

		BeforeEach(func() {

			testutils.WipeK8sPods(netconf)

			// Create a new ipPool.


====================
		var nsName string

		var nwsName []string

		lastNWName := ""

		var nwName string

		var clientset *kubernetes.Clientset

		netconf := fmt.Sprintf(`

		{

			"cniVersion": "%s",

			"name": "%s",

			"type": "calico",

			"etcd_endpoints": "%s",

			"datastore_type": "%s",

			"nodename_file_optional": true,

			"log_level": "debug",

			"ipam": {

				"type": "calico-ipam"

			},

			"kubernetes": {

				"k8s_api_root": "%s",

				"kubeconfig": "C:\\k\\config"


====================
		{

			"cniVersion": "%s",

			"name": "%s",

			"type": "calico",

			"etcd_endpoints": "%s",

			"datastore_type": "%s",

			"nodename_file_optional": true,

			"log_level": "debug",

			"ipam": {

				"type": "calico-ipam"

			},

			"kubernetes": {

				"k8s_api_root": "%s",

				"kubeconfig": "C:\\k\\config"

			},

			"policy": {"type": "k8s"}

		}`, cniVersion, networkName, os.Getenv("ETCD_ENDPOINTS"), os.Getenv("DATASTORE_TYPE"), os.Getenv("KUBERNETES_MASTER"))

		BeforeEach(func() {

			Skip("Calico for Windows does not support multiple network. Skip test...")

			testutils.WipeK8sPods(netconf)


====================
		})

	})

	Context("l2bridge network::With DNS capability in Runtime Config", func() {

		var nsName, name string

		var clientset *kubernetes.Clientset

		netconf := fmt.Sprintf(`

                        {

                                "cniVersion": "%s",

                                "name": "%s",

                                "type": "calico",

                                "etcd_endpoints": "%s",

                                "datastore_type": "%s",

                                "windows_use_single_network":true,

                                "ipam": {

                                        "type": "host-local",

                                        "subnet": "10.254.112.0/20"

                                },

                                "kubernetes": {

                                        "k8s_api_root": "%s",

                                        "kubeconfig": "C:\\k\\config"


====================
		netconf := fmt.Sprintf(`

                        {

                                "cniVersion": "%s",

                                "name": "%s",

                                "type": "calico",

                                "etcd_endpoints": "%s",

                                "datastore_type": "%s",

                                "windows_use_single_network":true,

                                "ipam": {

                                        "type": "host-local",

                                        "subnet": "10.254.112.0/20"

                                },

                                "kubernetes": {

                                        "k8s_api_root": "%s",

                                        "kubeconfig": "C:\\k\\config"

                                },

                                "policy": {"type": "k8s"},

                                "nodename_file_optional": true,

                                "log_level":"debug",

                                "DNS":  {


====================
		})

	})

	Context("overlay network::using host-local IPAM", func() {

		var nsName, name string

		var clientset *kubernetes.Clientset

		vxlanConf := fmt.Sprintf(`

		{

			"cniVersion": "%s",

			"name": "%s",

			"type": "calico",

			"mode": "vxlan",

			"vxlan_mac_prefix": "%s",

			"vxlan_vni": 4096,

			"etcd_endpoints": "%s",

			"datastore_type": "%s",

			"windows_use_single_network":true,

			"ipam": {

				"type": "host-local",

				"subnet": "10.254.112.0/20"

			},


====================
			"name": "%s",

			"type": "calico",

			"mode": "vxlan",

			"vxlan_mac_prefix": "%s",

			"vxlan_vni": 4096,

			"etcd_endpoints": "%s",

			"datastore_type": "%s",

			"windows_use_single_network":true,

			"ipam": {

				"type": "host-local",

				"subnet": "10.254.112.0/20"

			},

			"kubernetes": {

				"k8s_api_root": "%s",

				"kubeconfig": "C:\\k\\config"

			},

			"policy": {"type": "k8s"},

			"nodename_file_optional": true,

			"log_level":"debug"

		}`, cniVersion, networkName, os.Getenv("MAC_PREFIX"), os.Getenv("ETCD_ENDPOINTS"), os.Getenv("DATASTORE_TYPE"), os.Getenv("KUBERNETES_MASTER"))


====================
	})

	Context("overlay network:: Pod DEL timestamp", func() {

		var nsName, name string

		var clientset *kubernetes.Clientset

		// Set windows_pod_deletion_timestamp_timeout to 10 seconds

		vxlanConf := fmt.Sprintf(`

		{

			"cniVersion": "%s",

			"name": "%s",

			"type": "calico",

			"mode": "vxlan",

			"vxlan_mac_prefix": "%s",

			"vxlan_vni": 4096,

			"etcd_endpoints": "%s",

			"datastore_type": "%s",

			"windows_use_single_network":true,

			"windows_pod_deletion_timestamp_timeout": 12,

			"ipam": {

				"type": "host-local",

				"subnet": "10.254.112.0/20"


====================
			"type": "calico",

			"mode": "vxlan",

			"vxlan_mac_prefix": "%s",

			"vxlan_vni": 4096,

			"etcd_endpoints": "%s",

			"datastore_type": "%s",

			"windows_use_single_network":true,

			"windows_pod_deletion_timestamp_timeout": 12,

			"ipam": {

				"type": "host-local",

				"subnet": "10.254.112.0/20"

			},

			"kubernetes": {

				"k8s_api_root": "%s",

				"kubeconfig": "C:\\k\\config"

			},

			"policy": {"type": "k8s"},

			"nodename_file_optional": true,

			"log_level":"debug"

		}`, cniVersion, networkName, os.Getenv("MAC_PREFIX"), os.Getenv("ETCD_ENDPOINTS"), os.Getenv("DATASTORE_TYPE"), os.Getenv("KUBERNETES_MASTER"))


====================
					Expect(ip6Mask).Should(Equal("ffffffffffffffffffffffffffffffc0"))

				}

				_, _, exitCode := testutils.RunIPAMPlugin(netconf, "DEL", "", cid, cniVersion)

				Expect(exitCode).Should(Equal(0))

			},

			Entry("IPAM with no configuration", true, false, fmt.Sprintf(`

            {

              "cniVersion": "%s",

              "name": "net1",

              "type": "calico",

              "etcd_endpoints": "http://%s:2379",

              "kubernetes": {

                  "kubeconfig": "/home/user/certs/kubeconfig"

              },

              "log_level": "debug",

              "datastore_type": "%s",

              "ipam": {

                "type": "%s"

              }

            }`, cniVersion, os.Getenv("ETCD_IP"), os.Getenv("DATASTORE_TYPE"), plugin)),


====================
              "datastore_type": "%s",

              "ipam": {

                "type": "%s"

              }

            }`, cniVersion, os.Getenv("ETCD_IP"), os.Getenv("DATASTORE_TYPE"), plugin)),

			Entry("IPAM with IPv4 (explicit)", true, false, fmt.Sprintf(`

            {

              "cniVersion": "%s",

              "name": "net1",

              "type": "calico",

              "etcd_endpoints": "http://%s:2379",

              "kubernetes": {

                 "kubeconfig": "/home/user/certs/kubeconfig"

                  },

              "datastore_type": "%s",

              "ipam": {

                "type": "%s",

                "assign_ipv4": "true"

              }

            }`, cniVersion, os.Getenv("ETCD_IP"), os.Getenv("DATASTORE_TYPE"), plugin)),


====================
              "ipam": {

                "type": "%s",

                "assign_ipv4": "true"

              }

            }`, cniVersion, os.Getenv("ETCD_IP"), os.Getenv("DATASTORE_TYPE"), plugin)),

			Entry("IPAM with IPv6 only", false, true, fmt.Sprintf(`

            {

              "cniVersion": "%s",

              "name": "net1",

              "type": "calico",

              "etcd_endpoints": "http://%s:2379",

              "kubernetes": {

                 "kubeconfig": "/home/user/certs/kubeconfig"

              },

              "datastore_type": "%s",

              "ipam": {

                "type": "%s",

                "assign_ipv4": "false",

                "assign_ipv6": "true"

              }


====================
                "type": "%s",

                "assign_ipv4": "false",

                "assign_ipv6": "true"

              }

            }`, cniVersion, os.Getenv("ETCD_IP"), os.Getenv("DATASTORE_TYPE"), plugin)),

			Entry("IPAM with IPv4 and IPv6", true, true, fmt.Sprintf(`

            {

              "cniVersion": "%s",

              "name": "net1",

              "type": "calico",

              "etcd_endpoints": "http://%s:2379",

              "kubernetes": {

                 "kubeconfig": "/home/user/certs/kubeconfig"

              },

              "datastore_type": "%s",

              "log_level": "debug",

              "ipam": {

                "type": "%s",

                "assign_ipv4": "true",

                "assign_ipv6": "true"


====================
		Context("With no IPv4 pool", func() {

			It("Should not assign an IPv6 address in a dual stack configuration", func() {

				// Delete IPv6 pool.

				testutils.MustDeleteIPPool(calicoClient, "fd80:24e2:f998:72d6::/64")

				// Assign an IP to fill up the pool

				netconf := fmt.Sprintf(`

            {

              "cniVersion": "%s",

              "name": "net1",

              "type": "calico",

              "etcd_endpoints": "http://%s:2379",

              "kubernetes": {

                 "kubeconfig": "/home/user/certs/kubeconfig"

              },

              "datastore_type": "%s",

              "log_level": "debug",

              "ipam": {

                "type": "%s",

                "assign_ipv4": "true",

                "assign_ipv6": "true"


====================
		Context("With no IPv6 pool", func() {

			It("Should not assign an IPv4 address in a dual stack configuration", func() {

				// Delete IPv4 pool.

				testutils.MustDeleteIPPool(calicoClient, defaultIPv4Pool)

				// Assign an IP to fill up the pool

				netconf := fmt.Sprintf(`

            {

              "cniVersion": "%s",

              "name": "net1",

              "type": "calico",

              "etcd_endpoints": "http://%s:2379",

              "kubernetes": {

                 "kubeconfig": "/home/user/certs/kubeconfig"

              },

              "datastore_type": "%s",

              "log_level": "debug",

              "ipam": {

                "type": "%s",

                "assign_ipv4": "true",

                "assign_ipv6": "true"


====================
		})

	})

	Describe("Run IPAM plugin - Verify IP Pools", func() {

		Context("Pass valid pools", func() {

			It("Uses the ipv4 pool", func() {

				netconf := fmt.Sprintf(`

                {

                  "cniVersion": "%s",

                  "name": "net1",

                  "type": "calico",

                  "etcd_endpoints": "http://%s:2379",

                  "kubernetes": {

                    "kubeconfig": "/home/user/certs/kubeconfig"

                    },

                  "datastore_type": "%s",

                  "ipam": {

                    "type": "%s",

                    "assign_ipv4": "true",

                    "ipv4_pools": [ "192.168.0.0/16" ]

                    }


====================
			})

		})

		Context("Pass more than one pool", func() {

			It("Uses one of the ipv4 pools", func() {

				testutils.MustCreateNewIPPool(calicoClient, "192.169.1.0/24", false, false, true)

				netconf := fmt.Sprintf(`

                {

                      "cniVersion": "%s",

                      "name": "net1",

                      "type": "calico",

                      "etcd_endpoints": "http://%s:2379",

                        "kubernetes": {

                           "kubeconfig": "/home/user/certs/kubeconfig"

                      },

                      "datastore_type": "%s",

                      "ipam": {

                        "type": "%s",

                        "assign_ipv4": "true",

                        "ipv4_pools": [ "192.169.1.0/24", "192.168.0.0/16" ]

                      }


====================
				Expect(result.IPs[0].Address.IP.String()).Should(Or(HavePrefix("192.168."), HavePrefix("192.169.1")))

			})

		})

		Context("Disabled IP pool", func() {

			It("Never allocates from the disabled pool", func() {

				netconf := fmt.Sprintf(`

                {

                      "cniVersion": "%s",

                      "name": "net1",

                      "type": "calico",

                      "etcd_endpoints": "http://%s:2379",

                        "kubernetes": {

                         "kubeconfig": "/home/user/certs/kubeconfig"

                      },

                      "datastore_type": "%s",

                      "ipam": {

                        "type": "%s",

                        "assign_ipv4": "true"

                      }

                }`, cniVersion, os.Getenv("ETCD_IP"), os.Getenv("DATASTORE_TYPE"), plugin)


====================
			})

		})

		Context("Pass an invalid pool", func() {

			It("fails to get an IP", func() {

				// Put the bogus pool last in the array

				netconf := fmt.Sprintf(`

                    {

                      "cniVersion": "%s",

                      "name": "net1",

                      "type": "calico",

                      "etcd_endpoints": "http://%s:2379",

                        "kubernetes": {

                         "kubeconfig": "/home/user/certs/kubeconfig"

                      },

                      "datastore_type": "%s",

                      "ipam": {

                        "type": "%s",

                        "assign_ipv4": "true",

                        "ipv4_pools": [ "192.168.0.0/16", "192.169.1.0/24" ]

                      }


====================
				_, err, _ := testutils.RunIPAMPlugin(netconf, "ADD", "", cid, cniVersion)

				Expect(err.Msg).Should(ContainSubstring("192.169.1.0/24) does not exist"))

			})

			It("fails to get an IP", func() {

				// Put the bogus pool first in the array

				netconf := fmt.Sprintf(`

                    {

                      "cniVersion": "%s",

                      "name": "net1",

                      "type": "calico",

                      "etcd_endpoints": "http://%s:2379",

                        "kubernetes": {

                         "kubeconfig": "/home/user/certs/kubeconfig"

                      },

                      "datastore_type": "%s",

                      "ipam": {

                        "type": "%s",

                        "assign_ipv4": "true",

                        "ipv4_pools": [ "192.168.0.0/16", "192.169.1.0/24" ]

                      }


====================
				Expect(err.Msg).Should(ContainSubstring("192.169.1.0/24) does not exist"))

			})

		})

	})

	Describe("Requesting an explicit IP address", func() {

		netconf := fmt.Sprintf(`

                    {

                      "cniVersion": "%s",

                      "name": "net1",

                      "type": "calico",

                      "etcd_endpoints": "http://%s:2379",

                      "kubernetes": {

                        "kubeconfig": "/home/user/certs/kubeconfig"

                      },

                      "datastore_type": "%s",

                      "ipam": {

                        "type": "%s"

                      }

                    }`, cniVersion, os.Getenv("ETCD_IP"), os.Getenv("DATASTORE_TYPE"), plugin)

		Context("Pass explicit IP address", func() {


====================
				Expect(exitCode).Should(BeNumerically(">", 0))

			})

		})

	})

	Describe("Run IPAM DEL", func() {

		netconf := fmt.Sprintf(`

                    {

                      "cniVersion": "%s",

                      "name": "net1",

                      "type": "calico",

                      "etcd_endpoints": "http://%s:2379",

                      "kubernetes": {

                        "kubeconfig": "/home/user/certs/kubeconfig"

                      },

                      "datastore_type": "%s",

                      "ipam": {

                        "type": "%s"

                      }

                    }`, cniVersion, os.Getenv("ETCD_IP"), os.Getenv("DATASTORE_TYPE"), plugin)

		It("should exit successfully even if no address exists", func() {


====================
		Expect(err).NotTo(HaveOccurred())

	})

	cniVersion := os.Getenv("CNI_SPEC_VERSION")

	Expect(cniVersion).NotTo(BeEmpty())

	Context("using host-local IPAM", func() {

		netconf := fmt.Sprintf(`

			{

			  "cniVersion": "%s",

			  "name": "net1",

			  "type": "calico",

			  "etcd_endpoints": "http://%s:2379",

			  "datastore_type": "%s",

			  "ipam": {

			    "type": "host-local",

			    "subnet": "10.0.0.0/8"

			  },

			  "kubernetes": {

			    "kubeconfig": "/home/user/certs/kubeconfig"

			  },

			  "policy": {"type": "k8s"},


====================
	Context("using host-local IPAM", func() {

		netconf := fmt.Sprintf(`

			{

			  "cniVersion": "%s",

			  "name": "net1",

			  "type": "calico",

			  "etcd_endpoints": "http://%s:2379",

			  "datastore_type": "%s",

			  "ipam": {

			    "type": "host-local",

			    "subnet": "10.0.0.0/8"

			  },

			  "kubernetes": {

			    "kubeconfig": "/home/user/certs/kubeconfig"

			  },

			  "policy": {"type": "k8s"},

			  "nodename_file_optional": true,

			  "log_level":"debug"

			}`, cniVersion, os.Getenv("ETCD_IP"), os.Getenv("DATASTORE_TYPE"))

		It("successfully networks the namespace", func() {


====================
				_, err = testutils.DeleteContainer(netconf, contNs.Path(), name, testutils.K8S_TEST_NS)

				Expect(err).ShouldNot(HaveOccurred())

			})

		})

		Context("when /var/lib/calico/mtu file exists", func() {

			mtuNetconfTemplate := `

			{

			  "cniVersion": "%s",

			  "name": "net1",

			  "type": "calico",

			  "etcd_endpoints": "http://%s:2379",

			  "datastore_type": "%s",

			  "ipam": {

			    "type": "host-local",

			    "subnet": "10.0.0.0/8"

			  },

			  "kubernetes": {

			    "kubeconfig": "/home/user/certs/kubeconfig"

			  },

			  "policy": {"type": "k8s"},


====================
		Context("when /var/lib/calico/mtu file exists", func() {

			mtuNetconfTemplate := `

			{

			  "cniVersion": "%s",

			  "name": "net1",

			  "type": "calico",

			  "etcd_endpoints": "http://%s:2379",

			  "datastore_type": "%s",

			  "ipam": {

			    "type": "host-local",

			    "subnet": "10.0.0.0/8"

			  },

			  "kubernetes": {

			    "kubeconfig": "/home/user/certs/kubeconfig"

			  },

			  "policy": {"type": "k8s"},

			  "nodename_file_optional": true,

			  "log_level":"info"

			}`

			It("should create pods with the right MTU", func() {


====================
				_, err = testutils.DeleteContainer(mtuNetconf1, contNs1.Path(), name1, testutils.K8S_TEST_NS)

				Expect(err).ShouldNot(HaveOccurred())

			})

		})

		Context("when calico-config contains a custom mtu", func() {

			mtuNetconfTemplate := `

			{

			  "cniVersion": "%s",

			  "name": "net1",

			  "type": "calico",

			  "etcd_endpoints": "http://%s:2379",

			  "datastore_type": "%s",

			  "mtu": %d,

			  "ipam": {

			    "type": "host-local",

			    "subnet": "10.0.0.0/8"

			  },

			  "kubernetes": {

			    "kubeconfig": "/home/user/certs/kubeconfig"

			  },


====================
			mtuNetconfTemplate := `

			{

			  "cniVersion": "%s",

			  "name": "net1",

			  "type": "calico",

			  "etcd_endpoints": "http://%s:2379",

			  "datastore_type": "%s",

			  "mtu": %d,

			  "ipam": {

			    "type": "host-local",

			    "subnet": "10.0.0.0/8"

			  },

			  "kubernetes": {

			    "kubeconfig": "/home/user/certs/kubeconfig"

			  },

			  "policy": {"type": "k8s"},

			  "nodename_file_optional": true,

			  "log_level":"info"

			}`

			It("creates pods with the new mtu", func() {


====================
		}{

			{

				description: "old-style inline subnet",

				cniVersion:  cniVersion,

				config: `

					{

					  "cniVersion": "%s",

					  "name": "net6",

					  "nodename_file_optional": true,

					  "type": "calico",

					  "etcd_endpoints": "http://%s:2379",

					  "datastore_type": "%s",

					  "ipam": {

					    "type": "host-local",

					    "subnet": "usePodCidr"

					  },

					  "kubernetes": {

                                           "kubeconfig": "/home/user/certs/kubeconfig"

					  },

					  "policy": {"type": "k8s"},


====================
				config: `

					{

					  "cniVersion": "%s",

					  "name": "net6",

					  "nodename_file_optional": true,

					  "type": "calico",

					  "etcd_endpoints": "http://%s:2379",

					  "datastore_type": "%s",

					  "ipam": {

					    "type": "host-local",

					    "subnet": "usePodCidr"

					  },

					  "kubernetes": {

                                           "kubeconfig": "/home/user/certs/kubeconfig"

					  },

					  "policy": {"type": "k8s"},

					  "log_level":"info"

					}`,

				expectedV4Routes: []string{

					regexp.QuoteMeta("default via 169.254.1.1 dev eth0"),


====================
			{

				// This scenario tests IPv4+IPv6 without specifying any routes.

				description: "new-style with IPv4 and IPv6 ranges, no routes",

				cniVersion:  "0.3.1",

				config: `

					{

					  "cniVersion": "%s",

					  "name": "net6",

					  "nodename_file_optional": true,

					  "type": "calico",

					  "etcd_endpoints": "http://%s:2379",

					  "datastore_type": "%s",

					  "ipam": {

					    "type": "host-local",

					    "ranges": [

					       [

					         {

					           "subnet": "usePodCidr"

					         }

					       ],


====================
				config: `

					{

					  "cniVersion": "%s",

					  "name": "net6",

					  "nodename_file_optional": true,

					  "type": "calico",

					  "etcd_endpoints": "http://%s:2379",

					  "datastore_type": "%s",

					  "ipam": {

					    "type": "host-local",

					    "ranges": [

					       [

					         {

					           "subnet": "usePodCidr"

					         }

					       ],

					       [

					         {

					           "subnet": "dead:beef::/96"

					         }


====================
			{

				// This scenario tests IPv4+IPv6 without specifying any routes.

				description: "new-style with IPv4 and IPv6 both using usePodCidr, no routes",

				cniVersion:  "0.3.1",

				config: `

					{

					  "cniVersion": "%s",

					  "name": "net6",

					  "nodename_file_optional": true,

					  "type": "calico",

					  "etcd_endpoints": "http://%s:2379",

					  "datastore_type": "%s",

					  "ipam": {

					    "type": "host-local",

					    "ranges": [

					       [

					         {

					           "subnet": "usePodCidr"

					         }

					       ],


====================
				config: `

					{

					  "cniVersion": "%s",

					  "name": "net6",

					  "nodename_file_optional": true,

					  "type": "calico",

					  "etcd_endpoints": "http://%s:2379",

					  "datastore_type": "%s",

					  "ipam": {

					    "type": "host-local",

					    "ranges": [

					       [

					         {

					           "subnet": "usePodCidr"

					         }

					       ],

					       [

					         {

					           "subnet": "usePodCidrIPv6"

					         }


====================
				// This configuration is only supported for CNI version >= 0.3.0 since we assign multiple

				// addresses per family.

				description: "new-style with IPv4 and IPv6 ranges and routes",

				cniVersion:  "0.3.1",

				config: `

					{

					  "cniVersion": "%s",

					  "name": "net6",

					  "nodename_file_optional": true,

					  "type": "calico",

					  "etcd_endpoints": "http://%s:2379",

					  "datastore_type": "%s",

					  "ipam": {

					    "type": "host-local",

					    "ranges": [

					       [

					         {

					           "subnet": "usePodCidr"

					         }

					       ],


====================
				config: `

					{

					  "cniVersion": "%s",

					  "name": "net6",

					  "nodename_file_optional": true,

					  "type": "calico",

					  "etcd_endpoints": "http://%s:2379",

					  "datastore_type": "%s",

					  "ipam": {

					    "type": "host-local",

					    "ranges": [

					       [

					         {

					           "subnet": "usePodCidr"

					         }

					       ],

					       [

					         {

					             "subnet": "10.100.0.0/24"

					         }


====================
				// - we use multiple ranges, one of which is IPv6, the other uses the podCIDR

				// - we add custom routes, but configure the plugin to also include our default routes.

				description: "new-style with IPv4 and IPv6 ranges and routes and Calico default routes",

				cniVersion:  "0.3.1",

				config: `

					{

					  "cniVersion": "%s",

					  "name": "net6",

					  "nodename_file_optional": true,

					  "type": "calico",

					  "etcd_endpoints": "http://%s:2379",

					  "include_default_routes": true,

					  "datastore_type": "%s",

					  "ipam": {

					    "type": "host-local",

					    "ranges": [

					       [

					           {

					             "subnet": "usePodCidr"

					           }


====================
					{

					  "cniVersion": "%s",

					  "name": "net6",

					  "nodename_file_optional": true,

					  "type": "calico",

					  "etcd_endpoints": "http://%s:2379",

					  "include_default_routes": true,

					  "datastore_type": "%s",

					  "ipam": {

					    "type": "host-local",

					    "ranges": [

					       [

					           {

					             "subnet": "usePodCidr"

					           }

					       ],

					       [

					           {

					               "subnet": "10.100.0.0/24"

					           }


====================
						defer GinkgoRecover()

						out, err := exec.Command("ip", "route", "show").Output()

						Expect(err).NotTo(HaveOccurred())

						for _, r := range c.expectedV4Routes {

							Expect(string(out)).To(MatchRegexp(r))

						}

						if c.unexpectedRoute != "" {

							Expect(string(out)).NotTo(ContainSubstring(c.unexpectedRoute))

						}

						out, err = exec.Command("ip", "-6", "route", "show").Output()

						Expect(err).NotTo(HaveOccurred())

						for _, r := range c.expectedV6Routes {

							Expect(string(out)).To(MatchRegexp(r))

						}

						if c.numIPv6IPs > 0 {

							err := testutils.CheckSysctlValue("/proc/sys/net/ipv6/conf/eth0/accept_dad", "0")

							Expect(err).NotTo(HaveOccurred())

						}

						out, err = exec.Command("ip", "addr", "show").Output()

						Expect(err).NotTo(HaveOccurred())


====================
						defer GinkgoRecover()

						out, err := exec.Command("ip", "route", "show").Output()

						Expect(err).NotTo(HaveOccurred())

						for _, r := range c.expectedV4Routes {

							Expect(string(out)).To(MatchRegexp(r))

						}

						if c.unexpectedRoute != "" {

							Expect(string(out)).NotTo(ContainSubstring(c.unexpectedRoute))

						}

						out, err = exec.Command("ip", "-6", "route", "show").Output()

						Expect(err).NotTo(HaveOccurred())

						for _, r := range c.expectedV6Routes {

							Expect(string(out)).To(MatchRegexp(r))

						}

						if c.numIPv6IPs > 0 {

							err := testutils.CheckSysctlValue("/proc/sys/net/ipv6/conf/eth0/accept_dad", "0")

							Expect(err).NotTo(HaveOccurred())

						}

						out, err = exec.Command("ip", "addr", "show").Output()

						Expect(err).NotTo(HaveOccurred())


====================
		pool2 := "60.70.0.0/28"

		numAddrsInPool := 16

		var clientset *kubernetes.Clientset

		var testNS string

		BeforeEach(func() {

			// Build the network config for this set of tests.

			nc = types.NetConf{

				CNIVersion:           cniVersion,

				Name:                 "calico-uts",

				Type:                 "calico",

				EtcdEndpoints:        fmt.Sprintf("http://%s:2379", os.Getenv("ETCD_IP")),

				DatastoreType:        os.Getenv("DATASTORE_TYPE"),

				Kubernetes:           types.Kubernetes{Kubeconfig: "/home/user/certs/kubeconfig"},

				Policy:               types.Policy{PolicyType: "k8s"},

				NodenameFileOptional: true,

				LogLevel:             "info",

			}

			nc.IPAM.Type = "calico-ipam"

			ncb, err := json.Marshal(nc)

			Expect(err).NotTo(HaveOccurred())


====================
				Name:                 "calico-uts",

				Type:                 "calico",

				EtcdEndpoints:        fmt.Sprintf("http://%s:2379", os.Getenv("ETCD_IP")),

				DatastoreType:        os.Getenv("DATASTORE_TYPE"),

				Kubernetes:           types.Kubernetes{Kubeconfig: "/home/user/certs/kubeconfig"},

				Policy:               types.Policy{PolicyType: "k8s"},

				NodenameFileOptional: true,

				LogLevel:             "info",

			}

			nc.IPAM.Type = "calico-ipam"

			ncb, err := json.Marshal(nc)

			Expect(err).NotTo(HaveOccurred())

			netconf = string(ncb)

			// Create IP Pools.

			testutils.MustCreateNewIPPoolBlockSize(calicoClient, pool1, false, false, true, 29)

			_, pool1CIDR, err = net.ParseCIDR(pool1)

			Expect(err).NotTo(HaveOccurred())

			testutils.MustCreateNewIPPoolBlockSize(calicoClient, pool2, false, false, true, 29)

			_, pool2CIDR, err = net.ParseCIDR(pool2)

			Expect(err).NotTo(HaveOccurred())


====================
		var ipPoolCIDR *net.IPNet

		pool1 := "50.70.0.0/16"

		var clientset *kubernetes.Clientset

		var testNS string

		BeforeEach(func() {

			// Build the network config for this set of tests.

			nc = types.NetConf{

				CNIVersion:           cniVersion,

				Name:                 "calico-uts",

				Type:                 "calico",

				EtcdEndpoints:        fmt.Sprintf("http://%s:2379", os.Getenv("ETCD_IP")),

				DatastoreType:        os.Getenv("DATASTORE_TYPE"),

				Kubernetes:           types.Kubernetes{Kubeconfig: "/home/user/certs/kubeconfig"},

				Policy:               types.Policy{PolicyType: "k8s"},

				NodenameFileOptional: true,

				LogLevel:             "info",

			}

			nc.IPAM.Type = "calico-ipam"

			ncb, err := json.Marshal(nc)

			Expect(err).NotTo(HaveOccurred())


====================
				Name:                 "calico-uts",

				Type:                 "calico",

				EtcdEndpoints:        fmt.Sprintf("http://%s:2379", os.Getenv("ETCD_IP")),

				DatastoreType:        os.Getenv("DATASTORE_TYPE"),

				Kubernetes:           types.Kubernetes{Kubeconfig: "/home/user/certs/kubeconfig"},

				Policy:               types.Policy{PolicyType: "k8s"},

				NodenameFileOptional: true,

				LogLevel:             "info",

			}

			nc.IPAM.Type = "calico-ipam"

			ncb, err := json.Marshal(nc)

			Expect(err).NotTo(HaveOccurred())

			netconf = string(ncb)

			// Create a new IP Pool.

			testutils.MustCreateNewIPPool(calicoClient, pool1, false, false, true)

			_, ipPoolCIDR, err = net.ParseCIDR(pool1)

			Expect(err).NotTo(HaveOccurred())

			// Create clients.

			clientset = getKubernetesClient()

		})


====================
		pool2 := "172.17.0.0/16"

		var pool1CIDR, pool2CIDR *net.IPNet

		var pool2Name string

		var clientset *kubernetes.Clientset

		BeforeEach(func() {

			// Build the network config for this set of tests.

			nc = types.NetConf{

				CNIVersion:           cniVersion,

				Name:                 "calico-uts",

				Type:                 "calico",

				EtcdEndpoints:        fmt.Sprintf("http://%s:2379", os.Getenv("ETCD_IP")),

				DatastoreType:        os.Getenv("DATASTORE_TYPE"),

				Kubernetes:           types.Kubernetes{Kubeconfig: "/home/user/certs/kubeconfig"},

				Policy:               types.Policy{PolicyType: "k8s"},

				NodenameFileOptional: true,

				LogLevel:             "info",

			}

			nc.IPAM.Type = "calico-ipam"

			ncb, err := json.Marshal(nc)

			Expect(err).NotTo(HaveOccurred())


====================
				Name:                 "calico-uts",

				Type:                 "calico",

				EtcdEndpoints:        fmt.Sprintf("http://%s:2379", os.Getenv("ETCD_IP")),

				DatastoreType:        os.Getenv("DATASTORE_TYPE"),

				Kubernetes:           types.Kubernetes{Kubeconfig: "/home/user/certs/kubeconfig"},

				Policy:               types.Policy{PolicyType: "k8s"},

				NodenameFileOptional: true,

				LogLevel:             "info",

			}

			nc.IPAM.Type = "calico-ipam"

			ncb, err := json.Marshal(nc)

			Expect(err).NotTo(HaveOccurred())

			netconf = string(ncb)

			// Create two IP pools.

			testutils.MustCreateNewIPPool(calicoClient, pool1, false, false, true)

			_, pool1CIDR, err = net.ParseCIDR(pool1)

			Expect(err).NotTo(HaveOccurred())

			pool2Name = testutils.MustCreateNewIPPool(calicoClient, pool2, false, false, true)

			_, pool2CIDR, err = net.ParseCIDR(pool2)

			Expect(err).NotTo(HaveOccurred())


====================
		})

	})

	Context("using floatingIPs annotation to assign a DNAT", func() {

		var netconf types.NetConf

		var clientset *kubernetes.Clientset

		BeforeEach(func() {

			netconf = types.NetConf{

				CNIVersion:           cniVersion,

				Name:                 "calico-network-name",

				Type:                 "calico",

				EtcdEndpoints:        fmt.Sprintf("http://%s:2379", os.Getenv("ETCD_IP")),

				DatastoreType:        os.Getenv("DATASTORE_TYPE"),

				Kubernetes:           types.Kubernetes{Kubeconfig: "/home/user/certs/kubeconfig"},

				Policy:               types.Policy{PolicyType: "k8s"},

				NodenameFileOptional: true,

				LogLevel:             "info",

				FeatureControl:       types.FeatureControl{FloatingIPs: true},

			}

			netconf.IPAM.Type = "calico-ipam"

			// Create an IP pool for the pod IP as well as a floating IP range.


====================
				Type:                 "calico",

				EtcdEndpoints:        fmt.Sprintf("http://%s:2379", os.Getenv("ETCD_IP")),

				DatastoreType:        os.Getenv("DATASTORE_TYPE"),

				Kubernetes:           types.Kubernetes{Kubeconfig: "/home/user/certs/kubeconfig"},

				Policy:               types.Policy{PolicyType: "k8s"},

				NodenameFileOptional: true,

				LogLevel:             "info",

				FeatureControl:       types.FeatureControl{FloatingIPs: true},

			}

			netconf.IPAM.Type = "calico-ipam"

			// Create an IP pool for the pod IP as well as a floating IP range.

			for _, ipPool := range []string{"172.16.0.0/16", "1.1.1.0/24"} {

				testutils.MustCreateNewIPPool(calicoClient, ipPool, false, false, true)

				_, _, err := net.ParseCIDR(ipPool)

				Expect(err).NotTo(HaveOccurred())

			}

			// Build kubernetes clients.

			clientset = getKubernetesClient()

			// Now create a K8s pod passing in a floating IP.

			ensureNamespace(clientset, testutils.K8S_TEST_NS)


====================
		var netconf string

		var nc types.NetConf

		BeforeEach(func() {

			// Set up clients.

			clientset = getKubernetesClient()

			// Create a network config.

			nc = types.NetConf{

				CNIVersion:           cniVersion,

				Name:                 "calico-uts",

				Type:                 "calico",

				EtcdEndpoints:        fmt.Sprintf("http://%s:2379", os.Getenv("ETCD_IP")),

				DatastoreType:        os.Getenv("DATASTORE_TYPE"),

				Kubernetes:           types.Kubernetes{Kubeconfig: "/home/user/certs/kubeconfig"},

				Policy:               types.Policy{PolicyType: "k8s"},

				NodenameFileOptional: true,

				LogLevel:             "info",

				FeatureControl:       types.FeatureControl{IPAddrsNoIpam: true},

			}

			nc.IPAM.Type = "calico-ipam"

			Expect(nc.CNIVersion).NotTo(BeEmpty())


====================
				Type:                 "calico",

				EtcdEndpoints:        fmt.Sprintf("http://%s:2379", os.Getenv("ETCD_IP")),

				DatastoreType:        os.Getenv("DATASTORE_TYPE"),

				Kubernetes:           types.Kubernetes{Kubeconfig: "/home/user/certs/kubeconfig"},

				Policy:               types.Policy{PolicyType: "k8s"},

				NodenameFileOptional: true,

				LogLevel:             "info",

				FeatureControl:       types.FeatureControl{IPAddrsNoIpam: true},

			}

			nc.IPAM.Type = "calico-ipam"

			Expect(nc.CNIVersion).NotTo(BeEmpty())

			ncb, err := json.Marshal(nc)

			Expect(err).NotTo(HaveOccurred())

			netconf = string(ncb)

		})

		AfterEach(func() {

			// Delete pod

			ensurePodDeleted(clientset, testutils.K8S_TEST_NS, name)

		})

		It("should successfully assigns the annotated IP address", func() {


====================
		BeforeEach(func() {

			// Set up clients.

			clientset = getKubernetesClient()

		})

		It("should successfully assign the annotated IP address", func() {

			netconfCalicoIPAM := fmt.Sprintf(`

				{

				  "cniVersion": "%s",

				  "name": "net4",

				  "type": "calico",

				  "etcd_endpoints": "http://%s:2379",

				  "datastore_type": "%s",

			          "nodename_file_optional": true,

				  "ipam": {

					   "type": "calico-ipam",

					   "assign_ipv4": "true",

					   "assign_ipv6": "true"

				   },

					"kubernetes": {

                                          "kubeconfig": "/home/user/certs/kubeconfig"


====================
			netconfCalicoIPAM := fmt.Sprintf(`

				{

				  "cniVersion": "%s",

				  "name": "net4",

				  "type": "calico",

				  "etcd_endpoints": "http://%s:2379",

				  "datastore_type": "%s",

			          "nodename_file_optional": true,

				  "ipam": {

					   "type": "calico-ipam",

					   "assign_ipv4": "true",

					   "assign_ipv6": "true"

				   },

					"kubernetes": {

                                          "kubeconfig": "/home/user/certs/kubeconfig"

					 },

					"policy": {"type": "k8s"},

					"log_level":"info"

				}`, cniVersion, os.Getenv("ETCD_IP"), os.Getenv("DATASTORE_TYPE"))

			assignIP := net.IPv4(20, 0, 0, 111).To4()


====================
		})

		It("should allocate IPv4 and IPv6 addresses and handle dual stack floating IPs", func() {

			netconfCalicoIPAM := fmt.Sprintf(`

				{

     			  "feature_control": {

     			      "floating_ips": true

     			  },

     			  "cniVersion": "%s",

				  "name": "net4",

				  "type": "calico",

				  "etcd_endpoints": "http://%s:2379",

				  "datastore_type": "%s",

			          "nodename_file_optional": true,

				  "ipam": {

					   "type": "calico-ipam",

					   "assign_ipv4": "true",

					   "assign_ipv6": "true"

				   },

					"kubernetes": {

                                          "kubeconfig": "/home/user/certs/kubeconfig"


====================
     			      "floating_ips": true

     			  },

     			  "cniVersion": "%s",

				  "name": "net4",

				  "type": "calico",

				  "etcd_endpoints": "http://%s:2379",

				  "datastore_type": "%s",

			          "nodename_file_optional": true,

				  "ipam": {

					   "type": "calico-ipam",

					   "assign_ipv4": "true",

					   "assign_ipv6": "true"

				   },

					"kubernetes": {

                                          "kubeconfig": "/home/user/certs/kubeconfig"

					 },

					"policy": {"type": "k8s"},

					"log_level":"info"

				}`, cniVersion, os.Getenv("ETCD_IP"), os.Getenv("DATASTORE_TYPE"))

			// Now create a K8s pod (without any pod IP annotations).


====================
		var nc types.NetConf

		var netconf string

		BeforeEach(func() {

			// Set up clients.

			clientset = getKubernetesClient()

			// Create a network config.

			nc = types.NetConf{

				CNIVersion:           cniVersion,

				Name:                 "calico-uts",

				Type:                 "calico",

				EtcdEndpoints:        fmt.Sprintf("http://%s:2379", os.Getenv("ETCD_IP")),

				DatastoreType:        os.Getenv("DATASTORE_TYPE"),

				Kubernetes:           types.Kubernetes{Kubeconfig: "/home/user/certs/kubeconfig"},

				Policy:               types.Policy{PolicyType: "k8s"},

				NodenameFileOptional: true,

				LogLevel:             "info",

			}

			nc.IPAM.Type = "calico-ipam"

			ncb, err := json.Marshal(nc)

			Expect(err).NotTo(HaveOccurred())


====================
				Name:                 "calico-uts",

				Type:                 "calico",

				EtcdEndpoints:        fmt.Sprintf("http://%s:2379", os.Getenv("ETCD_IP")),

				DatastoreType:        os.Getenv("DATASTORE_TYPE"),

				Kubernetes:           types.Kubernetes{Kubeconfig: "/home/user/certs/kubeconfig"},

				Policy:               types.Policy{PolicyType: "k8s"},

				NodenameFileOptional: true,

				LogLevel:             "info",

			}

			nc.IPAM.Type = "calico-ipam"

			ncb, err := json.Marshal(nc)

			Expect(err).NotTo(HaveOccurred())

			netconf = string(ncb)

			// Make sure the namespace exists.

			ensureNamespace(clientset, testutils.K8S_TEST_NS)

			// Create a new ipPool.

			testutils.MustCreateNewIPPool(calicoClient, ipPool, false, false, true)

			// Now create a K8s pod.

			ensurePodCreated(clientset, testutils.K8S_TEST_NS,

				&v1.Pod{


====================
			ExpectWithOffset(1, ipamIPs[0].String()+"/32").To(Equal(endpointSpec.IPNetworks[0]))

		}

		BeforeEach(func() {

			// Create a new ipPool.

			testutils.MustCreateNewIPPool(calicoClient, "10.0.0.0/24", false, false, true)

			// Create a network config.

			nc = types.NetConf{

				CNIVersion:           cniVersion,

				Name:                 "calico-uts",

				Type:                 "calico",

				EtcdEndpoints:        fmt.Sprintf("http://%s:2379", os.Getenv("ETCD_IP")),

				DatastoreType:        os.Getenv("DATASTORE_TYPE"),

				Kubernetes:           types.Kubernetes{Kubeconfig: "/home/user/certs/kubeconfig"},

				Policy:               types.Policy{PolicyType: "k8s"},

				NodenameFileOptional: true,

				LogLevel:             "info",

			}

			nc.IPAM.Type = "calico-ipam"

			ncb, err := json.Marshal(nc)

			Expect(err).NotTo(HaveOccurred())


====================
				Name:                 "calico-uts",

				Type:                 "calico",

				EtcdEndpoints:        fmt.Sprintf("http://%s:2379", os.Getenv("ETCD_IP")),

				DatastoreType:        os.Getenv("DATASTORE_TYPE"),

				Kubernetes:           types.Kubernetes{Kubeconfig: "/home/user/certs/kubeconfig"},

				Policy:               types.Policy{PolicyType: "k8s"},

				NodenameFileOptional: true,

				LogLevel:             "info",

			}

			nc.IPAM.Type = "calico-ipam"

			ncb, err := json.Marshal(nc)

			Expect(err).NotTo(HaveOccurred())

			netconf = string(ncb)

			// Now create a K8s pod.

			clientset = getKubernetesClient()

			ensurePodCreated(clientset, testutils.K8S_TEST_NS,

				&v1.Pod{

					ObjectMeta: metav1.ObjectMeta{

						Name: name,

					},


====================
				renameVeth(tweakedVethName, realVethName)

			})

		})

	})

	Context("Create a container then send another ADD for the same container but with a different interface", func() {

		netconf := fmt.Sprintf(`

				{

				  "cniVersion": "%s",

				  "name": "net10",

				  "type": "calico",

				  "etcd_endpoints": "http://%s:2379",

				  "datastore_type": "%s",

           			  "nodename_file_optional": true,

				  "log_level": "info",

			 	  "ipam": {

				    "type": "calico-ipam"

				  },

				  "kubernetes": {

				    "kubeconfig": "/home/user/certs/kubeconfig"

				  },


====================
				{

				  "cniVersion": "%s",

				  "name": "net10",

				  "type": "calico",

				  "etcd_endpoints": "http://%s:2379",

				  "datastore_type": "%s",

           			  "nodename_file_optional": true,

				  "log_level": "info",

			 	  "ipam": {

				    "type": "calico-ipam"

				  },

				  "kubernetes": {

				    "kubeconfig": "/home/user/certs/kubeconfig"

				  },

				  "policy": {"type": "k8s"}

				}`, cniVersion, os.Getenv("ETCD_IP"), os.Getenv("DATASTORE_TYPE"))

		It("should successfully execute both ADDs but for second ADD will return the same result as the first time but it won't network the container", func() {

			// Create a new ipPool.

			testutils.MustCreateNewIPPool(calicoClient, "10.0.0.0/24", false, false, true)

			clientset := getKubernetesClient()


====================
		var nc types.NetConf

		var netconf string

		var clientset *kubernetes.Clientset

		var pool string = "172.24.0.0/24"

		BeforeEach(func() {

			// Build the network config for this set of tests.

			nc = types.NetConf{

				CNIVersion:           cniVersion,

				Name:                 "calico-uts",

				Type:                 "calico",

				EtcdEndpoints:        fmt.Sprintf("http://%s:2379", os.Getenv("ETCD_IP")),

				DatastoreType:        os.Getenv("DATASTORE_TYPE"),

				Kubernetes:           types.Kubernetes{Kubeconfig: "/home/user/certs/kubeconfig"},

				Policy:               types.Policy{PolicyType: "k8s"},

				NodenameFileOptional: true,

				LogLevel:             "info",

			}

			nc.IPAM.Type = "calico-ipam"

			ncb, err := json.Marshal(nc)

			Expect(err).NotTo(HaveOccurred())


====================
				Name:                 "calico-uts",

				Type:                 "calico",

				EtcdEndpoints:        fmt.Sprintf("http://%s:2379", os.Getenv("ETCD_IP")),

				DatastoreType:        os.Getenv("DATASTORE_TYPE"),

				Kubernetes:           types.Kubernetes{Kubeconfig: "/home/user/certs/kubeconfig"},

				Policy:               types.Policy{PolicyType: "k8s"},

				NodenameFileOptional: true,

				LogLevel:             "info",

			}

			nc.IPAM.Type = "calico-ipam"

			ncb, err := json.Marshal(nc)

			Expect(err).NotTo(HaveOccurred())

			netconf = string(ncb)

			// Create an IPPool for the test.

			testutils.MustCreateNewIPPool(calicoClient, pool, false, false, true)

			Expect(err).NotTo(HaveOccurred())

			clientset = getKubernetesClient()

		})

		AfterEach(func() {

			// Delete pod


====================
		var nc types.NetConf

		var netconf string

		var clientset *kubernetes.Clientset

		var pool string = "172.24.0.0/24"

		BeforeEach(func() {

			// Build the network config for this set of tests.

			nc = types.NetConf{

				CNIVersion:           cniVersion,

				Name:                 "calico-uts",

				Type:                 "calico",

				EtcdEndpoints:        fmt.Sprintf("http://%s:2379", os.Getenv("ETCD_IP")),

				DatastoreType:        os.Getenv("DATASTORE_TYPE"),

				Kubernetes:           types.Kubernetes{Kubeconfig: "/home/user/certs/kubeconfig"},

				Policy:               types.Policy{PolicyType: "k8s"},

				NodenameFileOptional: true,

				LogLevel:             "info",

			}

			nc.IPAM.Type = "calico-ipam"

			ncb, err := json.Marshal(nc)

			Expect(err).NotTo(HaveOccurred())


====================
				Name:                 "calico-uts",

				Type:                 "calico",

				EtcdEndpoints:        fmt.Sprintf("http://%s:2379", os.Getenv("ETCD_IP")),

				DatastoreType:        os.Getenv("DATASTORE_TYPE"),

				Kubernetes:           types.Kubernetes{Kubeconfig: "/home/user/certs/kubeconfig"},

				Policy:               types.Policy{PolicyType: "k8s"},

				NodenameFileOptional: true,

				LogLevel:             "info",

			}

			nc.IPAM.Type = "calico-ipam"

			ncb, err := json.Marshal(nc)

			Expect(err).NotTo(HaveOccurred())

			netconf = string(ncb)

			// Create an IPPool for the test.

			testutils.MustCreateNewIPPool(calicoClient, pool, false, false, true)

			Expect(err).NotTo(HaveOccurred())

			clientset = getKubernetesClient()

		})

		AfterEach(func() {

			// Delete pod


====================
			_, err = testutils.DeleteContainer(netconf, contNs.Path(), name, testutils.K8S_TEST_NS)

			Expect(err).ShouldNot(HaveOccurred())

		})

	})

	Context("using bogus readiness_gates", func() {

		netconf := fmt.Sprintf(`

				{

				  "cniVersion": "%s",

				  "name": "net10",

				  "type": "calico",

				  "etcd_endpoints": "http://%s:2379",

				  "datastore_type": "%s",

           			  "nodename_file_optional": true,

				  "log_level": "info",

				  "readiness_gates": "http://localhost:9099/invalid_x12vx",

			 	  "ipam": {

				    "type": "calico-ipam"

				  },

				  "kubernetes": {

				    "kubeconfig": "/home/user/certs/kubeconfig"


====================
				  "cniVersion": "%s",

				  "name": "net10",

				  "type": "calico",

				  "etcd_endpoints": "http://%s:2379",

				  "datastore_type": "%s",

           			  "nodename_file_optional": true,

				  "log_level": "info",

				  "readiness_gates": "http://localhost:9099/invalid_x12vx",

			 	  "ipam": {

				    "type": "calico-ipam"

				  },

				  "kubernetes": {

				    "kubeconfig": "/home/user/certs/kubeconfig"

				  },

				  "policy": {"type": "k8s"}

				}`, cniVersion, os.Getenv("ETCD_IP"), os.Getenv("DATASTORE_TYPE"))

		It("should fail container creation", func() {

			// Create a new ipPool.

			testutils.MustCreateNewIPPool(calicoClient, "10.0.0.0/24", false, false, true)

			clientset := getKubernetesClient()


====================
			server = httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {

				_, err := w.Write([]byte("Ok"))

				Expect(err).NotTo(HaveOccurred())

			}))

			testEndpoint := server.URL

			netconf = fmt.Sprintf(`

				{

				  "cniVersion": "%s",

				  "name": "net10",

				  "type": "calico",

				  "etcd_endpoints": "http://%s:2379",

				  "datastore_type": "%s",

           			  "nodename_file_optional": true,

				  "log_level": "info",

				  "readiness_gates": ["%s"],

			 	  "ipam": {

				    "type": "calico-ipam"

				  },

				  "kubernetes": {

				    "kubeconfig": "/home/user/certs/kubeconfig"


====================
				  "cniVersion": "%s",

				  "name": "net10",

				  "type": "calico",

				  "etcd_endpoints": "http://%s:2379",

				  "datastore_type": "%s",

           			  "nodename_file_optional": true,

				  "log_level": "info",

				  "readiness_gates": ["%s"],

			 	  "ipam": {

				    "type": "calico-ipam"

				  },

				  "kubernetes": {

				    "kubeconfig": "/home/user/certs/kubeconfig"

				  },

				  "policy": {"type": "k8s"}

				}`, cniVersion, os.Getenv("ETCD_IP"), os.Getenv("DATASTORE_TYPE"), testEndpoint)

		})

		AfterEach(func() {

			server.Close()

		})


====================
			ensurePodDeleted(clientset, testutils.K8S_TEST_NS, name)

		})

	})

	Describe("testConnection tests", func() {

		It("successfully connects to the datastore", func(done Done) {

			netconf := fmt.Sprintf(`

			{

			  "cniVersion": "%s",

			  "name": "net1",

			  "type": "calico",

			  "etcd_endpoints": "http://%s:2379",

			  "datastore_type": "%s",

			  "ipam": {

			    "type": "host-local",

			    "subnet": "10.0.0.0/8"

			  },

			  "kubernetes": {

			    "kubeconfig": "/home/user/certs/kubeconfig"

			  },

			  "policy": {"type": "k8s"},


====================
		It("successfully connects to the datastore", func(done Done) {

			netconf := fmt.Sprintf(`

			{

			  "cniVersion": "%s",

			  "name": "net1",

			  "type": "calico",

			  "etcd_endpoints": "http://%s:2379",

			  "datastore_type": "%s",

			  "ipam": {

			    "type": "host-local",

			    "subnet": "10.0.0.0/8"

			  },

			  "kubernetes": {

			    "kubeconfig": "/home/user/certs/kubeconfig"

			  },

			  "policy": {"type": "k8s"},

			  "nodename_file_optional": true,

			  "log_level":"info"

			}`, cniVersion, os.Getenv("ETCD_IP"), os.Getenv("DATASTORE_TYPE"))

			pluginPath := fmt.Sprintf("%s/%s", os.Getenv("BIN"), os.Getenv("PLUGIN"))


====================
			  },

			  "kubernetes": {

			    "kubeconfig": "/home/user/certs/kubeconfig"

			  },

			  "policy": {"type": "k8s"},

			  "nodename_file_optional": true,

			  "log_level":"info"

			}`, cniVersion, os.Getenv("ETCD_IP"), os.Getenv("DATASTORE_TYPE"))

			pluginPath := fmt.Sprintf("%s/%s", os.Getenv("BIN"), os.Getenv("PLUGIN"))

			c := exec.Command(pluginPath, "-t")

			stdin, err := c.StdinPipe()

			Expect(err).ToNot(HaveOccurred())

			go func() {

				defer stdin.Close()

				_, _ = io.WriteString(stdin, netconf)

			}()

			_, err = c.CombinedOutput()

			Expect(err).ToNot(HaveOccurred())

			close(done)

		}, 10)


====================
			Expect(err).ToNot(HaveOccurred())

			close(done)

		}, 10)

		It("reports it cannot connect to the datastore", func(done Done) {

			// wrong port(s).

			netconf := fmt.Sprintf(`

			{

			  "cniVersion": "%s",

			  "name": "net1",

			  "type": "calico",

			  "etcd_endpoints": "http://%s:2370",

			  "datastore_type": "%s",

			  "ipam": {

			    "type": "host-local",

			    "subnet": "10.0.0.0/8"

			  },

			  "kubernetes": {

			    "kubeconfig": "/home/user/certs/kubeconfig",

			    "k8s_api_root": "https://127.0.0.1:6446"

			  },


====================
			// wrong port(s).

			netconf := fmt.Sprintf(`

			{

			  "cniVersion": "%s",

			  "name": "net1",

			  "type": "calico",

			  "etcd_endpoints": "http://%s:2370",

			  "datastore_type": "%s",

			  "ipam": {

			    "type": "host-local",

			    "subnet": "10.0.0.0/8"

			  },

			  "kubernetes": {

			    "kubeconfig": "/home/user/certs/kubeconfig",

			    "k8s_api_root": "https://127.0.0.1:6446"

			  },

			  "policy": {"type": "k8s"},

			  "nodename_file_optional": true,

			  "log_level":"info"

			}`, cniVersion, os.Getenv("ETCD_IP"), os.Getenv("DATASTORE_TYPE"))


====================
			  "kubernetes": {

			    "kubeconfig": "/home/user/certs/kubeconfig",

			    "k8s_api_root": "https://127.0.0.1:6446"

			  },

			  "policy": {"type": "k8s"},

			  "nodename_file_optional": true,

			  "log_level":"info"

			}`, cniVersion, os.Getenv("ETCD_IP"), os.Getenv("DATASTORE_TYPE"))

			pluginPath := fmt.Sprintf("%s/%s", os.Getenv("BIN"), os.Getenv("PLUGIN"))

			c := exec.Command(pluginPath, "-t")

			stdin, err := c.StdinPipe()

			Expect(err).ToNot(HaveOccurred())

			go func() {

				defer stdin.Close()

				_, _ = io.WriteString(stdin, netconf)

			}()

			_, err = c.CombinedOutput()

			Expect(err).To(HaveOccurred())

			close(done)

		}, 10)


====================
	})

	Describe("using hwAddr annotations to assign a fixed MAC address to a container veth", func() {

		calicoClient, err := client.NewFromEnv()

		Expect(err).NotTo(HaveOccurred())

		k8sClient := getKubernetesClient()

		netconf := fmt.Sprintf(`

			{

			  "cniVersion": "%s",

			  "name": "net1",

			  "type": "calico",

			  "etcd_endpoints": "http://%s:2379",

			  "datastore_type": "%s",

			  "ipam": {

			    "type": "host-local",

			    "subnet": "10.0.0.0/8"

			  },

			  "kubernetes": {

			    "kubeconfig": "/home/user/certs/kubeconfig"

			  },

			  "policy": {"type": "k8s"},


====================
		k8sClient := getKubernetesClient()

		netconf := fmt.Sprintf(`

			{

			  "cniVersion": "%s",

			  "name": "net1",

			  "type": "calico",

			  "etcd_endpoints": "http://%s:2379",

			  "datastore_type": "%s",

			  "ipam": {

			    "type": "host-local",

			    "subnet": "10.0.0.0/8"

			  },

			  "kubernetes": {

			    "kubeconfig": "/home/user/certs/kubeconfig"

			  },

			  "policy": {"type": "k8s"},

			  "nodename_file_optional": true,

			  "log_level":"debug"

			}`, cniVersion, os.Getenv("ETCD_IP"), os.Getenv("DATASTORE_TYPE"))

		var name string


====================
		_, err = calicoClient.Nodes().Delete(context.Background(), name, options.DeleteOptions{})

		Expect(err).NotTo(HaveOccurred())

	})

	cniVersion := os.Getenv("CNI_SPEC_VERSION")

	Context("using host-local IPAM", func() {

		netconf := fmt.Sprintf(`

		{

		  "cniVersion": "%s",

		  "name": "net1",

		  "type": "calico",

		  "etcd_endpoints": "http://%s:2379",

		  "log_level": "info",

		  "nodename_file_optional": true,

		  "datastore_type": "%s",

		  "ipam": {

		    "type": "host-local",

		    "subnet": "10.0.0.0/8"

		  }

		}`, cniVersion, os.Getenv("ETCD_IP"), os.Getenv("DATASTORE_TYPE"))

		It("successfully networks the namespace", func() {


====================
		{

		  "cniVersion": "%s",

		  "name": "net1",

		  "type": "calico",

		  "etcd_endpoints": "http://%s:2379",

		  "log_level": "info",

		  "nodename_file_optional": true,

		  "datastore_type": "%s",

		  "ipam": {

		    "type": "host-local",

		    "subnet": "10.0.0.0/8"

		  }

		}`, cniVersion, os.Getenv("ETCD_IP"), os.Getenv("DATASTORE_TYPE"))

		It("successfully networks the namespace", func() {

			containerID, result, contVeth, contAddresses, contRoutes, contNs, err := testutils.CreateContainerWithId(netconf, "", testutils.TEST_DEFAULT_NS, "", "abc123")

			Expect(err).ShouldNot(HaveOccurred())

			Expect(len(result.IPs)).Should(Equal(1))

			ip := result.IPs[0].Address.IP.String()

			result.IPs[0].Address.IP = result.IPs[0].Address.IP.To4() // Make sure the IP is respresented as 4 bytes

			Expect(result.IPs[0].Address.Mask.String()).Should(Equal("ffffffff"))


====================
				Expect(exitCode).ShouldNot(Equal(0))

			})

		})

	})

	Context("With IP forwarding enabled", func() {

		netconf := fmt.Sprintf(`

			{

			  "cniVersion": "%s",

			  "name": "net1",

			  "type": "calico",

			  "etcd_endpoints": "http://%s:2379",

			  "log_level": "info",

			  "nodename_file_optional": true,

			  "datastore_type": "%s",

			  "container_settings": {

			    "allow_ip_forwarding": true

			  },

			  "ipam": {

			    "type": "host-local",

			    "subnet": "10.0.0.0/8"


====================
			  "type": "calico",

			  "etcd_endpoints": "http://%s:2379",

			  "log_level": "info",

			  "nodename_file_optional": true,

			  "datastore_type": "%s",

			  "container_settings": {

			    "allow_ip_forwarding": true

			  },

			  "ipam": {

			    "type": "host-local",

			    "subnet": "10.0.0.0/8"

			  }

			}`, cniVersion, os.Getenv("ETCD_IP"), os.Getenv("DATASTORE_TYPE"))

		It("should enable IPv4 forwarding", func() {

			containerID := fmt.Sprintf("con%d", rand.Uint32())

			_, _, _, _, _, contNs, err := testutils.CreateContainerWithId(netconf, "", testutils.TEST_DEFAULT_NS, "", containerID)

			By("successfully networking the container", func() {

				Expect(err).ShouldNot(HaveOccurred())

			})

			By("asserting IPv4 forwarding is enabled", func() {


====================
				Expect(err).ShouldNot(HaveOccurred())

			})

		})

	})

	Context("With an invalid dataplane type", func() {

		netconf := fmt.Sprintf(`

			{

			  "cniVersion": "%s",

			  "name": "net1",

			  "type": "calico",

			  "etcd_endpoints": "http://%s:2379",

			  "log_level": "info",

			  "nodename_file_optional": true,

			  "datastore_type": "%s",

			  "ipam": {

			    "type": "host-local",

			    "subnet": "10.0.0.0/8"

			  },

			  "dataplane_options": {

			  	"type": "invalid-dataplane-type"


====================
			{

			  "cniVersion": "%s",

			  "name": "net1",

			  "type": "calico",

			  "etcd_endpoints": "http://%s:2379",

			  "log_level": "info",

			  "nodename_file_optional": true,

			  "datastore_type": "%s",

			  "ipam": {

			    "type": "host-local",

			    "subnet": "10.0.0.0/8"

			  },

			  "dataplane_options": {

			  	"type": "invalid-dataplane-type"

			  }

			}`, cniVersion, os.Getenv("ETCD_IP"), os.Getenv("DATASTORE_TYPE"))

		It("fails with an error", func() {

			_, _, _, _, _, _, err := testutils.CreateContainer(netconf, "", testutils.TEST_DEFAULT_NS, "")

			Expect(err).Should(HaveOccurred())

		})


====================
			_, _, _, _, _, _, err := testutils.CreateContainer(netconf, "", testutils.TEST_DEFAULT_NS, "")

			Expect(err).Should(HaveOccurred())

		})

	})

	Context("With a misconfigured gRPC dataplane", func() {

		netconf := fmt.Sprintf(`

			{

			  "cniVersion": "%s",

			  "name": "net1",

			  "type": "calico",

			  "etcd_endpoints": "http://%s:2379",

			  "log_level": "info",

			  "nodename_file_optional": true,

			  "datastore_type": "%s",

			  "ipam": {

			    "type": "host-local",

			    "subnet": "10.0.0.0/8"

			  },

			  "dataplane_options": {

			  	"type": "grpc",


====================
			{

			  "cniVersion": "%s",

			  "name": "net1",

			  "type": "calico",

			  "etcd_endpoints": "http://%s:2379",

			  "log_level": "info",

			  "nodename_file_optional": true,

			  "datastore_type": "%s",

			  "ipam": {

			    "type": "host-local",

			    "subnet": "10.0.0.0/8"

			  },

			  "dataplane_options": {

			  	"type": "grpc",

			  	"socket": "unix:///tmp/xxxx-non-existent-dont-create-this-please.sock"

			  }

			}`, cniVersion, os.Getenv("ETCD_IP"), os.Getenv("DATASTORE_TYPE"))

		It("fails with an error", func() {

			_, _, _, _, _, _, err := testutils.CreateContainer(netconf, "", testutils.TEST_DEFAULT_NS, "")

			Expect(err).Should(HaveOccurred())


====================
			var contNs ns.NetNS

			var grpcBackend *grpc_dataplane.TestServer

			var exitCode int

			var err error

			socket := fmt.Sprintf("/tmp/cni_grpc_dataplane_test%d.sock", rand.Uint32())

			netconf := fmt.Sprintf(`

				{

					"cniVersion": "%s",

					"name": "net1",

					"type": "calico",

					"etcd_endpoints": "http://%s:2379",

					"log_level": "info",

					"nodename_file_optional": true,

					"datastore_type": "%s",

					"ipam": {

			    		"type": "host-local",

			    		"subnet": "10.0.0.0/8"

					},

					"dataplane_options": {

			  			"type": "grpc",


====================
				{

					"cniVersion": "%s",

					"name": "net1",

					"type": "calico",

					"etcd_endpoints": "http://%s:2379",

					"log_level": "info",

					"nodename_file_optional": true,

					"datastore_type": "%s",

					"ipam": {

			    		"type": "host-local",

			    		"subnet": "10.0.0.0/8"

					},

					"dataplane_options": {

			  			"type": "grpc",

			  			"socket": "unix://%s",

						"extra": "option"

					}

				}`, cniVersion, os.Getenv("ETCD_IP"), os.Getenv("DATASTORE_TYPE"), socket)

			grpcBackend, err = grpc_dataplane.StartTestServer(socket, true, "00:11:22:33:44:55")

			Expect(err).ShouldNot(HaveOccurred())


====================
			}

			close(done)

		}, 30.0)

	})

	Context("deprecate hostname for nodename", func() {

		netconf := fmt.Sprintf(`

		{

		  "cniVersion": "%s",

		  "name": "net1",

		  "type": "calico",

		  "etcd_endpoints": "http://%s:2379",

		  "hostname": "named-hostname.somewhere",

		  "nodename_file_optional": true,

		  "datastore_type": "%s",

		  "ipam": {

		    "type": "host-local",

		    "subnet": "10.0.0.0/8"

		  }

		}`, cniVersion, os.Getenv("ETCD_IP"), os.Getenv("DATASTORE_TYPE"))

		It("has hostname even though deprecated", func() {


====================
		{

		  "cniVersion": "%s",

		  "name": "net1",

		  "type": "calico",

		  "etcd_endpoints": "http://%s:2379",

		  "hostname": "named-hostname.somewhere",

		  "nodename_file_optional": true,

		  "datastore_type": "%s",

		  "ipam": {

		    "type": "host-local",

		    "subnet": "10.0.0.0/8"

		  }

		}`, cniVersion, os.Getenv("ETCD_IP"), os.Getenv("DATASTORE_TYPE"))

		It("has hostname even though deprecated", func() {

			containerID, _, _, _, _, contNs, err := testutils.CreateContainerWithId(netconf, "", testutils.TEST_DEFAULT_NS, "", "abcd1234")

			Expect(err).ShouldNot(HaveOccurred())

			// The endpoint is created in etcd

			endpoints, err := calicoClient.WorkloadEndpoints().List(ctx, options.ListOptions{})

			Expect(err).ShouldNot(HaveOccurred())

			Expect(endpoints.Items).Should(HaveLen(1))


====================
			Expect(endpoints.Items[0].Namespace).Should(Equal(testutils.TEST_DEFAULT_NS))

			Expect(endpoints.Items[0].Spec.Node).Should(Equal("named-hostname.somewhere"))

			_, err = testutils.DeleteContainerWithId(netconf, contNs.Path(), "", testutils.TEST_DEFAULT_NS, containerID)

			Expect(err).ShouldNot(HaveOccurred())

		})

		netconf2 := fmt.Sprintf(`

		{

		  "cniVersion": "%s",

		  "name": "net1",

		  "type": "calico",

		  "etcd_endpoints": "http://%s:2379",

		  "hostname": "named-hostname",

		  "nodename": "named-nodename",

		  "nodename_file_optional": true,

		  "datastore_type": "%s",

		  "ipam": {

		    "type": "host-local",

		    "subnet": "10.0.0.0/8"

		  }

		}`, cniVersion, os.Getenv("ETCD_IP"), os.Getenv("DATASTORE_TYPE"))


====================
		  "cniVersion": "%s",

		  "name": "net1",

		  "type": "calico",

		  "etcd_endpoints": "http://%s:2379",

		  "hostname": "named-hostname",

		  "nodename": "named-nodename",

		  "nodename_file_optional": true,

		  "datastore_type": "%s",

		  "ipam": {

		    "type": "host-local",

		    "subnet": "10.0.0.0/8"

		  }

		}`, cniVersion, os.Getenv("ETCD_IP"), os.Getenv("DATASTORE_TYPE"))

		It("nodename takes precedence over hostname", func() {

			containerID, _, _, _, _, contNs, err := testutils.CreateContainerWithId(netconf2, "", testutils.TEST_DEFAULT_NS, "", "abcd")

			Expect(err).ShouldNot(HaveOccurred())

			// The endpoint is created in etcd

			endpoints, err := calicoClient.WorkloadEndpoints().List(ctx, options.ListOptions{})

			Expect(err).ShouldNot(HaveOccurred())

			Expect(endpoints.Items).Should(HaveLen(1))


====================
			Expect(err).ShouldNot(HaveOccurred())

		})

	})

	Context("Mesos Labels", func() {

		It("applies mesos labels", func() {

			netconf := fmt.Sprintf(`

			{

			  "cniVersion": "%s",

			  "name": "net1",

			  "type": "calico",

			  "etcd_endpoints": "http://%s:2379",

			  "hostname": "named-hostname.somewhere",

		          "nodename_file_optional": true,

			  "ipam": {

				"type": "host-local",

				"subnet": "10.0.0.0/8"

			  },

			  "args": {

				"org.apache.mesos": {

				  "network_info": {


====================
			netconf := fmt.Sprintf(`

			{

			  "cniVersion": "%s",

			  "name": "net1",

			  "type": "calico",

			  "etcd_endpoints": "http://%s:2379",

			  "hostname": "named-hostname.somewhere",

		          "nodename_file_optional": true,

			  "ipam": {

				"type": "host-local",

				"subnet": "10.0.0.0/8"

			  },

			  "args": {

				"org.apache.mesos": {

				  "network_info": {

					"labels": {

					  "labels": [

						{

						  "key": "k",

						  "value": "v"


====================
			Expect(endpoints.Items[0].Labels["k"]).Should(Equal("v"))

			_, err = testutils.DeleteContainerWithId(netconf, contNs.Path(), "", testutils.TEST_DEFAULT_NS, containerID)

			Expect(err).ShouldNot(HaveOccurred())

		})

		It("sanitizes dcos label", func() {

			netconf := fmt.Sprintf(`

			{

			  "cniVersion": "%s",

			  "name": "net1",

			  "type": "calico",

			  "etcd_endpoints": "http://%s:2379",

			  "hostname": "named-hostname.somewhere",

		          "nodename_file_optional": true,

			  "ipam": {

				"type": "host-local",

				"subnet": "10.0.0.0/8"

			  },

			  "args": {

				"org.apache.mesos": {

				  "network_info": {


====================
			netconf := fmt.Sprintf(`

			{

			  "cniVersion": "%s",

			  "name": "net1",

			  "type": "calico",

			  "etcd_endpoints": "http://%s:2379",

			  "hostname": "named-hostname.somewhere",

		          "nodename_file_optional": true,

			  "ipam": {

				"type": "host-local",

				"subnet": "10.0.0.0/8"

			  },

			  "args": {

				"org.apache.mesos": {

				  "network_info": {

					"labels": {

					  "labels": [

						{

						  "key": "DCOS_SPACE",

						  "value": "/a/b/c"


====================
			Expect(err).ShouldNot(HaveOccurred())

		})

	})

	Context("feature flag processing", func() {

		It("errors if ip_addrs_no_ipam if not running kubernetes", func() {

			netconf := fmt.Sprintf(`

			{

				"cniVersion": "%s",

				"name": "net1",

				"type": "calico",

				"feature_control": {

					"ip_addrs_no_ipam": true

				},

				"etcd_endpoints": "http://%s:2379",

				"nodename": "named-nodename",

				"nodename_file_optional": true,

				"datastore_type": "%s",

				"ipam": {

					"type": "host-local",

					"subnet": "10.0.0.0/8"


====================
				"type": "calico",

				"feature_control": {

					"ip_addrs_no_ipam": true

				},

				"etcd_endpoints": "http://%s:2379",

				"nodename": "named-nodename",

				"nodename_file_optional": true,

				"datastore_type": "%s",

				"ipam": {

					"type": "host-local",

					"subnet": "10.0.0.0/8"

				}

			}`, cniVersion, os.Getenv("ETCD_IP"), os.Getenv("DATASTORE_TYPE"))

			containerNs, containerId, err := testutils.CreateContainerNamespace()

			Expect(err).ToNot(HaveOccurred())

			_, _, _, _, err = testutils.RunCNIPluginWithId(netconf, "", testutils.K8S_TEST_NS, "", containerId, "", containerNs)

			Expect(err).To(HaveOccurred())

		})

	})

	Describe("DEL", func() {


====================
			_, _, _, _, err = testutils.RunCNIPluginWithId(netconf, "", testutils.K8S_TEST_NS, "", containerId, "", containerNs)

			Expect(err).To(HaveOccurred())

		})

	})

	Describe("DEL", func() {

		netconf := fmt.Sprintf(`

		{

			"cniVersion": "%s",

			"name": "net1",

			"type": "calico",

			"etcd_endpoints": "http://%s:2379",

			"nodename_file_optional": true,

			"datastore_type": "%s",

			"ipam": {

				"type": "host-local",

				"subnet": "10.0.0.0/8"

			}

		}`, cniVersion, os.Getenv("ETCD_IP"), os.Getenv("DATASTORE_TYPE"))

		Context("when it was never called for SetUP", func() {

			Context("and a namespace does exist", func() {


====================
		netconf := fmt.Sprintf(`

		{

			"cniVersion": "%s",

			"name": "net1",

			"type": "calico",

			"etcd_endpoints": "http://%s:2379",

			"nodename_file_optional": true,

			"datastore_type": "%s",

			"ipam": {

				"type": "host-local",

				"subnet": "10.0.0.0/8"

			}

		}`, cniVersion, os.Getenv("ETCD_IP"), os.Getenv("DATASTORE_TYPE"))

		Context("when it was never called for SetUP", func() {

			Context("and a namespace does exist", func() {

				It("exits with 'success' error code", func() {

					contNs, containerID, err := testutils.CreateContainerNamespace()

					Expect(err).ShouldNot(HaveOccurred())

					exitCode, err := testutils.DeleteContainerWithId(netconf, contNs.Path(), "", testutils.TEST_DEFAULT_NS, containerID)

					Expect(err).ShouldNot(HaveOccurred())


====================
				})

			})

		})

	})

	Describe("with calico-ipam enabled, after creating a container", func() {

		netconf := fmt.Sprintf(`

		{

		  "cniVersion": "%s",

		  "name": "net1",

		  "type": "calico",

		  "etcd_endpoints": "http://%s:2379",

		  "datastore_type": "%s",

		  "log_level": "info",

	          "nodename_file_optional": true,

		  "ipam": { "type": "calico-ipam" }

		}`, cniVersion, os.Getenv("ETCD_IP"), os.Getenv("DATASTORE_TYPE"))

		var containerID string

		var workloadName string

		var endpointSpec libapiv3.WorkloadEndpointSpec

		var contNs ns.NetNS


====================
		netconf := fmt.Sprintf(`

		{

		  "cniVersion": "%s",

		  "name": "net1",

		  "type": "calico",

		  "etcd_endpoints": "http://%s:2379",

		  "datastore_type": "%s",

		  "log_level": "info",

	          "nodename_file_optional": true,

		  "ipam": { "type": "calico-ipam" }

		}`, cniVersion, os.Getenv("ETCD_IP"), os.Getenv("DATASTORE_TYPE"))

		var containerID string

		var workloadName string

		var endpointSpec libapiv3.WorkloadEndpointSpec

		var contNs ns.NetNS

		var result *cniv1.Result

		checkIPAMReservation := func() {

			// IPAM reservation should still be in place.

			handleID := utils.GetHandleID("net1", containerID, workloadName)

			ipamIPs, err := calicoClient.IPAM().IPsByHandle(context.Background(), handleID)


====================
			})

		})

	})

	Describe("SetupRoutes works fine when the route is already programmed", func() {

		Context("container route already exists on the host", func() {

			netconf := fmt.Sprintf(`

			{

			  "cniVersion": "%s",

			  "name": "net1",

			  "type": "calico",

			  "etcd_endpoints": "http://%s:2379",

			  "datastore_type": "%s",

			  "ipam": {

			    "type": "host-local",

			    "subnet": "10.0.0.0/8"

			  },

			  "nodename_file_optional": true,

			  "log_level":"info"

			}`, cniVersion, os.Getenv("ETCD_IP"), os.Getenv("DATASTORE_TYPE"))

			It("route setup should be resilient to existing route", func() {


====================
		Context("container route already exists on the host", func() {

			netconf := fmt.Sprintf(`

			{

			  "cniVersion": "%s",

			  "name": "net1",

			  "type": "calico",

			  "etcd_endpoints": "http://%s:2379",

			  "datastore_type": "%s",

			  "ipam": {

			    "type": "host-local",

			    "subnet": "10.0.0.0/8"

			  },

			  "nodename_file_optional": true,

			  "log_level":"info"

			}`, cniVersion, os.Getenv("ETCD_IP"), os.Getenv("DATASTORE_TYPE"))

			It("route setup should be resilient to existing route", func() {

				By("creating a CNI networked container, which should also install the container route in the host namespace")

				containerID, result, _, _, _, contNs, err := testutils.CreateContainerWithId(netconf, "", testutils.TEST_DEFAULT_NS, "", "meep1337")

				Expect(err).ShouldNot(HaveOccurred())

				// CNI plugin generates host side vEth name from containerID if used for "cni" orchestrator.


====================
			})

		})

	})

	Describe("testConnection tests", func() {

		It("successfully connects to the datastore", func(done Done) {

			netconf := fmt.Sprintf(`

{

  "cniVersion": "%s",

  "name": "net1",

  "type": "calico",

  "etcd_endpoints": "http://%s:2379",

  "log_level": "info",

  "nodename_file_optional": true,

  "datastore_type": "%s",

  "ipam": {

	"type": "host-local",

	"subnet": "10.0.0.0/8"

  }

}`, cniVersion, os.Getenv("ETCD_IP"), os.Getenv("DATASTORE_TYPE"))

			pluginPath := fmt.Sprintf("%s/%s", os.Getenv("BIN"), os.Getenv("PLUGIN"))


====================
{

  "cniVersion": "%s",

  "name": "net1",

  "type": "calico",

  "etcd_endpoints": "http://%s:2379",

  "log_level": "info",

  "nodename_file_optional": true,

  "datastore_type": "%s",

  "ipam": {

	"type": "host-local",

	"subnet": "10.0.0.0/8"

  }

}`, cniVersion, os.Getenv("ETCD_IP"), os.Getenv("DATASTORE_TYPE"))

			pluginPath := fmt.Sprintf("%s/%s", os.Getenv("BIN"), os.Getenv("PLUGIN"))

			c := exec.Command(pluginPath, "-t")

			stdin, err := c.StdinPipe()

			Expect(err).ToNot(HaveOccurred())

			go func() {

				defer stdin.Close()

				_, _ = io.WriteString(stdin, netconf)


====================
  "log_level": "info",

  "nodename_file_optional": true,

  "datastore_type": "%s",

  "ipam": {

	"type": "host-local",

	"subnet": "10.0.0.0/8"

  }

}`, cniVersion, os.Getenv("ETCD_IP"), os.Getenv("DATASTORE_TYPE"))

			pluginPath := fmt.Sprintf("%s/%s", os.Getenv("BIN"), os.Getenv("PLUGIN"))

			c := exec.Command(pluginPath, "-t")

			stdin, err := c.StdinPipe()

			Expect(err).ToNot(HaveOccurred())

			go func() {

				defer stdin.Close()

				_, _ = io.WriteString(stdin, netconf)

			}()

			_, err = c.CombinedOutput()

			Expect(err).ToNot(HaveOccurred())

			close(done)

		}, 10)


====================
			Expect(err).ToNot(HaveOccurred())

			close(done)

		}, 10)

		It("reports it cannot connect to the datastore", func(done Done) {

			// wrong port.

			netconf := fmt.Sprintf(`

{

  "cniVersion": "%s",

  "name": "net1",

  "type": "calico",

  "etcd_endpoints": "http://%s:2370",

  "log_level": "info",

  "nodename_file_optional": true,

  "datastore_type": "%s",

  "ipam": {

	"type": "host-local",

	"subnet": "10.0.0.0/8"

  }

}`, cniVersion, os.Getenv("ETCD_IP"), os.Getenv("DATASTORE_TYPE"))

			pluginPath := fmt.Sprintf("%s/%s", os.Getenv("BIN"), os.Getenv("PLUGIN"))


====================
{

  "cniVersion": "%s",

  "name": "net1",

  "type": "calico",

  "etcd_endpoints": "http://%s:2370",

  "log_level": "info",

  "nodename_file_optional": true,

  "datastore_type": "%s",

  "ipam": {

	"type": "host-local",

	"subnet": "10.0.0.0/8"

  }

}`, cniVersion, os.Getenv("ETCD_IP"), os.Getenv("DATASTORE_TYPE"))

			pluginPath := fmt.Sprintf("%s/%s", os.Getenv("BIN"), os.Getenv("PLUGIN"))

			c := exec.Command(pluginPath, "-t")

			stdin, err := c.StdinPipe()

			Expect(err).ToNot(HaveOccurred())

			go func() {

				defer stdin.Close()

				_, _ = io.WriteString(stdin, netconf)


====================
  "log_level": "info",

  "nodename_file_optional": true,

  "datastore_type": "%s",

  "ipam": {

	"type": "host-local",

	"subnet": "10.0.0.0/8"

  }

}`, cniVersion, os.Getenv("ETCD_IP"), os.Getenv("DATASTORE_TYPE"))

			pluginPath := fmt.Sprintf("%s/%s", os.Getenv("BIN"), os.Getenv("PLUGIN"))

			c := exec.Command(pluginPath, "-t")

			stdin, err := c.StdinPipe()

			Expect(err).ToNot(HaveOccurred())

			go func() {

				defer stdin.Close()

				_, _ = io.WriteString(stdin, netconf)

			}()

			_, err = c.CombinedOutput()

			Expect(err).To(HaveOccurred())

			close(done)

		}, 10)


====================
		return nil, nil, err

	}

	endpointName := hns.ConstructEndpointName(args.ContainerID, args.Netns, n.Name)

	epIP := result.IPs[0].Address.IP

	epIPBytes := epIP.To4()

	macAddr := ""

	if d.conf.Mode == "vxlan" {

		vxlanMACPrefix := d.conf.VXLANMacPrefix

		if len(vxlanMACPrefix) != 0 {

			if len(vxlanMACPrefix) != 5 || vxlanMACPrefix[2] != '-' {

				return nil, nil, fmt.Errorf("endpointMacPrefix [%v] is invalid, value must be of the format xx-xx", vxlanMACPrefix)

			}

		} else {

			vxlanMACPrefix = "0E-2A"

		}

		// conjure a MAC based on the IP for Overlay

		macAddr = fmt.Sprintf("%v-%02x-%02x-%02x-%02x", vxlanMACPrefix, epIPBytes[0], epIPBytes[1], epIPBytes[2], epIPBytes[3])

		v1pols = append(v1pols, []json.RawMessage{

			[]byte(fmt.Sprintf(`{"Type":"PA","PA":"%s"}`, hnsNetwork.ManagementIP)),

		}...)


====================
func getNthIP(PodCIDR *net.IPNet, n int) net.IP {

	gwaddr := PodCIDR.IP.To4()

	buffer := make([]byte, len(gwaddr))

	copy(buffer, gwaddr)

	buffer[3] += byte(n)

	return buffer

}

func CreateNetworkName(netName string, subnet *net.IPNet) string {

	str := subnet.IP.String()

	network := strings.Replace(str, ".", "-", -1)

	name := netName + "-" + network

	return name

}

// SetupRoutes sets up the routes for the host side of the veth pair.

func SetupRoutes(hostVeth interface{}, result *cniv1.Result) error {

	// Go through all the IPs and add routes for each IP in the result.

	for _, ipAddr := range result.IPs {

		logrus.WithFields(logrus.Fields{"interface": hostVeth, "IP": ipAddr.Address}).Debugf("STUB: CNI adding route")

	}

	return nil


====================
	gwaddr := PodCIDR.IP.To4()

	buffer := make([]byte, len(gwaddr))

	copy(buffer, gwaddr)

	buffer[3] += byte(n)

	return buffer

}

func CreateNetworkName(netName string, subnet *net.IPNet) string {

	str := subnet.IP.String()

	network := strings.Replace(str, ".", "-", -1)

	name := netName + "-" + network

	return name

}

// SetupRoutes sets up the routes for the host side of the veth pair.

func SetupRoutes(hostVeth interface{}, result *cniv1.Result) error {

	// Go through all the IPs and add routes for each IP in the result.

	for _, ipAddr := range result.IPs {

		logrus.WithFields(logrus.Fields{"interface": hostVeth, "IP": ipAddr.Address}).Debugf("STUB: CNI adding route")

	}

	return nil

}


====================
type AddRequest struct {

	InterfaceName            string             `protobuf:"bytes,1,opt,name=interface_name,json=interfaceName,proto3" json:"interface_name,omitempty"`

	Netns                    string             `protobuf:"bytes,2,opt,name=netns,proto3" json:"netns,omitempty"`

	DesiredHostInterfaceName string             `protobuf:"bytes,3,opt,name=desired_host_interface_name,json=desiredHostInterfaceName,proto3" json:"desired_host_interface_name,omitempty"`

	Settings                 *ContainerSettings `protobuf:"bytes,4,opt,name=settings,proto3" json:"settings,omitempty"`

	ContainerIps             []*IPConfig        `protobuf:"bytes,5,rep,name=container_ips,json=containerIps,proto3" json:"container_ips,omitempty"`

	ContainerRoutes          []string           `protobuf:"bytes,6,rep,name=container_routes,json=containerRoutes,proto3" json:"container_routes,omitempty"`

	Workload                 *WorkloadIDs       `protobuf:"bytes,7,opt,name=workload,proto3" json:"workload,omitempty"`

	DataplaneOptions         map[string]string  `protobuf:"bytes,8,rep,name=dataplane_options,json=dataplaneOptions,proto3" json:"dataplane_options,omitempty" protobuf_key:"bytes,1,opt,name=key,proto3" protobuf_val:"bytes,2,opt,name=value,proto3"`

	XXX_NoUnkeyedLiteral     struct{}           `json:"-"`

	XXX_unrecognized         []byte             `json:"-"`

	XXX_sizecache            int32              `json:"-"`

}

func (m *AddRequest) Reset()         { *m = AddRequest{} }

func (m *AddRequest) String() string { return proto.CompactTextString(m) }

func (*AddRequest) ProtoMessage()    {}

func (*AddRequest) Descriptor() ([]byte, []int) {

	return fileDescriptor_42950ee2e0543837, []int{0}

}

func (m *AddRequest) XXX_Unmarshal(b []byte) error {


====================
	InterfaceName            string             `protobuf:"bytes,1,opt,name=interface_name,json=interfaceName,proto3" json:"interface_name,omitempty"`

	Netns                    string             `protobuf:"bytes,2,opt,name=netns,proto3" json:"netns,omitempty"`

	DesiredHostInterfaceName string             `protobuf:"bytes,3,opt,name=desired_host_interface_name,json=desiredHostInterfaceName,proto3" json:"desired_host_interface_name,omitempty"`

	Settings                 *ContainerSettings `protobuf:"bytes,4,opt,name=settings,proto3" json:"settings,omitempty"`

	ContainerIps             []*IPConfig        `protobuf:"bytes,5,rep,name=container_ips,json=containerIps,proto3" json:"container_ips,omitempty"`

	ContainerRoutes          []string           `protobuf:"bytes,6,rep,name=container_routes,json=containerRoutes,proto3" json:"container_routes,omitempty"`

	Workload                 *WorkloadIDs       `protobuf:"bytes,7,opt,name=workload,proto3" json:"workload,omitempty"`

	DataplaneOptions         map[string]string  `protobuf:"bytes,8,rep,name=dataplane_options,json=dataplaneOptions,proto3" json:"dataplane_options,omitempty" protobuf_key:"bytes,1,opt,name=key,proto3" protobuf_val:"bytes,2,opt,name=value,proto3"`

	XXX_NoUnkeyedLiteral     struct{}           `json:"-"`

	XXX_unrecognized         []byte             `json:"-"`

	XXX_sizecache            int32              `json:"-"`

}

func (m *AddRequest) Reset()         { *m = AddRequest{} }

func (m *AddRequest) String() string { return proto.CompactTextString(m) }

func (*AddRequest) ProtoMessage()    {}

func (*AddRequest) Descriptor() ([]byte, []int) {

	return fileDescriptor_42950ee2e0543837, []int{0}

}

func (m *AddRequest) XXX_Unmarshal(b []byte) error {

	return xxx_messageInfo_AddRequest.Unmarshal(m, b)


====================
	Netns                    string             `protobuf:"bytes,2,opt,name=netns,proto3" json:"netns,omitempty"`

	DesiredHostInterfaceName string             `protobuf:"bytes,3,opt,name=desired_host_interface_name,json=desiredHostInterfaceName,proto3" json:"desired_host_interface_name,omitempty"`

	Settings                 *ContainerSettings `protobuf:"bytes,4,opt,name=settings,proto3" json:"settings,omitempty"`

	ContainerIps             []*IPConfig        `protobuf:"bytes,5,rep,name=container_ips,json=containerIps,proto3" json:"container_ips,omitempty"`

	ContainerRoutes          []string           `protobuf:"bytes,6,rep,name=container_routes,json=containerRoutes,proto3" json:"container_routes,omitempty"`

	Workload                 *WorkloadIDs       `protobuf:"bytes,7,opt,name=workload,proto3" json:"workload,omitempty"`

	DataplaneOptions         map[string]string  `protobuf:"bytes,8,rep,name=dataplane_options,json=dataplaneOptions,proto3" json:"dataplane_options,omitempty" protobuf_key:"bytes,1,opt,name=key,proto3" protobuf_val:"bytes,2,opt,name=value,proto3"`

	XXX_NoUnkeyedLiteral     struct{}           `json:"-"`

	XXX_unrecognized         []byte             `json:"-"`

	XXX_sizecache            int32              `json:"-"`

}

func (m *AddRequest) Reset()         { *m = AddRequest{} }

func (m *AddRequest) String() string { return proto.CompactTextString(m) }

func (*AddRequest) ProtoMessage()    {}

func (*AddRequest) Descriptor() ([]byte, []int) {

	return fileDescriptor_42950ee2e0543837, []int{0}

}

func (m *AddRequest) XXX_Unmarshal(b []byte) error {

	return xxx_messageInfo_AddRequest.Unmarshal(m, b)

}


====================
func (m *AddRequest) GetDataplaneOptions() map[string]string {

	if m != nil {

		return m.DataplaneOptions

	}

	return nil

}

type ContainerSettings struct {

	AllowIpForwarding    bool     `protobuf:"varint,1,opt,name=allow_ip_forwarding,json=allowIpForwarding,proto3" json:"allow_ip_forwarding,omitempty"`

	Mtu                  int32    `protobuf:"varint,2,opt,name=mtu,proto3" json:"mtu,omitempty"`

	XXX_NoUnkeyedLiteral struct{} `json:"-"`

	XXX_unrecognized     []byte   `json:"-"`

	XXX_sizecache        int32    `json:"-"`

}

func (m *ContainerSettings) Reset()         { *m = ContainerSettings{} }

func (m *ContainerSettings) String() string { return proto.CompactTextString(m) }

func (*ContainerSettings) ProtoMessage()    {}

func (*ContainerSettings) Descriptor() ([]byte, []int) {

	return fileDescriptor_42950ee2e0543837, []int{1}

}

func (m *ContainerSettings) XXX_Unmarshal(b []byte) error {


====================
	if m != nil {

		return m.DataplaneOptions

	}

	return nil

}

type ContainerSettings struct {

	AllowIpForwarding    bool     `protobuf:"varint,1,opt,name=allow_ip_forwarding,json=allowIpForwarding,proto3" json:"allow_ip_forwarding,omitempty"`

	Mtu                  int32    `protobuf:"varint,2,opt,name=mtu,proto3" json:"mtu,omitempty"`

	XXX_NoUnkeyedLiteral struct{} `json:"-"`

	XXX_unrecognized     []byte   `json:"-"`

	XXX_sizecache        int32    `json:"-"`

}

func (m *ContainerSettings) Reset()         { *m = ContainerSettings{} }

func (m *ContainerSettings) String() string { return proto.CompactTextString(m) }

func (*ContainerSettings) ProtoMessage()    {}

func (*ContainerSettings) Descriptor() ([]byte, []int) {

	return fileDescriptor_42950ee2e0543837, []int{1}

}

func (m *ContainerSettings) XXX_Unmarshal(b []byte) error {

	return xxx_messageInfo_ContainerSettings.Unmarshal(m, b)


====================
		return m.DataplaneOptions

	}

	return nil

}

type ContainerSettings struct {

	AllowIpForwarding    bool     `protobuf:"varint,1,opt,name=allow_ip_forwarding,json=allowIpForwarding,proto3" json:"allow_ip_forwarding,omitempty"`

	Mtu                  int32    `protobuf:"varint,2,opt,name=mtu,proto3" json:"mtu,omitempty"`

	XXX_NoUnkeyedLiteral struct{} `json:"-"`

	XXX_unrecognized     []byte   `json:"-"`

	XXX_sizecache        int32    `json:"-"`

}

func (m *ContainerSettings) Reset()         { *m = ContainerSettings{} }

func (m *ContainerSettings) String() string { return proto.CompactTextString(m) }

func (*ContainerSettings) ProtoMessage()    {}

func (*ContainerSettings) Descriptor() ([]byte, []int) {

	return fileDescriptor_42950ee2e0543837, []int{1}

}

func (m *ContainerSettings) XXX_Unmarshal(b []byte) error {

	return xxx_messageInfo_ContainerSettings.Unmarshal(m, b)

}


====================
func (m *ContainerSettings) GetMtu() int32 {

	if m != nil {

		return m.Mtu

	}

	return 0

}

type IPConfig struct {

	Address              string   `protobuf:"bytes,1,opt,name=address,proto3" json:"address,omitempty"`

	Gateway              string   `protobuf:"bytes,2,opt,name=gateway,proto3" json:"gateway,omitempty"`

	XXX_NoUnkeyedLiteral struct{} `json:"-"`

	XXX_unrecognized     []byte   `json:"-"`

	XXX_sizecache        int32    `json:"-"`

}

func (m *IPConfig) Reset()         { *m = IPConfig{} }

func (m *IPConfig) String() string { return proto.CompactTextString(m) }

func (*IPConfig) ProtoMessage()    {}

func (*IPConfig) Descriptor() ([]byte, []int) {

	return fileDescriptor_42950ee2e0543837, []int{2}

}

func (m *IPConfig) XXX_Unmarshal(b []byte) error {


====================
	if m != nil {

		return m.Mtu

	}

	return 0

}

type IPConfig struct {

	Address              string   `protobuf:"bytes,1,opt,name=address,proto3" json:"address,omitempty"`

	Gateway              string   `protobuf:"bytes,2,opt,name=gateway,proto3" json:"gateway,omitempty"`

	XXX_NoUnkeyedLiteral struct{} `json:"-"`

	XXX_unrecognized     []byte   `json:"-"`

	XXX_sizecache        int32    `json:"-"`

}

func (m *IPConfig) Reset()         { *m = IPConfig{} }

func (m *IPConfig) String() string { return proto.CompactTextString(m) }

func (*IPConfig) ProtoMessage()    {}

func (*IPConfig) Descriptor() ([]byte, []int) {

	return fileDescriptor_42950ee2e0543837, []int{2}

}

func (m *IPConfig) XXX_Unmarshal(b []byte) error {

	return xxx_messageInfo_IPConfig.Unmarshal(m, b)


====================
		return m.Mtu

	}

	return 0

}

type IPConfig struct {

	Address              string   `protobuf:"bytes,1,opt,name=address,proto3" json:"address,omitempty"`

	Gateway              string   `protobuf:"bytes,2,opt,name=gateway,proto3" json:"gateway,omitempty"`

	XXX_NoUnkeyedLiteral struct{} `json:"-"`

	XXX_unrecognized     []byte   `json:"-"`

	XXX_sizecache        int32    `json:"-"`

}

func (m *IPConfig) Reset()         { *m = IPConfig{} }

func (m *IPConfig) String() string { return proto.CompactTextString(m) }

func (*IPConfig) ProtoMessage()    {}

func (*IPConfig) Descriptor() ([]byte, []int) {

	return fileDescriptor_42950ee2e0543837, []int{2}

}

func (m *IPConfig) XXX_Unmarshal(b []byte) error {

	return xxx_messageInfo_IPConfig.Unmarshal(m, b)

}


====================
	Name                 string            `protobuf:"bytes,1,opt,name=name,proto3" json:"name,omitempty"`

	Namespace            string            `protobuf:"bytes,2,opt,name=namespace,proto3" json:"namespace,omitempty"`

	Labels               map[string]string `protobuf:"bytes,3,rep,name=labels,proto3" json:"labels,omitempty" protobuf_key:"bytes,1,opt,name=key,proto3" protobuf_val:"bytes,2,opt,name=value,proto3"`

	Annotations          map[string]string `protobuf:"bytes,4,rep,name=annotations,proto3" json:"annotations,omitempty" protobuf_key:"bytes,1,opt,name=key,proto3" protobuf_val:"bytes,2,opt,name=value,proto3"`

	Endpoint             string            `protobuf:"bytes,5,opt,name=endpoint,proto3" json:"endpoint,omitempty"`

	Node                 string            `protobuf:"bytes,6,opt,name=node,proto3" json:"node,omitempty"`

	Orchestrator         string            `protobuf:"bytes,7,opt,name=orchestrator,proto3" json:"orchestrator,omitempty"`

	Pod                  string            `protobuf:"bytes,8,opt,name=pod,proto3" json:"pod,omitempty"`

	Ports                []*Port           `protobuf:"bytes,9,rep,name=ports,proto3" json:"ports,omitempty"`

	XXX_NoUnkeyedLiteral struct{}          `json:"-"`

	XXX_unrecognized     []byte            `json:"-"`

	XXX_sizecache        int32             `json:"-"`

}

func (m *WorkloadIDs) Reset()         { *m = WorkloadIDs{} }

func (m *WorkloadIDs) String() string { return proto.CompactTextString(m) }

func (*WorkloadIDs) ProtoMessage()    {}

func (*WorkloadIDs) Descriptor() ([]byte, []int) {

	return fileDescriptor_42950ee2e0543837, []int{3}

}

func (m *WorkloadIDs) XXX_Unmarshal(b []byte) error {


====================
	Namespace            string            `protobuf:"bytes,2,opt,name=namespace,proto3" json:"namespace,omitempty"`

	Labels               map[string]string `protobuf:"bytes,3,rep,name=labels,proto3" json:"labels,omitempty" protobuf_key:"bytes,1,opt,name=key,proto3" protobuf_val:"bytes,2,opt,name=value,proto3"`

	Annotations          map[string]string `protobuf:"bytes,4,rep,name=annotations,proto3" json:"annotations,omitempty" protobuf_key:"bytes,1,opt,name=key,proto3" protobuf_val:"bytes,2,opt,name=value,proto3"`

	Endpoint             string            `protobuf:"bytes,5,opt,name=endpoint,proto3" json:"endpoint,omitempty"`

	Node                 string            `protobuf:"bytes,6,opt,name=node,proto3" json:"node,omitempty"`

	Orchestrator         string            `protobuf:"bytes,7,opt,name=orchestrator,proto3" json:"orchestrator,omitempty"`

	Pod                  string            `protobuf:"bytes,8,opt,name=pod,proto3" json:"pod,omitempty"`

	Ports                []*Port           `protobuf:"bytes,9,rep,name=ports,proto3" json:"ports,omitempty"`

	XXX_NoUnkeyedLiteral struct{}          `json:"-"`

	XXX_unrecognized     []byte            `json:"-"`

	XXX_sizecache        int32             `json:"-"`

}

func (m *WorkloadIDs) Reset()         { *m = WorkloadIDs{} }

func (m *WorkloadIDs) String() string { return proto.CompactTextString(m) }

func (*WorkloadIDs) ProtoMessage()    {}

func (*WorkloadIDs) Descriptor() ([]byte, []int) {

	return fileDescriptor_42950ee2e0543837, []int{3}

}

func (m *WorkloadIDs) XXX_Unmarshal(b []byte) error {

	return xxx_messageInfo_WorkloadIDs.Unmarshal(m, b)


====================
	Labels               map[string]string `protobuf:"bytes,3,rep,name=labels,proto3" json:"labels,omitempty" protobuf_key:"bytes,1,opt,name=key,proto3" protobuf_val:"bytes,2,opt,name=value,proto3"`

	Annotations          map[string]string `protobuf:"bytes,4,rep,name=annotations,proto3" json:"annotations,omitempty" protobuf_key:"bytes,1,opt,name=key,proto3" protobuf_val:"bytes,2,opt,name=value,proto3"`

	Endpoint             string            `protobuf:"bytes,5,opt,name=endpoint,proto3" json:"endpoint,omitempty"`

	Node                 string            `protobuf:"bytes,6,opt,name=node,proto3" json:"node,omitempty"`

	Orchestrator         string            `protobuf:"bytes,7,opt,name=orchestrator,proto3" json:"orchestrator,omitempty"`

	Pod                  string            `protobuf:"bytes,8,opt,name=pod,proto3" json:"pod,omitempty"`

	Ports                []*Port           `protobuf:"bytes,9,rep,name=ports,proto3" json:"ports,omitempty"`

	XXX_NoUnkeyedLiteral struct{}          `json:"-"`

	XXX_unrecognized     []byte            `json:"-"`

	XXX_sizecache        int32             `json:"-"`

}

func (m *WorkloadIDs) Reset()         { *m = WorkloadIDs{} }

func (m *WorkloadIDs) String() string { return proto.CompactTextString(m) }

func (*WorkloadIDs) ProtoMessage()    {}

func (*WorkloadIDs) Descriptor() ([]byte, []int) {

	return fileDescriptor_42950ee2e0543837, []int{3}

}

func (m *WorkloadIDs) XXX_Unmarshal(b []byte) error {

	return xxx_messageInfo_WorkloadIDs.Unmarshal(m, b)

}


====================
	}

	return nil

}

type Port struct {

	Name                 string   `protobuf:"bytes,1,opt,name=name,proto3" json:"name,omitempty"`

	Protocol             string   `protobuf:"bytes,2,opt,name=protocol,proto3" json:"protocol,omitempty"`

	Port                 uint32   `protobuf:"varint,3,opt,name=port,proto3" json:"port,omitempty"`

	HostPort             uint32   `protobuf:"varint,4,opt,name=host_port,json=hostPort,proto3" json:"host_port,omitempty"`

	HostIp               string   `protobuf:"bytes,5,opt,name=host_ip,json=hostIp,proto3" json:"host_ip,omitempty"`

	XXX_NoUnkeyedLiteral struct{} `json:"-"`

	XXX_unrecognized     []byte   `json:"-"`

	XXX_sizecache        int32    `json:"-"`

}

func (m *Port) Reset()         { *m = Port{} }

func (m *Port) String() string { return proto.CompactTextString(m) }

func (*Port) ProtoMessage()    {}

func (*Port) Descriptor() ([]byte, []int) {

	return fileDescriptor_42950ee2e0543837, []int{4}

}

func (m *Port) XXX_Unmarshal(b []byte) error {


====================
	return nil

}

type Port struct {

	Name                 string   `protobuf:"bytes,1,opt,name=name,proto3" json:"name,omitempty"`

	Protocol             string   `protobuf:"bytes,2,opt,name=protocol,proto3" json:"protocol,omitempty"`

	Port                 uint32   `protobuf:"varint,3,opt,name=port,proto3" json:"port,omitempty"`

	HostPort             uint32   `protobuf:"varint,4,opt,name=host_port,json=hostPort,proto3" json:"host_port,omitempty"`

	HostIp               string   `protobuf:"bytes,5,opt,name=host_ip,json=hostIp,proto3" json:"host_ip,omitempty"`

	XXX_NoUnkeyedLiteral struct{} `json:"-"`

	XXX_unrecognized     []byte   `json:"-"`

	XXX_sizecache        int32    `json:"-"`

}

func (m *Port) Reset()         { *m = Port{} }

func (m *Port) String() string { return proto.CompactTextString(m) }

func (*Port) ProtoMessage()    {}

func (*Port) Descriptor() ([]byte, []int) {

	return fileDescriptor_42950ee2e0543837, []int{4}

}

func (m *Port) XXX_Unmarshal(b []byte) error {

	return xxx_messageInfo_Port.Unmarshal(m, b)


====================
}

type Port struct {

	Name                 string   `protobuf:"bytes,1,opt,name=name,proto3" json:"name,omitempty"`

	Protocol             string   `protobuf:"bytes,2,opt,name=protocol,proto3" json:"protocol,omitempty"`

	Port                 uint32   `protobuf:"varint,3,opt,name=port,proto3" json:"port,omitempty"`

	HostPort             uint32   `protobuf:"varint,4,opt,name=host_port,json=hostPort,proto3" json:"host_port,omitempty"`

	HostIp               string   `protobuf:"bytes,5,opt,name=host_ip,json=hostIp,proto3" json:"host_ip,omitempty"`

	XXX_NoUnkeyedLiteral struct{} `json:"-"`

	XXX_unrecognized     []byte   `json:"-"`

	XXX_sizecache        int32    `json:"-"`

}

func (m *Port) Reset()         { *m = Port{} }

func (m *Port) String() string { return proto.CompactTextString(m) }

func (*Port) ProtoMessage()    {}

func (*Port) Descriptor() ([]byte, []int) {

	return fileDescriptor_42950ee2e0543837, []int{4}

}

func (m *Port) XXX_Unmarshal(b []byte) error {

	return xxx_messageInfo_Port.Unmarshal(m, b)

}


====================
		return m.HostIp

	}

	return ""

}

type AddReply struct {

	Successful           bool     `protobuf:"varint,1,opt,name=successful,proto3" json:"successful,omitempty"`

	ErrorMessage         string   `protobuf:"bytes,2,opt,name=error_message,json=errorMessage,proto3" json:"error_message,omitempty"`

	HostInterfaceName    string   `protobuf:"bytes,3,opt,name=host_interface_name,json=hostInterfaceName,proto3" json:"host_interface_name,omitempty"`

	ContainerMac         string   `protobuf:"bytes,4,opt,name=container_mac,json=containerMac,proto3" json:"container_mac,omitempty"`

	XXX_NoUnkeyedLiteral struct{} `json:"-"`

	XXX_unrecognized     []byte   `json:"-"`

	XXX_sizecache        int32    `json:"-"`

}

func (m *AddReply) Reset()         { *m = AddReply{} }

func (m *AddReply) String() string { return proto.CompactTextString(m) }

func (*AddReply) ProtoMessage()    {}

func (*AddReply) Descriptor() ([]byte, []int) {

	return fileDescriptor_42950ee2e0543837, []int{5}

}

func (m *AddReply) XXX_Unmarshal(b []byte) error {


====================
	}

	return ""

}

type AddReply struct {

	Successful           bool     `protobuf:"varint,1,opt,name=successful,proto3" json:"successful,omitempty"`

	ErrorMessage         string   `protobuf:"bytes,2,opt,name=error_message,json=errorMessage,proto3" json:"error_message,omitempty"`

	HostInterfaceName    string   `protobuf:"bytes,3,opt,name=host_interface_name,json=hostInterfaceName,proto3" json:"host_interface_name,omitempty"`

	ContainerMac         string   `protobuf:"bytes,4,opt,name=container_mac,json=containerMac,proto3" json:"container_mac,omitempty"`

	XXX_NoUnkeyedLiteral struct{} `json:"-"`

	XXX_unrecognized     []byte   `json:"-"`

	XXX_sizecache        int32    `json:"-"`

}

func (m *AddReply) Reset()         { *m = AddReply{} }

func (m *AddReply) String() string { return proto.CompactTextString(m) }

func (*AddReply) ProtoMessage()    {}

func (*AddReply) Descriptor() ([]byte, []int) {

	return fileDescriptor_42950ee2e0543837, []int{5}

}

func (m *AddReply) XXX_Unmarshal(b []byte) error {

	return xxx_messageInfo_AddReply.Unmarshal(m, b)


====================
	return ""

}

type AddReply struct {

	Successful           bool     `protobuf:"varint,1,opt,name=successful,proto3" json:"successful,omitempty"`

	ErrorMessage         string   `protobuf:"bytes,2,opt,name=error_message,json=errorMessage,proto3" json:"error_message,omitempty"`

	HostInterfaceName    string   `protobuf:"bytes,3,opt,name=host_interface_name,json=hostInterfaceName,proto3" json:"host_interface_name,omitempty"`

	ContainerMac         string   `protobuf:"bytes,4,opt,name=container_mac,json=containerMac,proto3" json:"container_mac,omitempty"`

	XXX_NoUnkeyedLiteral struct{} `json:"-"`

	XXX_unrecognized     []byte   `json:"-"`

	XXX_sizecache        int32    `json:"-"`

}

func (m *AddReply) Reset()         { *m = AddReply{} }

func (m *AddReply) String() string { return proto.CompactTextString(m) }

func (*AddReply) ProtoMessage()    {}

func (*AddReply) Descriptor() ([]byte, []int) {

	return fileDescriptor_42950ee2e0543837, []int{5}

}

func (m *AddReply) XXX_Unmarshal(b []byte) error {

	return xxx_messageInfo_AddReply.Unmarshal(m, b)

}


====================
	if m != nil {

		return m.ContainerMac

	}

	return ""

}

type DelRequest struct {

	InterfaceName        string            `protobuf:"bytes,1,opt,name=interface_name,json=interfaceName,proto3" json:"interface_name,omitempty"`

	Netns                string            `protobuf:"bytes,2,opt,name=netns,proto3" json:"netns,omitempty"`

	DataplaneOptions     map[string]string `protobuf:"bytes,3,rep,name=dataplane_options,json=dataplaneOptions,proto3" json:"dataplane_options,omitempty" protobuf_key:"bytes,1,opt,name=key,proto3" protobuf_val:"bytes,2,opt,name=value,proto3"`

	XXX_NoUnkeyedLiteral struct{}          `json:"-"`

	XXX_unrecognized     []byte            `json:"-"`

	XXX_sizecache        int32             `json:"-"`

}

func (m *DelRequest) Reset()         { *m = DelRequest{} }

func (m *DelRequest) String() string { return proto.CompactTextString(m) }

func (*DelRequest) ProtoMessage()    {}

func (*DelRequest) Descriptor() ([]byte, []int) {

	return fileDescriptor_42950ee2e0543837, []int{6}

}

func (m *DelRequest) XXX_Unmarshal(b []byte) error {


====================
		return m.ContainerMac

	}

	return ""

}

type DelRequest struct {

	InterfaceName        string            `protobuf:"bytes,1,opt,name=interface_name,json=interfaceName,proto3" json:"interface_name,omitempty"`

	Netns                string            `protobuf:"bytes,2,opt,name=netns,proto3" json:"netns,omitempty"`

	DataplaneOptions     map[string]string `protobuf:"bytes,3,rep,name=dataplane_options,json=dataplaneOptions,proto3" json:"dataplane_options,omitempty" protobuf_key:"bytes,1,opt,name=key,proto3" protobuf_val:"bytes,2,opt,name=value,proto3"`

	XXX_NoUnkeyedLiteral struct{}          `json:"-"`

	XXX_unrecognized     []byte            `json:"-"`

	XXX_sizecache        int32             `json:"-"`

}

func (m *DelRequest) Reset()         { *m = DelRequest{} }

func (m *DelRequest) String() string { return proto.CompactTextString(m) }

func (*DelRequest) ProtoMessage()    {}

func (*DelRequest) Descriptor() ([]byte, []int) {

	return fileDescriptor_42950ee2e0543837, []int{6}

}

func (m *DelRequest) XXX_Unmarshal(b []byte) error {

	return xxx_messageInfo_DelRequest.Unmarshal(m, b)


====================
	}

	return ""

}

type DelRequest struct {

	InterfaceName        string            `protobuf:"bytes,1,opt,name=interface_name,json=interfaceName,proto3" json:"interface_name,omitempty"`

	Netns                string            `protobuf:"bytes,2,opt,name=netns,proto3" json:"netns,omitempty"`

	DataplaneOptions     map[string]string `protobuf:"bytes,3,rep,name=dataplane_options,json=dataplaneOptions,proto3" json:"dataplane_options,omitempty" protobuf_key:"bytes,1,opt,name=key,proto3" protobuf_val:"bytes,2,opt,name=value,proto3"`

	XXX_NoUnkeyedLiteral struct{}          `json:"-"`

	XXX_unrecognized     []byte            `json:"-"`

	XXX_sizecache        int32             `json:"-"`

}

func (m *DelRequest) Reset()         { *m = DelRequest{} }

func (m *DelRequest) String() string { return proto.CompactTextString(m) }

func (*DelRequest) ProtoMessage()    {}

func (*DelRequest) Descriptor() ([]byte, []int) {

	return fileDescriptor_42950ee2e0543837, []int{6}

}

func (m *DelRequest) XXX_Unmarshal(b []byte) error {

	return xxx_messageInfo_DelRequest.Unmarshal(m, b)

}


====================
func (m *DelRequest) GetDataplaneOptions() map[string]string {

	if m != nil {

		return m.DataplaneOptions

	}

	return nil

}

type DelReply struct {

	Successful           bool     `protobuf:"varint,1,opt,name=successful,proto3" json:"successful,omitempty"`

	ErrorMessage         string   `protobuf:"bytes,2,opt,name=error_message,json=errorMessage,proto3" json:"error_message,omitempty"`

	XXX_NoUnkeyedLiteral struct{} `json:"-"`

	XXX_unrecognized     []byte   `json:"-"`

	XXX_sizecache        int32    `json:"-"`

}

func (m *DelReply) Reset()         { *m = DelReply{} }

func (m *DelReply) String() string { return proto.CompactTextString(m) }

func (*DelReply) ProtoMessage()    {}

func (*DelReply) Descriptor() ([]byte, []int) {

	return fileDescriptor_42950ee2e0543837, []int{7}

}

func (m *DelReply) XXX_Unmarshal(b []byte) error {


====================
	if m != nil {

		return m.DataplaneOptions

	}

	return nil

}

type DelReply struct {

	Successful           bool     `protobuf:"varint,1,opt,name=successful,proto3" json:"successful,omitempty"`

	ErrorMessage         string   `protobuf:"bytes,2,opt,name=error_message,json=errorMessage,proto3" json:"error_message,omitempty"`

	XXX_NoUnkeyedLiteral struct{} `json:"-"`

	XXX_unrecognized     []byte   `json:"-"`

	XXX_sizecache        int32    `json:"-"`

}

func (m *DelReply) Reset()         { *m = DelReply{} }

func (m *DelReply) String() string { return proto.CompactTextString(m) }

func (*DelReply) ProtoMessage()    {}

func (*DelReply) Descriptor() ([]byte, []int) {

	return fileDescriptor_42950ee2e0543837, []int{7}

}

func (m *DelReply) XXX_Unmarshal(b []byte) error {

	return xxx_messageInfo_DelReply.Unmarshal(m, b)


====================
		return m.DataplaneOptions

	}

	return nil

}

type DelReply struct {

	Successful           bool     `protobuf:"varint,1,opt,name=successful,proto3" json:"successful,omitempty"`

	ErrorMessage         string   `protobuf:"bytes,2,opt,name=error_message,json=errorMessage,proto3" json:"error_message,omitempty"`

	XXX_NoUnkeyedLiteral struct{} `json:"-"`

	XXX_unrecognized     []byte   `json:"-"`

	XXX_sizecache        int32    `json:"-"`

}

func (m *DelReply) Reset()         { *m = DelReply{} }

func (m *DelReply) String() string { return proto.CompactTextString(m) }

func (*DelReply) ProtoMessage()    {}

func (*DelReply) Descriptor() ([]byte, []int) {

	return fileDescriptor_42950ee2e0543837, []int{7}

}

func (m *DelReply) XXX_Unmarshal(b []byte) error {

	return xxx_messageInfo_DelReply.Unmarshal(m, b)

}


====================
	"k8s.io/client-go/kubernetes"

	"k8s.io/client-go/tools/clientcmd"

	"k8s.io/client-go/tools/clientcmd/api"

)

var expectedDefaultConfig string = `{

  "name": "k8s-pod-network",

  "cniVersion": "0.3.1",

  "plugins": [

    {

      "type": "calico",

      "log_level": "info",

      "log_file_path": "/var/log/calico/cni/cni.log",

      "datastore_type": "kubernetes",

      "nodename": "my-node",

      "mtu": 1500,

      "ipam": {"type": "calico-ipam"},

      "policy": {"type": "k8s"},

      "kubernetes": {"kubeconfig": "/etc/cni/net.d/calico-kubeconfig"}

    },

    {


====================
  "cniVersion": "0.3.1",

  "plugins": [

    {

      "type": "calico",

      "log_level": "info",

      "log_file_path": "/var/log/calico/cni/cni.log",

      "datastore_type": "kubernetes",

      "nodename": "my-node",

      "mtu": 1500,

      "ipam": {"type": "calico-ipam"},

      "policy": {"type": "k8s"},

      "kubernetes": {"kubeconfig": "/etc/cni/net.d/calico-kubeconfig"}

    },

    {

      "type": "portmap",

      "snat": true,

      "capabilities": {"portMappings": true}

    }

  ]

}`


====================
      "log_file_path": "/var/log/calico/cni/cni.log",

      "datastore_type": "kubernetes",

      "nodename": "my-node",

      "mtu": 1500,

      "ipam": {"type": "calico-ipam"},

      "policy": {"type": "k8s"},

      "kubernetes": {"kubeconfig": "/etc/cni/net.d/calico-kubeconfig"}

    },

    {

      "type": "portmap",

      "snat": true,

      "capabilities": {"portMappings": true}

    }

  ]

}`

var expectedAlternateConfig string = `{

    "name": "alternate",

    "type": "calico",

    "etcd_endpoints": "",

    "etcd_discovery_srv": "",


====================
    {

      "type": "portmap",

      "snat": true,

      "capabilities": {"portMappings": true}

    }

  ]

}`

var expectedAlternateConfig string = `{

    "name": "alternate",

    "type": "calico",

    "etcd_endpoints": "",

    "etcd_discovery_srv": "",

    "etcd_key_file": "",

    "etcd_cert_file": "",

    "etcd_ca_cert_file": "",

    "log_level": "info",

    "ipam": {

        "type": "calico-ipam"

    },

    "policy": {


====================
    "name": "alternate",

    "type": "calico",

    "etcd_endpoints": "",

    "etcd_discovery_srv": "",

    "etcd_key_file": "",

    "etcd_cert_file": "",

    "etcd_ca_cert_file": "",

    "log_level": "info",

    "ipam": {

        "type": "calico-ipam"

    },

    "policy": {

        "type": "k8s",

        "k8s_api_root": "https://127.0.0.1:6443",

        "k8s_auth_token": "my-secret-key"

    },

    "kubernetes": {

        "kubeconfig": "/etc/cni/net.d/calico-kubeconfig"

    }

}`


====================
			Fail(fmt.Sprintf("Error running docker command: %s", out))

		}

	}

	// Assemble our arguments.

	binFolder := "/host/opt/cni/bin"

	if !binFolderWriteable {

		binFolder += ":ro"

	}

	args := []string{

		"run", "--rm", "--name", name,

		"--net=host",

		"-e", "SLEEP=false",

		"-e", "KUBERNETES_SERVICE_HOST=127.0.0.1",

		"-e", "KUBERNETES_SERVICE_PORT=6443",

		"-e", "KUBERNETES_NODE_NAME=my-node",

		"-e", "KUBECONFIG=/home/user/certs/kubeconfig",

		"-v", tempDir + "/bin:" + binFolder,

		"-v", tempDir + "/net.d:/host/etc/cni/net.d",

		"-v", tempDir + "/serviceaccount:/var/run/secrets/kubernetes.io/serviceaccount",

		"-v", os.Getenv("CERTS_PATH") + ":/home/user/certs",


====================
		}

	}

	// Assemble our arguments.

	binFolder := "/host/opt/cni/bin"

	if !binFolderWriteable {

		binFolder += ":ro"

	}

	args := []string{

		"run", "--rm", "--name", name,

		"--net=host",

		"-e", "SLEEP=false",

		"-e", "KUBERNETES_SERVICE_HOST=127.0.0.1",

		"-e", "KUBERNETES_SERVICE_PORT=6443",

		"-e", "KUBERNETES_NODE_NAME=my-node",

		"-e", "KUBECONFIG=/home/user/certs/kubeconfig",

		"-v", tempDir + "/bin:" + binFolder,

		"-v", tempDir + "/net.d:/host/etc/cni/net.d",

		"-v", tempDir + "/serviceaccount:/var/run/secrets/kubernetes.io/serviceaccount",

		"-v", os.Getenv("CERTS_PATH") + ":/home/user/certs",

	}


====================
	}

	// Assemble our arguments.

	binFolder := "/host/opt/cni/bin"

	if !binFolderWriteable {

		binFolder += ":ro"

	}

	args := []string{

		"run", "--rm", "--name", name,

		"--net=host",

		"-e", "SLEEP=false",

		"-e", "KUBERNETES_SERVICE_HOST=127.0.0.1",

		"-e", "KUBERNETES_SERVICE_PORT=6443",

		"-e", "KUBERNETES_NODE_NAME=my-node",

		"-e", "KUBECONFIG=/home/user/certs/kubeconfig",

		"-v", tempDir + "/bin:" + binFolder,

		"-v", tempDir + "/net.d:/host/etc/cni/net.d",

		"-v", tempDir + "/serviceaccount:/var/run/secrets/kubernetes.io/serviceaccount",

		"-v", os.Getenv("CERTS_PATH") + ":/home/user/certs",

	}

	args = append(args, extraArgs...)


====================
	// Assemble our arguments.

	binFolder := "/host/opt/cni/bin"

	if !binFolderWriteable {

		binFolder += ":ro"

	}

	args := []string{

		"run", "--rm", "--name", name,

		"--net=host",

		"-e", "SLEEP=false",

		"-e", "KUBERNETES_SERVICE_HOST=127.0.0.1",

		"-e", "KUBERNETES_SERVICE_PORT=6443",

		"-e", "KUBERNETES_NODE_NAME=my-node",

		"-e", "KUBECONFIG=/home/user/certs/kubeconfig",

		"-v", tempDir + "/bin:" + binFolder,

		"-v", tempDir + "/net.d:/host/etc/cni/net.d",

		"-v", tempDir + "/serviceaccount:/var/run/secrets/kubernetes.io/serviceaccount",

		"-v", os.Getenv("CERTS_PATH") + ":/home/user/certs",

	}

	args = append(args, extraArgs...)

	image := os.Getenv("CONTAINER_NAME")


====================
	binFolder := "/host/opt/cni/bin"

	if !binFolderWriteable {

		binFolder += ":ro"

	}

	args := []string{

		"run", "--rm", "--name", name,

		"--net=host",

		"-e", "SLEEP=false",

		"-e", "KUBERNETES_SERVICE_HOST=127.0.0.1",

		"-e", "KUBERNETES_SERVICE_PORT=6443",

		"-e", "KUBERNETES_NODE_NAME=my-node",

		"-e", "KUBECONFIG=/home/user/certs/kubeconfig",

		"-v", tempDir + "/bin:" + binFolder,

		"-v", tempDir + "/net.d:/host/etc/cni/net.d",

		"-v", tempDir + "/serviceaccount:/var/run/secrets/kubernetes.io/serviceaccount",

		"-v", os.Getenv("CERTS_PATH") + ":/home/user/certs",

	}

	args = append(args, extraArgs...)

	image := os.Getenv("CONTAINER_NAME")

	args = append(args, image, "/opt/cni/bin/install")


====================
	if !binFolderWriteable {

		binFolder += ":ro"

	}

	args := []string{

		"run", "--rm", "--name", name,

		"--net=host",

		"-e", "SLEEP=false",

		"-e", "KUBERNETES_SERVICE_HOST=127.0.0.1",

		"-e", "KUBERNETES_SERVICE_PORT=6443",

		"-e", "KUBERNETES_NODE_NAME=my-node",

		"-e", "KUBECONFIG=/home/user/certs/kubeconfig",

		"-v", tempDir + "/bin:" + binFolder,

		"-v", tempDir + "/net.d:/host/etc/cni/net.d",

		"-v", tempDir + "/serviceaccount:/var/run/secrets/kubernetes.io/serviceaccount",

		"-v", os.Getenv("CERTS_PATH") + ":/home/user/certs",

	}

	args = append(args, extraArgs...)

	image := os.Getenv("CONTAINER_NAME")

	args = append(args, image, "/opt/cni/bin/install")

	out, err = exec.Command("docker", args...).CombinedOutput()


====================
		binFolder += ":ro"

	}

	args := []string{

		"run", "--rm", "--name", name,

		"--net=host",

		"-e", "SLEEP=false",

		"-e", "KUBERNETES_SERVICE_HOST=127.0.0.1",

		"-e", "KUBERNETES_SERVICE_PORT=6443",

		"-e", "KUBERNETES_NODE_NAME=my-node",

		"-e", "KUBECONFIG=/home/user/certs/kubeconfig",

		"-v", tempDir + "/bin:" + binFolder,

		"-v", tempDir + "/net.d:/host/etc/cni/net.d",

		"-v", tempDir + "/serviceaccount:/var/run/secrets/kubernetes.io/serviceaccount",

		"-v", os.Getenv("CERTS_PATH") + ":/home/user/certs",

	}

	args = append(args, extraArgs...)

	image := os.Getenv("CONTAINER_NAME")

	args = append(args, image, "/opt/cni/bin/install")

	out, err = exec.Command("docker", args...).CombinedOutput()

	_, writeErr := GinkgoWriter.Write(out)


====================
	}

	args := []string{

		"run", "--rm", "--name", name,

		"--net=host",

		"-e", "SLEEP=false",

		"-e", "KUBERNETES_SERVICE_HOST=127.0.0.1",

		"-e", "KUBERNETES_SERVICE_PORT=6443",

		"-e", "KUBERNETES_NODE_NAME=my-node",

		"-e", "KUBECONFIG=/home/user/certs/kubeconfig",

		"-v", tempDir + "/bin:" + binFolder,

		"-v", tempDir + "/net.d:/host/etc/cni/net.d",

		"-v", tempDir + "/serviceaccount:/var/run/secrets/kubernetes.io/serviceaccount",

		"-v", os.Getenv("CERTS_PATH") + ":/home/user/certs",

	}

	args = append(args, extraArgs...)

	image := os.Getenv("CONTAINER_NAME")

	args = append(args, image, "/opt/cni/bin/install")

	out, err = exec.Command("docker", args...).CombinedOutput()

	_, writeErr := GinkgoWriter.Write(out)

	if writeErr != nil {


====================
	args := []string{

		"run", "--rm", "--name", name,

		"--net=host",

		"-e", "SLEEP=false",

		"-e", "KUBERNETES_SERVICE_HOST=127.0.0.1",

		"-e", "KUBERNETES_SERVICE_PORT=6443",

		"-e", "KUBERNETES_NODE_NAME=my-node",

		"-e", "KUBECONFIG=/home/user/certs/kubeconfig",

		"-v", tempDir + "/bin:" + binFolder,

		"-v", tempDir + "/net.d:/host/etc/cni/net.d",

		"-v", tempDir + "/serviceaccount:/var/run/secrets/kubernetes.io/serviceaccount",

		"-v", os.Getenv("CERTS_PATH") + ":/home/user/certs",

	}

	args = append(args, extraArgs...)

	image := os.Getenv("CONTAINER_NAME")

	args = append(args, image, "/opt/cni/bin/install")

	out, err = exec.Command("docker", args...).CombinedOutput()

	_, writeErr := GinkgoWriter.Write(out)

	if writeErr != nil {

		log.WithField("out", out).WithError(writeErr).Warn("GinkgoWriter failed to write output from command.")


====================
		"run", "--rm", "--name", name,

		"--net=host",

		"-e", "SLEEP=false",

		"-e", "KUBERNETES_SERVICE_HOST=127.0.0.1",

		"-e", "KUBERNETES_SERVICE_PORT=6443",

		"-e", "KUBERNETES_NODE_NAME=my-node",

		"-e", "KUBECONFIG=/home/user/certs/kubeconfig",

		"-v", tempDir + "/bin:" + binFolder,

		"-v", tempDir + "/net.d:/host/etc/cni/net.d",

		"-v", tempDir + "/serviceaccount:/var/run/secrets/kubernetes.io/serviceaccount",

		"-v", os.Getenv("CERTS_PATH") + ":/home/user/certs",

	}

	args = append(args, extraArgs...)

	image := os.Getenv("CONTAINER_NAME")

	args = append(args, image, "/opt/cni/bin/install")

	out, err = exec.Command("docker", args...).CombinedOutput()

	_, writeErr := GinkgoWriter.Write(out)

	if writeErr != nil {

		log.WithField("out", out).WithError(writeErr).Warn("GinkgoWriter failed to write output from command.")

	}


====================
		"--net=host",

		"-e", "SLEEP=false",

		"-e", "KUBERNETES_SERVICE_HOST=127.0.0.1",

		"-e", "KUBERNETES_SERVICE_PORT=6443",

		"-e", "KUBERNETES_NODE_NAME=my-node",

		"-e", "KUBECONFIG=/home/user/certs/kubeconfig",

		"-v", tempDir + "/bin:" + binFolder,

		"-v", tempDir + "/net.d:/host/etc/cni/net.d",

		"-v", tempDir + "/serviceaccount:/var/run/secrets/kubernetes.io/serviceaccount",

		"-v", os.Getenv("CERTS_PATH") + ":/home/user/certs",

	}

	args = append(args, extraArgs...)

	image := os.Getenv("CONTAINER_NAME")

	args = append(args, image, "/opt/cni/bin/install")

	out, err = exec.Command("docker", args...).CombinedOutput()

	_, writeErr := GinkgoWriter.Write(out)

	if writeErr != nil {

		log.WithField("out", out).WithError(writeErr).Warn("GinkgoWriter failed to write output from command.")

	}

	return err


====================
		"-e", "KUBERNETES_NODE_NAME=my-node",

		"-e", "KUBECONFIG=/home/user/certs/kubeconfig",

		"-v", tempDir + "/bin:" + binFolder,

		"-v", tempDir + "/net.d:/host/etc/cni/net.d",

		"-v", tempDir + "/serviceaccount:/var/run/secrets/kubernetes.io/serviceaccount",

		"-v", os.Getenv("CERTS_PATH") + ":/home/user/certs",

	}

	args = append(args, extraArgs...)

	image := os.Getenv("CONTAINER_NAME")

	args = append(args, image, "/opt/cni/bin/install")

	out, err = exec.Command("docker", args...).CombinedOutput()

	_, writeErr := GinkgoWriter.Write(out)

	if writeErr != nil {

		log.WithField("out", out).WithError(writeErr).Warn("GinkgoWriter failed to write output from command.")

	}

	return err

}

func createKubernetesClient() *kubernetes.Clientset {

	certsPath := os.Getenv("CERTS_PATH")

	if len(certsPath) == 0 {


====================
			for _, file := range files {

				names = append(names, file.Name())

			}

			// Get a list of files in the default location for CNI config.

			files, err = os.ReadDir(tempDir + "/net.d")

			Expect(err).NotTo(HaveOccurred(), fmt.Sprintf("Could not list the files in %s/net.d", tempDir))

			for _, file := range files {

				names = append(names, file.Name())

			}

			Expect(names).To(ContainElement("calico"))

			Expect(names).To(ContainElement("calico-ipam"))

			Expect(names).To(ContainElement("10-calico.conflist"))

		})

		It("Should parse and output a templated config", func() {

			err := runCniContainer(tempDir, true)

			Expect(err).NotTo(HaveOccurred())

			expectFileContents(tempDir+"/net.d/10-calico.conflist", expectedDefaultConfig)

		})

	})

	It("should fail on read-only folder install", func() {


====================
				names = append(names, file.Name())

			}

			// Get a list of files in the default location for CNI config.

			files, err = os.ReadDir(tempDir + "/net.d")

			Expect(err).NotTo(HaveOccurred(), fmt.Sprintf("Could not list the files in %s/net.d", tempDir))

			for _, file := range files {

				names = append(names, file.Name())

			}

			Expect(names).To(ContainElement("calico"))

			Expect(names).To(ContainElement("calico-ipam"))

			Expect(names).To(ContainElement("10-calico.conflist"))

		})

		It("Should parse and output a templated config", func() {

			err := runCniContainer(tempDir, true)

			Expect(err).NotTo(HaveOccurred())

			expectFileContents(tempDir+"/net.d/10-calico.conflist", expectedDefaultConfig)

		})

	})

	It("should fail on read-only folder install", func() {

		err := runCniContainer(tempDir, false)


====================
			Expect(err).NotTo(HaveOccurred())

			expectFileContents(tempDir+"/net.d/10-calico.conflist", expectedDefaultConfig)

		})

	})

	It("should fail on read-only folder install", func() {

		err := runCniContainer(tempDir, false)

		Expect(err).To(HaveOccurred())

	})

	It("should not fail on one of the folders being read-only", func() {

		err := runCniContainer(tempDir, false, "-v", tempDir+"/secondary-bin-dir:/host/secondary-bin-dir")

		Expect(err).NotTo(HaveOccurred())

		files, err := os.ReadDir(tempDir + "/secondary-bin-dir")

		Expect(err).NotTo(HaveOccurred())

		names := []string{}

		for _, file := range files {

			names = append(names, file.Name())

		}

		Expect(names).To(ContainElement("calico"))

		Expect(names).To(ContainElement("calico-ipam"))

	})


====================
	It("should not fail on one of the folders being read-only", func() {

		err := runCniContainer(tempDir, false, "-v", tempDir+"/secondary-bin-dir:/host/secondary-bin-dir")

		Expect(err).NotTo(HaveOccurred())

		files, err := os.ReadDir(tempDir + "/secondary-bin-dir")

		Expect(err).NotTo(HaveOccurred())

		names := []string{}

		for _, file := range files {

			names = append(names, file.Name())

		}

		Expect(names).To(ContainElement("calico"))

		Expect(names).To(ContainElement("calico-ipam"))

	})

	It("should fail when no directory is writeable", func() {

		err := runCniContainer(tempDir, false, "-v", tempDir+"/secondary-bin-dir:/host/secondary-bin-dir:ro")

		Expect(err).To(HaveOccurred())

	})

	It("should support CNI_CONF_NAME", func() {

		err := runCniContainer(tempDir, true, "-e", "CNI_CONF_NAME=20-calico.conflist")

		Expect(err).NotTo(HaveOccurred())

		expectFileContents(tempDir+"/net.d/20-calico.conflist", expectedDefaultConfig)


====================
		err := runCniContainer(tempDir, false, "-v", tempDir+"/secondary-bin-dir:/host/secondary-bin-dir")

		Expect(err).NotTo(HaveOccurred())

		files, err := os.ReadDir(tempDir + "/secondary-bin-dir")

		Expect(err).NotTo(HaveOccurred())

		names := []string{}

		for _, file := range files {

			names = append(names, file.Name())

		}

		Expect(names).To(ContainElement("calico"))

		Expect(names).To(ContainElement("calico-ipam"))

	})

	It("should fail when no directory is writeable", func() {

		err := runCniContainer(tempDir, false, "-v", tempDir+"/secondary-bin-dir:/host/secondary-bin-dir:ro")

		Expect(err).To(HaveOccurred())

	})

	It("should support CNI_CONF_NAME", func() {

		err := runCniContainer(tempDir, true, "-e", "CNI_CONF_NAME=20-calico.conflist")

		Expect(err).NotTo(HaveOccurred())

		expectFileContents(tempDir+"/net.d/20-calico.conflist", expectedDefaultConfig)

	})


====================
		Expect(err).NotTo(HaveOccurred())

		names := []string{}

		for _, file := range files {

			names = append(names, file.Name())

		}

		Expect(names).To(ContainElement("calico"))

		Expect(names).To(ContainElement("calico-ipam"))

	})

	It("should fail when no directory is writeable", func() {

		err := runCniContainer(tempDir, false, "-v", tempDir+"/secondary-bin-dir:/host/secondary-bin-dir:ro")

		Expect(err).To(HaveOccurred())

	})

	It("should support CNI_CONF_NAME", func() {

		err := runCniContainer(tempDir, true, "-e", "CNI_CONF_NAME=20-calico.conflist")

		Expect(err).NotTo(HaveOccurred())

		expectFileContents(tempDir+"/net.d/20-calico.conflist", expectedDefaultConfig)

	})

	It("should support a custom CNI_NETWORK_CONFIG", func() {

		err := runCniContainer(tempDir, true, "-e", "CNI_NETWORK_CONFIG={}")

		Expect(err).NotTo(HaveOccurred())


====================
		}

		Expect(names).To(ContainElement("calico"))

		Expect(names).To(ContainElement("calico-ipam"))

	})

	It("should fail when no directory is writeable", func() {

		err := runCniContainer(tempDir, false, "-v", tempDir+"/secondary-bin-dir:/host/secondary-bin-dir:ro")

		Expect(err).To(HaveOccurred())

	})

	It("should support CNI_CONF_NAME", func() {

		err := runCniContainer(tempDir, true, "-e", "CNI_CONF_NAME=20-calico.conflist")

		Expect(err).NotTo(HaveOccurred())

		expectFileContents(tempDir+"/net.d/20-calico.conflist", expectedDefaultConfig)

	})

	It("should support a custom CNI_NETWORK_CONFIG", func() {

		err := runCniContainer(tempDir, true, "-e", "CNI_NETWORK_CONFIG={}")

		Expect(err).NotTo(HaveOccurred())

		actual, err := os.ReadFile(tempDir + "/net.d/10-calico.conflist")

		Expect(err).NotTo(HaveOccurred())

		Expect(string(actual)).To(Equal("{}"))

	})


====================
		err := runCniContainer(tempDir, false, "-v", tempDir+"/secondary-bin-dir:/host/secondary-bin-dir:ro")

		Expect(err).To(HaveOccurred())

	})

	It("should support CNI_CONF_NAME", func() {

		err := runCniContainer(tempDir, true, "-e", "CNI_CONF_NAME=20-calico.conflist")

		Expect(err).NotTo(HaveOccurred())

		expectFileContents(tempDir+"/net.d/20-calico.conflist", expectedDefaultConfig)

	})

	It("should support a custom CNI_NETWORK_CONFIG", func() {

		err := runCniContainer(tempDir, true, "-e", "CNI_NETWORK_CONFIG={}")

		Expect(err).NotTo(HaveOccurred())

		actual, err := os.ReadFile(tempDir + "/net.d/10-calico.conflist")

		Expect(err).NotTo(HaveOccurred())

		Expect(string(actual)).To(Equal("{}"))

	})

	It("should check if the custom CNI_NETWORK_CONFIG is valid json", func() {

		err := runCniContainer(tempDir, true, "-e", "CNI_NETWORK_CONFIG={\"missing quote}")

		Expect(err).To(HaveOccurred())

	})

	It("should use CNI_NETWORK_CONFIG_FILE over CNI_NETWORK_CONFIG", func() {


====================
	})

	It("should support a custom CNI_NETWORK_CONFIG", func() {

		err := runCniContainer(tempDir, true, "-e", "CNI_NETWORK_CONFIG={}")

		Expect(err).NotTo(HaveOccurred())

		actual, err := os.ReadFile(tempDir + "/net.d/10-calico.conflist")

		Expect(err).NotTo(HaveOccurred())

		Expect(string(actual)).To(Equal("{}"))

	})

	It("should check if the custom CNI_NETWORK_CONFIG is valid json", func() {

		err := runCniContainer(tempDir, true, "-e", "CNI_NETWORK_CONFIG={\"missing quote}")

		Expect(err).To(HaveOccurred())

	})

	It("should use CNI_NETWORK_CONFIG_FILE over CNI_NETWORK_CONFIG", func() {

		// Write the alternate configuration to disk so it can be picked up by

		// the CNI container.

		altConfigFile := tempDir + "/net.d/alternate-config"

		err := os.WriteFile(altConfigFile, []byte(expectedAlternateConfig), 0755)

		Expect(err).NotTo(HaveOccurred())

		err = runCniContainer(

			tempDir, true,


====================
	})

	It("should use CNI_NETWORK_CONFIG_FILE over CNI_NETWORK_CONFIG", func() {

		// Write the alternate configuration to disk so it can be picked up by

		// the CNI container.

		altConfigFile := tempDir + "/net.d/alternate-config"

		err := os.WriteFile(altConfigFile, []byte(expectedAlternateConfig), 0755)

		Expect(err).NotTo(HaveOccurred())

		err = runCniContainer(

			tempDir, true,

			"-e", "CNI_NETWORK_CONFIG='oops, I used the CNI_NETWORK_CONFIG'",

			"-e", "CNI_NETWORK_CONFIG_FILE=/host/etc/cni/net.d/alternate-config",

		)

		Expect(err).NotTo(HaveOccurred())

		expectFileContents(tempDir+"/net.d/10-calico.conflist", expectedAlternateConfig)

	})

	It("should copy even if plugin is opened", func() {

		// Install the CNI plugin.

		err := runCniContainer(tempDir, true)

		Expect(err).NotTo(HaveOccurred())

		done := make(chan bool)


====================
	It("should use CNI_NETWORK_CONFIG_FILE over CNI_NETWORK_CONFIG", func() {

		// Write the alternate configuration to disk so it can be picked up by

		// the CNI container.

		altConfigFile := tempDir + "/net.d/alternate-config"

		err := os.WriteFile(altConfigFile, []byte(expectedAlternateConfig), 0755)

		Expect(err).NotTo(HaveOccurred())

		err = runCniContainer(

			tempDir, true,

			"-e", "CNI_NETWORK_CONFIG='oops, I used the CNI_NETWORK_CONFIG'",

			"-e", "CNI_NETWORK_CONFIG_FILE=/host/etc/cni/net.d/alternate-config",

		)

		Expect(err).NotTo(HaveOccurred())

		expectFileContents(tempDir+"/net.d/10-calico.conflist", expectedAlternateConfig)

	})

	It("should copy even if plugin is opened", func() {

		// Install the CNI plugin.

		err := runCniContainer(tempDir, true)

		Expect(err).NotTo(HaveOccurred())

		done := make(chan bool)

		defer close(done)


====================
	Context("copying /calico-secrets", func() {

		var err error

		BeforeEach(func() {

			err = os.MkdirAll(tempDir+"/certs", 0755)

			Expect(err).NotTo(HaveOccurred())

		})

		It("Should not crash or copy when having a hidden file", func() {

			err = os.WriteFile(tempDir+"/certs/.hidden", []byte("doesn't matter"), 0644)

			Expect(err).NotTo(HaveOccurred(), fmt.Sprintf("Failed to write hidden file: %v", err))

			err = runCniContainer(tempDir, true, "-v", tempDir+"/certs:/calico-secrets")

			Expect(err).NotTo(HaveOccurred())

			_, err = os.Open(tempDir + "/net.d/calico-tls/.hidden")

			Expect(err).To(HaveOccurred())

		})

		It("Should copy a non-hidden file", func() {

			err = os.WriteFile(tempDir+"/certs/etcd-cert", []byte("doesn't matter"), 0644)

			Expect(err).NotTo(HaveOccurred(), fmt.Sprintf("Failed to write file: %v", err))

			err = runCniContainer(tempDir, true, "-v", tempDir+"/certs:/calico-secrets", "-e", "CNI_NETWORK_CONFIG={\"etcd_cert\": \"__ETCD_CERT_FILE__\"}")

			Expect(err).NotTo(HaveOccurred())

			file, err := os.Open(tempDir + "/net.d/calico-tls/etcd-cert")


====================
			Expect(err).NotTo(HaveOccurred(), fmt.Sprintf("Failed to write hidden file: %v", err))

			err = runCniContainer(tempDir, true, "-v", tempDir+"/certs:/calico-secrets")

			Expect(err).NotTo(HaveOccurred())

			_, err = os.Open(tempDir + "/net.d/calico-tls/.hidden")

			Expect(err).To(HaveOccurred())

		})

		It("Should copy a non-hidden file", func() {

			err = os.WriteFile(tempDir+"/certs/etcd-cert", []byte("doesn't matter"), 0644)

			Expect(err).NotTo(HaveOccurred(), fmt.Sprintf("Failed to write file: %v", err))

			err = runCniContainer(tempDir, true, "-v", tempDir+"/certs:/calico-secrets", "-e", "CNI_NETWORK_CONFIG={\"etcd_cert\": \"__ETCD_CERT_FILE__\"}")

			Expect(err).NotTo(HaveOccurred())

			file, err := os.Open(tempDir + "/net.d/calico-tls/etcd-cert")

			Expect(err).NotTo(HaveOccurred())

			err = file.Close()

			Expect(err).NotTo(HaveOccurred())

			// Expect the config to have the correct value filled in.

			expectedConfig := "{\"etcd_cert\": \"/etc/cni/net.d/calico-tls/etcd-cert\"}"

			expectFileContents(tempDir+"/net.d/10-calico.conflist", expectedConfig)

		})

	})


====================
		}

		if err := copyFileAndPermissions(fmt.Sprintf("%s/%s", c.TLSAssetsDir, "etcd-cert"), "/host/etc/cni/net.d/calico-tls/etcd-cert"); err != nil {

			logrus.Warnf("Missing etcd-cert")

		}

		if err := copyFileAndPermissions(fmt.Sprintf("%s/%s", c.TLSAssetsDir, "etcd-key"), "/host/etc/cni/net.d/calico-tls/etcd-key"); err != nil {

			logrus.Warnf("Missing etcd-key")

		}

	}

	// Set the suid bit on the binaries to allow them to run as non-root users.

	if err := setSuidBit("/opt/cni/bin/install"); err != nil {

		logrus.WithError(err).Fatalf("Failed to set the suid bit on the install binary")

	}

	// TODO: Remove the setSUID code here on calico and calico-ipam when they eventually

	// get refactored to all use install as the source.

	if err := setSuidBit("/opt/cni/bin/calico"); err != nil {

		logrus.WithError(err).Fatalf("Failed to set the suid bit on the calico binary")

	}

	if err := setSuidBit("/opt/cni/bin/calico-ipam"); err != nil {

		logrus.WithError(err).Fatalf("Failed to set the suid bit on the calico-ipam")

	}


====================
			logrus.Warnf("Missing etcd-key")

		}

	}

	// Set the suid bit on the binaries to allow them to run as non-root users.

	if err := setSuidBit("/opt/cni/bin/install"); err != nil {

		logrus.WithError(err).Fatalf("Failed to set the suid bit on the install binary")

	}

	// TODO: Remove the setSUID code here on calico and calico-ipam when they eventually

	// get refactored to all use install as the source.

	if err := setSuidBit("/opt/cni/bin/calico"); err != nil {

		logrus.WithError(err).Fatalf("Failed to set the suid bit on the calico binary")

	}

	if err := setSuidBit("/opt/cni/bin/calico-ipam"); err != nil {

		logrus.WithError(err).Fatalf("Failed to set the suid bit on the calico-ipam")

	}

	// Place the new binaries if the directory is writeable.

	dirs := []string{"/host/opt/cni/bin", "/host/secondary-bin-dir"}

	binsWritten := false

	for _, d := range dirs {

		if err := fileutil.IsDirWriteable(d); err != nil {


====================
	// Set the suid bit on the binaries to allow them to run as non-root users.

	if err := setSuidBit("/opt/cni/bin/install"); err != nil {

		logrus.WithError(err).Fatalf("Failed to set the suid bit on the install binary")

	}

	// TODO: Remove the setSUID code here on calico and calico-ipam when they eventually

	// get refactored to all use install as the source.

	if err := setSuidBit("/opt/cni/bin/calico"); err != nil {

		logrus.WithError(err).Fatalf("Failed to set the suid bit on the calico binary")

	}

	if err := setSuidBit("/opt/cni/bin/calico-ipam"); err != nil {

		logrus.WithError(err).Fatalf("Failed to set the suid bit on the calico-ipam")

	}

	// Place the new binaries if the directory is writeable.

	dirs := []string{"/host/opt/cni/bin", "/host/secondary-bin-dir"}

	binsWritten := false

	for _, d := range dirs {

		if err := fileutil.IsDirWriteable(d); err != nil {

			logrus.Infof("%s is not writeable, skipping", d)

			continue

		}


====================
				os.Exit(1)

			}

			logrus.Infof("Installed %s", target)

		}

		// Binaries were placed into at least one directory

		logrus.Infof("Wrote Calico CNI binaries to %s\n", d)

		binsWritten = true

		// Print CNI plugin version to confirm that the binary was actually written.

		// If this fails, it means something has gone wrong so we should retry.

		cmd := exec.Command(d+"/calico", "-v")

		var out bytes.Buffer

		cmd.Stdout = &out

		err = cmd.Run()

		if err != nil {

			logrus.WithError(err).Warnf("Failed getting CNI plugin version from installed binary, exiting")

			return err

		}

		logrus.Infof("CNI plugin version: %s", out.String())

	}

	// If binaries were not placed, exit


====================
	var js map[string]interface{}

	return json.Unmarshal([]byte(s), &js)

}

func writeCNIConfig(c config) {

	netconf := `{

  "name": "k8s-pod-network",

  "cniVersion": "0.3.1",

  "plugins": [

    {

      "type": "calico",

      "log_level": "__LOG_LEVEL__",

      "log_file_path": "__LOG_FILE_PATH__",

      "datastore_type": "__DATASTORE_TYPE__",

      "nodename": "__KUBERNETES_NODE_NAME__",

      "mtu": __CNI_MTU__,

      "ipam": {"type": "calico-ipam"},

      "policy": {"type": "k8s"},

      "kubernetes": {"kubeconfig": "__KUBECONFIG_FILEPATH__"}

    },

    {


====================
  "cniVersion": "0.3.1",

  "plugins": [

    {

      "type": "calico",

      "log_level": "__LOG_LEVEL__",

      "log_file_path": "__LOG_FILE_PATH__",

      "datastore_type": "__DATASTORE_TYPE__",

      "nodename": "__KUBERNETES_NODE_NAME__",

      "mtu": __CNI_MTU__,

      "ipam": {"type": "calico-ipam"},

      "policy": {"type": "k8s"},

      "kubernetes": {"kubeconfig": "__KUBECONFIG_FILEPATH__"}

    },

    {

      "type": "portmap",

      "snat": true,

      "capabilities": {"portMappings": true}

    }

  ]

}`


====================
      "log_file_path": "__LOG_FILE_PATH__",

      "datastore_type": "__DATASTORE_TYPE__",

      "nodename": "__KUBERNETES_NODE_NAME__",

      "mtu": __CNI_MTU__,

      "ipam": {"type": "calico-ipam"},

      "policy": {"type": "k8s"},

      "kubernetes": {"kubeconfig": "__KUBECONFIG_FILEPATH__"}

    },

    {

      "type": "portmap",

      "snat": true,

      "capabilities": {"portMappings": true}

    }

  ]

}`

	// Pick the config template to use. This can either be through an env var,

	// or a file mounted into the container.

	if c.CNINetworkConfig != "" {

		log.Info("Using CNI config template from CNI_NETWORK_CONFIG environment variable.")

		netconf = c.CNINetworkConfig


====================
func Main(version string) {

	// Make sure the RNG is seeded.

	seedrng.EnsureSeeded()

	// Set up logging formatting.

	logrus.SetFormatter(&logutils.Formatter{})

	// Install a hook that adds file/line no information.

	logrus.AddHook(&logutils.ContextHook{})

	// Use a new flag set so as not to conflict with existing libraries which use "flag"

	flagSet := flag.NewFlagSet("Calico", flag.ExitOnError)

	// Display the version on "-v"

	versionFlag := flagSet.Bool("v", false, "Display version")

	// Test datastore connection on "-t" this is used to gate installation of the

	// CNI config file, which triggers some orchestrators (K8s included) to start

	// scheduling pods.  By waiting until we get a successful datastore connection

	// test, we can avoid some startup races where host networking to the datastore

	// takes a little while to start up.

	testConnectionFlag := flagSet.Bool("t", false, "Test datastore connection")

	err := flagSet.Parse(os.Args[1:])

	if err != nil {

		cniError := cnitypes.Error{


====================
	seedrng.EnsureSeeded()

	// Set up logging formatting.

	logrus.SetFormatter(&logutils.Formatter{})

	// Install a hook that adds file/line no information.

	logrus.AddHook(&logutils.ContextHook{})

	// Use a new flag set so as not to conflict with existing libraries which use "flag"

	flagSet := flag.NewFlagSet("Calico", flag.ExitOnError)

	// Display the version on "-v"

	versionFlag := flagSet.Bool("v", false, "Display version")

	// Test datastore connection on "-t" this is used to gate installation of the

	// CNI config file, which triggers some orchestrators (K8s included) to start

	// scheduling pods.  By waiting until we get a successful datastore connection

	// test, we can avoid some startup races where host networking to the datastore

	// takes a little while to start up.

	testConnectionFlag := flagSet.Bool("t", false, "Test datastore connection")

	err := flagSet.Parse(os.Args[1:])

	if err != nil {

		cniError := cnitypes.Error{

			Code:    100,

			Msg:     "failed to parse CLI flags",


====================
	}

	// Allocate the IP and update/create the endpoint. Do this even if the endpoint already exists and has an IP

	// allocation. The kubelet will send a DEL call for any old containers and we'll clean up the old IPs then.

	client, err := NewK8sClient(conf, logger)

	if err != nil {

		return nil, err

	}

	logger.WithField("client", client).Debug("Created Kubernetes client")

	var routes []*net.IPNet

	if conf.IPAM.Type == "host-local" {

		// We're using the host-local IPAM plugin.  We implement some special-case support for that

		// plugin.  Namely:

		//

		// - We support a special value for its subnet config field, "usePodCIDR".  If that is specified,

		//   we swap the string "usePodCIDR" for the actual PodCIDR (looked up via the k8s API) before we pass the

		//   configuration to the plugin.

		// - We have partial support for its "routes" setting, which allows the routes that we install into

		//   the pod to be varied from our default (which is to insert /0 routes via the host).  If any routes

		//   are specified in the routes section then only the specified routes are programmed.  Since Calico

		//   uses a point-to-point link, the gateway parameter of the route is ignored and the host side IP


====================
		labels, annot, ports, profiles, generateName, serviceAccount, err = getK8sPodInfo(client, epIDs.Pod, epIDs.Namespace)

		if err != nil {

			return nil, err

		}

		logger.WithField("labels", labels).Debug("Fetched K8s labels")

		logger.WithField("annotations", annot).Debug("Fetched K8s annotations")

		logger.WithField("ports", ports).Debug("Fetched K8s ports")

		logger.WithField("profiles", profiles).Debug("Generated profiles")

		// Check for calico IPAM specific annotations and set them if needed.

		if conf.IPAM.Type == "calico-ipam" {

			var v4pools, v6pools string

			// Sets  the Namespace annotation for IP pools as default

			v4pools = annotNS["cni.projectcalico.org/ipv4pools"]

			v6pools = annotNS["cni.projectcalico.org/ipv6pools"]

			// Gets the POD annotation for IP Pools and overwrites Namespace annotation if it exists

			v4poolpod := annot["cni.projectcalico.org/ipv4pools"]

			if len(v4poolpod) != 0 {

				v4pools = v4poolpod

			}

			v6poolpod := annot["cni.projectcalico.org/ipv6pools"]


====================
			return nil, err

		}

	case ipAddrs != "" && ipAddrsNoIpam != "":

		// Can't have both ipAddrs and ipAddrsNoIpam annotations at the same time.

		e := fmt.Errorf("can't have both annotations: 'ipAddrs' and 'ipAddrsNoIpam' in use at the same time")

		logger.Error(e)

		return nil, e

	case ipAddrsNoIpam != "":

		// Validate that we're allowed to use this feature.

		if conf.IPAM.Type != "calico-ipam" {

			e := fmt.Errorf("ipAddrsNoIpam is not compatible with configured IPAM: %s", conf.IPAM.Type)

			logger.Error(e)

			return nil, e

		}

		if !conf.FeatureControl.IPAddrsNoIpam {

			e := fmt.Errorf("requested feature is not enabled: ip_addrs_no_ipam")

			logger.Error(e)

			return nil, e

		}

		// ipAddrsNoIpam annotation is set so bypass IPAM, and set the IPs manually.


====================
		result, err = cniv1.NewResultFromResult(overriddenResult)

		if err != nil {

			return nil, err

		}

		if len(result.IPs) == 0 {

			return nil, errors.New("failed to build result")

		}

	case ipAddrs != "":

		// Validate that we're allowed to use this feature.

		if conf.IPAM.Type != "calico-ipam" {

			e := fmt.Errorf("ipAddrs is not compatible with configured IPAM: %s", conf.IPAM.Type)

			logger.Error(e)

			return nil, e

		}

		// If the endpoint already exists, we need to attempt to release the previous IP addresses here

		// since the ADD call will fail when it tries to reallocate the same IPs. releaseIPAddrs assumes

		// that Calico IPAM is in use, which is OK here since only Calico IPAM supports the ipAddrs

		// annotation.

		if endpoint != nil {

			logger.Info("Endpoint already exists and ipAddrs is set. Release any old IPs")


====================
func Main(version string) {

	// Make sure the RNG is seeded.

	seedrng.EnsureSeeded()

	// Set up logging formatting.

	logrus.SetFormatter(&logutils.Formatter{})

	// Install a hook that adds file/line no information.

	logrus.AddHook(&logutils.ContextHook{})

	// Display the version on "-v", otherwise just delegate to the skel code.

	// Use a new flag set so as not to conflict with existing libraries which use "flag"

	flagSet := flag.NewFlagSet("calico-ipam", flag.ExitOnError)

	versionFlag := flagSet.Bool("v", false, "Display version")

	upgradeFlag := flagSet.Bool("upgrade", false, "Upgrade from host-local")

	err := flagSet.Parse(os.Args[1:])

	if err != nil {

		fmt.Println(err)

		os.Exit(1)

	}

	if *versionFlag {

		fmt.Println(version)

		os.Exit(0)


====================
var VERSION string

func main() {

	// Make sure the RNG is seeded.

	seedrng.EnsureSeeded()

	arguments, err := docopt.ParseArgs(usage, nil, VERSION)

	if err != nil {

		println(usage)

		return

	}

	if arguments["--debug"].(bool) {

		log.SetLevel(log.DebugLevel)

	}

	if arguments["server"].(bool) {

		runServer(arguments)

	} else if arguments["client"].(bool) {

		runClient(arguments)

	}

}

func runServer(arguments map[string]interface{}) {

	filePath := arguments["--listen"].(string)


====================
		log.SetLevel(log.DebugLevel)

	}

	if arguments["server"].(bool) {

		runServer(arguments)

	} else if arguments["client"].(bool) {

		runClient(arguments)

	}

}

func runServer(arguments map[string]interface{}) {

	filePath := arguments["--listen"].(string)

	dial := arguments["--dial"].(string)

	_, err := os.Stat(filePath)

	if !os.IsNotExist(err) {

		// file exists, try to delete it.

		err := os.Remove(filePath)

		if err != nil {

			log.WithFields(log.Fields{

				"listen": filePath,

				"err":    err,

			}).Fatal("File exists and unable to remove.")


====================
	}

	if arguments["server"].(bool) {

		runServer(arguments)

	} else if arguments["client"].(bool) {

		runClient(arguments)

	}

}

func runServer(arguments map[string]interface{}) {

	filePath := arguments["--listen"].(string)

	dial := arguments["--dial"].(string)

	_, err := os.Stat(filePath)

	if !os.IsNotExist(err) {

		// file exists, try to delete it.

		err := os.Remove(filePath)

		if err != nil {

			log.WithFields(log.Fields{

				"listen": filePath,

				"err":    err,

			}).Fatal("File exists and unable to remove.")

		}


====================
	select {

	case sig := <-sigChan:

		log.Infof("Got signal: %v", sig)

	case <-th.termChan:

		log.Info("Received HTTP termination request")

	}

	gs.GracefulStop()

}

func runClient(arguments map[string]interface{}) {

	dial := arguments["--dial"].(string)

	namespace := arguments["<namespace>"].(string)

	account := arguments["<account>"].(string)

	useMethod := arguments["--method"].(bool)

	method := arguments["<method>"].(string)

	opts := uds.GetDialOptions()

	conn, err := grpc.Dial(dial, opts...)

	if err != nil {

		log.Fatalf("fail to dial: %v", err)

	}

	defer conn.Close()


====================
	case <-th.termChan:

		log.Info("Received HTTP termination request")

	}

	gs.GracefulStop()

}

func runClient(arguments map[string]interface{}) {

	dial := arguments["--dial"].(string)

	namespace := arguments["<namespace>"].(string)

	account := arguments["<account>"].(string)

	useMethod := arguments["--method"].(bool)

	method := arguments["<method>"].(string)

	opts := uds.GetDialOptions()

	conn, err := grpc.Dial(dial, opts...)

	if err != nil {

		log.Fatalf("fail to dial: %v", err)

	}

	defer conn.Close()

	client := authz.NewAuthorizationClient(conn)

	req := authz.CheckRequest{

		Attributes: &authz.AttributeContext{


====================
	buildInfoLogCxt := log.WithFields(log.Fields{

		"version":    buildinfo.GitVersion,

		"buildDate":  buildinfo.BuildDate,

		"gitCommit":  buildinfo.GitRevision,

		"GOMAXPROCS": runtime.GOMAXPROCS(0),

	})

	buildInfoLogCxt.Info("Typha client starting up")

	log.Infof("Command line arguments: %v", arguments)

	callbacks := &syncerCallbacks{}

	addr := arguments["--server"].(string)

	var syncerType syncproto.SyncerType

	if t, ok := arguments["--type"].(string); ok {

		syncerType = syncproto.SyncerType(t)

	}

	options := &syncclient.Options{

		SyncerType:   syncerType,

		KeyFile:      arguments["--key-file"].(string),

		CertFile:     arguments["--cert-file"].(string),

		CAFile:       arguments["--ca-file"].(string),

		ServerCN:     arguments["--server-cn"].(string),


====================
		"buildDate":  buildinfo.BuildDate,

		"gitCommit":  buildinfo.GitRevision,

		"GOMAXPROCS": runtime.GOMAXPROCS(0),

	})

	buildInfoLogCxt.Info("Typha client starting up")

	log.Infof("Command line arguments: %v", arguments)

	callbacks := &syncerCallbacks{}

	addr := arguments["--server"].(string)

	var syncerType syncproto.SyncerType

	if t, ok := arguments["--type"].(string); ok {

		syncerType = syncproto.SyncerType(t)

	}

	options := &syncclient.Options{

		SyncerType:   syncerType,

		KeyFile:      arguments["--key-file"].(string),

		CertFile:     arguments["--cert-file"].(string),

		CAFile:       arguments["--ca-file"].(string),

		ServerCN:     arguments["--server-cn"].(string),

		ServerURISAN: arguments["--server-uri"].(string),

	}


====================
	log.Infof("Command line arguments: %v", arguments)

	callbacks := &syncerCallbacks{}

	addr := arguments["--server"].(string)

	var syncerType syncproto.SyncerType

	if t, ok := arguments["--type"].(string); ok {

		syncerType = syncproto.SyncerType(t)

	}

	options := &syncclient.Options{

		SyncerType:   syncerType,

		KeyFile:      arguments["--key-file"].(string),

		CertFile:     arguments["--cert-file"].(string),

		CAFile:       arguments["--ca-file"].(string),

		ServerCN:     arguments["--server-cn"].(string),

		ServerURISAN: arguments["--server-uri"].(string),

	}

	hostname, _ := os.Hostname()

	client := syncclient.New([]discovery.Typha{{Addr: addr}}, buildinfo.GitVersion, hostname, "typha command-line client", callbacks, options)

	err = client.Start(context.Background())

	if err != nil {

		log.WithError(err).Panic("Client failed")


====================
	callbacks := &syncerCallbacks{}

	addr := arguments["--server"].(string)

	var syncerType syncproto.SyncerType

	if t, ok := arguments["--type"].(string); ok {

		syncerType = syncproto.SyncerType(t)

	}

	options := &syncclient.Options{

		SyncerType:   syncerType,

		KeyFile:      arguments["--key-file"].(string),

		CertFile:     arguments["--cert-file"].(string),

		CAFile:       arguments["--ca-file"].(string),

		ServerCN:     arguments["--server-cn"].(string),

		ServerURISAN: arguments["--server-uri"].(string),

	}

	hostname, _ := os.Hostname()

	client := syncclient.New([]discovery.Typha{{Addr: addr}}, buildinfo.GitVersion, hostname, "typha command-line client", callbacks, options)

	err = client.Start(context.Background())

	if err != nil {

		log.WithError(err).Panic("Client failed")

	}


====================
	addr := arguments["--server"].(string)

	var syncerType syncproto.SyncerType

	if t, ok := arguments["--type"].(string); ok {

		syncerType = syncproto.SyncerType(t)

	}

	options := &syncclient.Options{

		SyncerType:   syncerType,

		KeyFile:      arguments["--key-file"].(string),

		CertFile:     arguments["--cert-file"].(string),

		CAFile:       arguments["--ca-file"].(string),

		ServerCN:     arguments["--server-cn"].(string),

		ServerURISAN: arguments["--server-uri"].(string),

	}

	hostname, _ := os.Hostname()

	client := syncclient.New([]discovery.Typha{{Addr: addr}}, buildinfo.GitVersion, hostname, "typha command-line client", callbacks, options)

	err = client.Start(context.Background())

	if err != nil {

		log.WithError(err).Panic("Client failed")

	}

	client.Finished.Wait()


====================
	var syncerType syncproto.SyncerType

	if t, ok := arguments["--type"].(string); ok {

		syncerType = syncproto.SyncerType(t)

	}

	options := &syncclient.Options{

		SyncerType:   syncerType,

		KeyFile:      arguments["--key-file"].(string),

		CertFile:     arguments["--cert-file"].(string),

		CAFile:       arguments["--ca-file"].(string),

		ServerCN:     arguments["--server-cn"].(string),

		ServerURISAN: arguments["--server-uri"].(string),

	}

	hostname, _ := os.Hostname()

	client := syncclient.New([]discovery.Typha{{Addr: addr}}, buildinfo.GitVersion, hostname, "typha command-line client", callbacks, options)

	err = client.Start(context.Background())

	if err != nil {

		log.WithError(err).Panic("Client failed")

	}

	client.Finished.Wait()

	log.Panic("Client failed")


====================
	if t, ok := arguments["--type"].(string); ok {

		syncerType = syncproto.SyncerType(t)

	}

	options := &syncclient.Options{

		SyncerType:   syncerType,

		KeyFile:      arguments["--key-file"].(string),

		CertFile:     arguments["--cert-file"].(string),

		CAFile:       arguments["--ca-file"].(string),

		ServerCN:     arguments["--server-cn"].(string),

		ServerURISAN: arguments["--server-uri"].(string),

	}

	hostname, _ := os.Hostname()

	client := syncclient.New([]discovery.Typha{{Addr: addr}}, buildinfo.GitVersion, hostname, "typha command-line client", callbacks, options)

	err = client.Start(context.Background())

	if err != nil {

		log.WithError(err).Panic("Client failed")

	}

	client.Finished.Wait()

	log.Panic("Client failed")

}


====================
		}).Info("Defaulting WakeUpInterval.")

		config.WakeUpInterval = defaultWakeUpInterval

	}

	if config.HealthName == "" {

		if config.Name == "" {

			config.HealthName = "cache"

		} else if strings.HasSuffix(config.Name, "cache") {

			config.HealthName = config.Name

		} else {

			config.HealthName = config.Name + "-cache"

		}

	}

	if config.Name == "" {

		config.Name = "cache"

	}

}

func New(config Config) *Cache {

	config.ApplyDefaults()

	kvs := btree.NewG[syncproto.SerializedUpdate](2, func(a, b syncproto.SerializedUpdate) bool { return a.Key < b.Key })

	cond := sync.NewCond(&sync.Mutex{})


====================
	version := "Version:            " + buildinfo.GitVersion + "\n" +

		"Full git commit ID: " + buildinfo.GitRevision + "\n" +

		"Build date:         " + buildinfo.BuildDate + "\n"

	p := &docopt.Parser{OptionsFirst: false, SkipHelpFlags: false}

	arguments, err := p.ParseArgs(usage, argv, version)

	if err != nil {

		println(usage)

		log.Fatalf("Failed to parse usage, exiting: %v", err)

	}

	t.ConfigFilePath = arguments["--config-file"].(string)

	t.BuildInfoLogCxt = log.WithFields(log.Fields{

		"version":    buildinfo.GitVersion,

		"buildDate":  buildinfo.BuildDate,

		"gitCommit":  buildinfo.GitRevision,

		"GOMAXPROCS": runtime.GOMAXPROCS(0),

	})

	t.BuildInfoLogCxt.Info("Typha starting up")

	log.Infof("Command line arguments: %v", arguments)

}

// LoadConfiguration uses the command-line configuration and environment variables to load our configuration.


====================
			defer flagMutex.Unlock()

			loggingConfigured = true

		}

	})

	It("shouldn't panic when DoEarlyRuntimeSetup is called", func() {

		d.DoEarlyRuntimeSetup()

		Expect(earlyLoggingConfigured).To(BeTrue())

	})

	It("should parse the config file path", func() {

		d.ParseCommandLineArgs([]string{"-c", "/tmp/config.cfg"})

		Expect(d.ConfigFilePath).To(Equal("/tmp/config.cfg"))

	})

	It("should parse the config file path", func() {

		d.ParseCommandLineArgs([]string{"--config", "/tmp/config.cfg"})

		Expect(d.ConfigFilePath).To(Equal("/tmp/config.cfg"))

	})

	It("should default the config file path", func() {

		d.ParseCommandLineArgs([]string{})

		Expect(d.ConfigFilePath).To(Equal("/etc/calico/typha.cfg"))

	})


====================
	It("shouldn't panic when DoEarlyRuntimeSetup is called", func() {

		d.DoEarlyRuntimeSetup()

		Expect(earlyLoggingConfigured).To(BeTrue())

	})

	It("should parse the config file path", func() {

		d.ParseCommandLineArgs([]string{"-c", "/tmp/config.cfg"})

		Expect(d.ConfigFilePath).To(Equal("/tmp/config.cfg"))

	})

	It("should parse the config file path", func() {

		d.ParseCommandLineArgs([]string{"--config", "/tmp/config.cfg"})

		Expect(d.ConfigFilePath).To(Equal("/tmp/config.cfg"))

	})

	It("should default the config file path", func() {

		d.ParseCommandLineArgs([]string{})

		Expect(d.ConfigFilePath).To(Equal("/etc/calico/typha.cfg"))

	})

	Describe("with a config file loaded", func() {

		var configFile *os.File

		var cxt context.Context

		var cancelFunc context.CancelFunc


====================
		var cancelFunc context.CancelFunc

		BeforeEach(func() {

			var err error

			configFile, err = os.CreateTemp("", "typha")

			Expect(err).NotTo(HaveOccurred())

			_, err = configFile.Write(configContents)

			Expect(err).NotTo(HaveOccurred())

			err = configFile.Close()

			Expect(err).NotTo(HaveOccurred())

			d.ParseCommandLineArgs([]string{"-c", configFile.Name()})

			cxt, cancelFunc = context.WithTimeout(context.Background(), 10*time.Second)

		})

		AfterEach(func() {

			cancelFunc()

			err := os.Remove(configFile.Name())

			Expect(err).NotTo(HaveOccurred())

		})

		const (

			downSecs  = 2

			checkTime = "2s"


====================
		"docker.io/calico",

		"quay.io/calico",

		"gcr.io/projectcalico-org",

		"eu.gcr.io/projectcalico-org",

		"asia.gcr.io/projectcalico-org",

		"us.gcr.io/projectcalico-org",

	}

	// Git configuration for publishing to GitHub.

	organization = "projectcalico"

	repo         = "calico"

	origin       = "origin"

)

func NewReleaseBuilder(runner CommandRunner) *ReleaseBuilder {

	return &ReleaseBuilder{

		runner: runner,

	}

}

type ReleaseBuilder struct {

	// Allow specification of command runner so it can be overridden in tests.

	runner CommandRunner


====================
	err = os.WriteFile(fmt.Sprintf("%s/metadata.yaml", dir), []byte(bs), 0o644)

	if err != nil {

		return err

	}

	return nil

}

// BuildRelease creates a Calico release.

func (r *ReleaseBuilder) BuildRelease() error {

	// Check that we're not already on a git tag.

	out, err := r.git("describe", "--exact-match", "--tags", "HEAD")

	if err == nil {

		// On a current tag.

		return fmt.Errorf("Already on a tag (%s), refusing to create release", out)

	}

	// Check that the repository is not a shallow clone. We need correct history.

	out, err = r.git("rev-parse", "--is-shallow-repository")

	if err != nil {

		return fmt.Errorf("rev-parse failed: %s", err)

	}

	if strings.TrimSpace(out) == "true" {


====================
// BuildRelease creates a Calico release.

func (r *ReleaseBuilder) BuildRelease() error {

	// Check that we're not already on a git tag.

	out, err := r.git("describe", "--exact-match", "--tags", "HEAD")

	if err == nil {

		// On a current tag.

		return fmt.Errorf("Already on a tag (%s), refusing to create release", out)

	}

	// Check that the repository is not a shallow clone. We need correct history.

	out, err = r.git("rev-parse", "--is-shallow-repository")

	if err != nil {

		return fmt.Errorf("rev-parse failed: %s", err)

	}

	if strings.TrimSpace(out) == "true" {

		return fmt.Errorf("Attempt to release from a shallow clone is not possible")

	}

	// Check that the environment has the necessary prereqs.

	if err := r.releasePrereqs(); err != nil {

		return err

	}


====================
	}

	if strings.TrimSpace(out) == "true" {

		return fmt.Errorf("Attempt to release from a shallow clone is not possible")

	}

	// Check that the environment has the necessary prereqs.

	if err := r.releasePrereqs(); err != nil {

		return err

	}

	// Determine the last tag on this branch.

	out, err = r.git("describe", "--tags", "--dirty", "--always", "--abbrev=12")

	if err != nil {

		logrus.WithError(err).Fatal("Failed to git describe")

	}

	logrus.WithField("out", out).Info("Current git describe")

	// Determine the release version to use based on the last tag.

	ver, err := r.determineReleaseVersion(out)

	if err != nil {

		return err

	}

	// Assert that manifests are using the correct version.


====================
	logrus.WithFields(logrus.Fields{"branch": branch, "version": ver}).Infof("Creating Calico release from branch")

	_, err = r.git("tag", ver)

	if err != nil {

		return fmt.Errorf("Failed to tag release: %s", err)

	}

	// Successfully tagged. If we fail to release after this stage, we need to delete the tag.

	defer func() {

		if err != nil {

			logrus.WithError(err).Warn("Failed to release, cleaning up tag")

			r.git("tag", "-d", ver)

		}

	}()

	// Build container images for the release.

	if err = r.buildContainerImages(ver); err != nil {

		return err

	}

	// Build the helm charts

	r.runner.Run("make", []string{"chart"}, []string{})

	// Build OpenShift bundle.

	r.runner.Run("make", []string{"bin/ocp.tgz"}, []string{})


====================
	return nil

}

func (r *ReleaseBuilder) NewBranch() error {

	// Check that we're on the master branch. We always cut branches from master.

	branch := r.determineBranch()

	if branch != "master" {

		return fmt.Errorf("Release branches can only be cut from master")

	}

	// Determine the version for the branch. We can get this from the previous dev tag.

	out, err := r.git("describe", "--tags", "--dirty", "--always", "--abbrev=12")

	if err != nil {

		logrus.WithError(err).Fatal("Failed to git describe")

	}

	logrus.WithField("out", out).Info("Current git describe")

	if !strings.Contains(out, "-0.dev") {

		return fmt.Errorf("Unable to determine release branch name from tag: %s", out)

	}

	// Determine the name of the new branch.

	nextBranchVersion := strings.Split(out, "-0.dev")[0]

	sv, err := semver.NewVersion(strings.TrimPrefix(nextBranchVersion, "v"))


====================
	if branch != "master" {

		return fmt.Errorf("Release branches can only be cut from master")

	}

	// Determine the version for the branch. We can get this from the previous dev tag.

	out, err := r.git("describe", "--tags", "--dirty", "--always", "--abbrev=12")

	if err != nil {

		logrus.WithError(err).Fatal("Failed to git describe")

	}

	logrus.WithField("out", out).Info("Current git describe")

	if !strings.Contains(out, "-0.dev") {

		return fmt.Errorf("Unable to determine release branch name from tag: %s", out)

	}

	// Determine the name of the new branch.

	nextBranchVersion := strings.Split(out, "-0.dev")[0]

	sv, err := semver.NewVersion(strings.TrimPrefix(nextBranchVersion, "v"))

	branchName := fmt.Sprintf("release-v%d.%d", sv.Major, sv.Minor)

	logrus.WithField("branch", branchName).Info("Next release branch")

	// Determine the next -0.dev tag.

	nextVersion := fmt.Sprintf("v%d.%d.0", sv.Major, sv.Minor+1)

	newDevTag := fmt.Sprintf("%s-0.dev", nextVersion)


====================
	out, err := r.git("describe", "--tags", "--dirty", "--always", "--abbrev=12")

	if err != nil {

		logrus.WithError(err).Fatal("Failed to git describe")

	}

	logrus.WithField("out", out).Info("Current git describe")

	if !strings.Contains(out, "-0.dev") {

		return fmt.Errorf("Unable to determine release branch name from tag: %s", out)

	}

	// Determine the name of the new branch.

	nextBranchVersion := strings.Split(out, "-0.dev")[0]

	sv, err := semver.NewVersion(strings.TrimPrefix(nextBranchVersion, "v"))

	branchName := fmt.Sprintf("release-v%d.%d", sv.Major, sv.Minor)

	logrus.WithField("branch", branchName).Info("Next release branch")

	// Determine the next -0.dev tag.

	nextVersion := fmt.Sprintf("v%d.%d.0", sv.Major, sv.Minor+1)

	newDevTag := fmt.Sprintf("%s-0.dev", nextVersion)

	logrus.WithField("tag", newDevTag).Info("Next dev tag")

	// Create a new branch from the current master.

	r.gitOrFail("checkout", "-b", branchName)

	r.gitOrFail("push", origin, branchName)


====================
	nextBranchVersion := strings.Split(out, "-0.dev")[0]

	sv, err := semver.NewVersion(strings.TrimPrefix(nextBranchVersion, "v"))

	branchName := fmt.Sprintf("release-v%d.%d", sv.Major, sv.Minor)

	logrus.WithField("branch", branchName).Info("Next release branch")

	// Determine the next -0.dev tag.

	nextVersion := fmt.Sprintf("v%d.%d.0", sv.Major, sv.Minor+1)

	newDevTag := fmt.Sprintf("%s-0.dev", nextVersion)

	logrus.WithField("tag", newDevTag).Info("Next dev tag")

	// Create a new branch from the current master.

	r.gitOrFail("checkout", "-b", branchName)

	r.gitOrFail("push", origin, branchName)

	// Create the new dev tag on master and push it.

	r.gitOrFail("checkout", "master")

	r.gitOrFail("commit", "--allow-empty", "-m", fmt.Sprintf("Begin development on %s", nextVersion))

	r.gitOrFail("tag", newDevTag)

	r.gitOrFail("push", origin, "master")

	r.gitOrFail("push", origin, newDevTag)

	return nil

}

// Check general prerequisites for cutting and publishing a release.


====================
	// Determine the next -0.dev tag.

	nextVersion := fmt.Sprintf("v%d.%d.0", sv.Major, sv.Minor+1)

	newDevTag := fmt.Sprintf("%s-0.dev", nextVersion)

	logrus.WithField("tag", newDevTag).Info("Next dev tag")

	// Create a new branch from the current master.

	r.gitOrFail("checkout", "-b", branchName)

	r.gitOrFail("push", origin, branchName)

	// Create the new dev tag on master and push it.

	r.gitOrFail("checkout", "master")

	r.gitOrFail("commit", "--allow-empty", "-m", fmt.Sprintf("Begin development on %s", nextVersion))

	r.gitOrFail("tag", newDevTag)

	r.gitOrFail("push", origin, "master")

	r.gitOrFail("push", origin, newDevTag)

	return nil

}

// Check general prerequisites for cutting and publishing a release.

func (r *ReleaseBuilder) releasePrereqs() error {

	// Check that we're not on the master branch. We never cut releases from master.

	branch := r.determineBranch()

	if branch == "master" {


====================
		// Felix binaries.

		"felix/bin/calico-bpf": binDir,

	}

	for src, dst := range binaries {

		if _, err := r.runner.Run("cp", []string{"-r", src, dst}, nil); err != nil {

			return err

		}

	}

	// Add in manifests directory generated from the docs.

	if _, err := r.runner.Run("cp", []string{"-r", "manifests", releaseBase}, nil); err != nil {

		return err

	}

	// tar up the whole thing, and copy it to the target directory

	if _, err := r.runner.Run("tar", []string{"-czvf", fmt.Sprintf("_output/release-%s.tgz", ver), "-C", "_output", fmt.Sprintf("release-%s", ver)}, nil); err != nil {

		return err

	}

	if _, err := r.runner.Run("cp", []string{fmt.Sprintf("_output/release-%s.tgz", ver), targetDir}, nil); err != nil {

		return err

	}

	return nil


====================
		if _, err := r.runner.Run("cp", []string{"-r", src, dst}, nil); err != nil {

			return err

		}

	}

	// Add in manifests directory generated from the docs.

	if _, err := r.runner.Run("cp", []string{"-r", "manifests", releaseBase}, nil); err != nil {

		return err

	}

	// tar up the whole thing, and copy it to the target directory

	if _, err := r.runner.Run("tar", []string{"-czvf", fmt.Sprintf("_output/release-%s.tgz", ver), "-C", "_output", fmt.Sprintf("release-%s", ver)}, nil); err != nil {

		return err

	}

	if _, err := r.runner.Run("cp", []string{fmt.Sprintf("_output/release-%s.tgz", ver), targetDir}, nil); err != nil {

		return err

	}

	return nil

}

func (r *ReleaseBuilder) buildContainerImages(ver string) error {

	releaseDirs := []string{

		"node",


====================
		"{branch}", fmt.Sprintf("release-v%d.%d", sv.Major, sv.Minor),

		"{release_stream}", fmt.Sprintf("v%d.%d", sv.Major, sv.Minor),

		"{release_tar}", fmt.Sprintf("`release-%s.tgz`", ver),

		"{calico_windows_zip}", fmt.Sprintf("`calico-windows-%s.zip`", ver),

		"{helm_chart}", fmt.Sprintf("`tigera-operator-%s.tgz`", ver),

	}

	replacer := strings.NewReplacer(formatters...)

	releaseNote := replacer.Replace(releaseNoteTemplate)

	args := []string{

		"-username", organization,

		"-repository", repo,

		"-name", ver,

		"-body", releaseNote,

		ver,

		r.uploadDir(ver),

	}

	_, err = r.runner.Run("./hack/release/ghr", args, nil)

	return err

}

func (r *ReleaseBuilder) publishContainerImages(ver string) error {


====================
		"{release_stream}", fmt.Sprintf("v%d.%d", sv.Major, sv.Minor),

		"{release_tar}", fmt.Sprintf("`release-%s.tgz`", ver),

		"{calico_windows_zip}", fmt.Sprintf("`calico-windows-%s.zip`", ver),

		"{helm_chart}", fmt.Sprintf("`tigera-operator-%s.tgz`", ver),

	}

	replacer := strings.NewReplacer(formatters...)

	releaseNote := replacer.Replace(releaseNoteTemplate)

	args := []string{

		"-username", organization,

		"-repository", repo,

		"-name", ver,

		"-body", releaseNote,

		ver,

		r.uploadDir(ver),

	}

	_, err = r.runner.Run("./hack/release/ghr", args, nil)

	return err

}

func (r *ReleaseBuilder) publishContainerImages(ver string) error {

	releaseDirs := []string{


====================
		"{release_tar}", fmt.Sprintf("`release-%s.tgz`", ver),

		"{calico_windows_zip}", fmt.Sprintf("`calico-windows-%s.zip`", ver),

		"{helm_chart}", fmt.Sprintf("`tigera-operator-%s.tgz`", ver),

	}

	replacer := strings.NewReplacer(formatters...)

	releaseNote := replacer.Replace(releaseNoteTemplate)

	args := []string{

		"-username", organization,

		"-repository", repo,

		"-name", ver,

		"-body", releaseNote,

		ver,

		r.uploadDir(ver),

	}

	_, err = r.runner.Run("./hack/release/ghr", args, nil)

	return err

}

func (r *ReleaseBuilder) publishContainerImages(ver string) error {

	releaseDirs := []string{

		"pod2daemon",


====================
		"{calico_windows_zip}", fmt.Sprintf("`calico-windows-%s.zip`", ver),

		"{helm_chart}", fmt.Sprintf("`tigera-operator-%s.tgz`", ver),

	}

	replacer := strings.NewReplacer(formatters...)

	releaseNote := replacer.Replace(releaseNoteTemplate)

	args := []string{

		"-username", organization,

		"-repository", repo,

		"-name", ver,

		"-body", releaseNote,

		ver,

		r.uploadDir(ver),

	}

	_, err = r.runner.Run("./hack/release/ghr", args, nil)

	return err

}

func (r *ReleaseBuilder) publishContainerImages(ver string) error {

	releaseDirs := []string{

		"pod2daemon",

		"cni-plugin",


====================
	}

	return nil

}

func (r *ReleaseBuilder) assertManifestVersions(ver string) error {

	// Go through a subset of yaml files in manifests/ and extract the images

	// that they use. Verify that the images are using the given version.

	// We also do the manifests/ocp/ yaml to check the calico/ctl image is correct.

	manifests := []string{"calico.yaml", "ocp/02-tigera-operator.yaml"}

	for _, m := range manifests {

		args := []string{"-Po", `image:\K(.*)`, m}

		out, err := r.runner.RunInDir("manifests", "grep", args, nil)

		if err != nil {

			return err

		}

		imgs := strings.Split(out, "\n")

		for _, i := range imgs {

			if strings.Contains(i, "operator") {

				// We don't handle the operator image here yet, since

				// the version is different.

				continue


====================
	}

	return nil

}

// getVersionsFromManifests returns the Calico and Operator versions in-use by this

// release based on the generated manifests to be used for this release.

func (r *ReleaseBuilder) getVersionsFromManifests() (string, string) {

	manifests := []string{"calico.yaml", "tigera-operator.yaml"}

	var operatorVersion, version string

	for _, m := range manifests {

		args := []string{"-Po", `image:\K(.*)`, m}

		out, err := r.runner.RunInDir("manifests", "grep", args, nil)

		if err != nil {

			panic(err)

		}

		imgs := strings.Split(out, "\n")

		for _, i := range imgs {

			if strings.Contains(i, "operator") && operatorVersion == "" {

				splits := strings.SplitAfter(i, ":")

				operatorVersion = splits[len(splits)-1]

				logrus.Infof("Using version %s from image %s", version, i)


====================
		panic("Missing version!")

	}

	return version, operatorVersion

}

// determineReleaseVersion uses historical clues to figure out the next semver

// release number to use for this release.

func (r *ReleaseBuilder) determineReleaseVersion(previousTag string) (string, error) {

	// There are two types of tag that this might be - either it was a previous patch release,

	// or it was a "vX.Y.Z-0.dev" tag produced when cutting the release branch.

	if strings.Contains(previousTag, "-0.dev") {

		// This is the first release from this branch - we can simply extract the version from

		// the dev tag.

		return strings.Split(previousTag, "-0.dev")[0], nil

	} else {

		// This is a patch release - we need to parse the previous, and

		// bump the patch version.

		previousVersion := strings.Split(previousTag, "-")[0]

		logrus.WithField("previousVersion", previousVersion).Info("Previous version")

		v, err := semver.NewVersion(strings.TrimPrefix(previousVersion, "v"))

		if err != nil {


====================
}

// determineReleaseVersion uses historical clues to figure out the next semver

// release number to use for this release.

func (r *ReleaseBuilder) determineReleaseVersion(previousTag string) (string, error) {

	// There are two types of tag that this might be - either it was a previous patch release,

	// or it was a "vX.Y.Z-0.dev" tag produced when cutting the release branch.

	if strings.Contains(previousTag, "-0.dev") {

		// This is the first release from this branch - we can simply extract the version from

		// the dev tag.

		return strings.Split(previousTag, "-0.dev")[0], nil

	} else {

		// This is a patch release - we need to parse the previous, and

		// bump the patch version.

		previousVersion := strings.Split(previousTag, "-")[0]

		logrus.WithField("previousVersion", previousVersion).Info("Previous version")

		v, err := semver.NewVersion(strings.TrimPrefix(previousVersion, "v"))

		if err != nil {

			logrus.WithField("previousVersion", previousVersion).WithError(err).Error("Failed to parse git version as semver")

			return "", fmt.Errorf("failed to parse git version as semver: %s", err)

		}


====================
	// There are two types of tag that this might be - either it was a previous patch release,

	// or it was a "vX.Y.Z-0.dev" tag produced when cutting the release branch.

	if strings.Contains(previousTag, "-0.dev") {

		// This is the first release from this branch - we can simply extract the version from

		// the dev tag.

		return strings.Split(previousTag, "-0.dev")[0], nil

	} else {

		// This is a patch release - we need to parse the previous, and

		// bump the patch version.

		previousVersion := strings.Split(previousTag, "-")[0]

		logrus.WithField("previousVersion", previousVersion).Info("Previous version")

		v, err := semver.NewVersion(strings.TrimPrefix(previousVersion, "v"))

		if err != nil {

			logrus.WithField("previousVersion", previousVersion).WithError(err).Error("Failed to parse git version as semver")

			return "", fmt.Errorf("failed to parse git version as semver: %s", err)

		}

		v.BumpPatch()

		return fmt.Sprintf("v%s", v.String()), nil

	}

}


====================
			logrus.WithField("previousVersion", previousVersion).WithError(err).Error("Failed to parse git version as semver")

			return "", fmt.Errorf("failed to parse git version as semver: %s", err)

		}

		v.BumpPatch()

		return fmt.Sprintf("v%s", v.String()), nil

	}

}

// determineBranch returns the current checked out branch.

func (r *ReleaseBuilder) determineBranch() string {

	out, err := r.git("rev-parse", "--abbrev-ref", "HEAD")

	if err != nil {

		logrus.WithError(err).Fatal("Error determining branch")

	} else if strings.TrimSpace(out) == "HEAD" {

		logrus.Fatal("Not on a branch, refusing to cut release")

	}

	return strings.TrimSpace(out)

}

// Uses docker to build a tgz archive of the specified container image.

func (r *ReleaseBuilder) archiveContainerImage(out, image string) error {

	_, err := r.runner.Run("docker", []string{"save", "--output", out, image}, nil)


====================
	if err != nil {

		logrus.WithError(err).Fatal("Error determining branch")

	} else if strings.TrimSpace(out) == "HEAD" {

		logrus.Fatal("Not on a branch, refusing to cut release")

	}

	return strings.TrimSpace(out)

}

// Uses docker to build a tgz archive of the specified container image.

func (r *ReleaseBuilder) archiveContainerImage(out, image string) error {

	_, err := r.runner.Run("docker", []string{"save", "--output", out, image}, nil)

	return err

}

func (r *ReleaseBuilder) git(args ...string) (string, error) {

	return r.runner.Run("git", args, nil)

}

func (r *ReleaseBuilder) gitOrFail(args ...string) {

	_, err := r.runner.Run("git", args, nil)

	if err != nil {

		logrus.WithError(err).Fatal("git command failed")

	}


====================
	return r.runner.Run("git", args, nil)

}

func (r *ReleaseBuilder) gitOrFail(args ...string) {

	_, err := r.runner.Run("git", args, nil)

	if err != nil {

		logrus.WithError(err).Fatal("git command failed")

	}

}

func (r *ReleaseBuilder) makeInDirectory(dir, target string, env ...string) error {

	err := r.runner.RunNoCapture("make", []string{"-C", dir, target}, env)

	return err

}

func (r *ReleaseBuilder) makeInDirectoryWithOutput(dir, target string, env ...string) (string, error) {

	return r.runner.Run("make", []string{"-C", dir, target}, env)

}

// Copyright (c) 2021 Tigera, Inc. All rights reserved.

// Licensed under the Apache License, Version 2.0 (the "License");

// you may not use this file except in compliance with the License.

// You may obtain a copy of the License at

//


====================
	if err != nil {

		logrus.WithError(err).Fatal("git command failed")

	}

}

func (r *ReleaseBuilder) makeInDirectory(dir, target string, env ...string) error {

	err := r.runner.RunNoCapture("make", []string{"-C", dir, target}, env)

	return err

}

func (r *ReleaseBuilder) makeInDirectoryWithOutput(dir, target string, env ...string) (string, error) {

	return r.runner.Run("make", []string{"-C", dir, target}, env)

}

// Copyright (c) 2021 Tigera, Inc. All rights reserved.

// Licensed under the Apache License, Version 2.0 (the "License");

// you may not use this file except in compliance with the License.

// You may obtain a copy of the License at

//

//     http://www.apache.org/licenses/LICENSE-2.0

//

// Unless required by applicable law or agreed to in writing, software

// distributed under the License is distributed on an "AS IS" BASIS,


====================
	}

	if filterDir == "" || strings.HasPrefix(pkg, filterDir) {

		// No filter, or a filter is specified and matches.

		return strings.TrimPrefix(pkg, filterDir)

	}

	return ""

}

func loadPackages() []Package {

	var out, stderr bytes.Buffer

	cmd := exec.Command("go", "list", "-json", "all")

	cmd.Stdout = &out

	cmd.Stderr = &stderr

	err := cmd.Run()

	if err != nil {

		panic(fmt.Sprintf("%s: %s", err, stderr.String()))

	}

	splits := strings.SplitAfter(out.String(), "}\n")

	// Load each package.

	packages := []Package{}

	for _, s := range splits {


====================
		return nil, fmt.Errorf("error creating self-signed certificates: %v", err)

	}

	serverConfig := genericapiserver.NewRecommendedConfig(apiserver.Codecs)

	serverConfig.OpenAPIConfig = genericapiserver.DefaultOpenAPIConfig(openapi.GetOpenAPIDefinitions, k8sopenapi.NewDefinitionNamer(apiserver.Scheme))

	if serverConfig.OpenAPIConfig.Info == nil {

		serverConfig.OpenAPIConfig.Info = &spec.Info{}

	}

	if serverConfig.OpenAPIConfig.Info.Version == "" {

		if serverConfig.Version != nil {

			serverConfig.OpenAPIConfig.Info.Version = strings.Split(serverConfig.Version.String(), "-")[0]

		} else {

			serverConfig.OpenAPIConfig.Info.Version = "unversioned"

		}

	}

	if err := o.RecommendedOptions.Etcd.ApplyTo(&serverConfig.Config); err != nil {

		return nil, err

	}

	o.RecommendedOptions.Etcd.StorageConfig.Paging = utilfeature.DefaultFeatureGate.Enabled(features.APIListChunking)

	if err := o.RecommendedOptions.SecureServing.ApplyTo(&serverConfig.SecureServing, &serverConfig.LoopbackClientConfig); err != nil {

		return nil, err


====================
// New returns a new instance of ProjectCalicoServer from the given config.

func (c completedConfig) New() (*ProjectCalicoServer, error) {

	genericServer, err := c.GenericConfig.New("apiserver", genericapiserver.NewEmptyDelegate())

	if err != nil {

		return nil, err

	}

	apiGroupInfo := genericapiserver.NewDefaultAPIGroupInfo(GroupName, Scheme, metav1.ParameterCodec, Codecs)

	apiGroupInfo.NegotiatedSerializer = newProtocolShieldSerializer(&Codecs)

	// TODO: Make the storage type configurable

	calicostore := calicorest.RESTStorageProvider{StorageType: "calico"}

	s := &ProjectCalicoServer{GenericAPIServer: genericServer}

	apiGroupInfo.VersionedResourcesStorageMap["v3"], err = calicostore.NewV3Storage(

		Scheme, c.GenericConfig.RESTOptionsGetter, c.GenericConfig.Authorization.Authorizer,

	)

	if err != nil {

		return nil, err

	}

	if err := s.GenericAPIServer.InstallAPIGroup(&apiGroupInfo); err != nil {

		return nil, err

	}


====================
	default:

		return StorageType(""), errUnsupportedStorageType{t: StorageType(s)}

	}

}

func (s StorageType) String() string {

	return string(s)

}

const (

	// StorageTypeCalico indicates a storage interface should use libcalico

	StorageTypeCalico StorageType = "calico"

	// StorageTypeEtcd indicates a storage interface should use default etcd

	StorageTypeEtcd StorageType = "etcd"

)

// Options is the extension of a generic.RESTOptions struct, complete with service-catalog

// specific things

type Options struct {

	EtcdOptions   etcd.Options

	CalicoOptions calico.Options

	storageType   StorageType

	Authorizer    authorizer.Authorizer


====================
			logError("doMount", inp, fmt.Sprintf("failed to unmount %s\n", destinationDir), syslogOnlyTrue)

		}

		e = os.RemoveAll(newDir)

		if e != nil {

			logError("doMount", inp, fmt.Sprintf("failed to clear %s\n", newDir), syslogOnlyTrue)

		}

		return err

	}

	// Do a bind mount

	cmd := exec.Command("/bin/mount", "--bind", newDir, newDestianationDir)

	err = cmd.Run()

	if err != nil {

		cmd = exec.Command("/bin/umount", destinationDir)

		e := cmd.Run()

		if e != nil {

			logError("doMount", inp, fmt.Sprintf("failed to unmount %s\n", destinationDir), syslogOnlyTrue)

		}

		e = os.RemoveAll(newDir)

		if e != nil {

			logError("doMount", inp, fmt.Sprintf("failed to clear %s\n", newDir), syslogOnlyTrue)


====================
	)

	It("should reject MaxBlocksPerHost less than zero", func() {

		_, err := c.IPAMConfig().Create(ctx, &libapiv3.IPAMConfig{

			ObjectMeta: metav1.ObjectMeta{Name: "default"},

			Spec: libapiv3.IPAMConfigSpec{

				MaxBlocksPerHost: -1,

			},

		}, options.SetOptions{})

		Expect(err).To(HaveOccurred())

		Expect(err.Error()).To(Equal("error with field MaxBlocksPerHost = '-1' (must be greater than or equal to 0)"))

	})

})

// Copyright (c) 2017 Tigera, Inc. All rights reserved.

// Licensed under the Apache License, Version 2.0 (the "License");

// you may not use this file except in compliance with the License.

// You may obtain a copy of the License at

//

//     http://www.apache.org/licenses/LICENSE-2.0

//

// Unless required by applicable law or agreed to in writing, software


====================
					EgressRule: &networkingv1.NetworkPolicyEgressRule{

						Ports: []networkingv1.NetworkPolicyPort{

							{

								Protocol: nil,

								Port:     &intstr.IntOrString{Type: 0, IntVal: 80, StrVal: ""},

								EndPort:  nil,

							},

							{

								Protocol: nil,

								Port:     &intstr.IntOrString{Type: 1, IntVal: 0, StrVal: "-22:-3"},

								EndPort:  nil,

							},

						},

						To: []networkingv1.NetworkPolicyPeer{

							{

								PodSelector: &metav1.LabelSelector{

									MatchLabels:      map[string]string{"k2": "v2", "k": "v"},

									MatchExpressions: nil,

								},

								NamespaceSelector: nil,


====================
					EgressRule: &networkingv1.NetworkPolicyEgressRule{

						Ports: []networkingv1.NetworkPolicyPort{

							{

								Protocol: nil,

								Port:     &intstr.IntOrString{Type: 0, IntVal: 80, StrVal: ""},

								EndPort:  nil,

							},

							{

								Protocol: nil,

								Port:     &intstr.IntOrString{Type: 1, IntVal: 0, StrVal: "-22:-3"},

								EndPort:  nil,

							},

						},

						To: []networkingv1.NetworkPolicyPeer{

							{

								PodSelector: &metav1.LabelSelector{

									MatchLabels:      map[string]string{"k2": "v2", "k": "v"},

									MatchExpressions: nil,

								},

								NamespaceSelector: nil,


====================
					IngressRule: &networkingv1.NetworkPolicyIngressRule{

						Ports: []networkingv1.NetworkPolicyPort{

							{

								Protocol: nil,

								Port:     &intstr.IntOrString{Type: 0, IntVal: 80, StrVal: ""},

								EndPort:  nil,

							},

							{

								Protocol: nil,

								Port:     &intstr.IntOrString{Type: 1, IntVal: 0, StrVal: "-50:-1"},

								EndPort:  nil,

							},

						},

						From: []networkingv1.NetworkPolicyPeer{

							{

								PodSelector: &metav1.LabelSelector{

									MatchLabels:      map[string]string{"k2": "v2", "k": "v"},

									MatchExpressions: nil,

								},

								NamespaceSelector: nil,


====================
	log.Info("Datastore type: ", c.Spec.DatastoreType)

	return &c, nil

}

// LoadClientConfig loads the ClientConfig from the specified file (if specified)

// or from environment variables (if the file is not specified).

func LoadClientConfigFromEnvironment() (*api.CalicoAPIConfig, error) {

	c := api.NewCalicoAPIConfig()

	// Load client config from environment variables.

	log.Info("Loading config from environment")

	if err := envconfig.Process("calico", &c.Spec); err != nil {

		return nil, err

	}

	return c, nil

}

// Interface used to convert between backend and API representations of our

// objects.

type conversionHelper interface {

	convertAPIToKVPair(unversioned.Resource) (*model.KVPair, error)

	convertKVPairToAPI(*model.KVPair) (unversioned.Resource, error)

	convertMetadataToKey(unversioned.ResourceMetadata) (model.Key, error)


====================
		Entry("should accept ProtoPort.Protocol: UDP", api.ProtoPort{Protocol: "UDP", Port: 0}, true),

		Entry("should accept ProtoPort.Protocol: TCP", api.ProtoPort{Protocol: "TCP", Port: 20}, true),

		Entry("should accept ProtoPort.Protocol: SCTP", api.ProtoPort{Protocol: "SCTP", Port: 20}, true),

		Entry("should reject random ProtoPort.Protocol", api.ProtoPort{Protocol: "jolly-UDP", Port: 0}, false),

		// (API) Selectors.  Selectors themselves are thoroughly UT'd so only need to test simple

		// accept and reject cases here.

		Entry("should accept valid selector", api.EntityRule{Selector: "foo == \"bar\""}, true),

		Entry("should accept valid selector with 'has' and a '/'", api.EntityRule{Selector: "has(calico/k8s_ns)"}, true),

		Entry("should accept valid selector with 'has' and two '/'", api.EntityRule{Selector: "has(calico/k8s_ns/role)"}, true),

		Entry("should accept valid selector with 'has' and two '/' and '-.'", api.EntityRule{Selector: "has(calico/k8s_NS-.1/role)"}, true),

		Entry("should reject invalid selector", api.EntityRule{Selector: "thing=hello &"}, false),

		// (API) Labels and Annotations.

		Entry("should accept a valid labelsToApply", api.ProfileSpec{LabelsToApply: map[string]string{"project.calico.org/my-valid-label": value63}}, true),

		Entry("should reject an excessively long value in labelsToApply", api.ProfileSpec{LabelsToApply: map[string]string{"project.calico.org/my-valid-label": value64}}, false),

		Entry("should reject . at start of key in a labelsToApply", api.ProfileSpec{LabelsToApply: map[string]string{".mylabel": "value"}}, false),

		Entry("should reject ! in a labelsToApply", api.ProfileSpec{LabelsToApply: map[string]string{"my!nvalid-label": "value"}}, false),

		Entry("should reject $ in a labelsToApply", api.ProfileSpec{LabelsToApply: map[string]string{"my-invalid-label$": "value"}}, false),

		Entry("should accept valid labels in metadata",

			api.IPPool{

				ObjectMeta: v1.ObjectMeta{


====================
		Entry("should reject workload endpoint with IPv6 NAT not covered by network",

			libapiv3.WorkloadEndpointSpec{

				InterfaceName: "cali012371237",

				IPNetworks:    []string{netv6_1},

				IPNATs:        []libapiv3.IPNAT{{InternalIP: ipv6_2, ExternalIP: ipv6_1}},

			}, false),

		Entry("should reject workload endpoint containerID that starts with a dash",

			libapiv3.WorkloadEndpointSpec{

				InterfaceName: "cali0134",

				ContainerID:   "-abcdefg",

			}, false),

		Entry("should reject workload endpoint containerID that ends with a dash",

			libapiv3.WorkloadEndpointSpec{

				InterfaceName: "cali0134",

				ContainerID:   "abcdeSg-",

			}, false),

		Entry("should reject workload endpoint containerID that contains a period",

			libapiv3.WorkloadEndpointSpec{

				InterfaceName: "cali0134",

				ContainerID:   "abcde-j.g",


====================
		)

	}

	// Uses the k8s DN1123 subdomain format for most resource names.

	matched := nameRegex.MatchString(om.Name)

	if !matched {

		structLevel.ReportError(

			reflect.ValueOf(om.Name),

			"Metadata.Name",

			"",

			reason("name must consist of lower case alphanumeric characters, '-' or '.' (regex: "+nameSubdomainFmt+")"),

			"",

		)

	}

	validateObjectMetaAnnotations(structLevel, om.Annotations)

	validateObjectMetaLabels(structLevel, om.Labels)

}

func validateNetworkPolicy(structLevel validator.StructLevel) {

	np := structLevel.Current().Interface().(api.NetworkPolicy)

	spec := np.Spec

	// Check (and disallow) any repeats in Types field.


====================
		)

	}

	// Uses the k8s DN1123 label format for policy names (plus knp.default prefixed k8s policies).

	matched := networkPolicyNameRegex.MatchString(np.Name)

	if !matched {

		structLevel.ReportError(

			reflect.ValueOf(np.Name),

			"Metadata.Name",

			"",

			reason("name must consist of lower case alphanumeric characters or '-' (regex: "+nameLabelFmt+")"),

			"",

		)

	}

	validateObjectMetaAnnotations(structLevel, np.Annotations)

	validateObjectMetaLabels(structLevel, np.Labels)

	for _, r := range spec.Egress {

		// Services are only allowed in the destination on Egress rules.

		if r.Source.Services != nil {

			structLevel.ReportError(

				reflect.ValueOf(r.Source.Services), "Services", "",


====================
		)

	}

	// Uses the k8s DN1123 label format for policy names.

	matched := globalNetworkPolicyNameRegex.MatchString(gnp.Name)

	if !matched {

		structLevel.ReportError(

			reflect.ValueOf(gnp.Name),

			"Metadata.Name",

			"",

			reason("name must consist of lower case alphanumeric characters or '-' (regex: "+nameLabelFmt+")"),

			"",

		)

	}

	validateObjectMetaAnnotations(structLevel, gnp.Annotations)

	validateObjectMetaLabels(structLevel, gnp.Labels)

	if spec.DoNotTrack && spec.PreDNAT {

		structLevel.ReportError(reflect.ValueOf(spec.PreDNAT),

			"PolicySpec.PreDNAT", "", reason("PreDNAT and DoNotTrack cannot both be true, for a given PolicySpec"), "")

	}

	if spec.PreDNAT && len(spec.Egress) > 0 {


====================
		// (API) Names.

		Entry("should accept a valid name", api.ProfileMetadata{Name: ".My-valid-Profile_190"}, true),

		Entry("should reject ! in a name", api.ProfileMetadata{Name: "my!nvalid-Profile"}, false),

		Entry("should reject $ in a name", api.ProfileMetadata{Name: "my-invalid-profile$"}, false),

		// (API) Selectors.  Selectors themselves are thorougly UT'd so only need to test simple

		// accept and reject cases here.

		Entry("should accept valid selector", api.EntityRule{Selector: "foo == \"bar\""}, true),

		Entry("should accept valid selector with 'has' and a '/'", api.EntityRule{Selector: "has(calico/k8s_ns)"}, true),

		Entry("should accept valid selector with 'has' and two '/'", api.EntityRule{Selector: "has(calico/k8s_ns/role)"}, true),

		Entry("should accept valid selector with 'has' and two '/' and '-.'", api.EntityRule{Selector: "has(calico/k8s_NS-.1/role)"}, true),

		Entry("should reject invalid selector", api.EntityRule{Selector: "thing=hello &"}, false),

		// (API) Tags.

		Entry("should accept a valid tag", api.ProfileMetadata{Tags: []string{".My-valid-tag_190"}}, true),

		Entry("should reject ! in a tag", api.ProfileMetadata{Tags: []string{"my!nvalid-tag"}}, false),

		Entry("should reject $ in a tag", api.ProfileMetadata{Tags: []string{"my-invalid-tag$"}}, false),

		// (API) Labels.

		Entry("should accept a valid label", api.HostEndpointMetadata{Labels: map[string]string{"rank_.0-9": "gold._0-9"}}, true),

		Entry("should accept label key starting with 0-9", api.HostEndpointMetadata{Labels: map[string]string{"2rank": "gold"}}, true),

		Entry("should accept label value starting with 0-9", api.HostEndpointMetadata{Labels: map[string]string{"rank": "2gold"}}, true),

		Entry("should accept label key with dns prefix", api.HostEndpointMetadata{Labels: map[string]string{"calico/k8s_ns": "kube-system"}}, true),


====================
	}

	applyConfigDefaults(&c)

	log.Debug("Datastore type: ", c.Spec.DatastoreType)

	return &c, nil

}

// LoadClientConfigFromEnvironment loads a client config from the environment.

// The datastore type is defaulted if not specified.

func LoadClientConfigFromEnvironment() (*CalicoAPIConfig, error) {

	c := NewCalicoAPIConfig()

	if err := envconfig.Process("calico", &c.Spec); err != nil {

		return nil, fmt.Errorf("failed to load config from env vars: %w", err)

	}

	applyConfigDefaults(c)

	return c, nil

}

// applyConfigDefaults tries to detect the correct datastore type and config parameters.

func applyConfigDefaults(c *CalicoAPIConfig) {

	if c.Spec.DatastoreType == "" {

		log.Debug("Datastore type isn't set, trying to detect it")

		if c.Spec.EtcdEndpoints != "" {


====================
				Destination: apiv3.EntityRule{

					Ports: []numorstring.Port{numorstring.SinglePort(53)},

				},

			},

		))

	})

	It("should drop rules with invalid ports in a k8s NetworkPolicy", func() {

		port80 := intstr.FromInt(80)

		portFoo := intstr.FromString("foo")

		portBad1 := intstr.FromString("-50:-1")

		portBad2 := intstr.FromString("-22:-3")

		np1 := networkingv1.NetworkPolicy{

			ObjectMeta: metav1.ObjectMeta{

				Name:      "test.policy",

				Namespace: "default",

			},

			Spec: networkingv1.NetworkPolicySpec{

				PodSelector: metav1.LabelSelector{

					MatchLabels: map[string]string{

						"label":  "value",


====================
					Ports: []numorstring.Port{numorstring.SinglePort(53)},

				},

			},

		))

	})

	It("should drop rules with invalid ports in a k8s NetworkPolicy", func() {

		port80 := intstr.FromInt(80)

		portFoo := intstr.FromString("foo")

		portBad1 := intstr.FromString("-50:-1")

		portBad2 := intstr.FromString("-22:-3")

		np1 := networkingv1.NetworkPolicy{

			ObjectMeta: metav1.ObjectMeta{

				Name:      "test.policy",

				Namespace: "default",

			},

			Spec: networkingv1.NetworkPolicySpec{

				PodSelector: metav1.LabelSelector{

					MatchLabels: map[string]string{

						"label":  "value",

						"label2": "value2",


====================
					IngressRule: &networkingv1.NetworkPolicyIngressRule{

						Ports: []networkingv1.NetworkPolicyPort{

							{

								Protocol: nil,

								Port:     &intstr.IntOrString{Type: 0, IntVal: 80, StrVal: ""},

								EndPort:  nil,

							},

							{

								Protocol: nil,

								Port:     &intstr.IntOrString{Type: 1, IntVal: 0, StrVal: "-50:-1"},

								EndPort:  nil,

							},

						},

						From: []networkingv1.NetworkPolicyPeer{

							{

								PodSelector: &metav1.LabelSelector{

									MatchLabels:      map[string]string{"k2": "v2", "k": "v"},

									MatchExpressions: nil,

								},

								NamespaceSelector: nil,


====================
					EgressRule: &networkingv1.NetworkPolicyEgressRule{

						Ports: []networkingv1.NetworkPolicyPort{

							{

								Protocol: nil,

								Port:     &intstr.IntOrString{Type: 0, IntVal: 80, StrVal: ""},

								EndPort:  nil,

							},

							{

								Protocol: nil,

								Port:     &intstr.IntOrString{Type: 1, IntVal: 0, StrVal: "-50:-1"},

								EndPort:  nil,

							},

						},

						To: []networkingv1.NetworkPolicyPeer{

							{

								PodSelector: &metav1.LabelSelector{

									MatchLabels:      map[string]string{"k2": "v2", "k": "v"},

									MatchExpressions: nil,

								},

								NamespaceSelector: nil,


====================
					EgressRule: &networkingv1.NetworkPolicyEgressRule{

						Ports: []networkingv1.NetworkPolicyPort{

							{

								Protocol: nil,

								Port:     &intstr.IntOrString{Type: 0, IntVal: 80, StrVal: ""},

								EndPort:  nil,

							},

							{

								Protocol: nil,

								Port:     &intstr.IntOrString{Type: 1, IntVal: 0, StrVal: "-22:-3"},

								EndPort:  nil,

							},

						},

						To: []networkingv1.NetworkPolicyPeer{

							{

								PodSelector: &metav1.LabelSelector{

									MatchLabels:      map[string]string{"k2": "v2", "k": "v"},

									MatchExpressions: nil,

								},

								NamespaceSelector: nil,


====================
	}

	parts := strings.Split(normalizedPath, "/")

	if len(parts) < 3 {

		// After removing the optional `/` prefix, should have at least 3 segments.

		return nil

	}

	return keyFromDefaultPathInner(path, parts)

}

func keyFromDefaultPathInner(path string, parts []string) Key {

	if parts[0] != "calico" {

		return nil

	}

	switch parts[1] {

	case "v1":

		switch parts[2] {

		case "ipam":

			return IPPoolListOptions{}.KeyFromDefaultPath(path)

		case "config":

			return GlobalConfigKey{Name: strings.Join(parts[3:], "/")}

		case "host":


====================
	} else if m := matchHostIp.FindStringSubmatch(path); m != nil {

		log.Debugf("Path is a host ID: %v", path)

		return HostIPKey{Hostname: m[1]}

	} else if m := matchWireguard.FindStringSubmatch(path); m != nil {

		log.Debugf("Path is a node name: %v", path)

		return WireguardKey{NodeName: m[1]}

	} else if m := matchIPPool.FindStringSubmatch(path); m != nil {

		log.Debugf("Path is a pool: %v", path)

		mungedCIDR := m[1]

		cidr := strings.Replace(mungedCIDR, "-", "/", 1)

		_, c, err := net.ParseCIDR(cidr)

		if err != nil {

			log.WithError(err).Warningf("Failed to parse CIDR %s", cidr)

		} else {

			return IPPoolKey{CIDR: *c}

		}

	} else if m := matchGlobalConfig.FindStringSubmatch(path); m != nil {

		log.Debugf("Path is a global felix config: %v", path)

		return GlobalConfigKey{Name: m[1]}

	} else if m := matchHostConfig.FindStringSubmatch(path); m != nil {


====================
	return nil, nil

}

func (key ReadyFlagKey) valueType() (reflect.Type, error) {

	return typeReadyFlag, nil

}

func (key ReadyFlagKey) String() string {

	return "ReadyFlagKey()"

}

type GlobalConfigKey struct {

	Name string `json:"-" validate:"required,name"`

}

func (key GlobalConfigKey) defaultPath() (string, error) {

	if key.Name == "" {

		return "", errors.ErrorInsufficientIdentifiers{Name: "name"}

	}

	e := fmt.Sprintf("/calico/v1/config/%s", key.Name)

	return e, nil

}

func (key GlobalConfigKey) defaultDeletePath() (string, error) {

	return key.defaultPath()


====================
	}

	name := r[0][1]

	if options.Name != "" && name != options.Name {

		log.Debugf("Didn't match name %s != %s", options.Name, name)

		return nil

	}

	return GlobalConfigKey{Name: name}

}

type HostConfigKey struct {

	Hostname string `json:"-" validate:"required,name"`

	Name     string `json:"-" validate:"required,name"`

}

func (key HostConfigKey) defaultPath() (string, error) {

	if key.Name == "" {

		return "", errors.ErrorInsufficientIdentifiers{Name: "name"}

	}

	if key.Hostname == "" {

		return "", errors.ErrorInsufficientIdentifiers{Name: "node"}

	}

	e := fmt.Sprintf("/calico/v1/host/%s/config/%s", key.Hostname, key.Name)


====================
	name := r[0][1]

	if options.Name != "" && name != options.Name {

		log.Debugf("Didn't match name %s != %s", options.Name, name)

		return nil

	}

	return GlobalConfigKey{Name: name}

}

type HostConfigKey struct {

	Hostname string `json:"-" validate:"required,name"`

	Name     string `json:"-" validate:"required,name"`

}

func (key HostConfigKey) defaultPath() (string, error) {

	if key.Name == "" {

		return "", errors.ErrorInsufficientIdentifiers{Name: "name"}

	}

	if key.Hostname == "" {

		return "", errors.ErrorInsufficientIdentifiers{Name: "node"}

	}

	e := fmt.Sprintf("/calico/v1/host/%s/config/%s", key.Hostname, key.Name)

	return e, nil


====================
	typeBlockAff       = reflect.TypeOf(BlockAffinity{})

)

type BlockAffinityState string

const (

	StateConfirmed       BlockAffinityState = "confirmed"

	StatePending         BlockAffinityState = "pending"

	StatePendingDeletion BlockAffinityState = "pendingDeletion"

)

type BlockAffinityKey struct {

	CIDR net.IPNet `json:"-" validate:"required,name"`

	Host string    `json:"-"`

}

type BlockAffinity struct {

	State   BlockAffinityState `json:"state"`

	Deleted bool               `json:"deleted"`

}

func (key BlockAffinityKey) defaultPath() (string, error) {

	if key.CIDR.IP == nil || key.Host == "" {

		return "", errors.ErrorInsufficientIdentifiers{}

	}


====================
)

type BlockAffinityState string

const (

	StateConfirmed       BlockAffinityState = "confirmed"

	StatePending         BlockAffinityState = "pending"

	StatePendingDeletion BlockAffinityState = "pendingDeletion"

)

type BlockAffinityKey struct {

	CIDR net.IPNet `json:"-" validate:"required,name"`

	Host string    `json:"-"`

}

type BlockAffinity struct {

	State   BlockAffinityState `json:"state"`

	Deleted bool               `json:"deleted"`

}

func (key BlockAffinityKey) defaultPath() (string, error) {

	if key.CIDR.IP == nil || key.Host == "" {

		return "", errors.ErrorInsufficientIdentifiers{}

	}

	c := strings.Replace(key.CIDR.String(), "/", "-", 1)


====================
}

type BlockAffinity struct {

	State   BlockAffinityState `json:"state"`

	Deleted bool               `json:"deleted"`

}

func (key BlockAffinityKey) defaultPath() (string, error) {

	if key.CIDR.IP == nil || key.Host == "" {

		return "", errors.ErrorInsufficientIdentifiers{}

	}

	c := strings.Replace(key.CIDR.String(), "/", "-", 1)

	e := fmt.Sprintf("/calico/ipam/v2/host/%s/ipv%d/block/%s", key.Host, key.CIDR.Version(), c)

	return e, nil

}

func (key BlockAffinityKey) defaultDeletePath() (string, error) {

	return key.defaultPath()

}

func (key BlockAffinityKey) defaultDeleteParentPaths() ([]string, error) {

	return nil, nil

}

func (key BlockAffinityKey) valueType() (reflect.Type, error) {


====================
	return k

}

func (options BlockAffinityListOptions) KeyFromDefaultPath(path string) Key {

	log.Debugf("Get Block affinity key from %s", path)

	r := matchBlockAffinity.FindAllStringSubmatch(path, -1)

	if len(r) != 1 {

		log.Debugf("%s didn't match regex", path)

		return nil

	}

	cidrStr := strings.Replace(r[0][2], "-", "/", 1)

	_, cidr, _ := net.ParseCIDR(cidrStr)

	if cidr == nil {

		log.Debugf("Failed to parse CIDR in block affinity path: %q", path)

		return nil

	}

	host := r[0][1]

	if options.Host != "" && options.Host != host {

		log.Debugf("Didn't match hostname: %s != %s", options.Host, host)

		return nil

	}


====================
)

var (

	matchProfile = regexp.MustCompile("^/?calico/v1/policy/profile/([^/]+)/(rules|labels)$")

	typeProfile  = reflect.TypeOf(Profile{})

)

// The profile key actually returns the common parent of the three separate entries.

// It is useful to define this to re-use some of the common machinery, and can be used

// for delete processing since delete needs to remove the common parent.

type ProfileKey struct {

	Name string `json:"-" validate:"required,name"`

}

func (key ProfileKey) defaultPath() (string, error) {

	if key.Name == "" {

		return "", errors.ErrorInsufficientIdentifiers{Name: "name"}

	}

	e := fmt.Sprintf("/calico/v1/policy/profile/%s", escapeName(key.Name))

	return e, nil

}

func (key ProfileKey) defaultDeletePath() (string, error) {

	return key.defaultPath()


====================
	IPAMBlockAttributeTypeWireguard   = "wireguardTunnelAddress"

	IPAMBlockAttributeTypeWireguardV6 = "wireguardV6TunnelAddress"

	IPAMBlockAttributeTimestamp       = "timestamp"

)

var (

	matchBlock = regexp.MustCompile("^/?calico/ipam/v2/assignment/ipv./block/([^/]+)$")

	typeBlock  = reflect.TypeOf(AllocationBlock{})

)

type BlockKey struct {

	CIDR net.IPNet `json:"-" validate:"required,name"`

}

func (key BlockKey) defaultPath() (string, error) {

	if key.CIDR.IP == nil {

		return "", errors.ErrorInsufficientIdentifiers{}

	}

	c := strings.Replace(key.CIDR.String(), "/", "-", 1)

	e := fmt.Sprintf("/calico/ipam/v2/assignment/ipv%d/block/%s", key.CIDR.Version(), c)

	return e, nil

}

func (key BlockKey) defaultDeletePath() (string, error) {


====================
	typeBlock  = reflect.TypeOf(AllocationBlock{})

)

type BlockKey struct {

	CIDR net.IPNet `json:"-" validate:"required,name"`

}

func (key BlockKey) defaultPath() (string, error) {

	if key.CIDR.IP == nil {

		return "", errors.ErrorInsufficientIdentifiers{}

	}

	c := strings.Replace(key.CIDR.String(), "/", "-", 1)

	e := fmt.Sprintf("/calico/ipam/v2/assignment/ipv%d/block/%s", key.CIDR.Version(), c)

	return e, nil

}

func (key BlockKey) defaultDeletePath() (string, error) {

	return key.defaultPath()

}

func (key BlockKey) defaultDeleteParentPaths() ([]string, error) {

	return nil, nil

}

func (key BlockKey) valueType() (reflect.Type, error) {


====================
	return nil, nil

}

func (key BlockKey) valueType() (reflect.Type, error) {

	return typeBlock, nil

}

func (key BlockKey) String() string {

	return fmt.Sprintf("BlockKey(cidr=%s)", key.CIDR.String())

}

type BlockListOptions struct {

	IPVersion int `json:"-"`

}

func (options BlockListOptions) defaultPathRoot() string {

	k := "/calico/ipam/v2/assignment/"

	if options.IPVersion != 0 {

		k = k + fmt.Sprintf("ipv%d/", options.IPVersion)

	}

	return k

}

func (options BlockListOptions) KeyFromDefaultPath(path string) Key {

	log.Debugf("Get Block key from %s", path)


====================
	return k

}

func (options BlockListOptions) KeyFromDefaultPath(path string) Key {

	log.Debugf("Get Block key from %s", path)

	r := matchBlock.FindAllStringSubmatch(path, -1)

	if len(r) != 1 {

		log.Debugf("%s didn't match regex", path)

		return nil

	}

	cidrStr := strings.Replace(r[0][1], "-", "/", 1)

	_, cidr, err := net.ParseCIDR(cidrStr)

	if err != nil {

		log.Debugf("find an invalid cidr %s for path=%v , info=%v ", r[0][1], path, err)

		return nil

	}

	return BlockKey{CIDR: *cidr}

}

type AllocationBlock struct {

	// The block's CIDR.

	CIDR net.IPNet `json:"cidr"`


====================
)

var (

	matchGlobalBGPConfig = regexp.MustCompile("^/?calico/bgp/v1/global/(.+)$")

	matchNodeBGPConfig   = regexp.MustCompile("^/?calico/bgp/v1/host/([^/]+)/(.+)$")

	typeGlobalBGPConfig  = rawStringType

	typeNodeBGPConfig    = rawStringType

)

type GlobalBGPConfigKey struct {

	// The name of the global BGP config key.

	Name string `json:"-" validate:"required,name"`

}

func (key GlobalBGPConfigKey) defaultPath() (string, error) {

	return key.defaultDeletePath()

}

func (key GlobalBGPConfigKey) defaultDeletePath() (string, error) {

	if key.Name == "" {

		return "", errors.ErrorInsufficientIdentifiers{Name: "name"}

	}

	e := fmt.Sprintf("/calico/bgp/v1/global/%s", key.Name)

	return e, nil


====================
	name := r[0][1]

	if options.Name != "" && name != options.Name {

		log.Debugf("Didn't match name %s != %s", options.Name, name)

		return nil

	}

	return GlobalBGPConfigKey{Name: name}

}

type NodeBGPConfigKey struct {

	// The hostname for the host specific BGP config

	Nodename string `json:"-" validate:"required,name"`

	// The name of the host specific BGP config key.

	Name string `json:"-" validate:"required,name"`

}

func (key NodeBGPConfigKey) defaultPath() (string, error) {

	return key.defaultDeletePath()

}

func (key NodeBGPConfigKey) defaultDeletePath() (string, error) {

	if key.Nodename == "" {

		return "", errors.ErrorInsufficientIdentifiers{Name: "node"}

	}


====================
		log.Debugf("Didn't match name %s != %s", options.Name, name)

		return nil

	}

	return GlobalBGPConfigKey{Name: name}

}

type NodeBGPConfigKey struct {

	// The hostname for the host specific BGP config

	Nodename string `json:"-" validate:"required,name"`

	// The name of the host specific BGP config key.

	Name string `json:"-" validate:"required,name"`

}

func (key NodeBGPConfigKey) defaultPath() (string, error) {

	return key.defaultDeletePath()

}

func (key NodeBGPConfigKey) defaultDeletePath() (string, error) {

	if key.Nodename == "" {

		return "", errors.ErrorInsufficientIdentifiers{Name: "node"}

	}

	if key.Name == "" {

		return "", errors.ErrorInsufficientIdentifiers{Name: "name"}


====================
	log.Debugf("Get IPAM handle key from %s", path)

	r := matchHandle.FindAllStringSubmatch(path, -1)

	if len(r) != 1 {

		log.Debugf("%s didn't match regex", path)

		return nil

	}

	return IPAMHandleKey{HandleID: r[0][1]}

}

type IPAMHandle struct {

	HandleID string         `json:"-"`

	Block    map[string]int `json:"block"`

	Deleted  bool           `json:"deleted"`

}

// Copyright (c) 2017 Tigera, Inc. All rights reserved.

// Licensed under the Apache License, Version 2.0 (the "License");

// you may not use this file except in compliance with the License.

// You may obtain a copy of the License at

//

//     http://www.apache.org/licenses/LICENSE-2.0

//


====================
	typeIPPool  = reflect.TypeOf(IPPool{})

)

type IPPoolKey struct {

	CIDR net.IPNet `json:"-" validate:"required,name"`

}

func (key IPPoolKey) defaultPath() (string, error) {

	if key.CIDR.IP == nil {

		return "", errors.ErrorInsufficientIdentifiers{Name: "cidr"}

	}

	c := strings.Replace(key.CIDR.String(), "/", "-", 1)

	e := fmt.Sprintf("/calico/v1/ipam/v%d/pool/%s", key.CIDR.Version(), c)

	return e, nil

}

func (key IPPoolKey) defaultDeletePath() (string, error) {

	return key.defaultPath()

}

func (key IPPoolKey) defaultDeleteParentPaths() ([]string, error) {

	return nil, nil

}

func (key IPPoolKey) valueType() (reflect.Type, error) {


====================
}

type IPPoolListOptions struct {

	CIDR net.IPNet

}

func (options IPPoolListOptions) defaultPathRoot() string {

	k := "/calico/v1/ipam/"

	if options.CIDR.IP == nil {

		return k

	}

	c := strings.Replace(options.CIDR.String(), "/", "-", 1)

	k = k + fmt.Sprintf("v%d/pool/", options.CIDR.Version()) + fmt.Sprintf("%s", c)

	return k

}

func (options IPPoolListOptions) KeyFromDefaultPath(path string) Key {

	log.Debugf("Get Pool key from %s", path)

	r := matchIPPool.FindAllStringSubmatch(path, -1)

	if len(r) != 1 {

		log.Debugf("%s didn't match regex", path)

		return nil

	}


====================
	return k

}

func (options IPPoolListOptions) KeyFromDefaultPath(path string) Key {

	log.Debugf("Get Pool key from %s", path)

	r := matchIPPool.FindAllStringSubmatch(path, -1)

	if len(r) != 1 {

		log.Debugf("%s didn't match regex", path)

		return nil

	}

	cidrStr := strings.Replace(r[0][1], "-", "/", 1)

	_, cidr, err := net.ParseCIDR(cidrStr)

	if err != nil {

		log.WithError(err).Warningf("Failed to parse CIDR %s", cidrStr)

		return nil

	}

	if options.CIDR.IP != nil && !reflect.DeepEqual(*cidr, options.CIDR) {

		log.Debugf("Didn't match cidr %s != %s", options.CIDR.String(), cidr.String())

		return nil

	}

	return IPPoolKey{CIDR: *cidr}


====================
)

var (

	matchGlobalBGPPeer        = regexp.MustCompile("^/?calico/bgp/v1/global/peer_v./([^/]+)$")

	matchHostBGPPeer          = regexp.MustCompile("^/?calico/bgp/v1/host/([^/]+)/peer_v./([^/]+)$")

	typeBGPPeer               = reflect.TypeOf(BGPPeer{})

	ipPortSeparator           = "-"

	defaultPort        uint16 = 179

)

type NodeBGPPeerKey struct {

	Nodename string `json:"-" validate:"omitempty"`

	PeerIP   net.IP `json:"-" validate:"required"`

	Port     uint16 `json:"-" validate:"omitempty"`

}

func (key NodeBGPPeerKey) defaultPath() (string, error) {

	if key.PeerIP.IP == nil {

		return "", errors.ErrorInsufficientIdentifiers{Name: "peerIP"}

	}

	if key.Nodename == "" {

		return "", errors.ErrorInsufficientIdentifiers{Name: "node"}

	}


====================
var (

	matchGlobalBGPPeer        = regexp.MustCompile("^/?calico/bgp/v1/global/peer_v./([^/]+)$")

	matchHostBGPPeer          = regexp.MustCompile("^/?calico/bgp/v1/host/([^/]+)/peer_v./([^/]+)$")

	typeBGPPeer               = reflect.TypeOf(BGPPeer{})

	ipPortSeparator           = "-"

	defaultPort        uint16 = 179

)

type NodeBGPPeerKey struct {

	Nodename string `json:"-" validate:"omitempty"`

	PeerIP   net.IP `json:"-" validate:"required"`

	Port     uint16 `json:"-" validate:"omitempty"`

}

func (key NodeBGPPeerKey) defaultPath() (string, error) {

	if key.PeerIP.IP == nil {

		return "", errors.ErrorInsufficientIdentifiers{Name: "peerIP"}

	}

	if key.Nodename == "" {

		return "", errors.ErrorInsufficientIdentifiers{Name: "node"}

	}

	e := fmt.Sprintf("/calico/bgp/v1/host/%s/peer_v%d/%s",


====================
	matchGlobalBGPPeer        = regexp.MustCompile("^/?calico/bgp/v1/global/peer_v./([^/]+)$")

	matchHostBGPPeer          = regexp.MustCompile("^/?calico/bgp/v1/host/([^/]+)/peer_v./([^/]+)$")

	typeBGPPeer               = reflect.TypeOf(BGPPeer{})

	ipPortSeparator           = "-"

	defaultPort        uint16 = 179

)

type NodeBGPPeerKey struct {

	Nodename string `json:"-" validate:"omitempty"`

	PeerIP   net.IP `json:"-" validate:"required"`

	Port     uint16 `json:"-" validate:"omitempty"`

}

func (key NodeBGPPeerKey) defaultPath() (string, error) {

	if key.PeerIP.IP == nil {

		return "", errors.ErrorInsufficientIdentifiers{Name: "peerIP"}

	}

	if key.Nodename == "" {

		return "", errors.ErrorInsufficientIdentifiers{Name: "node"}

	}

	e := fmt.Sprintf("/calico/bgp/v1/host/%s/peer_v%d/%s",

		key.Nodename, key.PeerIP.Version(), combineIPAndPort(key.PeerIP, key.Port))


====================
		log.Debugf("Didn't match hostname %s != %s", options.Nodename, nodename)

		return nil

	}

	if port == 0 {

		return NodeBGPPeerKey{PeerIP: peerIP, Nodename: nodename}

	}

	return NodeBGPPeerKey{PeerIP: peerIP, Nodename: nodename, Port: port}

}

type GlobalBGPPeerKey struct {

	PeerIP net.IP `json:"-" validate:"required"`

	Port   uint16 `json:"-" validate:"omitempty"`

}

func (key GlobalBGPPeerKey) defaultPath() (string, error) {

	if key.PeerIP.IP == nil {

		return "", errors.ErrorInsufficientIdentifiers{Name: "peerIP"}

	}

	e := fmt.Sprintf("/calico/bgp/v1/global/peer_v%d/%s",

		key.PeerIP.Version(), combineIPAndPort(key.PeerIP, key.Port))

	return e, nil

}


====================
		return nil

	}

	if port == 0 {

		return NodeBGPPeerKey{PeerIP: peerIP, Nodename: nodename}

	}

	return NodeBGPPeerKey{PeerIP: peerIP, Nodename: nodename, Port: port}

}

type GlobalBGPPeerKey struct {

	PeerIP net.IP `json:"-" validate:"required"`

	Port   uint16 `json:"-" validate:"omitempty"`

}

func (key GlobalBGPPeerKey) defaultPath() (string, error) {

	if key.PeerIP.IP == nil {

		return "", errors.ErrorInsufficientIdentifiers{Name: "peerIP"}

	}

	e := fmt.Sprintf("/calico/bgp/v1/global/peer_v%d/%s",

		key.PeerIP.Version(), combineIPAndPort(key.PeerIP, key.Port))

	return e, nil

}

func (key GlobalBGPPeerKey) defaultDeletePath() (string, error) {


====================
		return nil

	}

	if options.Hostname != "" && name != options.Hostname {

		log.Debugf("Didn't match name %s != %s", options.Hostname, name)

		return nil

	}

	return ActiveStatusReportKey{Hostname: name, RegionString: regionString}

}

type LastStatusReportKey struct {

	Hostname     string `json:"-" validate:"required,hostname"`

	RegionString string

}

func (key LastStatusReportKey) defaultPath() (string, error) {

	return key.defaultDeletePath()

}

func (key LastStatusReportKey) defaultDeletePath() (string, error) {

	if key.Hostname == "" {

		return "", errors.ErrorInsufficientIdentifiers{Name: "hostname"}

	}

	if key.RegionString == "" {


====================
			if !allowPrefix {

				// We are not allowing prefixes.  This is an error scenario

				return "", cerrors.ErrorValidation{

					ErroredFields: []cerrors.ErroredField{

						{Name: s.field, Value: s.value, Reason: "field should be assigned"},

					},

				}

			}

			// We are allowing prefixes, so return the prefix that we have constructed thus far,

			// terminating with a "-".

			return strings.Join(parts, "-") + "-", nil

		}

		part, ef := escapeDashes(s)

		if ef != nil {

			return "", cerrors.ErrorValidation{ErroredFields: []cerrors.ErroredField{*ef}}

		}

		parts = append(parts, part)

	}

	// We have extracted all of the required segments, join the segments with a "-" and

	// return that as the name.


====================
				// We are not allowing prefixes.  This is an error scenario

				return "", cerrors.ErrorValidation{

					ErroredFields: []cerrors.ErroredField{

						{Name: s.field, Value: s.value, Reason: "field should be assigned"},

					},

				}

			}

			// We are allowing prefixes, so return the prefix that we have constructed thus far,

			// terminating with a "-".

			return strings.Join(parts, "-") + "-", nil

		}

		part, ef := escapeDashes(s)

		if ef != nil {

			return "", cerrors.ErrorValidation{ErroredFields: []cerrors.ErroredField{*ef}}

		}

		parts = append(parts, part)

	}

	// We have extracted all of the required segments, join the segments with a "-" and

	// return that as the name.

	return strings.Join(parts, "-"), nil


====================
			// terminating with a "-".

			return strings.Join(parts, "-") + "-", nil

		}

		part, ef := escapeDashes(s)

		if ef != nil {

			return "", cerrors.ErrorValidation{ErroredFields: []cerrors.ErroredField{*ef}}

		}

		parts = append(parts, part)

	}

	// We have extracted all of the required segments, join the segments with a "-" and

	// return that as the name.

	return strings.Join(parts, "-"), nil

}

// getSegments returns the ID segments specific to the orchestrator.

func (ids WorkloadEndpointIdentifiers) getSegments() ([]segment, error) {

	node := segment{value: ids.Node, field: "node", structField: "Node"}

	orch := segment{value: ids.Orchestrator, field: "orchestrator", structField: "Orchestrator"}

	cont := segment{value: ids.ContainerID, field: "containerID", structField: "ContainerID"}

	pod := segment{value: ids.Pod, field: "pod", structField: "Pod"}

	endp := segment{value: ids.Endpoint, field: "endpoint", structField: "Endpoint"}


====================
		}

		part, ef := escapeDashes(s)

		if ef != nil {

			return "", cerrors.ErrorValidation{ErroredFields: []cerrors.ErroredField{*ef}}

		}

		parts = append(parts, part)

	}

	// We have extracted all of the required segments, join the segments with a "-" and

	// return that as the name.

	return strings.Join(parts, "-"), nil

}

// getSegments returns the ID segments specific to the orchestrator.

func (ids WorkloadEndpointIdentifiers) getSegments() ([]segment, error) {

	node := segment{value: ids.Node, field: "node", structField: "Node"}

	orch := segment{value: ids.Orchestrator, field: "orchestrator", structField: "Orchestrator"}

	cont := segment{value: ids.ContainerID, field: "containerID", structField: "ContainerID"}

	pod := segment{value: ids.Pod, field: "pod", structField: "Pod"}

	endp := segment{value: ids.Endpoint, field: "endpoint", structField: "Endpoint"}

	workl := segment{value: ids.Workload, field: "workload", structField: "Workload"}

	// Node is *always* required.


====================
	// The JSON/YAML name of the corresponding field in the WorkloadEndpointSpec

	field string

	// The structure name of the corresponding field in the WorkloadEndpointSpec

	structField string

}

// escapeDashes replaces a single dash with a double dash.  This type of escaping is

// used for names constructed by joining a set of names with dashes - it assumes that

// each name segment cannot begin or end in a dash.

func escapeDashes(seg segment) (string, *cerrors.ErroredField) {

	if seg.value[0] == '-' {

		return "", &cerrors.ErroredField{Name: seg.field, Value: seg.value, Reason: "field must not begin with a '-'"}

	}

	if seg.value[len(seg.value)-1] == '-' {

		return "", &cerrors.ErroredField{Name: seg.field, Value: seg.value, Reason: "field must not end with a '-'"}

	}

	return strings.Replace(seg.value, "-", "--", -1), nil

}

func extractParts(name string) []string {

	parts := []string{}

	lastDash := -1


====================
	field string

	// The structure name of the corresponding field in the WorkloadEndpointSpec

	structField string

}

// escapeDashes replaces a single dash with a double dash.  This type of escaping is

// used for names constructed by joining a set of names with dashes - it assumes that

// each name segment cannot begin or end in a dash.

func escapeDashes(seg segment) (string, *cerrors.ErroredField) {

	if seg.value[0] == '-' {

		return "", &cerrors.ErroredField{Name: seg.field, Value: seg.value, Reason: "field must not begin with a '-'"}

	}

	if seg.value[len(seg.value)-1] == '-' {

		return "", &cerrors.ErroredField{Name: seg.field, Value: seg.value, Reason: "field must not end with a '-'"}

	}

	return strings.Replace(seg.value, "-", "--", -1), nil

}

func extractParts(name string) []string {

	parts := []string{}

	lastDash := -1

	for i := 1; i < len(name); i++ {


====================
	structField string

}

// escapeDashes replaces a single dash with a double dash.  This type of escaping is

// used for names constructed by joining a set of names with dashes - it assumes that

// each name segment cannot begin or end in a dash.

func escapeDashes(seg segment) (string, *cerrors.ErroredField) {

	if seg.value[0] == '-' {

		return "", &cerrors.ErroredField{Name: seg.field, Value: seg.value, Reason: "field must not begin with a '-'"}

	}

	if seg.value[len(seg.value)-1] == '-' {

		return "", &cerrors.ErroredField{Name: seg.field, Value: seg.value, Reason: "field must not end with a '-'"}

	}

	return strings.Replace(seg.value, "-", "--", -1), nil

}

func extractParts(name string) []string {

	parts := []string{}

	lastDash := -1

	for i := 1; i < len(name); i++ {

		// Skip non-dashes.

		if name[i] != '-' {


====================
}

// escapeDashes replaces a single dash with a double dash.  This type of escaping is

// used for names constructed by joining a set of names with dashes - it assumes that

// each name segment cannot begin or end in a dash.

func escapeDashes(seg segment) (string, *cerrors.ErroredField) {

	if seg.value[0] == '-' {

		return "", &cerrors.ErroredField{Name: seg.field, Value: seg.value, Reason: "field must not begin with a '-'"}

	}

	if seg.value[len(seg.value)-1] == '-' {

		return "", &cerrors.ErroredField{Name: seg.field, Value: seg.value, Reason: "field must not end with a '-'"}

	}

	return strings.Replace(seg.value, "-", "--", -1), nil

}

func extractParts(name string) []string {

	parts := []string{}

	lastDash := -1

	for i := 1; i < len(name); i++ {

		// Skip non-dashes.

		if name[i] != '-' {

			continue


====================
// used for names constructed by joining a set of names with dashes - it assumes that

// each name segment cannot begin or end in a dash.

func escapeDashes(seg segment) (string, *cerrors.ErroredField) {

	if seg.value[0] == '-' {

		return "", &cerrors.ErroredField{Name: seg.field, Value: seg.value, Reason: "field must not begin with a '-'"}

	}

	if seg.value[len(seg.value)-1] == '-' {

		return "", &cerrors.ErroredField{Name: seg.field, Value: seg.value, Reason: "field must not end with a '-'"}

	}

	return strings.Replace(seg.value, "-", "--", -1), nil

}

func extractParts(name string) []string {

	parts := []string{}

	lastDash := -1

	for i := 1; i < len(name); i++ {

		// Skip non-dashes.

		if name[i] != '-' {

			continue

		}

		// Skip over double dashes


====================
		return "", &cerrors.ErroredField{Name: seg.field, Value: seg.value, Reason: "field must not end with a '-'"}

	}

	return strings.Replace(seg.value, "-", "--", -1), nil

}

func extractParts(name string) []string {

	parts := []string{}

	lastDash := -1

	for i := 1; i < len(name); i++ {

		// Skip non-dashes.

		if name[i] != '-' {

			continue

		}

		// Skip over double dashes

		if i < len(name)-1 && name[i+1] == '-' {

			i++

			continue

		}

		// This is a dash separator.

		parts = append(parts, strings.Replace(name[lastDash+1:i], "--", "-", -1))

		lastDash = i


====================
func extractParts(name string) []string {

	parts := []string{}

	lastDash := -1

	for i := 1; i < len(name); i++ {

		// Skip non-dashes.

		if name[i] != '-' {

			continue

		}

		// Skip over double dashes

		if i < len(name)-1 && name[i+1] == '-' {

			i++

			continue

		}

		// This is a dash separator.

		parts = append(parts, strings.Replace(name[lastDash+1:i], "--", "-", -1))

		lastDash = i

	}

	// Add the last segment.

	parts = append(parts, strings.Replace(name[lastDash+1:], "--", "-", -1))

	return parts


====================
		if name[i] != '-' {

			continue

		}

		// Skip over double dashes

		if i < len(name)-1 && name[i+1] == '-' {

			i++

			continue

		}

		// This is a dash separator.

		parts = append(parts, strings.Replace(name[lastDash+1:i], "--", "-", -1))

		lastDash = i

	}

	// Add the last segment.

	parts = append(parts, strings.Replace(name[lastDash+1:], "--", "-", -1))

	return parts

}

// Extract the dash separated parms from the name.  Each parm will have had their dashes escaped,

// this also removes that escaping.  Returns nil if the parameters could not be extracted.

func ExtractDashSeparatedParms(name string, numParms int) []string {

	// The name must be at least as long as the number of parameters plus the separators.


====================
		if i < len(name)-1 && name[i+1] == '-' {

			i++

			continue

		}

		// This is a dash separator.

		parts = append(parts, strings.Replace(name[lastDash+1:i], "--", "-", -1))

		lastDash = i

	}

	// Add the last segment.

	parts = append(parts, strings.Replace(name[lastDash+1:], "--", "-", -1))

	return parts

}

// Extract the dash separated parms from the name.  Each parm will have had their dashes escaped,

// this also removes that escaping.  Returns nil if the parameters could not be extracted.

func ExtractDashSeparatedParms(name string, numParms int) []string {

	// The name must be at least as long as the number of parameters plus the separators.

	if len(name) < (2*numParms - 1) {

		return nil

	}

	parts := extractParts(name)


====================
	}, "", "orchestrator"),

	Entry("Missing k8s Pod", names.WorkloadEndpointIdentifiers{

		Node:         "node-1",

		Orchestrator: "k8s",

		Endpoint:     "eth0",

	}, "", "pod"),

	Entry("CNI container ID starts with a -", names.WorkloadEndpointIdentifiers{

		Node:         "node-1",

		Orchestrator: "cni",

		ContainerID:  "-abcdefa0123456",

		Endpoint:     "eth0",

	}, "", "containerID"),

	Entry("Unknown orchestrator workload ends with a -", names.WorkloadEndpointIdentifiers{

		Node:         "node-1",

		Orchestrator: "foo",

		Workload:     "foo-foo-",

		Endpoint:     "abcdefgh",

	}, "", "workload"),

)

var _ = DescribeTable("WorkloadEndpoint name construction, name prefix",


====================
	}, "node--1-foo-", ""),

	Entry("Missing k8s Pod", names.WorkloadEndpointIdentifiers{

		Node:         "node-1",

		Orchestrator: "k8s",

		Endpoint:     "eth0",

	}, "node--1-k8s-", ""),

	Entry("CNI container ID starts with a -", names.WorkloadEndpointIdentifiers{

		Node:         "node-1",

		Orchestrator: "cni",

		ContainerID:  "-abcdefa0123456",

		Endpoint:     "eth0",

	}, "", "containerID"),

	Entry("Unknown orchestrator, workload ends with a -", names.WorkloadEndpointIdentifiers{

		Node:         "node-1",

		Orchestrator: "foo",

		Workload:     "foo-foo-",

		Endpoint:     "abcdefgh",

	}, "", "workload"),

	Entry("Node is missing", names.WorkloadEndpointIdentifiers{

		Orchestrator: "k8s",


====================
type ResourceMetadata interface {

	// GetObjectMetadata returns the ObjectMetadata instance of the ResourceMetadata.

	GetObjectMetadata() ObjectMetadata

}

// ---- Metadata common to all resources ----

type ObjectMetadata struct {

	// Object revision used to perform atomic updates and deletes.  Currently

	// only supported on Get and Delete operations of the WorkloadEndpoint

	// resource type.

	Revision string `json:"-"`

}

func (md ObjectMetadata) GetObjectMetadata() ObjectMetadata {

	return md

}

// ---- Metadata common to all lists ----

type ListMetadata struct {

}

// Copyright (c) 2017-2018 Tigera, Inc. All rights reserved.

// Licensed under the Apache License, Version 2.0 (the "License");

// you may not use this file except in compliance with the License.


====================
	// Prepare a table to report detail.

	var buf bytes.Buffer

	table := tablewriter.NewWriter(&buf)

	table.SetHeader([]string{"COMPONENT", "TIMEOUT", "LIVENESS", "READINESS", "DETAIL"})

	componentData := map[string][]string{}

	componentNames := []string(nil)

	// Now for each reporter...

	for _, reporter := range aggregator.reporters {

		log.WithField("reporter", reporter).Debug("Checking state of reporter")

		livenessStr := "-"

		if reporter.HasLivenessProblem() {

			log.WithField("name", reporter.name).Warn("Reporter is not live.")

			summary.Live = false

			if reporter.TimedOut() {

				livenessStr = "timed out"

			} else {

				livenessStr = "reporting non-live"

			}

		} else if reporter.reports.Live {

			livenessStr = "reporting live"


====================
			summary.Live = false

			if reporter.TimedOut() {

				livenessStr = "timed out"

			} else {

				livenessStr = "reporting non-live"

			}

		} else if reporter.reports.Live {

			livenessStr = "reporting live"

		}

		readinessStr := "-"

		if reporter.HasReadinessProblem() {

			log.WithField("name", reporter.name).Warn("Reporter is not ready.")

			summary.Ready = false

			if reporter.TimedOut() {

				readinessStr = "timed out"

			} else {

				readinessStr = "reporting non-ready"

			}

		} else if reporter.reports.Ready {

			readinessStr = "reporting ready"


====================
)

// This file contains various name conversion methods that can be used to convert

// between Calico key types and resource names.

// IPToResourceName converts an IP address to a name used for a k8s resource.

func IPToResourceName(ip net.IP) string {

	name := ""

	if ip.To4() != nil {

		name = strings.Replace(ip.String(), ".", "-", 3)

	} else {

		// IPv6 address can end in a "::" which would be a string ending in "--",

		// which is not allowed in k8s name field, so we expand the IPv6 address and then replace ":" with "-".

		// fe08:123:445:: will look like fe08-0123-0445-0000-0000-0000-0000-0000

		ip6 := ip.To16()

		bytes := []string{}

		// Go through pairs of bytes in the address and convert them to a hex string.

		for i := 0; i < len(ip6); i += 2 {

			bytes = append(bytes, fmt.Sprintf("%.2x%.2x", ip6[i], ip6[i+1]))

		}

		// Combine them all into a name.

		name = strings.Join(bytes, "-")


====================
// This file contains various name conversion methods that can be used to convert

// between Calico key types and resource names.

// IPToResourceName converts an IP address to a name used for a k8s resource.

func IPToResourceName(ip net.IP) string {

	name := ""

	if ip.To4() != nil {

		name = strings.Replace(ip.String(), ".", "-", 3)

	} else {

		// IPv6 address can end in a "::" which would be a string ending in "--",

		// which is not allowed in k8s name field, so we expand the IPv6 address and then replace ":" with "-".

		// fe08:123:445:: will look like fe08-0123-0445-0000-0000-0000-0000-0000

		ip6 := ip.To16()

		bytes := []string{}

		// Go through pairs of bytes in the address and convert them to a hex string.

		for i := 0; i < len(ip6); i += 2 {

			bytes = append(bytes, fmt.Sprintf("%.2x%.2x", ip6[i], ip6[i+1]))

		}

		// Combine them all into a name.

		name = strings.Join(bytes, "-")

	}


====================
		// which is not allowed in k8s name field, so we expand the IPv6 address and then replace ":" with "-".

		// fe08:123:445:: will look like fe08-0123-0445-0000-0000-0000-0000-0000

		ip6 := ip.To16()

		bytes := []string{}

		// Go through pairs of bytes in the address and convert them to a hex string.

		for i := 0; i < len(ip6); i += 2 {

			bytes = append(bytes, fmt.Sprintf("%.2x%.2x", ip6[i], ip6[i+1]))

		}

		// Combine them all into a name.

		name = strings.Join(bytes, "-")

	}

	log.WithFields(log.Fields{

		"Name": name,

		"IP":   ip.String(),

	}).Debug("Converting IP to resource name")

	return name

}

// ResourceNameToIP converts a name used for a k8s resource to an IP address.

func ResourceNameToIP(name string) (*net.IP, error) {

	ip := net.ParseIP(resourceNameToIPString(name))


====================
	return ip, nil

}

// resourceNameToIPString converts a name used for a k8s resource to an IP address string.

// This function does not check the validity of the result - it merely reverses the

// character conversion used to convert an IP address to a k8s compatible name.

func resourceNameToIPString(name string) string {

	// The IP address is stored in the name with periods and colons replaced

	// by dashes.  To determine if this is IPv4 or IPv6 count the dashes. If

	// either of the following are true, it's IPv6:

	// -  There is a "--"

	// -  The number of "-" is greater than 3.

	var ipstr string

	if strings.Contains(name, "--") || strings.Count(name, "-") > 3 {

		// IPv6:  replace - with :

		ipstr = strings.Replace(name, "-", ":", 7)

	} else {

		// IPv4:  replace - with .

		ipstr = strings.Replace(name, "-", ".", 3)

	}

	log.WithFields(log.Fields{


====================
}

// resourceNameToIPString converts a name used for a k8s resource to an IP address string.

// This function does not check the validity of the result - it merely reverses the

// character conversion used to convert an IP address to a k8s compatible name.

func resourceNameToIPString(name string) string {

	// The IP address is stored in the name with periods and colons replaced

	// by dashes.  To determine if this is IPv4 or IPv6 count the dashes. If

	// either of the following are true, it's IPv6:

	// -  There is a "--"

	// -  The number of "-" is greater than 3.

	var ipstr string

	if strings.Contains(name, "--") || strings.Count(name, "-") > 3 {

		// IPv6:  replace - with :

		ipstr = strings.Replace(name, "-", ":", 7)

	} else {

		// IPv4:  replace - with .

		ipstr = strings.Replace(name, "-", ".", 3)

	}

	log.WithFields(log.Fields{

		"Name": name,


====================
// This function does not check the validity of the result - it merely reverses the

// character conversion used to convert an IP address to a k8s compatible name.

func resourceNameToIPString(name string) string {

	// The IP address is stored in the name with periods and colons replaced

	// by dashes.  To determine if this is IPv4 or IPv6 count the dashes. If

	// either of the following are true, it's IPv6:

	// -  There is a "--"

	// -  The number of "-" is greater than 3.

	var ipstr string

	if strings.Contains(name, "--") || strings.Count(name, "-") > 3 {

		// IPv6:  replace - with :

		ipstr = strings.Replace(name, "-", ":", 7)

	} else {

		// IPv4:  replace - with .

		ipstr = strings.Replace(name, "-", ".", 3)

	}

	log.WithFields(log.Fields{

		"Name": name,

		"IP":   ipstr,

	}).Debug("Converting resource name to IP String")


====================
func resourceNameToIPString(name string) string {

	// The IP address is stored in the name with periods and colons replaced

	// by dashes.  To determine if this is IPv4 or IPv6 count the dashes. If

	// either of the following are true, it's IPv6:

	// -  There is a "--"

	// -  The number of "-" is greater than 3.

	var ipstr string

	if strings.Contains(name, "--") || strings.Count(name, "-") > 3 {

		// IPv6:  replace - with :

		ipstr = strings.Replace(name, "-", ":", 7)

	} else {

		// IPv4:  replace - with .

		ipstr = strings.Replace(name, "-", ".", 3)

	}

	log.WithFields(log.Fields{

		"Name": name,

		"IP":   ipstr,

	}).Debug("Converting resource name to IP String")

	return ipstr

}


====================
	// either of the following are true, it's IPv6:

	// -  There is a "--"

	// -  The number of "-" is greater than 3.

	var ipstr string

	if strings.Contains(name, "--") || strings.Count(name, "-") > 3 {

		// IPv6:  replace - with :

		ipstr = strings.Replace(name, "-", ":", 7)

	} else {

		// IPv4:  replace - with .

		ipstr = strings.Replace(name, "-", ".", 3)

	}

	log.WithFields(log.Fields{

		"Name": name,

		"IP":   ipstr,

	}).Debug("Converting resource name to IP String")

	return ipstr

}

// Copyright (c) 2017 Tigera, Inc. All rights reserved.

// Licensed under the Apache License, Version 2.0 (the "License");

// you may not use this file except in compliance with the License.


====================
	Entry("Convert name abc$!$def", "abc$!$def", "abc-def", true),

	Entry("Convert name abc..def", "abc..def", "abc.def", true),

	Entry("Convert name abc...def", "abc...def", "abc.def", true),

	Entry("Convert name abc.-def", "abc.-def", "abc.def", true),

	Entry("Convert name abc.-.def", "abc.-.def", "abc.def", true),

	Entry("Convert name abc-.def", "abc-.def", "abc.def", true),

	Entry("Convert name abc-.-def", "abc-.-def", "abc.def", true),

	Entry("Convert name aBcDe019", "aBcDe019", "abcde019", true),

	Entry("Convert name abc$def", "abc$def", "abc-def", true),

	Entry("Convert name -abc.def", "-abc.def", "abc.def", true),

	Entry("Convert name abc.def-", "abc.def-", "abc.def", true),

	Entry("Convert name .abc.def", ".abc.def", "abc.def", true),

	Entry("Convert name abc.def.", "abc.def.", "abc.def", true),

	Entry("Convert name -.abc.def", "-.abc.def", "abc.def", true),

	Entry("Convert name abc.def.-", "abc.def.-", "abc.def", true),

	Entry("Convert name $ABC/DeF-123.-456!", "$ABC/DeF-123.-456!", "abc.def-123.456", true),

}

var _ = DescribeTable("v1->v3 name conversion tests",

	func(v1Name string, v3Name string, expectQualifier bool) {

		// Get the converted name.


====================
	Entry("Convert name abc.-.def", "abc.-.def", "abc.def", true),

	Entry("Convert name abc-.def", "abc-.def", "abc.def", true),

	Entry("Convert name abc-.-def", "abc-.-def", "abc.def", true),

	Entry("Convert name aBcDe019", "aBcDe019", "abcde019", true),

	Entry("Convert name abc$def", "abc$def", "abc-def", true),

	Entry("Convert name -abc.def", "-abc.def", "abc.def", true),

	Entry("Convert name abc.def-", "abc.def-", "abc.def", true),

	Entry("Convert name .abc.def", ".abc.def", "abc.def", true),

	Entry("Convert name abc.def.", "abc.def.", "abc.def", true),

	Entry("Convert name -.abc.def", "-.abc.def", "abc.def", true),

	Entry("Convert name abc.def.-", "abc.def.-", "abc.def", true),

	Entry("Convert name $ABC/DeF-123.-456!", "$ABC/DeF-123.-456!", "abc.def-123.456", true),

}

var _ = DescribeTable("v1->v3 name conversion tests",

	func(v1Name string, v3Name string, expectQualifier bool) {

		// Get the converted name.

		c1 := convertName(v1Name)

		if !expectQualifier {

			// No qualifier is expected, the names should match exactly.

			Expect(c1).To(Equal(v3Name))


====================
	Entry("Convert name abc/def", "abc/def", "abc-def", true),

	Entry("Convert name abc..def", "abc..def", "abc-def", true),

	Entry("Convert name abc...def", "abc...def", "abc-def", true),

	Entry("Convert name abc.-def", "abc.-def", "abc-def", true),

	Entry("Convert name abc.-.def", "abc.-.def", "abc-def", true),

	Entry("Convert name abc-.def", "abc-.def", "abc-def", true),

	Entry("Convert name abc-.-def", "abc-.-def", "abc-def", true),

	Entry("Convert name aBcDe019", "aBcDe019", "abcde019", true),

	Entry("Convert name abc$def", "abc$def", "abc-def", true),

	Entry("Convert name -abc.def", "-abc.def", "abc-def", true),

	Entry("Convert name abc.def-", "abc.def-", "abc-def", true),

	Entry("Convert name .abc.def", ".abc.def", "abc-def", true),

	Entry("Convert name abc.def.", "abc.def.", "abc-def", true),

	Entry("Convert name -.abc.def", "-.abc.def", "abc-def", true),

	Entry("Convert name abc.def.-", "abc.def.-", "abc-def", true),

	Entry("Convert name $ABC/DeF-123.-456!", "$ABC/DeF-123.-456!", "abc-def-123-456", true),

}

var _ = DescribeTable("v1->v3 name conversion tests (no dots)",

	func(v1Name, v3Name string, expectQualifier bool) {

		// Get the converted name.


====================
	Entry("Convert name abc.-.def", "abc.-.def", "abc-def", true),

	Entry("Convert name abc-.def", "abc-.def", "abc-def", true),

	Entry("Convert name abc-.-def", "abc-.-def", "abc-def", true),

	Entry("Convert name aBcDe019", "aBcDe019", "abcde019", true),

	Entry("Convert name abc$def", "abc$def", "abc-def", true),

	Entry("Convert name -abc.def", "-abc.def", "abc-def", true),

	Entry("Convert name abc.def-", "abc.def-", "abc-def", true),

	Entry("Convert name .abc.def", ".abc.def", "abc-def", true),

	Entry("Convert name abc.def.", "abc.def.", "abc-def", true),

	Entry("Convert name -.abc.def", "-.abc.def", "abc-def", true),

	Entry("Convert name abc.def.-", "abc.def.-", "abc-def", true),

	Entry("Convert name $ABC/DeF-123.-456!", "$ABC/DeF-123.-456!", "abc-def-123-456", true),

}

var _ = DescribeTable("v1->v3 name conversion tests (no dots)",

	func(v1Name, v3Name string, expectQualifier bool) {

		// Get the converted name.

		c1 := convertNameNoDots(v1Name)

		if !expectQualifier {

			// No qualifier is expected, the names should match exactly.

			Expect(c1).To(Equal(v3Name))


====================
	Entry("Convert abc$!$def", "abc$!$def", "abc-def"),

	Entry("Convert abc..def", "abc..def", "abc.def"),

	Entry("Convert abc...def", "abc...def", "abc.def"),

	Entry("Convert abc.-def", "abc.-def", "abc.def"),

	Entry("Convert abc.-.def", "abc.-.def", "abc.def"),

	Entry("Convert abc-.def", "abc-.def", "abc.def"),

	Entry("Convert abc-.-def", "abc-.-def", "abc.def"),

	Entry("Convert aBcDe019", "aBcDe019", "abcde019"),

	Entry("Convert abc$def", "abc$def", "abc-def"),

	Entry("Convert -abc.def", "-abc.def", "abc.def"),

	Entry("Convert abc.def-", "abc.def-", "abc.def"),

	Entry("Convert .abc.def", ".abc.def", "abc.def"),

	Entry("Convert abc.def.", "abc.def.", "abc.def"),

	Entry("Convert -.abc.def", "-.abc.def", "abc.def"),

	Entry("Convert abc.def.-", "abc.def.-", "abc.def"),

	Entry("Convert $ABC/DEF-123.-456!", "$ABC/DEF-123.-456!", "abc.def-123.456"),

}

var _ = DescribeTable("v1->v3 node name conversion tests",

	func(before, after string) {

		Expect(ConvertNodeName(before)).To(Equal(after), before)


====================
	Entry("Convert abc.-.def", "abc.-.def", "abc.def"),

	Entry("Convert abc-.def", "abc-.def", "abc.def"),

	Entry("Convert abc-.-def", "abc-.-def", "abc.def"),

	Entry("Convert aBcDe019", "aBcDe019", "abcde019"),

	Entry("Convert abc$def", "abc$def", "abc-def"),

	Entry("Convert -abc.def", "-abc.def", "abc.def"),

	Entry("Convert abc.def-", "abc.def-", "abc.def"),

	Entry("Convert .abc.def", ".abc.def", "abc.def"),

	Entry("Convert abc.def.", "abc.def.", "abc.def"),

	Entry("Convert -.abc.def", "-.abc.def", "abc.def"),

	Entry("Convert abc.def.-", "abc.def.-", "abc.def"),

	Entry("Convert $ABC/DEF-123.-456!", "$ABC/DEF-123.-456!", "abc.def-123.456"),

}

var _ = DescribeTable("v1->v3 node name conversion tests",

	func(before, after string) {

		Expect(ConvertNodeName(before)).To(Equal(after), before)

	},

	nodeNamesTable...,

)

// Copyright (c) 2017-2018 Tigera, Inc. All rights reserved.


====================
// suitable node name, and is also used for the v2->v3 migration code.

// -  Convert to lowercase

// -  Convert [/] to .

// -  Convert any other char that is not in the set [-.a-z0-9] to -

// -  Convert any multi-byte sequence of [-.] with at least one [.] to a single .

// -  Remove leading and trailing dashes and dots

func normalizeName(name string) string {

	name = strings.ToLower(name)

	name = strings.Replace(name, "/", ".", -1)

	name = nonNameChar.ReplaceAllString(name, "-")

	name = dotDashSeq.ReplaceAllString(name, ".")

	// Extract the trailing and leading dots and dashes.   This should always match even if

	// the matched substring is empty.  The second item in the returned submatch

	// slice is the captured match group.

	submatches := trailingLeadingDotsDashes.FindStringSubmatch(name)

	name = submatches[1]

	return name

}

// Convert the v1 name to a standard v3 name.  This uses the standard name normalization,

// and adds an additional qualifier if the name was modified.  The qualifier is calculated


====================
func convertName(v1Name string) string {

	name := normalizeName(v1Name)

	// If the name is different append a qualifier.

	return qualifiedName(v1Name, name)

}

// Convert the v1 name to a standard v3 name with no dots.

func convertNameNoDots(v1Name string) string {

	// Normalize the name and then convert dots to dashes.

	name := normalizeName(v1Name)

	name = strings.Replace(name, ".", "-", -1)

	// If the name is different append a qualifier.

	return qualifiedName(v1Name, name)

}

func qualifiedName(orig, final string) string {

	// If the name was not modified, just return the unmodified name.

	if orig == final {

		return orig

	}

	// The name was modified.  Calculate an 8-byte hex qualifier to append.

	h := sha1.New()


====================
	return fmt.Sprintf("%s-%s", final, strings.ToLower(hex.EncodeToString(h.Sum(nil))[:8]))

}

// Convert an IP to an IPv4 or IPv6 representation

//   - IPv4 addresses will be of the format 1-2-3-4

//   - IPv6 addresses will be of the format 00aa-00bb-0000-0000-0000-0000-0000-0000

//     with all zeros expanded

func convertIpToName(ip net.IP) string {

	name := ""

	if ip.To4() != nil {

		name = strings.Replace(ip.String(), ".", "-", 3)

	} else {

		ip6 := ip.To16()

		bytes := []string{}

		for i := 0; i < len(ip6); i += 2 {

			bytes = append(bytes, fmt.Sprintf("%.2x%.2x", ip6[i], ip6[i+1]))

		}

		name = strings.Join(bytes, "-")

	}

	return name

}


====================
	name := ""

	if ip.To4() != nil {

		name = strings.Replace(ip.String(), ".", "-", 3)

	} else {

		ip6 := ip.To16()

		bytes := []string{}

		for i := 0; i < len(ip6); i += 2 {

			bytes = append(bytes, fmt.Sprintf("%.2x%.2x", ip6[i], ip6[i+1]))

		}

		name = strings.Join(bytes, "-")

	}

	return name

}

// Copyright (c) 2021 Tigera, Inc. All rights reserved.

// Licensed under the Apache License, Version 2.0 (the "License");

// you may not use this file except in compliance with the License.

// You may obtain a copy of the License at

//

//     http://www.apache.org/licenses/LICENSE-2.0

//


====================
		Entry("should accept 4294967295 AS number as string", "\"4294967295\"", asNumberType, numorstring.ASNumber(4294967295)),

		Entry("should accept 1.10 AS number as string", "\"1.10\"", asNumberType, numorstring.ASNumber(65546)),

		Entry("should accept 00.00 AS number as string", "\"00.00\"", asNumberType, numorstring.ASNumber(0)),

		Entry("should accept 00.01 AS number as string", "\"00.01\"", asNumberType, numorstring.ASNumber(1)),

		Entry("should accept 65535.65535 AS number as string", "\"65535.65535\"", asNumberType, numorstring.ASNumber(4294967295)),

		Entry("should reject 1.1.1 AS number as string", "\"1.1.1\"", asNumberType, nil),

		Entry("should reject 65536.65535 AS number as string", "\"65536.65535\"", asNumberType, nil),

		Entry("should reject 65535.65536 AS number as string", "\"65535.65536\"", asNumberType, nil),

		Entry("should reject 0.-1 AS number as string", "\"0.-1\"", asNumberType, nil),

		Entry("should reject -1 AS number as int", "-1", asNumberType, nil),

		Entry("should reject 4294967296 AS number as int", "4294967296", asNumberType, nil),

		// Port tests.

		Entry("should accept 0 port as int", "0", portType, numorstring.SinglePort(0)),

		Entry("should accept 65535 port as int", "65535", portType, numorstring.SinglePort(65535)),

		Entry("should accept 0:65535 port range as string", "\"0:65535\"", portType, portFromRange(0, 65535)),

		Entry("should accept 1:10 port range as string", "\"1:10\"", portType, portFromRange(1, 10)),

		Entry("should accept foo-bar as named port", "\"foo-bar\"", portType, numorstring.NamedPort("foo-bar")),

		Entry("should reject -1 port as int", "-1", portType, nil),

		Entry("should reject 65536 port as int", "65536", portType, nil),

		Entry("should reject 0:65536 port range as string", "\"0:65536\"", portType, nil),


====================
		Entry("should reject 0.-1 AS number as string", "\"0.-1\"", asNumberType, nil),

		Entry("should reject -1 AS number as int", "-1", asNumberType, nil),

		Entry("should reject 4294967296 AS number as int", "4294967296", asNumberType, nil),

		// Port tests.

		Entry("should accept 0 port as int", "0", portType, numorstring.SinglePort(0)),

		Entry("should accept 65535 port as int", "65535", portType, numorstring.SinglePort(65535)),

		Entry("should accept 0:65535 port range as string", "\"0:65535\"", portType, portFromRange(0, 65535)),

		Entry("should accept 1:10 port range as string", "\"1:10\"", portType, portFromRange(1, 10)),

		Entry("should accept foo-bar as named port", "\"foo-bar\"", portType, numorstring.NamedPort("foo-bar")),

		Entry("should reject -1 port as int", "-1", portType, nil),

		Entry("should reject 65536 port as int", "65536", portType, nil),

		Entry("should reject 0:65536 port range as string", "\"0:65536\"", portType, nil),

		Entry("should reject -1:65535 port range as string", "\"-1:65535\"", portType, nil),

		Entry("should reject 10:1 port range as string", "\"10:1\"", portType, nil),

		Entry("should reject 1:2:3 port range as string", "\"1:2:3\"", portType, nil),

		Entry("should reject bad named port string", "\"*\"", portType, nil),

		Entry("should reject bad port string", "\"1:2", portType, nil),

		// Protocol tests.  Invalid integer values will be stored as strings.

		Entry("should accept 0 protocol as int", "0", protocolType, numorstring.ProtocolFromInt(0)),

		Entry("should accept 255 protocol as int", "255", protocolType, numorstring.ProtocolFromInt(255)),


====================
					"immutable": {

						SchemaProps: spec.SchemaProps{

							Description: "Immutable, if set to true, ensures that data stored in the ConfigMap cannot be updated (only object metadata can be modified). If not set to true, the field can be modified at any time. Defaulted to nil.",

							Type:        []string{"boolean"},

							Format:      "",

						},

					},

					"data": {

						SchemaProps: spec.SchemaProps{

							Description: "Data contains the configuration data. Each key must consist of alphanumeric characters, '-', '_' or '.'. Values with non-UTF-8 byte sequences must use the BinaryData field. The keys stored in Data must not overlap with the keys in the BinaryData field, this is enforced during validation process.",

							Type:        []string{"object"},

							AdditionalProperties: &spec.SchemaOrBool{

								Allows: true,

								Schema: &spec.Schema{

									SchemaProps: spec.SchemaProps{

										Default: "",

										Type:    []string{"string"},

										Format:  "",

									},

								},


====================
										Type:    []string{"string"},

										Format:  "",

									},

								},

							},

						},

					},

					"binaryData": {

						SchemaProps: spec.SchemaProps{

							Description: "BinaryData contains the binary data. Each key must consist of alphanumeric characters, '-', '_' or '.'. BinaryData can contain byte sequences that are not in the UTF-8 range. The keys stored in BinaryData must not overlap with the ones in the Data field, this is enforced during validation process. Using this field will require 1.10+ apiserver and kubelet.",

							Type:        []string{"object"},

							AdditionalProperties: &spec.SchemaOrBool{

								Allows: true,

								Schema: &spec.Schema{

									SchemaProps: spec.SchemaProps{

										Type:   []string{"string"},

										Format: "byte",

									},

								},

							},


====================
					"immutable": {

						SchemaProps: spec.SchemaProps{

							Description: "Immutable, if set to true, ensures that data stored in the Secret cannot be updated (only object metadata can be modified). If not set to true, the field can be modified at any time. Defaulted to nil.",

							Type:        []string{"boolean"},

							Format:      "",

						},

					},

					"data": {

						SchemaProps: spec.SchemaProps{

							Description: "Data contains the secret data. Each key must consist of alphanumeric characters, '-', '_' or '.'. The serialized form of the secret data is a base64 encoded string, representing the arbitrary (possibly non-string) data value here. Described in https://tools.ietf.org/html/rfc4648#section-4",

							Type:        []string{"object"},

							AdditionalProperties: &spec.SchemaOrBool{

								Allows: true,

								Schema: &spec.Schema{

									SchemaProps: spec.SchemaProps{

										Type:   []string{"string"},

										Format: "byte",

									},

								},

							},


====================
		}, 10*time.Second).ShouldNot(BeNil())

		Expect(info.Spec.ClusterGUID).To(MatchRegexp("^[a-f0-9]{32}$"))

		Expect(info.Spec.ClusterType).To(Equal("k8s"))

		Expect(*info.Spec.DatastoreReady).To(BeTrue())

	})

	Context("Healthcheck FV tests", func() {

		It("should pass health check", func() {

			By("Waiting for an initial readiness report")

			Eventually(func() []byte {

				cmd := exec.Command("docker", "exec", policyController.Name, "/usr/bin/check-status", "-r")

				stdoutStderr, _ := cmd.CombinedOutput()

				return stdoutStderr

			}, 20*time.Second, 500*time.Millisecond).ShouldNot(ContainSubstring("initialized to false"))

			By("Waiting for the controller to be ready")

			Eventually(func() string {

				cmd := exec.Command("docker", "exec", policyController.Name, "/usr/bin/check-status", "-r")

				stdoutStderr, _ := cmd.CombinedOutput()

				return strings.TrimSpace(string(stdoutStderr))

			}, 20*time.Second, 500*time.Millisecond).Should(Equal("Ready"))

		})


====================
		It("should pass health check", func() {

			By("Waiting for an initial readiness report")

			Eventually(func() []byte {

				cmd := exec.Command("docker", "exec", policyController.Name, "/usr/bin/check-status", "-r")

				stdoutStderr, _ := cmd.CombinedOutput()

				return stdoutStderr

			}, 20*time.Second, 500*time.Millisecond).ShouldNot(ContainSubstring("initialized to false"))

			By("Waiting for the controller to be ready")

			Eventually(func() string {

				cmd := exec.Command("docker", "exec", policyController.Name, "/usr/bin/check-status", "-r")

				stdoutStderr, _ := cmd.CombinedOutput()

				return strings.TrimSpace(string(stdoutStderr))

			}, 20*time.Second, 500*time.Millisecond).Should(Equal("Ready"))

		})

		It("should fail health check if apiserver is not running", func() {

			By("Waiting for an initial readiness report")

			Eventually(func() []byte {

				cmd := exec.Command("docker", "exec", policyController.Name, "/usr/bin/check-status", "-r")

				stdoutStderr, _ := cmd.CombinedOutput()

				return stdoutStderr


====================
			Eventually(func() string {

				cmd := exec.Command("docker", "exec", policyController.Name, "/usr/bin/check-status", "-r")

				stdoutStderr, _ := cmd.CombinedOutput()

				return strings.TrimSpace(string(stdoutStderr))

			}, 20*time.Second, 500*time.Millisecond).Should(Equal("Ready"))

		})

		It("should fail health check if apiserver is not running", func() {

			By("Waiting for an initial readiness report")

			Eventually(func() []byte {

				cmd := exec.Command("docker", "exec", policyController.Name, "/usr/bin/check-status", "-r")

				stdoutStderr, _ := cmd.CombinedOutput()

				return stdoutStderr

			}, 20*time.Second, 500*time.Millisecond).ShouldNot(ContainSubstring("initialized to false"))

			By("Stopping the apiserver")

			apiserver.Stop()

			By("Waiting for the readiness to change")

			Eventually(func() []byte {

				cmd := exec.Command("docker", "exec", policyController.Name, "/usr/bin/check-status", "-r")

				stdoutStderr, _ := cmd.CombinedOutput()

				return stdoutStderr


====================
			Eventually(func() []byte {

				cmd := exec.Command("docker", "exec", policyController.Name, "/usr/bin/check-status", "-r")

				stdoutStderr, _ := cmd.CombinedOutput()

				return stdoutStderr

			}, 20*time.Second, 500*time.Millisecond).ShouldNot(ContainSubstring("initialized to false"))

			By("Stopping the apiserver")

			apiserver.Stop()

			By("Waiting for the readiness to change")

			Eventually(func() []byte {

				cmd := exec.Command("docker", "exec", policyController.Name, "/usr/bin/check-status", "-r")

				stdoutStderr, _ := cmd.CombinedOutput()

				return stdoutStderr

			}, 20*time.Second, 500*time.Millisecond).Should(ContainSubstring("Error reaching apiserver"))

		})

		It("should fail health check if etcd not running", func() {

			By("Waiting for an initial readiness report")

			Eventually(func() []byte {

				cmd := exec.Command("docker", "exec", policyController.Name, "/usr/bin/check-status", "-r")

				stdoutStderr, _ := cmd.CombinedOutput()

				return stdoutStderr


====================
			Eventually(func() []byte {

				cmd := exec.Command("docker", "exec", policyController.Name, "/usr/bin/check-status", "-r")

				stdoutStderr, _ := cmd.CombinedOutput()

				return stdoutStderr

			}, 20*time.Second, 500*time.Millisecond).Should(ContainSubstring("Error reaching apiserver"))

		})

		It("should fail health check if etcd not running", func() {

			By("Waiting for an initial readiness report")

			Eventually(func() []byte {

				cmd := exec.Command("docker", "exec", policyController.Name, "/usr/bin/check-status", "-r")

				stdoutStderr, _ := cmd.CombinedOutput()

				return stdoutStderr

			}, 20*time.Second, 500*time.Millisecond).ShouldNot(ContainSubstring("initialized to false"))

			By("Stopping etcd")

			etcd.Stop()

			By("Waiting for the readiness to change")

			Eventually(func() []byte {

				cmd := exec.Command("docker", "exec", policyController.Name, "/usr/bin/check-status", "-r")

				stdoutStderr, _ := cmd.CombinedOutput()

				return stdoutStderr


====================
			Eventually(func() []byte {

				cmd := exec.Command("docker", "exec", policyController.Name, "/usr/bin/check-status", "-r")

				stdoutStderr, _ := cmd.CombinedOutput()

				return stdoutStderr

			}, 20*time.Second, 500*time.Millisecond).ShouldNot(ContainSubstring("initialized to false"))

			By("Stopping etcd")

			etcd.Stop()

			By("Waiting for the readiness to change")

			Eventually(func() []byte {

				cmd := exec.Command("docker", "exec", policyController.Name, "/usr/bin/check-status", "-r")

				stdoutStderr, _ := cmd.CombinedOutput()

				return stdoutStderr

			}, 20*time.Second, 500*time.Millisecond).Should(ContainSubstring("Error verifying datastore"))

		})

	})

})

var _ = Describe("[kdd] kube-controllers health check FV tests", func() {

	var (

		etcd              *containers.Container

		policyController  *containers.Container


====================
			return err

		}, 30*time.Second, 1*time.Second).Should(BeNil())

		Consistently(func() error {

			_, err := k8sClient.CoreV1().Namespaces().List(context.Background(), metav1.ListOptions{})

			return err

		}, 10*time.Second, 1*time.Second).Should(BeNil())

		// Apply the necessary CRDs. There can sometimes be a delay between starting

		// the API server and when CRDs are apply-able, so retry here.

		apply := func() error {

			out, err := apiserver.ExecOutput("kubectl", "apply", "-f", "/crds/")

			if err != nil {

				return fmt.Errorf("%s: %s", err, out)

			}

			return nil

		}

		By("Applying CRDs")

		Eventually(apply, 10*time.Second).ShouldNot(HaveOccurred())

		calicoClient = testutils.GetCalicoClient(apiconfig.Kubernetes, "", kconfigfile.Name())

		// In KDD mode, we only support the node controller right now.

		policyController = testutils.RunPolicyController(apiconfig.Kubernetes, "", kconfigfile.Name(), "node")


====================
		}, 10*time.Second).ShouldNot(BeNil())

		Expect(info.Spec.ClusterGUID).To(MatchRegexp("^[a-f0-9]{32}$"))

		Expect(info.Spec.ClusterType).To(Equal("k8s,kdd"))

		Expect(*info.Spec.DatastoreReady).To(BeTrue())

	})

	Context("Healthcheck FV tests", func() {

		It("should pass health check", func() {

			By("Waiting for an initial readiness report")

			Eventually(func() []byte {

				cmd := exec.Command("docker", "exec", policyController.Name, "/usr/bin/check-status", "-r")

				stdoutStderr, _ := cmd.CombinedOutput()

				return stdoutStderr

			}, 20*time.Second, 500*time.Millisecond).ShouldNot(ContainSubstring("initialized to false"))

			By("Waiting for the controller to be ready")

			Eventually(func() string {

				cmd := exec.Command("docker", "exec", policyController.Name, "/usr/bin/check-status", "-r")

				stdoutStderr, _ := cmd.CombinedOutput()

				return strings.TrimSpace(string(stdoutStderr))

			}, 20*time.Second, 500*time.Millisecond).Should(Equal("Ready"))

		})


====================
		It("should pass health check", func() {

			By("Waiting for an initial readiness report")

			Eventually(func() []byte {

				cmd := exec.Command("docker", "exec", policyController.Name, "/usr/bin/check-status", "-r")

				stdoutStderr, _ := cmd.CombinedOutput()

				return stdoutStderr

			}, 20*time.Second, 500*time.Millisecond).ShouldNot(ContainSubstring("initialized to false"))

			By("Waiting for the controller to be ready")

			Eventually(func() string {

				cmd := exec.Command("docker", "exec", policyController.Name, "/usr/bin/check-status", "-r")

				stdoutStderr, _ := cmd.CombinedOutput()

				return strings.TrimSpace(string(stdoutStderr))

			}, 20*time.Second, 500*time.Millisecond).Should(Equal("Ready"))

		})

		It("should fail health check if apiserver is not running", func() {

			By("Waiting for an initial readiness report")

			Eventually(func() []byte {

				cmd := exec.Command("docker", "exec", policyController.Name, "/usr/bin/check-status", "-r")

				stdoutStderr, _ := cmd.CombinedOutput()

				return stdoutStderr


====================
			Eventually(func() string {

				cmd := exec.Command("docker", "exec", policyController.Name, "/usr/bin/check-status", "-r")

				stdoutStderr, _ := cmd.CombinedOutput()

				return strings.TrimSpace(string(stdoutStderr))

			}, 20*time.Second, 500*time.Millisecond).Should(Equal("Ready"))

		})

		It("should fail health check if apiserver is not running", func() {

			By("Waiting for an initial readiness report")

			Eventually(func() []byte {

				cmd := exec.Command("docker", "exec", policyController.Name, "/usr/bin/check-status", "-r")

				stdoutStderr, _ := cmd.CombinedOutput()

				return stdoutStderr

			}, 20*time.Second, 500*time.Millisecond).ShouldNot(ContainSubstring("initialized to false"))

			By("Stopping the apiserver")

			apiserver.Stop()

			By("Waiting for the readiness to change")

			Eventually(func() []byte {

				cmd := exec.Command("docker", "exec", policyController.Name, "/usr/bin/check-status", "-r")

				stdoutStderr, _ := cmd.CombinedOutput()

				return stdoutStderr


====================
			Eventually(func() []byte {

				cmd := exec.Command("docker", "exec", policyController.Name, "/usr/bin/check-status", "-r")

				stdoutStderr, _ := cmd.CombinedOutput()

				return stdoutStderr

			}, 20*time.Second, 500*time.Millisecond).ShouldNot(ContainSubstring("initialized to false"))

			By("Stopping the apiserver")

			apiserver.Stop()

			By("Waiting for the readiness to change")

			Eventually(func() []byte {

				cmd := exec.Command("docker", "exec", policyController.Name, "/usr/bin/check-status", "-r")

				stdoutStderr, _ := cmd.CombinedOutput()

				return stdoutStderr

			}, 60*time.Second, 500*time.Millisecond).Should(ContainSubstring("Error"))

		})

	})

})

// Copyright (c) 2017-2020 Tigera, Inc. All rights reserved.

//

// Licensed under the Apache License, Version 2.0 (the "License");

// you may not use this file except in compliance with the License.


====================
	adminKeyBytes, err := os.ReadFile(os.Getenv("CERTS_PATH") + "/admin-key.pem")

	Expect(err).NotTo(HaveOccurred())

	encodedAdminKey := base64.StdEncoding.EncodeToString(adminKeyBytes)

	// Put it all together.

	return fmt.Sprintf(kubeconfigTemplate, apiserverIP, encodedAdminCert, encodedAdminKey)

}

func RunK8sApiserver(etcdIp string) *containers.Container {

	return containers.Run("st-apiserver",

		containers.RunOpts{AutoRemove: true},

		"-v", os.Getenv("CERTS_PATH")+":/home/user/certs", // Mount in location of certificates.

		"-v", os.Getenv("CRDS")+":/crds",

		"-e", "KUBECONFIG=/home/user/certs/kubeconfig", // We run kubectl from within this container.

		os.Getenv("KUBE_IMAGE"),

		"kube-apiserver",

		"--v=0",

		"--service-cluster-ip-range=10.101.0.0/16",

		"--authorization-mode=RBAC",

		fmt.Sprintf("--etcd-servers=http://%s:2379", etcdIp),

		"--service-account-key-file=/home/user/certs/service-account.pem",

		"--service-account-signing-key-file=/home/user/certs/service-account-key.pem",


====================
	Expect(err).NotTo(HaveOccurred())

	encodedAdminKey := base64.StdEncoding.EncodeToString(adminKeyBytes)

	// Put it all together.

	return fmt.Sprintf(kubeconfigTemplate, apiserverIP, encodedAdminCert, encodedAdminKey)

}

func RunK8sApiserver(etcdIp string) *containers.Container {

	return containers.Run("st-apiserver",

		containers.RunOpts{AutoRemove: true},

		"-v", os.Getenv("CERTS_PATH")+":/home/user/certs", // Mount in location of certificates.

		"-v", os.Getenv("CRDS")+":/crds",

		"-e", "KUBECONFIG=/home/user/certs/kubeconfig", // We run kubectl from within this container.

		os.Getenv("KUBE_IMAGE"),

		"kube-apiserver",

		"--v=0",

		"--service-cluster-ip-range=10.101.0.0/16",

		"--authorization-mode=RBAC",

		fmt.Sprintf("--etcd-servers=http://%s:2379", etcdIp),

		"--service-account-key-file=/home/user/certs/service-account.pem",

		"--service-account-signing-key-file=/home/user/certs/service-account-key.pem",

		"--service-account-issuer=https://localhost:443",


====================
	encodedAdminKey := base64.StdEncoding.EncodeToString(adminKeyBytes)

	// Put it all together.

	return fmt.Sprintf(kubeconfigTemplate, apiserverIP, encodedAdminCert, encodedAdminKey)

}

func RunK8sApiserver(etcdIp string) *containers.Container {

	return containers.Run("st-apiserver",

		containers.RunOpts{AutoRemove: true},

		"-v", os.Getenv("CERTS_PATH")+":/home/user/certs", // Mount in location of certificates.

		"-v", os.Getenv("CRDS")+":/crds",

		"-e", "KUBECONFIG=/home/user/certs/kubeconfig", // We run kubectl from within this container.

		os.Getenv("KUBE_IMAGE"),

		"kube-apiserver",

		"--v=0",

		"--service-cluster-ip-range=10.101.0.0/16",

		"--authorization-mode=RBAC",

		fmt.Sprintf("--etcd-servers=http://%s:2379", etcdIp),

		"--service-account-key-file=/home/user/certs/service-account.pem",

		"--service-account-signing-key-file=/home/user/certs/service-account-key.pem",

		"--service-account-issuer=https://localhost:443",

		"--api-audiences=kubernetes.default",


====================
}

func RunK8sApiserver(etcdIp string) *containers.Container {

	return containers.Run("st-apiserver",

		containers.RunOpts{AutoRemove: true},

		"-v", os.Getenv("CERTS_PATH")+":/home/user/certs", // Mount in location of certificates.

		"-v", os.Getenv("CRDS")+":/crds",

		"-e", "KUBECONFIG=/home/user/certs/kubeconfig", // We run kubectl from within this container.

		os.Getenv("KUBE_IMAGE"),

		"kube-apiserver",

		"--v=0",

		"--service-cluster-ip-range=10.101.0.0/16",

		"--authorization-mode=RBAC",

		fmt.Sprintf("--etcd-servers=http://%s:2379", etcdIp),

		"--service-account-key-file=/home/user/certs/service-account.pem",

		"--service-account-signing-key-file=/home/user/certs/service-account-key.pem",

		"--service-account-issuer=https://localhost:443",

		"--api-audiences=kubernetes.default",

		"--client-ca-file=/home/user/certs/ca.pem",

		"--tls-cert-file=/home/user/certs/kubernetes.pem",

		"--tls-private-key-file=/home/user/certs/kubernetes-key.pem",


====================
func RunK8sApiserver(etcdIp string) *containers.Container {

	return containers.Run("st-apiserver",

		containers.RunOpts{AutoRemove: true},

		"-v", os.Getenv("CERTS_PATH")+":/home/user/certs", // Mount in location of certificates.

		"-v", os.Getenv("CRDS")+":/crds",

		"-e", "KUBECONFIG=/home/user/certs/kubeconfig", // We run kubectl from within this container.

		os.Getenv("KUBE_IMAGE"),

		"kube-apiserver",

		"--v=0",

		"--service-cluster-ip-range=10.101.0.0/16",

		"--authorization-mode=RBAC",

		fmt.Sprintf("--etcd-servers=http://%s:2379", etcdIp),

		"--service-account-key-file=/home/user/certs/service-account.pem",

		"--service-account-signing-key-file=/home/user/certs/service-account-key.pem",

		"--service-account-issuer=https://localhost:443",

		"--api-audiences=kubernetes.default",

		"--client-ca-file=/home/user/certs/ca.pem",

		"--tls-cert-file=/home/user/certs/kubernetes.pem",

		"--tls-private-key-file=/home/user/certs/kubernetes-key.pem",

		"--enable-priority-and-fairness=false",


====================
	return containers.Run("st-apiserver",

		containers.RunOpts{AutoRemove: true},

		"-v", os.Getenv("CERTS_PATH")+":/home/user/certs", // Mount in location of certificates.

		"-v", os.Getenv("CRDS")+":/crds",

		"-e", "KUBECONFIG=/home/user/certs/kubeconfig", // We run kubectl from within this container.

		os.Getenv("KUBE_IMAGE"),

		"kube-apiserver",

		"--v=0",

		"--service-cluster-ip-range=10.101.0.0/16",

		"--authorization-mode=RBAC",

		fmt.Sprintf("--etcd-servers=http://%s:2379", etcdIp),

		"--service-account-key-file=/home/user/certs/service-account.pem",

		"--service-account-signing-key-file=/home/user/certs/service-account-key.pem",

		"--service-account-issuer=https://localhost:443",

		"--api-audiences=kubernetes.default",

		"--client-ca-file=/home/user/certs/ca.pem",

		"--tls-cert-file=/home/user/certs/kubernetes.pem",

		"--tls-private-key-file=/home/user/certs/kubernetes-key.pem",

		"--enable-priority-and-fairness=false",

		"--max-mutating-requests-inflight=0",


====================
		containers.RunOpts{AutoRemove: true},

		"-v", os.Getenv("CERTS_PATH")+":/home/user/certs", // Mount in location of certificates.

		"-v", os.Getenv("CRDS")+":/crds",

		"-e", "KUBECONFIG=/home/user/certs/kubeconfig", // We run kubectl from within this container.

		os.Getenv("KUBE_IMAGE"),

		"kube-apiserver",

		"--v=0",

		"--service-cluster-ip-range=10.101.0.0/16",

		"--authorization-mode=RBAC",

		fmt.Sprintf("--etcd-servers=http://%s:2379", etcdIp),

		"--service-account-key-file=/home/user/certs/service-account.pem",

		"--service-account-signing-key-file=/home/user/certs/service-account-key.pem",

		"--service-account-issuer=https://localhost:443",

		"--api-audiences=kubernetes.default",

		"--client-ca-file=/home/user/certs/ca.pem",

		"--tls-cert-file=/home/user/certs/kubernetes.pem",

		"--tls-private-key-file=/home/user/certs/kubernetes-key.pem",

		"--enable-priority-and-fairness=false",

		"--max-mutating-requests-inflight=0",

		"--max-requests-inflight=0",


====================
		"-v", os.Getenv("CERTS_PATH")+":/home/user/certs", // Mount in location of certificates.

		"-v", os.Getenv("CRDS")+":/crds",

		"-e", "KUBECONFIG=/home/user/certs/kubeconfig", // We run kubectl from within this container.

		os.Getenv("KUBE_IMAGE"),

		"kube-apiserver",

		"--v=0",

		"--service-cluster-ip-range=10.101.0.0/16",

		"--authorization-mode=RBAC",

		fmt.Sprintf("--etcd-servers=http://%s:2379", etcdIp),

		"--service-account-key-file=/home/user/certs/service-account.pem",

		"--service-account-signing-key-file=/home/user/certs/service-account-key.pem",

		"--service-account-issuer=https://localhost:443",

		"--api-audiences=kubernetes.default",

		"--client-ca-file=/home/user/certs/ca.pem",

		"--tls-cert-file=/home/user/certs/kubernetes.pem",

		"--tls-private-key-file=/home/user/certs/kubernetes-key.pem",

		"--enable-priority-and-fairness=false",

		"--max-mutating-requests-inflight=0",

		"--max-requests-inflight=0",

	)


====================
		"-v", os.Getenv("CRDS")+":/crds",

		"-e", "KUBECONFIG=/home/user/certs/kubeconfig", // We run kubectl from within this container.

		os.Getenv("KUBE_IMAGE"),

		"kube-apiserver",

		"--v=0",

		"--service-cluster-ip-range=10.101.0.0/16",

		"--authorization-mode=RBAC",

		fmt.Sprintf("--etcd-servers=http://%s:2379", etcdIp),

		"--service-account-key-file=/home/user/certs/service-account.pem",

		"--service-account-signing-key-file=/home/user/certs/service-account-key.pem",

		"--service-account-issuer=https://localhost:443",

		"--api-audiences=kubernetes.default",

		"--client-ca-file=/home/user/certs/ca.pem",

		"--tls-cert-file=/home/user/certs/kubernetes.pem",

		"--tls-private-key-file=/home/user/certs/kubernetes-key.pem",

		"--enable-priority-and-fairness=false",

		"--max-mutating-requests-inflight=0",

		"--max-requests-inflight=0",

	)

}


====================
		"-e", "KUBECONFIG=/home/user/certs/kubeconfig", // We run kubectl from within this container.

		os.Getenv("KUBE_IMAGE"),

		"kube-apiserver",

		"--v=0",

		"--service-cluster-ip-range=10.101.0.0/16",

		"--authorization-mode=RBAC",

		fmt.Sprintf("--etcd-servers=http://%s:2379", etcdIp),

		"--service-account-key-file=/home/user/certs/service-account.pem",

		"--service-account-signing-key-file=/home/user/certs/service-account-key.pem",

		"--service-account-issuer=https://localhost:443",

		"--api-audiences=kubernetes.default",

		"--client-ca-file=/home/user/certs/ca.pem",

		"--tls-cert-file=/home/user/certs/kubernetes.pem",

		"--tls-private-key-file=/home/user/certs/kubernetes-key.pem",

		"--enable-priority-and-fairness=false",

		"--max-mutating-requests-inflight=0",

		"--max-requests-inflight=0",

	)

}

func RunK8sControllerManager(apiserverIp string) *containers.Container {


====================
		os.Getenv("KUBE_IMAGE"),

		"kube-apiserver",

		"--v=0",

		"--service-cluster-ip-range=10.101.0.0/16",

		"--authorization-mode=RBAC",

		fmt.Sprintf("--etcd-servers=http://%s:2379", etcdIp),

		"--service-account-key-file=/home/user/certs/service-account.pem",

		"--service-account-signing-key-file=/home/user/certs/service-account-key.pem",

		"--service-account-issuer=https://localhost:443",

		"--api-audiences=kubernetes.default",

		"--client-ca-file=/home/user/certs/ca.pem",

		"--tls-cert-file=/home/user/certs/kubernetes.pem",

		"--tls-private-key-file=/home/user/certs/kubernetes-key.pem",

		"--enable-priority-and-fairness=false",

		"--max-mutating-requests-inflight=0",

		"--max-requests-inflight=0",

	)

}

func RunK8sControllerManager(apiserverIp string) *containers.Container {

	c := containers.Run("st-controller-manager",


====================
		"kube-apiserver",

		"--v=0",

		"--service-cluster-ip-range=10.101.0.0/16",

		"--authorization-mode=RBAC",

		fmt.Sprintf("--etcd-servers=http://%s:2379", etcdIp),

		"--service-account-key-file=/home/user/certs/service-account.pem",

		"--service-account-signing-key-file=/home/user/certs/service-account-key.pem",

		"--service-account-issuer=https://localhost:443",

		"--api-audiences=kubernetes.default",

		"--client-ca-file=/home/user/certs/ca.pem",

		"--tls-cert-file=/home/user/certs/kubernetes.pem",

		"--tls-private-key-file=/home/user/certs/kubernetes-key.pem",

		"--enable-priority-and-fairness=false",

		"--max-mutating-requests-inflight=0",

		"--max-requests-inflight=0",

	)

}

func RunK8sControllerManager(apiserverIp string) *containers.Container {

	c := containers.Run("st-controller-manager",

		containers.RunOpts{AutoRemove: true},


====================
		"--v=0",

		"--service-cluster-ip-range=10.101.0.0/16",

		"--authorization-mode=RBAC",

		fmt.Sprintf("--etcd-servers=http://%s:2379", etcdIp),

		"--service-account-key-file=/home/user/certs/service-account.pem",

		"--service-account-signing-key-file=/home/user/certs/service-account-key.pem",

		"--service-account-issuer=https://localhost:443",

		"--api-audiences=kubernetes.default",

		"--client-ca-file=/home/user/certs/ca.pem",

		"--tls-cert-file=/home/user/certs/kubernetes.pem",

		"--tls-private-key-file=/home/user/certs/kubernetes-key.pem",

		"--enable-priority-and-fairness=false",

		"--max-mutating-requests-inflight=0",

		"--max-requests-inflight=0",

	)

}

func RunK8sControllerManager(apiserverIp string) *containers.Container {

	c := containers.Run("st-controller-manager",

		containers.RunOpts{AutoRemove: true},

		"-v", os.Getenv("CERTS_PATH")+":/home/user/certs", // Mount in location of certificates.


====================
		"--service-cluster-ip-range=10.101.0.0/16",

		"--authorization-mode=RBAC",

		fmt.Sprintf("--etcd-servers=http://%s:2379", etcdIp),

		"--service-account-key-file=/home/user/certs/service-account.pem",

		"--service-account-signing-key-file=/home/user/certs/service-account-key.pem",

		"--service-account-issuer=https://localhost:443",

		"--api-audiences=kubernetes.default",

		"--client-ca-file=/home/user/certs/ca.pem",

		"--tls-cert-file=/home/user/certs/kubernetes.pem",

		"--tls-private-key-file=/home/user/certs/kubernetes-key.pem",

		"--enable-priority-and-fairness=false",

		"--max-mutating-requests-inflight=0",

		"--max-requests-inflight=0",

	)

}

func RunK8sControllerManager(apiserverIp string) *containers.Container {

	c := containers.Run("st-controller-manager",

		containers.RunOpts{AutoRemove: true},

		"-v", os.Getenv("CERTS_PATH")+":/home/user/certs", // Mount in location of certificates.

		os.Getenv("KUBE_IMAGE"),


====================
		"--authorization-mode=RBAC",

		fmt.Sprintf("--etcd-servers=http://%s:2379", etcdIp),

		"--service-account-key-file=/home/user/certs/service-account.pem",

		"--service-account-signing-key-file=/home/user/certs/service-account-key.pem",

		"--service-account-issuer=https://localhost:443",

		"--api-audiences=kubernetes.default",

		"--client-ca-file=/home/user/certs/ca.pem",

		"--tls-cert-file=/home/user/certs/kubernetes.pem",

		"--tls-private-key-file=/home/user/certs/kubernetes-key.pem",

		"--enable-priority-and-fairness=false",

		"--max-mutating-requests-inflight=0",

		"--max-requests-inflight=0",

	)

}

func RunK8sControllerManager(apiserverIp string) *containers.Container {

	c := containers.Run("st-controller-manager",

		containers.RunOpts{AutoRemove: true},

		"-v", os.Getenv("CERTS_PATH")+":/home/user/certs", // Mount in location of certificates.

		os.Getenv("KUBE_IMAGE"),

		"kube-controller-manager",


====================
		fmt.Sprintf("--etcd-servers=http://%s:2379", etcdIp),

		"--service-account-key-file=/home/user/certs/service-account.pem",

		"--service-account-signing-key-file=/home/user/certs/service-account-key.pem",

		"--service-account-issuer=https://localhost:443",

		"--api-audiences=kubernetes.default",

		"--client-ca-file=/home/user/certs/ca.pem",

		"--tls-cert-file=/home/user/certs/kubernetes.pem",

		"--tls-private-key-file=/home/user/certs/kubernetes-key.pem",

		"--enable-priority-and-fairness=false",

		"--max-mutating-requests-inflight=0",

		"--max-requests-inflight=0",

	)

}

func RunK8sControllerManager(apiserverIp string) *containers.Container {

	c := containers.Run("st-controller-manager",

		containers.RunOpts{AutoRemove: true},

		"-v", os.Getenv("CERTS_PATH")+":/home/user/certs", // Mount in location of certificates.

		os.Getenv("KUBE_IMAGE"),

		"kube-controller-manager",

		fmt.Sprintf("--master=https://%v:6443", apiserverIp),


====================
		"--service-account-key-file=/home/user/certs/service-account.pem",

		"--service-account-signing-key-file=/home/user/certs/service-account-key.pem",

		"--service-account-issuer=https://localhost:443",

		"--api-audiences=kubernetes.default",

		"--client-ca-file=/home/user/certs/ca.pem",

		"--tls-cert-file=/home/user/certs/kubernetes.pem",

		"--tls-private-key-file=/home/user/certs/kubernetes-key.pem",

		"--enable-priority-and-fairness=false",

		"--max-mutating-requests-inflight=0",

		"--max-requests-inflight=0",

	)

}

func RunK8sControllerManager(apiserverIp string) *containers.Container {

	c := containers.Run("st-controller-manager",

		containers.RunOpts{AutoRemove: true},

		"-v", os.Getenv("CERTS_PATH")+":/home/user/certs", // Mount in location of certificates.

		os.Getenv("KUBE_IMAGE"),

		"kube-controller-manager",

		fmt.Sprintf("--master=https://%v:6443", apiserverIp),

		"--cluster-cidr=192.168.0.0/16",


====================
		"--tls-private-key-file=/home/user/certs/kubernetes-key.pem",

		"--enable-priority-and-fairness=false",

		"--max-mutating-requests-inflight=0",

		"--max-requests-inflight=0",

	)

}

func RunK8sControllerManager(apiserverIp string) *containers.Container {

	c := containers.Run("st-controller-manager",

		containers.RunOpts{AutoRemove: true},

		"-v", os.Getenv("CERTS_PATH")+":/home/user/certs", // Mount in location of certificates.

		os.Getenv("KUBE_IMAGE"),

		"kube-controller-manager",

		fmt.Sprintf("--master=https://%v:6443", apiserverIp),

		"--cluster-cidr=192.168.0.0/16",

		"--min-resync-period=3m",

		"--kubeconfig=/home/user/certs/kube-controller-manager.kubeconfig",

		// We run trivially small clusters, so increase the QPS to get the

		// cluster to start up as fast as possible.

		"--kube-api-qps=100",

		"--kube-api-burst=200",


====================
		"--max-requests-inflight=0",

	)

}

func RunK8sControllerManager(apiserverIp string) *containers.Container {

	c := containers.Run("st-controller-manager",

		containers.RunOpts{AutoRemove: true},

		"-v", os.Getenv("CERTS_PATH")+":/home/user/certs", // Mount in location of certificates.

		os.Getenv("KUBE_IMAGE"),

		"kube-controller-manager",

		fmt.Sprintf("--master=https://%v:6443", apiserverIp),

		"--cluster-cidr=192.168.0.0/16",

		"--min-resync-period=3m",

		"--kubeconfig=/home/user/certs/kube-controller-manager.kubeconfig",

		// We run trivially small clusters, so increase the QPS to get the

		// cluster to start up as fast as possible.

		"--kube-api-qps=100",

		"--kube-api-burst=200",

		"--min-resync-period=3m",

		"--allocate-node-cidrs=true",

		"--leader-elect=false",


====================
	)

}

func RunK8sControllerManager(apiserverIp string) *containers.Container {

	c := containers.Run("st-controller-manager",

		containers.RunOpts{AutoRemove: true},

		"-v", os.Getenv("CERTS_PATH")+":/home/user/certs", // Mount in location of certificates.

		os.Getenv("KUBE_IMAGE"),

		"kube-controller-manager",

		fmt.Sprintf("--master=https://%v:6443", apiserverIp),

		"--cluster-cidr=192.168.0.0/16",

		"--min-resync-period=3m",

		"--kubeconfig=/home/user/certs/kube-controller-manager.kubeconfig",

		// We run trivially small clusters, so increase the QPS to get the

		// cluster to start up as fast as possible.

		"--kube-api-qps=100",

		"--kube-api-burst=200",

		"--min-resync-period=3m",

		"--allocate-node-cidrs=true",

		"--leader-elect=false",

		"--v=5",


====================
}

func RunK8sControllerManager(apiserverIp string) *containers.Container {

	c := containers.Run("st-controller-manager",

		containers.RunOpts{AutoRemove: true},

		"-v", os.Getenv("CERTS_PATH")+":/home/user/certs", // Mount in location of certificates.

		os.Getenv("KUBE_IMAGE"),

		"kube-controller-manager",

		fmt.Sprintf("--master=https://%v:6443", apiserverIp),

		"--cluster-cidr=192.168.0.0/16",

		"--min-resync-period=3m",

		"--kubeconfig=/home/user/certs/kube-controller-manager.kubeconfig",

		// We run trivially small clusters, so increase the QPS to get the

		// cluster to start up as fast as possible.

		"--kube-api-qps=100",

		"--kube-api-burst=200",

		"--min-resync-period=3m",

		"--allocate-node-cidrs=true",

		"--leader-elect=false",

		"--v=5",

		"--service-account-private-key-file=/home/user/certs/service-account-key.pem",


====================
func RunK8sControllerManager(apiserverIp string) *containers.Container {

	c := containers.Run("st-controller-manager",

		containers.RunOpts{AutoRemove: true},

		"-v", os.Getenv("CERTS_PATH")+":/home/user/certs", // Mount in location of certificates.

		os.Getenv("KUBE_IMAGE"),

		"kube-controller-manager",

		fmt.Sprintf("--master=https://%v:6443", apiserverIp),

		"--cluster-cidr=192.168.0.0/16",

		"--min-resync-period=3m",

		"--kubeconfig=/home/user/certs/kube-controller-manager.kubeconfig",

		// We run trivially small clusters, so increase the QPS to get the

		// cluster to start up as fast as possible.

		"--kube-api-qps=100",

		"--kube-api-burst=200",

		"--min-resync-period=3m",

		"--allocate-node-cidrs=true",

		"--leader-elect=false",

		"--v=5",

		"--service-account-private-key-file=/home/user/certs/service-account-key.pem",

		"--root-ca-file=/home/user/certs/ca.pem",


====================
		"-v", os.Getenv("CERTS_PATH")+":/home/user/certs", // Mount in location of certificates.

		os.Getenv("KUBE_IMAGE"),

		"kube-controller-manager",

		fmt.Sprintf("--master=https://%v:6443", apiserverIp),

		"--cluster-cidr=192.168.0.0/16",

		"--min-resync-period=3m",

		"--kubeconfig=/home/user/certs/kube-controller-manager.kubeconfig",

		// We run trivially small clusters, so increase the QPS to get the

		// cluster to start up as fast as possible.

		"--kube-api-qps=100",

		"--kube-api-burst=200",

		"--min-resync-period=3m",

		"--allocate-node-cidrs=true",

		"--leader-elect=false",

		"--v=5",

		"--service-account-private-key-file=/home/user/certs/service-account-key.pem",

		"--root-ca-file=/home/user/certs/ca.pem",

		"--concurrent-gc-syncs=50",

	)

	return c


====================
		os.Getenv("KUBE_IMAGE"),

		"kube-controller-manager",

		fmt.Sprintf("--master=https://%v:6443", apiserverIp),

		"--cluster-cidr=192.168.0.0/16",

		"--min-resync-period=3m",

		"--kubeconfig=/home/user/certs/kube-controller-manager.kubeconfig",

		// We run trivially small clusters, so increase the QPS to get the

		// cluster to start up as fast as possible.

		"--kube-api-qps=100",

		"--kube-api-burst=200",

		"--min-resync-period=3m",

		"--allocate-node-cidrs=true",

		"--leader-elect=false",

		"--v=5",

		"--service-account-private-key-file=/home/user/certs/service-account-key.pem",

		"--root-ca-file=/home/user/certs/ca.pem",

		"--concurrent-gc-syncs=50",

	)

	return c

}


====================
		"kube-controller-manager",

		fmt.Sprintf("--master=https://%v:6443", apiserverIp),

		"--cluster-cidr=192.168.0.0/16",

		"--min-resync-period=3m",

		"--kubeconfig=/home/user/certs/kube-controller-manager.kubeconfig",

		// We run trivially small clusters, so increase the QPS to get the

		// cluster to start up as fast as possible.

		"--kube-api-qps=100",

		"--kube-api-burst=200",

		"--min-resync-period=3m",

		"--allocate-node-cidrs=true",

		"--leader-elect=false",

		"--v=5",

		"--service-account-private-key-file=/home/user/certs/service-account-key.pem",

		"--root-ca-file=/home/user/certs/ca.pem",

		"--concurrent-gc-syncs=50",

	)

	return c

}

func RunEtcd() *containers.Container {


====================
		fmt.Sprintf("--master=https://%v:6443", apiserverIp),

		"--cluster-cidr=192.168.0.0/16",

		"--min-resync-period=3m",

		"--kubeconfig=/home/user/certs/kube-controller-manager.kubeconfig",

		// We run trivially small clusters, so increase the QPS to get the

		// cluster to start up as fast as possible.

		"--kube-api-qps=100",

		"--kube-api-burst=200",

		"--min-resync-period=3m",

		"--allocate-node-cidrs=true",

		"--leader-elect=false",

		"--v=5",

		"--service-account-private-key-file=/home/user/certs/service-account-key.pem",

		"--root-ca-file=/home/user/certs/ca.pem",

		"--concurrent-gc-syncs=50",

	)

	return c

}

func RunEtcd() *containers.Container {

	return containers.Run("etcd-fv",


====================
		"--cluster-cidr=192.168.0.0/16",

		"--min-resync-period=3m",

		"--kubeconfig=/home/user/certs/kube-controller-manager.kubeconfig",

		// We run trivially small clusters, so increase the QPS to get the

		// cluster to start up as fast as possible.

		"--kube-api-qps=100",

		"--kube-api-burst=200",

		"--min-resync-period=3m",

		"--allocate-node-cidrs=true",

		"--leader-elect=false",

		"--v=5",

		"--service-account-private-key-file=/home/user/certs/service-account-key.pem",

		"--root-ca-file=/home/user/certs/ca.pem",

		"--concurrent-gc-syncs=50",

	)

	return c

}

func RunEtcd() *containers.Container {

	return containers.Run("etcd-fv",

		containers.RunOpts{AutoRemove: true},


====================
		"--min-resync-period=3m",

		"--kubeconfig=/home/user/certs/kube-controller-manager.kubeconfig",

		// We run trivially small clusters, so increase the QPS to get the

		// cluster to start up as fast as possible.

		"--kube-api-qps=100",

		"--kube-api-burst=200",

		"--min-resync-period=3m",

		"--allocate-node-cidrs=true",

		"--leader-elect=false",

		"--v=5",

		"--service-account-private-key-file=/home/user/certs/service-account-key.pem",

		"--root-ca-file=/home/user/certs/ca.pem",

		"--concurrent-gc-syncs=50",

	)

	return c

}

func RunEtcd() *containers.Container {

	return containers.Run("etcd-fv",

		containers.RunOpts{AutoRemove: true},

		os.Getenv("ETCD_IMAGE"),


====================
		"--kubeconfig=/home/user/certs/kube-controller-manager.kubeconfig",

		// We run trivially small clusters, so increase the QPS to get the

		// cluster to start up as fast as possible.

		"--kube-api-qps=100",

		"--kube-api-burst=200",

		"--min-resync-period=3m",

		"--allocate-node-cidrs=true",

		"--leader-elect=false",

		"--v=5",

		"--service-account-private-key-file=/home/user/certs/service-account-key.pem",

		"--root-ca-file=/home/user/certs/ca.pem",

		"--concurrent-gc-syncs=50",

	)

	return c

}

func RunEtcd() *containers.Container {

	return containers.Run("etcd-fv",

		containers.RunOpts{AutoRemove: true},

		os.Getenv("ETCD_IMAGE"),

		"etcd",


====================
		// We run trivially small clusters, so increase the QPS to get the

		// cluster to start up as fast as possible.

		"--kube-api-qps=100",

		"--kube-api-burst=200",

		"--min-resync-period=3m",

		"--allocate-node-cidrs=true",

		"--leader-elect=false",

		"--v=5",

		"--service-account-private-key-file=/home/user/certs/service-account-key.pem",

		"--root-ca-file=/home/user/certs/ca.pem",

		"--concurrent-gc-syncs=50",

	)

	return c

}

func RunEtcd() *containers.Container {

	return containers.Run("etcd-fv",

		containers.RunOpts{AutoRemove: true},

		os.Getenv("ETCD_IMAGE"),

		"etcd",

		"--advertise-client-urls", "http://127.0.0.1:2379",


====================
		// cluster to start up as fast as possible.

		"--kube-api-qps=100",

		"--kube-api-burst=200",

		"--min-resync-period=3m",

		"--allocate-node-cidrs=true",

		"--leader-elect=false",

		"--v=5",

		"--service-account-private-key-file=/home/user/certs/service-account-key.pem",

		"--root-ca-file=/home/user/certs/ca.pem",

		"--concurrent-gc-syncs=50",

	)

	return c

}

func RunEtcd() *containers.Container {

	return containers.Run("etcd-fv",

		containers.RunOpts{AutoRemove: true},

		os.Getenv("ETCD_IMAGE"),

		"etcd",

		"--advertise-client-urls", "http://127.0.0.1:2379",

		"--listen-client-urls", "http://0.0.0.0:2379")


====================
		"--concurrent-gc-syncs=50",

	)

	return c

}

func RunEtcd() *containers.Container {

	return containers.Run("etcd-fv",

		containers.RunOpts{AutoRemove: true},

		os.Getenv("ETCD_IMAGE"),

		"etcd",

		"--advertise-client-urls", "http://127.0.0.1:2379",

		"--listen-client-urls", "http://0.0.0.0:2379")

}

func GetCalicoClient(dsType apiconfig.DatastoreType, etcdIP, kcfg string) client.Interface {

	cfg := apiconfig.NewCalicoAPIConfig()

	cfg.Spec.DatastoreType = dsType

	cfg.Spec.EtcdEndpoints = fmt.Sprintf("http://%s:2379", etcdIP)

	cfg.Spec.Kubeconfig = kcfg

	client, err := client.New(*cfg)

	Expect(err).NotTo(HaveOccurred())

	return client


====================
	)

	return c

}

func RunEtcd() *containers.Container {

	return containers.Run("etcd-fv",

		containers.RunOpts{AutoRemove: true},

		os.Getenv("ETCD_IMAGE"),

		"etcd",

		"--advertise-client-urls", "http://127.0.0.1:2379",

		"--listen-client-urls", "http://0.0.0.0:2379")

}

func GetCalicoClient(dsType apiconfig.DatastoreType, etcdIP, kcfg string) client.Interface {

	cfg := apiconfig.NewCalicoAPIConfig()

	cfg.Spec.DatastoreType = dsType

	cfg.Spec.EtcdEndpoints = fmt.Sprintf("http://%s:2379", etcdIP)

	cfg.Spec.Kubeconfig = kcfg

	client, err := client.New(*cfg)

	Expect(err).NotTo(HaveOccurred())

	return client

}


====================
	ctrls := "workloadendpoint,namespace,policy,node,serviceaccount"

	autoHep := "disabled"

	if autoHepEnabled {

		autoHep = "enabled"

	}

	admin := os.Getenv("CERTS") + "/admin.pem"

	adminKey := os.Getenv("CERTS") + "/admin-key.pem"

	return containers.Run("calico-kube-controllers",

		containers.RunOpts{AutoRemove: true},

		"--privileged",

		"-e", fmt.Sprintf("ETCD_ENDPOINTS=http://%s:2379", etcdIP),

		"-e", fmt.Sprintf("DATASTORE_TYPE=%s", datastoreType),

		"-e", fmt.Sprintf("ENABLED_CONTROLLERS=%s", ctrls),

		"-e", fmt.Sprintf("AUTO_HOST_ENDPOINTS=%s", autoHep),

		"-e", "SYNC_NODE_LABELS=true",

		"-e", "LOG_LEVEL=debug",

		"-e", fmt.Sprintf("KUBECONFIG=%s", kconfigfile),

		"-e", "RECONCILER_PERIOD=10s",

		"-v", fmt.Sprintf("%s:%s", kconfigfile, kconfigfile),

		"-v", fmt.Sprintf("%s:/admin.pem", admin),


====================
	autoHep := "disabled"

	if autoHepEnabled {

		autoHep = "enabled"

	}

	admin := os.Getenv("CERTS") + "/admin.pem"

	adminKey := os.Getenv("CERTS") + "/admin-key.pem"

	return containers.Run("calico-kube-controllers",

		containers.RunOpts{AutoRemove: true},

		"--privileged",

		"-e", fmt.Sprintf("ETCD_ENDPOINTS=http://%s:2379", etcdIP),

		"-e", fmt.Sprintf("DATASTORE_TYPE=%s", datastoreType),

		"-e", fmt.Sprintf("ENABLED_CONTROLLERS=%s", ctrls),

		"-e", fmt.Sprintf("AUTO_HOST_ENDPOINTS=%s", autoHep),

		"-e", "SYNC_NODE_LABELS=true",

		"-e", "LOG_LEVEL=debug",

		"-e", fmt.Sprintf("KUBECONFIG=%s", kconfigfile),

		"-e", "RECONCILER_PERIOD=10s",

		"-v", fmt.Sprintf("%s:%s", kconfigfile, kconfigfile),

		"-v", fmt.Sprintf("%s:/admin.pem", admin),

		"-v", fmt.Sprintf("%s:/admin-key.pem", adminKey),


====================
	if autoHepEnabled {

		autoHep = "enabled"

	}

	admin := os.Getenv("CERTS") + "/admin.pem"

	adminKey := os.Getenv("CERTS") + "/admin-key.pem"

	return containers.Run("calico-kube-controllers",

		containers.RunOpts{AutoRemove: true},

		"--privileged",

		"-e", fmt.Sprintf("ETCD_ENDPOINTS=http://%s:2379", etcdIP),

		"-e", fmt.Sprintf("DATASTORE_TYPE=%s", datastoreType),

		"-e", fmt.Sprintf("ENABLED_CONTROLLERS=%s", ctrls),

		"-e", fmt.Sprintf("AUTO_HOST_ENDPOINTS=%s", autoHep),

		"-e", "SYNC_NODE_LABELS=true",

		"-e", "LOG_LEVEL=debug",

		"-e", fmt.Sprintf("KUBECONFIG=%s", kconfigfile),

		"-e", "RECONCILER_PERIOD=10s",

		"-v", fmt.Sprintf("%s:%s", kconfigfile, kconfigfile),

		"-v", fmt.Sprintf("%s:/admin.pem", admin),

		"-v", fmt.Sprintf("%s:/admin-key.pem", adminKey),

		os.Getenv("CONTAINER_NAME"))


====================
		autoHep = "enabled"

	}

	admin := os.Getenv("CERTS") + "/admin.pem"

	adminKey := os.Getenv("CERTS") + "/admin-key.pem"

	return containers.Run("calico-kube-controllers",

		containers.RunOpts{AutoRemove: true},

		"--privileged",

		"-e", fmt.Sprintf("ETCD_ENDPOINTS=http://%s:2379", etcdIP),

		"-e", fmt.Sprintf("DATASTORE_TYPE=%s", datastoreType),

		"-e", fmt.Sprintf("ENABLED_CONTROLLERS=%s", ctrls),

		"-e", fmt.Sprintf("AUTO_HOST_ENDPOINTS=%s", autoHep),

		"-e", "SYNC_NODE_LABELS=true",

		"-e", "LOG_LEVEL=debug",

		"-e", fmt.Sprintf("KUBECONFIG=%s", kconfigfile),

		"-e", "RECONCILER_PERIOD=10s",

		"-v", fmt.Sprintf("%s:%s", kconfigfile, kconfigfile),

		"-v", fmt.Sprintf("%s:/admin.pem", admin),

		"-v", fmt.Sprintf("%s:/admin-key.pem", adminKey),

		os.Getenv("CONTAINER_NAME"))

}


====================
	}

	admin := os.Getenv("CERTS") + "/admin.pem"

	adminKey := os.Getenv("CERTS") + "/admin-key.pem"

	return containers.Run("calico-kube-controllers",

		containers.RunOpts{AutoRemove: true},

		"--privileged",

		"-e", fmt.Sprintf("ETCD_ENDPOINTS=http://%s:2379", etcdIP),

		"-e", fmt.Sprintf("DATASTORE_TYPE=%s", datastoreType),

		"-e", fmt.Sprintf("ENABLED_CONTROLLERS=%s", ctrls),

		"-e", fmt.Sprintf("AUTO_HOST_ENDPOINTS=%s", autoHep),

		"-e", "SYNC_NODE_LABELS=true",

		"-e", "LOG_LEVEL=debug",

		"-e", fmt.Sprintf("KUBECONFIG=%s", kconfigfile),

		"-e", "RECONCILER_PERIOD=10s",

		"-v", fmt.Sprintf("%s:%s", kconfigfile, kconfigfile),

		"-v", fmt.Sprintf("%s:/admin.pem", admin),

		"-v", fmt.Sprintf("%s:/admin-key.pem", adminKey),

		os.Getenv("CONTAINER_NAME"))

}

func RunKubeControllerWithEnv(datastoreType apiconfig.DatastoreType, etcdIP, kconfigfile string, env map[string]string) *containers.Container {


====================
	admin := os.Getenv("CERTS") + "/admin.pem"

	adminKey := os.Getenv("CERTS") + "/admin-key.pem"

	return containers.Run("calico-kube-controllers",

		containers.RunOpts{AutoRemove: true},

		"--privileged",

		"-e", fmt.Sprintf("ETCD_ENDPOINTS=http://%s:2379", etcdIP),

		"-e", fmt.Sprintf("DATASTORE_TYPE=%s", datastoreType),

		"-e", fmt.Sprintf("ENABLED_CONTROLLERS=%s", ctrls),

		"-e", fmt.Sprintf("AUTO_HOST_ENDPOINTS=%s", autoHep),

		"-e", "SYNC_NODE_LABELS=true",

		"-e", "LOG_LEVEL=debug",

		"-e", fmt.Sprintf("KUBECONFIG=%s", kconfigfile),

		"-e", "RECONCILER_PERIOD=10s",

		"-v", fmt.Sprintf("%s:%s", kconfigfile, kconfigfile),

		"-v", fmt.Sprintf("%s:/admin.pem", admin),

		"-v", fmt.Sprintf("%s:/admin-key.pem", adminKey),

		os.Getenv("CONTAINER_NAME"))

}

func RunKubeControllerWithEnv(datastoreType apiconfig.DatastoreType, etcdIP, kconfigfile string, env map[string]string) *containers.Container {

	args := []string{


====================
	adminKey := os.Getenv("CERTS") + "/admin-key.pem"

	return containers.Run("calico-kube-controllers",

		containers.RunOpts{AutoRemove: true},

		"--privileged",

		"-e", fmt.Sprintf("ETCD_ENDPOINTS=http://%s:2379", etcdIP),

		"-e", fmt.Sprintf("DATASTORE_TYPE=%s", datastoreType),

		"-e", fmt.Sprintf("ENABLED_CONTROLLERS=%s", ctrls),

		"-e", fmt.Sprintf("AUTO_HOST_ENDPOINTS=%s", autoHep),

		"-e", "SYNC_NODE_LABELS=true",

		"-e", "LOG_LEVEL=debug",

		"-e", fmt.Sprintf("KUBECONFIG=%s", kconfigfile),

		"-e", "RECONCILER_PERIOD=10s",

		"-v", fmt.Sprintf("%s:%s", kconfigfile, kconfigfile),

		"-v", fmt.Sprintf("%s:/admin.pem", admin),

		"-v", fmt.Sprintf("%s:/admin-key.pem", adminKey),

		os.Getenv("CONTAINER_NAME"))

}

func RunKubeControllerWithEnv(datastoreType apiconfig.DatastoreType, etcdIP, kconfigfile string, env map[string]string) *containers.Container {

	args := []string{

		"--privileged",


====================
	return containers.Run("calico-kube-controllers",

		containers.RunOpts{AutoRemove: true},

		"--privileged",

		"-e", fmt.Sprintf("ETCD_ENDPOINTS=http://%s:2379", etcdIP),

		"-e", fmt.Sprintf("DATASTORE_TYPE=%s", datastoreType),

		"-e", fmt.Sprintf("ENABLED_CONTROLLERS=%s", ctrls),

		"-e", fmt.Sprintf("AUTO_HOST_ENDPOINTS=%s", autoHep),

		"-e", "SYNC_NODE_LABELS=true",

		"-e", "LOG_LEVEL=debug",

		"-e", fmt.Sprintf("KUBECONFIG=%s", kconfigfile),

		"-e", "RECONCILER_PERIOD=10s",

		"-v", fmt.Sprintf("%s:%s", kconfigfile, kconfigfile),

		"-v", fmt.Sprintf("%s:/admin.pem", admin),

		"-v", fmt.Sprintf("%s:/admin-key.pem", adminKey),

		os.Getenv("CONTAINER_NAME"))

}

func RunKubeControllerWithEnv(datastoreType apiconfig.DatastoreType, etcdIP, kconfigfile string, env map[string]string) *containers.Container {

	args := []string{

		"--privileged",

	}


====================
		containers.RunOpts{AutoRemove: true},

		"--privileged",

		"-e", fmt.Sprintf("ETCD_ENDPOINTS=http://%s:2379", etcdIP),

		"-e", fmt.Sprintf("DATASTORE_TYPE=%s", datastoreType),

		"-e", fmt.Sprintf("ENABLED_CONTROLLERS=%s", ctrls),

		"-e", fmt.Sprintf("AUTO_HOST_ENDPOINTS=%s", autoHep),

		"-e", "SYNC_NODE_LABELS=true",

		"-e", "LOG_LEVEL=debug",

		"-e", fmt.Sprintf("KUBECONFIG=%s", kconfigfile),

		"-e", "RECONCILER_PERIOD=10s",

		"-v", fmt.Sprintf("%s:%s", kconfigfile, kconfigfile),

		"-v", fmt.Sprintf("%s:/admin.pem", admin),

		"-v", fmt.Sprintf("%s:/admin-key.pem", adminKey),

		os.Getenv("CONTAINER_NAME"))

}

func RunKubeControllerWithEnv(datastoreType apiconfig.DatastoreType, etcdIP, kconfigfile string, env map[string]string) *containers.Container {

	args := []string{

		"--privileged",

	}

	for k, v := range env {


====================
		"--privileged",

		"-e", fmt.Sprintf("ETCD_ENDPOINTS=http://%s:2379", etcdIP),

		"-e", fmt.Sprintf("DATASTORE_TYPE=%s", datastoreType),

		"-e", fmt.Sprintf("ENABLED_CONTROLLERS=%s", ctrls),

		"-e", fmt.Sprintf("AUTO_HOST_ENDPOINTS=%s", autoHep),

		"-e", "SYNC_NODE_LABELS=true",

		"-e", "LOG_LEVEL=debug",

		"-e", fmt.Sprintf("KUBECONFIG=%s", kconfigfile),

		"-e", "RECONCILER_PERIOD=10s",

		"-v", fmt.Sprintf("%s:%s", kconfigfile, kconfigfile),

		"-v", fmt.Sprintf("%s:/admin.pem", admin),

		"-v", fmt.Sprintf("%s:/admin-key.pem", adminKey),

		os.Getenv("CONTAINER_NAME"))

}

func RunKubeControllerWithEnv(datastoreType apiconfig.DatastoreType, etcdIP, kconfigfile string, env map[string]string) *containers.Container {

	args := []string{

		"--privileged",

	}

	for k, v := range env {

		args = append(args, "-e", k+"="+v)


====================
		"-e", fmt.Sprintf("ETCD_ENDPOINTS=http://%s:2379", etcdIP),

		"-e", fmt.Sprintf("DATASTORE_TYPE=%s", datastoreType),

		"-e", fmt.Sprintf("ENABLED_CONTROLLERS=%s", ctrls),

		"-e", fmt.Sprintf("AUTO_HOST_ENDPOINTS=%s", autoHep),

		"-e", "SYNC_NODE_LABELS=true",

		"-e", "LOG_LEVEL=debug",

		"-e", fmt.Sprintf("KUBECONFIG=%s", kconfigfile),

		"-e", "RECONCILER_PERIOD=10s",

		"-v", fmt.Sprintf("%s:%s", kconfigfile, kconfigfile),

		"-v", fmt.Sprintf("%s:/admin.pem", admin),

		"-v", fmt.Sprintf("%s:/admin-key.pem", adminKey),

		os.Getenv("CONTAINER_NAME"))

}

func RunKubeControllerWithEnv(datastoreType apiconfig.DatastoreType, etcdIP, kconfigfile string, env map[string]string) *containers.Container {

	args := []string{

		"--privileged",

	}

	for k, v := range env {

		args = append(args, "-e", k+"="+v)

	}


====================
		"-e", fmt.Sprintf("DATASTORE_TYPE=%s", datastoreType),

		"-e", fmt.Sprintf("ENABLED_CONTROLLERS=%s", ctrls),

		"-e", fmt.Sprintf("AUTO_HOST_ENDPOINTS=%s", autoHep),

		"-e", "SYNC_NODE_LABELS=true",

		"-e", "LOG_LEVEL=debug",

		"-e", fmt.Sprintf("KUBECONFIG=%s", kconfigfile),

		"-e", "RECONCILER_PERIOD=10s",

		"-v", fmt.Sprintf("%s:%s", kconfigfile, kconfigfile),

		"-v", fmt.Sprintf("%s:/admin.pem", admin),

		"-v", fmt.Sprintf("%s:/admin-key.pem", adminKey),

		os.Getenv("CONTAINER_NAME"))

}

func RunKubeControllerWithEnv(datastoreType apiconfig.DatastoreType, etcdIP, kconfigfile string, env map[string]string) *containers.Container {

	args := []string{

		"--privileged",

	}

	for k, v := range env {

		args = append(args, "-e", k+"="+v)

	}

	args = append(args,


====================
		"-e", fmt.Sprintf("KUBECONFIG=%s", kconfigfile),

		"-e", "RECONCILER_PERIOD=10s",

		"-v", fmt.Sprintf("%s:%s", kconfigfile, kconfigfile),

		"-v", fmt.Sprintf("%s:/admin.pem", admin),

		"-v", fmt.Sprintf("%s:/admin-key.pem", adminKey),

		os.Getenv("CONTAINER_NAME"))

}

func RunKubeControllerWithEnv(datastoreType apiconfig.DatastoreType, etcdIP, kconfigfile string, env map[string]string) *containers.Container {

	args := []string{

		"--privileged",

	}

	for k, v := range env {

		args = append(args, "-e", k+"="+v)

	}

	args = append(args,

		"-e", fmt.Sprintf("ETCD_ENDPOINTS=http://%s:2379", etcdIP),

		"-e", fmt.Sprintf("DATASTORE_TYPE=%s", datastoreType),

		"-e", fmt.Sprintf("KUBECONFIG=%s", kconfigfile),

		"-v", fmt.Sprintf("%s:%s", kconfigfile, kconfigfile),

		os.Getenv("CONTAINER_NAME"))


====================
		"-v", fmt.Sprintf("%s:/admin.pem", admin),

		"-v", fmt.Sprintf("%s:/admin-key.pem", adminKey),

		os.Getenv("CONTAINER_NAME"))

}

func RunKubeControllerWithEnv(datastoreType apiconfig.DatastoreType, etcdIP, kconfigfile string, env map[string]string) *containers.Container {

	args := []string{

		"--privileged",

	}

	for k, v := range env {

		args = append(args, "-e", k+"="+v)

	}

	args = append(args,

		"-e", fmt.Sprintf("ETCD_ENDPOINTS=http://%s:2379", etcdIP),

		"-e", fmt.Sprintf("DATASTORE_TYPE=%s", datastoreType),

		"-e", fmt.Sprintf("KUBECONFIG=%s", kconfigfile),

		"-v", fmt.Sprintf("%s:%s", kconfigfile, kconfigfile),

		os.Getenv("CONTAINER_NAME"))

	return containers.Run("calico-kube-controllers",

		containers.RunOpts{AutoRemove: true},

		args...)


====================
}

func RunKubeControllerWithEnv(datastoreType apiconfig.DatastoreType, etcdIP, kconfigfile string, env map[string]string) *containers.Container {

	args := []string{

		"--privileged",

	}

	for k, v := range env {

		args = append(args, "-e", k+"="+v)

	}

	args = append(args,

		"-e", fmt.Sprintf("ETCD_ENDPOINTS=http://%s:2379", etcdIP),

		"-e", fmt.Sprintf("DATASTORE_TYPE=%s", datastoreType),

		"-e", fmt.Sprintf("KUBECONFIG=%s", kconfigfile),

		"-v", fmt.Sprintf("%s:%s", kconfigfile, kconfigfile),

		os.Getenv("CONTAINER_NAME"))

	return containers.Run("calico-kube-controllers",

		containers.RunOpts{AutoRemove: true},

		args...)

}

func ExpectNodeLabels(c client.Interface, labels map[string]string, node string) error {

	cn, err := c.Nodes().Get(context.Background(), node, options.GetOptions{})


====================
func RunKubeControllerWithEnv(datastoreType apiconfig.DatastoreType, etcdIP, kconfigfile string, env map[string]string) *containers.Container {

	args := []string{

		"--privileged",

	}

	for k, v := range env {

		args = append(args, "-e", k+"="+v)

	}

	args = append(args,

		"-e", fmt.Sprintf("ETCD_ENDPOINTS=http://%s:2379", etcdIP),

		"-e", fmt.Sprintf("DATASTORE_TYPE=%s", datastoreType),

		"-e", fmt.Sprintf("KUBECONFIG=%s", kconfigfile),

		"-v", fmt.Sprintf("%s:%s", kconfigfile, kconfigfile),

		os.Getenv("CONTAINER_NAME"))

	return containers.Run("calico-kube-controllers",

		containers.RunOpts{AutoRemove: true},

		args...)

}

func ExpectNodeLabels(c client.Interface, labels map[string]string, node string) error {

	cn, err := c.Nodes().Get(context.Background(), node, options.GetOptions{})

	if err != nil {


====================
	args := []string{

		"--privileged",

	}

	for k, v := range env {

		args = append(args, "-e", k+"="+v)

	}

	args = append(args,

		"-e", fmt.Sprintf("ETCD_ENDPOINTS=http://%s:2379", etcdIP),

		"-e", fmt.Sprintf("DATASTORE_TYPE=%s", datastoreType),

		"-e", fmt.Sprintf("KUBECONFIG=%s", kconfigfile),

		"-v", fmt.Sprintf("%s:%s", kconfigfile, kconfigfile),

		os.Getenv("CONTAINER_NAME"))

	return containers.Run("calico-kube-controllers",

		containers.RunOpts{AutoRemove: true},

		args...)

}

func ExpectNodeLabels(c client.Interface, labels map[string]string, node string) error {

	cn, err := c.Nodes().Get(context.Background(), node, options.GetOptions{})

	if err != nil {

		return err


====================
		"--privileged",

	}

	for k, v := range env {

		args = append(args, "-e", k+"="+v)

	}

	args = append(args,

		"-e", fmt.Sprintf("ETCD_ENDPOINTS=http://%s:2379", etcdIP),

		"-e", fmt.Sprintf("DATASTORE_TYPE=%s", datastoreType),

		"-e", fmt.Sprintf("KUBECONFIG=%s", kconfigfile),

		"-v", fmt.Sprintf("%s:%s", kconfigfile, kconfigfile),

		os.Getenv("CONTAINER_NAME"))

	return containers.Run("calico-kube-controllers",

		containers.RunOpts{AutoRemove: true},

		args...)

}

func ExpectNodeLabels(c client.Interface, labels map[string]string, node string) error {

	cn, err := c.Nodes().Get(context.Background(), node, options.GetOptions{})

	if err != nil {

		return err

	}


====================
)

func RunPolicyController(datastoreType apiconfig.DatastoreType, etcdIP, kconfigfile, ctrls string) *containers.Container {

	if ctrls == "" {

		// Default to all controllers.

		ctrls = "workloadendpoint,namespace,policy,node,serviceaccount"

	}

	return containers.Run("calico-kube-controllers",

		containers.RunOpts{AutoRemove: true},

		"-e", fmt.Sprintf("ETCD_ENDPOINTS=http://%s:2379", etcdIP),

		"-e", fmt.Sprintf("DATASTORE_TYPE=%s", datastoreType),

		"-e", fmt.Sprintf("ENABLED_CONTROLLERS=%s", ctrls),

		"-e", "LOG_LEVEL=debug",

		"-e", fmt.Sprintf("KUBECONFIG=%s", kconfigfile),

		"-e", "RECONCILER_PERIOD=10s",

		"-v", fmt.Sprintf("%s:%s", kconfigfile, kconfigfile),

		os.Getenv("CONTAINER_NAME"))

}

// Copyright (c) 2019 Tigera, Inc. All rights reserved.

//

// Licensed under the Apache License, Version 2.0 (the "License");


====================
func RunPolicyController(datastoreType apiconfig.DatastoreType, etcdIP, kconfigfile, ctrls string) *containers.Container {

	if ctrls == "" {

		// Default to all controllers.

		ctrls = "workloadendpoint,namespace,policy,node,serviceaccount"

	}

	return containers.Run("calico-kube-controllers",

		containers.RunOpts{AutoRemove: true},

		"-e", fmt.Sprintf("ETCD_ENDPOINTS=http://%s:2379", etcdIP),

		"-e", fmt.Sprintf("DATASTORE_TYPE=%s", datastoreType),

		"-e", fmt.Sprintf("ENABLED_CONTROLLERS=%s", ctrls),

		"-e", "LOG_LEVEL=debug",

		"-e", fmt.Sprintf("KUBECONFIG=%s", kconfigfile),

		"-e", "RECONCILER_PERIOD=10s",

		"-v", fmt.Sprintf("%s:%s", kconfigfile, kconfigfile),

		os.Getenv("CONTAINER_NAME"))

}

// Copyright (c) 2019 Tigera, Inc. All rights reserved.

//

// Licensed under the Apache License, Version 2.0 (the "License");

// you may not use this file except in compliance with the License.


====================
	if ctrls == "" {

		// Default to all controllers.

		ctrls = "workloadendpoint,namespace,policy,node,serviceaccount"

	}

	return containers.Run("calico-kube-controllers",

		containers.RunOpts{AutoRemove: true},

		"-e", fmt.Sprintf("ETCD_ENDPOINTS=http://%s:2379", etcdIP),

		"-e", fmt.Sprintf("DATASTORE_TYPE=%s", datastoreType),

		"-e", fmt.Sprintf("ENABLED_CONTROLLERS=%s", ctrls),

		"-e", "LOG_LEVEL=debug",

		"-e", fmt.Sprintf("KUBECONFIG=%s", kconfigfile),

		"-e", "RECONCILER_PERIOD=10s",

		"-v", fmt.Sprintf("%s:%s", kconfigfile, kconfigfile),

		os.Getenv("CONTAINER_NAME"))

}

// Copyright (c) 2019 Tigera, Inc. All rights reserved.

//

// Licensed under the Apache License, Version 2.0 (the "License");

// you may not use this file except in compliance with the License.

// You may obtain a copy of the License at


====================
		// Default to all controllers.

		ctrls = "workloadendpoint,namespace,policy,node,serviceaccount"

	}

	return containers.Run("calico-kube-controllers",

		containers.RunOpts{AutoRemove: true},

		"-e", fmt.Sprintf("ETCD_ENDPOINTS=http://%s:2379", etcdIP),

		"-e", fmt.Sprintf("DATASTORE_TYPE=%s", datastoreType),

		"-e", fmt.Sprintf("ENABLED_CONTROLLERS=%s", ctrls),

		"-e", "LOG_LEVEL=debug",

		"-e", fmt.Sprintf("KUBECONFIG=%s", kconfigfile),

		"-e", "RECONCILER_PERIOD=10s",

		"-v", fmt.Sprintf("%s:%s", kconfigfile, kconfigfile),

		os.Getenv("CONTAINER_NAME"))

}

// Copyright (c) 2019 Tigera, Inc. All rights reserved.

//

// Licensed under the Apache License, Version 2.0 (the "License");

// you may not use this file except in compliance with the License.

// You may obtain a copy of the License at

//


====================
		ctrls = "workloadendpoint,namespace,policy,node,serviceaccount"

	}

	return containers.Run("calico-kube-controllers",

		containers.RunOpts{AutoRemove: true},

		"-e", fmt.Sprintf("ETCD_ENDPOINTS=http://%s:2379", etcdIP),

		"-e", fmt.Sprintf("DATASTORE_TYPE=%s", datastoreType),

		"-e", fmt.Sprintf("ENABLED_CONTROLLERS=%s", ctrls),

		"-e", "LOG_LEVEL=debug",

		"-e", fmt.Sprintf("KUBECONFIG=%s", kconfigfile),

		"-e", "RECONCILER_PERIOD=10s",

		"-v", fmt.Sprintf("%s:%s", kconfigfile, kconfigfile),

		os.Getenv("CONTAINER_NAME"))

}

// Copyright (c) 2019 Tigera, Inc. All rights reserved.

//

// Licensed under the Apache License, Version 2.0 (the "License");

// you may not use this file except in compliance with the License.

// You may obtain a copy of the License at

//

//     http://www.apache.org/licenses/LICENSE-2.0


====================
	}

	return containers.Run("calico-kube-controllers",

		containers.RunOpts{AutoRemove: true},

		"-e", fmt.Sprintf("ETCD_ENDPOINTS=http://%s:2379", etcdIP),

		"-e", fmt.Sprintf("DATASTORE_TYPE=%s", datastoreType),

		"-e", fmt.Sprintf("ENABLED_CONTROLLERS=%s", ctrls),

		"-e", "LOG_LEVEL=debug",

		"-e", fmt.Sprintf("KUBECONFIG=%s", kconfigfile),

		"-e", "RECONCILER_PERIOD=10s",

		"-v", fmt.Sprintf("%s:%s", kconfigfile, kconfigfile),

		os.Getenv("CONTAINER_NAME"))

}

// Copyright (c) 2019 Tigera, Inc. All rights reserved.

//

// Licensed under the Apache License, Version 2.0 (the "License");

// you may not use this file except in compliance with the License.

// You may obtain a copy of the License at

//

//     http://www.apache.org/licenses/LICENSE-2.0

//


====================
)

// Run Flannel migration controller on a node.

func RunFlannelMigrationController(kconfigfile string, nodeName, subnetEnv string, waitBeforeStart, waitBeforeExit int) *containers.Container {

	return containers.Run("flannel-migration-controller",

		containers.RunOpts{AutoRemove: true},

		"--privileged",

		"-e", "DATASTORE_TYPE=kubernetes",

		"-e", "ENABLED_CONTROLLERS=flannelmigration",

		"-e", "LOG_LEVEL=debug",

		"-e", fmt.Sprintf("POD_NODE_NAME=%s", nodeName),

		"-e", fmt.Sprintf("FLANNEL_SUBNET_ENV=%s", subnetEnv),

		"-e", fmt.Sprintf("DEBUG_WAIT_BEFORE_START=%d", waitBeforeStart),

		"-e", fmt.Sprintf("DEBUG_WAIT_BEFORE_EXIT=%d", waitBeforeExit),

		"-e", fmt.Sprintf("KUBECONFIG=%s", kconfigfile),

		"-v", fmt.Sprintf("%s:%s", kconfigfile, kconfigfile),

		os.Getenv("MIGRATION_CONTAINER_NAME"))

}

type FlannelNode struct {

	PodCidr  string

	BackEnd  string


====================
// Run Flannel migration controller on a node.

func RunFlannelMigrationController(kconfigfile string, nodeName, subnetEnv string, waitBeforeStart, waitBeforeExit int) *containers.Container {

	return containers.Run("flannel-migration-controller",

		containers.RunOpts{AutoRemove: true},

		"--privileged",

		"-e", "DATASTORE_TYPE=kubernetes",

		"-e", "ENABLED_CONTROLLERS=flannelmigration",

		"-e", "LOG_LEVEL=debug",

		"-e", fmt.Sprintf("POD_NODE_NAME=%s", nodeName),

		"-e", fmt.Sprintf("FLANNEL_SUBNET_ENV=%s", subnetEnv),

		"-e", fmt.Sprintf("DEBUG_WAIT_BEFORE_START=%d", waitBeforeStart),

		"-e", fmt.Sprintf("DEBUG_WAIT_BEFORE_EXIT=%d", waitBeforeExit),

		"-e", fmt.Sprintf("KUBECONFIG=%s", kconfigfile),

		"-v", fmt.Sprintf("%s:%s", kconfigfile, kconfigfile),

		os.Getenv("MIGRATION_CONTAINER_NAME"))

}

type FlannelNode struct {

	PodCidr  string

	BackEnd  string

	VtepMac  string


====================
func RunFlannelMigrationController(kconfigfile string, nodeName, subnetEnv string, waitBeforeStart, waitBeforeExit int) *containers.Container {

	return containers.Run("flannel-migration-controller",

		containers.RunOpts{AutoRemove: true},

		"--privileged",

		"-e", "DATASTORE_TYPE=kubernetes",

		"-e", "ENABLED_CONTROLLERS=flannelmigration",

		"-e", "LOG_LEVEL=debug",

		"-e", fmt.Sprintf("POD_NODE_NAME=%s", nodeName),

		"-e", fmt.Sprintf("FLANNEL_SUBNET_ENV=%s", subnetEnv),

		"-e", fmt.Sprintf("DEBUG_WAIT_BEFORE_START=%d", waitBeforeStart),

		"-e", fmt.Sprintf("DEBUG_WAIT_BEFORE_EXIT=%d", waitBeforeExit),

		"-e", fmt.Sprintf("KUBECONFIG=%s", kconfigfile),

		"-v", fmt.Sprintf("%s:%s", kconfigfile, kconfigfile),

		os.Getenv("MIGRATION_CONTAINER_NAME"))

}

type FlannelNode struct {

	PodCidr  string

	BackEnd  string

	VtepMac  string

	PublicIP string


====================
	return containers.Run("flannel-migration-controller",

		containers.RunOpts{AutoRemove: true},

		"--privileged",

		"-e", "DATASTORE_TYPE=kubernetes",

		"-e", "ENABLED_CONTROLLERS=flannelmigration",

		"-e", "LOG_LEVEL=debug",

		"-e", fmt.Sprintf("POD_NODE_NAME=%s", nodeName),

		"-e", fmt.Sprintf("FLANNEL_SUBNET_ENV=%s", subnetEnv),

		"-e", fmt.Sprintf("DEBUG_WAIT_BEFORE_START=%d", waitBeforeStart),

		"-e", fmt.Sprintf("DEBUG_WAIT_BEFORE_EXIT=%d", waitBeforeExit),

		"-e", fmt.Sprintf("KUBECONFIG=%s", kconfigfile),

		"-v", fmt.Sprintf("%s:%s", kconfigfile, kconfigfile),

		os.Getenv("MIGRATION_CONTAINER_NAME"))

}

type FlannelNode struct {

	PodCidr  string

	BackEnd  string

	VtepMac  string

	PublicIP string

}


====================
		containers.RunOpts{AutoRemove: true},

		"--privileged",

		"-e", "DATASTORE_TYPE=kubernetes",

		"-e", "ENABLED_CONTROLLERS=flannelmigration",

		"-e", "LOG_LEVEL=debug",

		"-e", fmt.Sprintf("POD_NODE_NAME=%s", nodeName),

		"-e", fmt.Sprintf("FLANNEL_SUBNET_ENV=%s", subnetEnv),

		"-e", fmt.Sprintf("DEBUG_WAIT_BEFORE_START=%d", waitBeforeStart),

		"-e", fmt.Sprintf("DEBUG_WAIT_BEFORE_EXIT=%d", waitBeforeExit),

		"-e", fmt.Sprintf("KUBECONFIG=%s", kconfigfile),

		"-v", fmt.Sprintf("%s:%s", kconfigfile, kconfigfile),

		os.Getenv("MIGRATION_CONTAINER_NAME"))

}

type FlannelNode struct {

	PodCidr  string

	BackEnd  string

	VtepMac  string

	PublicIP string

}

func newFlannelNode(podCidr, backend, mac, ip string) FlannelNode {


====================
		"--privileged",

		"-e", "DATASTORE_TYPE=kubernetes",

		"-e", "ENABLED_CONTROLLERS=flannelmigration",

		"-e", "LOG_LEVEL=debug",

		"-e", fmt.Sprintf("POD_NODE_NAME=%s", nodeName),

		"-e", fmt.Sprintf("FLANNEL_SUBNET_ENV=%s", subnetEnv),

		"-e", fmt.Sprintf("DEBUG_WAIT_BEFORE_START=%d", waitBeforeStart),

		"-e", fmt.Sprintf("DEBUG_WAIT_BEFORE_EXIT=%d", waitBeforeExit),

		"-e", fmt.Sprintf("KUBECONFIG=%s", kconfigfile),

		"-v", fmt.Sprintf("%s:%s", kconfigfile, kconfigfile),

		os.Getenv("MIGRATION_CONTAINER_NAME"))

}

type FlannelNode struct {

	PodCidr  string

	BackEnd  string

	VtepMac  string

	PublicIP string

}

func newFlannelNode(podCidr, backend, mac, ip string) FlannelNode {

	return FlannelNode{


====================
			},

			Data: map[string]string{"veth_mtu": "1450"},

		},

		metav1.CreateOptions{})

	Expect(err).NotTo(HaveOccurred())

}

func (f *FlannelCluster) AddFlannelDaemonset(name string) {

	var gracePeriodSecs int64

	selector := metav1.LabelSelector{

		MatchLabels: map[string]string{"app": "flannel"},

	}

	ds := &appsv1.DaemonSet{

		ObjectMeta: metav1.ObjectMeta{

			Name:      name,

			Namespace: metav1.NamespaceSystem,

		},

		Spec: appsv1.DaemonSetSpec{

			Selector: &selector,

			Template: v1.PodTemplateSpec{

				ObjectMeta: metav1.ObjectMeta{


====================
		ObjectMeta: metav1.ObjectMeta{

			Name:      name,

			Namespace: metav1.NamespaceSystem,

		},

		Spec: appsv1.DaemonSetSpec{

			Selector: &selector,

			Template: v1.PodTemplateSpec{

				ObjectMeta: metav1.ObjectMeta{

					Labels: map[string]string{

						"app": "flannel",

					},

				},

				Spec: v1.PodSpec{

					Containers: []v1.Container{

						{

							Name:    "kube-flannel",

							Image:   "quay.io/coreos/flannel:v0.11.0-amd64",

							Command: []string{"/opt/bin/flanneld"},

						},

					},


====================
							},

						},

					},

					Containers: []v1.Container{

						{

							Name:  "calico-node",

							Image: "calico/node:v3.8.1",

						},

					},

					NodeSelector:                  map[string]string{"kubernetes.io/arch": "amd64", "projectcalico.org/node-network-during-migration": "calico"},

					NodeName:                      "random-name-to-avoid-schedule",

					Tolerations:                   []v1.Toleration{},

					TerminationGracePeriodSeconds: &gracePeriodSecs,

				},

			},

		},

	}

	_, err := f.k8sClient.AppsV1().DaemonSets(metav1.NamespaceSystem).Create(context.Background(), ds, metav1.CreateOptions{})

	Expect(err).NotTo(HaveOccurred())

}


====================
							Name:  "calico-node",

							Image: "calico/node:v3.8.1",

						},

						{

							Name:    "kube-flannel",

							Image:   "quay.io/coreos/flannel:v0.11.0-amd64",

							Command: []string{"/opt/bin/flanneld"},

						},

					},

					NodeSelector:                  map[string]string{"kubernetes.io/arch": "amd64", "projectcalico.org/node-network-during-migration": "calico"},

					NodeName:                      "random-name-to-avoid-schedule",

					Tolerations:                   []v1.Toleration{},

					TerminationGracePeriodSeconds: &gracePeriodSecs,

				},

			},

		},

	}

	_, err := f.k8sClient.AppsV1().DaemonSets(metav1.NamespaceSystem).Create(context.Background(), ds, metav1.CreateOptions{})

	Expect(err).NotTo(HaveOccurred())

}


====================
	if err != nil {

		if errors.IsNotFound(err) { // Node doesn't exist, so isn't being migrated.

			return false, nil

		}

		return false, fmt.Errorf("failed to check node for migration status: %w", err)

	}

	for labelName, labelVal := range node.ObjectMeta.Labels {

		// Check against labels used by the migration controller

		for migrationLabelName, migrationLabelValue := range flannelmigration.NodeNetworkCalico {

			// Only the label value "calico" specifies a migrated node where we can release the affinity

			if labelName == migrationLabelName && labelVal != migrationLabelValue {

				return true, nil

			}

		}

	}

	return false, nil

}

// kubernetesNodeForCalico returns the name of the Kubernetes node that corresponds to this Calico node.

// This function returns an empty string if no corresponding node could be found.

// Returns ErrorNotKubernetes if the given Calico node is not a Kubernetes node.


====================
		Expect(err).NotTo(HaveOccurred())

		// Wait for the apiserver to be available.

		Eventually(func() error {

			_, err := k8sClient.CoreV1().Namespaces().List(context.Background(), metav1.ListOptions{})

			return err

		}, 30*time.Second, 1*time.Second).Should(BeNil())

		// Apply the necessary CRDs. There can sometimes be a delay between starting

		// the API server and when CRDs are apply-able, so retry here.

		apply := func() error {

			out, err := apiserver.ExecOutput("kubectl", "apply", "-f", "/crds/")

			if err != nil {

				return fmt.Errorf("%s: %s", err, out)

			}

			return nil

		}

		Eventually(apply, 10*time.Second).ShouldNot(HaveOccurred())

		// Wait for the applied CRDs to become registered API resources.

		Eventually(func() error {

			crdDirEntries, err := os.ReadDir(os.Getenv("CRDS"))

			if err != nil {


====================
			return err

		}, 30*time.Second, 1*time.Second).Should(BeNil())

		Consistently(func() error {

			_, err := k8sClient.CoreV1().Namespaces().List(context.Background(), metav1.ListOptions{})

			return err

		}, 10*time.Second, 1*time.Second).Should(BeNil())

		// Apply the necessary CRDs. There can sometimes be a delay between starting

		// the API server and when CRDs are apply-able, so retry here.

		apply := func() error {

			out, err := apiserver.ExecOutput("kubectl", "apply", "-f", "/crds/")

			if err != nil {

				return fmt.Errorf("%s: %s", err, out)

			}

			return nil

		}

		Eventually(apply, 10*time.Second).ShouldNot(HaveOccurred())

		// Make a Calico client and backend client.

		type accessor interface {

			Backend() backend.Client

		}


====================
		Expect(err).NotTo(HaveOccurred())

		// Wait for the apiserver to be available.

		Eventually(func() error {

			_, err := k8sClient.CoreV1().Namespaces().List(context.Background(), metav1.ListOptions{})

			return err

		}, 30*time.Second, 1*time.Second).Should(BeNil())

		// Apply the necessary CRDs. There can sometimes be a delay between starting

		// the API server and when CRDs are apply-able, so retry here.

		apply := func() error {

			out, err := apiserver.ExecOutput("kubectl", "apply", "-f", "/crds/")

			if err != nil {

				return fmt.Errorf("%s: %s", err, out)

			}

			return nil

		}

		Eventually(apply, 10*time.Second).ShouldNot(HaveOccurred())

		// Make a Calico client and backend client.

		type accessor interface {

			Backend() backend.Client

		}


====================
		Expect(err).NotTo(HaveOccurred())

		// Wait for the apiserver to be available.

		Eventually(func() error {

			_, err := k8sClient.CoreV1().Namespaces().List(context.Background(), metav1.ListOptions{})

			return err

		}, 30*time.Second, 1*time.Second).Should(BeNil())

		// Apply the necessary CRDs. There can sometimes be a delay between starting

		// the API server and when CRDs are apply-able, so retry here.

		apply := func() error {

			out, err := apiserver.ExecOutput("kubectl", "apply", "-f", "/crds/")

			if err != nil {

				return fmt.Errorf("%s: %s", err, out)

			}

			return nil

		}

		Eventually(apply, 10*time.Second).ShouldNot(HaveOccurred())

		// Make a Calico client and backend client.

		type accessor interface {

			Backend() backend.Client

		}


====================
		Expect(err).NotTo(HaveOccurred())

		// Create a Calico node with a reference to it.

		cn := calicoNode(c, cNodeName, kNodeName, map[string]string{"calico-label": "calico-value", "label1": "badvalue"})

		_, err = c.Nodes().Create(context.Background(), cn, options.SetOptions{})

		Expect(err).NotTo(HaveOccurred())

		// Expect the node label to sync.

		expectedNodeLabels := map[string]string{"label1": "value1", "calico-label": "calico-value"}

		Eventually(func() error { return testutils.ExpectNodeLabels(c, expectedNodeLabels, cNodeName) },

			time.Second*15, 500*time.Millisecond).Should(BeNil())

		expectedHepName := cn.Name + "-auto-hep"

		// Expect a wildcard hostendpoint to be created.

		expectedHepLabels := map[string]string{

			"label1":                       "value1",

			"calico-label":                 "calico-value",

			"projectcalico.org/created-by": "calico-kube-controllers",

		}

		expectedIPs := []string{"172.16.1.1", "fe80::1", "192.168.100.1"}

		Eventually(func() error {

			return testutils.ExpectHostendpoint(c, expectedHepName, expectedHepLabels, expectedIPs, autoHepProfiles)

		}, time.Second*15, 500*time.Millisecond).Should(BeNil())


====================
		nodeController = testutils.RunNodeController(apiconfig.EtcdV3, etcd.IP, kconfigFile.Name(), true)

		labels := map[string]string{"calico-label": "calico-value", "calico-label2": "value2"}

		// Create a Calico node with a reference to an non-existent k8s node.

		cn := calicoNode(c, cNodeName, kNodeName, labels)

		_, err := c.Nodes().Create(context.Background(), cn, options.SetOptions{})

		Expect(err).NotTo(HaveOccurred())

		// Expect the node label to sync.

		Eventually(func() error { return testutils.ExpectNodeLabels(c, labels, cNodeName) },

			time.Second*15, 500*time.Millisecond).Should(BeNil())

		expectedHepName := cn.Name + "-auto-hep"

		// Expect a wildcard hostendpoint to be created.

		expectedHepLabels := labels

		expectedHepLabels["projectcalico.org/created-by"] = "calico-kube-controllers"

		expectedIPs := []string{"172.16.1.1", "fe80::1", "192.168.100.1"}

		Eventually(func() error {

			return testutils.ExpectHostendpoint(c, expectedHepName, expectedHepLabels, expectedIPs, autoHepProfiles)

		}, time.Second*15, 500*time.Millisecond).Should(BeNil())

	})

	It("should clean up dangling hostendpoints and create hostendpoints for nodes without them", func() {

		// Create a wildcard HEP that matches what might have been created


====================
			time.Second*2, 500*time.Millisecond).Should(BeNil())

		// Expect the user's own hostendpoint to still exist.

		// (Empty values in the hostendpoint spec are nil slices)

		var noExpectedIPs []string

		var noProfiles []string

		Eventually(func() error {

			return testutils.ExpectHostendpoint(c, userHep.Name, map[string]string{"env": "staging"}, noExpectedIPs, noProfiles)

		}, time.Second*15, 500*time.Millisecond).Should(BeNil())

		// Expect an auto hostendpoint was created for the Calico node.

		autoHepName := cNodeName + "-auto-hep"

		expectedIPs := []string{"172.16.1.1", "fe80::1", "192.168.100.1"}

		expectedHepLabels := map[string]string{

			"auto":                         "hep",

			"projectcalico.org/created-by": "calico-kube-controllers",

		}

		Eventually(func() error {

			return testutils.ExpectHostendpoint(c, autoHepName, expectedHepLabels, expectedIPs, autoHepProfiles)

		}, time.Second*15, 500*time.Millisecond).Should(BeNil())

	})

	It("should delete hostendpoints when AUTO_HOST_ENDPOINTS is disabled", func() {


====================
			OrchRefs: []libapi.OrchRef{

				{

					NodeName:     kNodeName,

					Orchestrator: "k8s",

				},

			},

		}

		_, err = c.Nodes().Create(context.Background(), cn, options.SetOptions{})

		Expect(err).NotTo(HaveOccurred())

		expectedHepName := cn.Name + "-auto-hep"

		// Expect a wildcard hostendpoint to be created.

		expectedIPs := []string{"172.16.1.1", "fe80::1", "192.168.100.1"}

		expectedHepLabels := map[string]string{

			"label1":                       "value1",

			"calico-label":                 "calico-value",

			"projectcalico.org/created-by": "calico-kube-controllers",

		}

		Eventually(func() error {

			return testutils.ExpectHostendpoint(c, expectedHepName, expectedHepLabels, expectedIPs, autoHepProfiles)

		}, time.Second*15, 500*time.Millisecond).Should(BeNil())


====================
// Run a pod with a host path volume on specified node. Wait till it is completed.

// Return error with log if for any reason pod not completed successfully.

func (p k8spod) RunPodOnNodeTillComplete(k8sClientset *kubernetes.Clientset, namespace, imageName, nodeName, shellCmd, hostPath string, privileged, hostNetwork bool) (string, error) {

	podName := string(p)

	containerName := podName

	hostPathDirectory := v1.HostPathDirectory

	log.Infof("Create pod on node %s to run [ %s ].", nodeName, shellCmd)

	podSpec := &v1.Pod{

		ObjectMeta: metav1.ObjectMeta{

			GenerateName: podName + "-",

			Labels: map[string]string{

				"flannel-migration": nodeName,

			},

		},

		Spec: v1.PodSpec{

			Containers: []v1.Container{

				{

					Name:    containerName,

					Image:   imageName,

					Command: []string{"/bin/sh"},


====================
			},

		},

		Spec: v1.PodSpec{

			Containers: []v1.Container{

				{

					Name:    containerName,

					Image:   imageName,

					Command: []string{"/bin/sh"},

					Args: []string{

						"-c",

						shellCmd,

					},

					VolumeMounts: []v1.VolumeMount{

						{

							Name:      "host-dir",

							MountPath: fmt.Sprintf("/host/%s", hostPath),

						},

					},

					SecurityContext: &v1.SecurityContext{Privileged: &privileged},

				},


====================
	}

	if !found {

		// Can not find pod.

		return "", fmt.Errorf("Failed to execute command in pod. Can not find pod with label in %v on node %s", label, nodeName)

	}

	if !isPodRunningAndReady(&pod) {

		// Pod is not running and ready.

		return "", fmt.Errorf("Failed to execute command in pod. Pod %s is not ready.", pod.Name)

	}

	cmdArgs := []string{"exec", pod.Name, fmt.Sprintf("--namespace=%s", namespace), fmt.Sprintf("-c=%s", containerName), "--"}

	cmdArgs = append(cmdArgs, args...)

	out, err := exec.Command("/usr/bin/kubectl", cmdArgs...).CombinedOutput()

	if err != nil {

		log.Errorf("Kubectl exec %s(%s) error. \n ---%v--- \n%s\n ------", pod.Name, containerName, cmdArgs, string(out))

		return "", err

	}

	log.Infof("Kubectl exec %s(%s) completed successfully. \n ---%v--- \n%s\n ------", pod.Name, containerName, cmdArgs, string(out))

	return string(out), nil

}

func (n k8snode) Drain() error {


====================
		return "", err

	}

	log.Infof("Kubectl exec %s(%s) completed successfully. \n ---%v--- \n%s\n ------", pod.Name, containerName, cmdArgs, string(out))

	return string(out), nil

}

func (n k8snode) Drain() error {

	nodeName := string(n)

	log.Infof("Start drain node %s", nodeName)

	out, err := exec.Command("/usr/bin/kubectl", "drain",

		"--ignore-daemonsets", "--delete-local-data", "--force", nodeName).CombinedOutput()

	if err != nil {

		log.Errorf("Drain node %s. \n ---Drain Node--- \n%s\n ------", nodeName, string(out))

		return err

	}

	log.Infof("Drain node %s completed successfully. \n ---Drain Node Logs--- \n%s\n ------", nodeName, string(out))

	return nil

}

func (n k8snode) Uncordon() error {

	nodeName := string(n)

	log.Infof("Start uncordon node %s", nodeName)


====================
	if err != nil {

		log.Errorf("Uncordon node %s. \n ---Uncordon Node Logs--- \n%s\n ------", nodeName, string(out))

		return err

	}

	log.Infof("Uncordon node %s completed successfully.", nodeName)

	return nil

}

func removeLabelForAllNodes(key string) error {

	log.Infof("Start remove node label %s", key)

	out, err := exec.Command("/usr/bin/kubectl", "label", "node", key+"-", "--all").CombinedOutput()

	if err != nil {

		log.Errorf("Remove label node %s. \n ---Remove Node Label Logs--- \n %s \n ------", key, string(out))

		return err

	}

	log.Infof("Remove node label %s completed successfully.", key)

	return nil

}

// Get value of a node label.

// If node does not have that label, return empty string and error.

func getNodeLabelValue(node *v1.Node, key string) (string, error) {


====================
	flannelContainerName       = "kube-flannel"

)

// Flannel migration controller consists of three major components.

// IPAM Migrator who setups Calico IPAM based on Flannel network configurations.

// Network Migrator who removes Flannel vxlan data plane and allow Calico vxlan network to be setup on nodes.

// Main controller logic controls the entire migration process and handle new node events.

var (

	// nodeNetworkFlannel is a map value indicates a node is still part of Flannel vxlan network.

	// This is used both as a nodeSelector for Flannel daemonset and a label for a node.

	nodeNetworkFlannel = map[string]string{migrationNodeSelectorKey: "flannel"}

	// NodeNetworkCalico is a map value indicates a node is becoming part of Calico vxlan network.

	// This is used both as a nodeSelector for Calico daemonset and a label for a node.

	NodeNetworkCalico = map[string]string{migrationNodeSelectorKey: "calico"}

	// nodeNetworkNone is a map value indicates there should be neither Flannel nor Calico running on the node.

	nodeNetworkNone = map[string]string{migrationNodeSelectorKey: "none"}

	// nodeMigrationInProgress is a map value indicates a node is running network migration.

	nodeMigrationInProgress = map[string]string{migrationNodeInProgressKey: "true"}

	// Possible Labels for Flannel daemonset pod.

	flannelPodLabel = map[string]string{"app": "flannel", "k8s-app": "flannel"}

	// Label for Canal daemonset pod.


====================
// IPAM Migrator who setups Calico IPAM based on Flannel network configurations.

// Network Migrator who removes Flannel vxlan data plane and allow Calico vxlan network to be setup on nodes.

// Main controller logic controls the entire migration process and handle new node events.

var (

	// nodeNetworkFlannel is a map value indicates a node is still part of Flannel vxlan network.

	// This is used both as a nodeSelector for Flannel daemonset and a label for a node.

	nodeNetworkFlannel = map[string]string{migrationNodeSelectorKey: "flannel"}

	// NodeNetworkCalico is a map value indicates a node is becoming part of Calico vxlan network.

	// This is used both as a nodeSelector for Calico daemonset and a label for a node.

	NodeNetworkCalico = map[string]string{migrationNodeSelectorKey: "calico"}

	// nodeNetworkNone is a map value indicates there should be neither Flannel nor Calico running on the node.

	nodeNetworkNone = map[string]string{migrationNodeSelectorKey: "none"}

	// nodeMigrationInProgress is a map value indicates a node is running network migration.

	nodeMigrationInProgress = map[string]string{migrationNodeInProgressKey: "true"}

	// Possible Labels for Flannel daemonset pod.

	flannelPodLabel = map[string]string{"app": "flannel", "k8s-app": "flannel"}

	// Label for Canal daemonset pod.

	canalPodLabel = map[string]string{"k8s-app": "canal"}

	// Label for Calico daemonset pod.

	calicoPodLabel = map[string]string{"k8s-app": "calico-node"}


====================
	nodeNetworkFlannel = map[string]string{migrationNodeSelectorKey: "flannel"}

	// NodeNetworkCalico is a map value indicates a node is becoming part of Calico vxlan network.

	// This is used both as a nodeSelector for Calico daemonset and a label for a node.

	NodeNetworkCalico = map[string]string{migrationNodeSelectorKey: "calico"}

	// nodeNetworkNone is a map value indicates there should be neither Flannel nor Calico running on the node.

	nodeNetworkNone = map[string]string{migrationNodeSelectorKey: "none"}

	// nodeMigrationInProgress is a map value indicates a node is running network migration.

	nodeMigrationInProgress = map[string]string{migrationNodeInProgressKey: "true"}

	// Possible Labels for Flannel daemonset pod.

	flannelPodLabel = map[string]string{"app": "flannel", "k8s-app": "flannel"}

	// Label for Canal daemonset pod.

	canalPodLabel = map[string]string{"k8s-app": "canal"}

	// Label for Calico daemonset pod.

	calicoPodLabel = map[string]string{"k8s-app": "calico-node"}

)

// flannelMigrationController implements the Controller interface.

type flannelMigrationController struct {

	ctx          context.Context

	informer     cache.Controller

	indexer      cache.Indexer


====================
	// The controller will start ipam and network migration for all cases except case 5.

	// Work out list of nodes not running Calico. It could happen that all nodes are running Calico and it returns an empty list.

	items := c.indexer.List()

	var controllerNodes []*v1.Node

	var masterNodes []*v1.Node

	for _, obj := range items {

		node := obj.(*v1.Node)

		migrationInProgress, _ := getNodeLabelValue(node, migrationNodeInProgressKey)

		network, _ := getNodeLabelValue(node, migrationNodeSelectorKey)

		if network != "calico" || migrationInProgress == "true" {

			if network != "calico" && network != "none" {

				// Allow Flannel to run if the node is not starting to run Calico or Flannel network has been removed.

				n := k8snode(node.Name)

				if err := n.addNodeLabels(c.k8sClientset, nodeNetworkFlannel); err != nil {

					log.WithError(err).Errorf("Error adding node label to node %s.", node.Name)

					return []*v1.Node{}, err

				}

			}

			addToList := true

			// check if migration controller is running on this node.


====================
	// Work out list of nodes not running Calico. It could happen that all nodes are running Calico and it returns an empty list.

	items := c.indexer.List()

	var controllerNodes []*v1.Node

	var masterNodes []*v1.Node

	for _, obj := range items {

		node := obj.(*v1.Node)

		migrationInProgress, _ := getNodeLabelValue(node, migrationNodeInProgressKey)

		network, _ := getNodeLabelValue(node, migrationNodeSelectorKey)

		if network != "calico" || migrationInProgress == "true" {

			if network != "calico" && network != "none" {

				// Allow Flannel to run if the node is not starting to run Calico or Flannel network has been removed.

				n := k8snode(node.Name)

				if err := n.addNodeLabels(c.k8sClientset, nodeNetworkFlannel); err != nil {

					log.WithError(err).Errorf("Error adding node label to node %s.", node.Name)

					return []*v1.Node{}, err

				}

			}

			addToList := true

			// check if migration controller is running on this node.

			// If it is, make sure it is the last node we try to process.


====================
	if len(controllerNodes) != 0 {

		for _, cn := range controllerNodes {

			if !nodeInList(cn, masterNodes) {

				log.Infof("Adding node hosting migration controller to end of queue: %s", cn)

				nodes = append(nodes, cn)

			}

		}

	}

	// At this point, any node would have a "projectcalico.org/node-network-during-migration" label.

	// The value is either "flannel" or "calico".

	// Start IPAM migration.

	err := c.ipamMigrator.MigrateNodes(nodes)

	if err != nil {

		log.WithError(err).Errorf("Error running ipam migration for nodes.")

		return nodes, err

	}

	return nodes, nil

}

func nodeInList(node *v1.Node, nodes []*v1.Node) bool {

	for _, n := range nodes {


====================
		Expect(err).NotTo(HaveOccurred())

		// Wait for the apiserver to be available.

		Eventually(func() error {

			_, err := k8sClient.CoreV1().Namespaces().List(context.Background(), metav1.ListOptions{})

			return err

		}, 30*time.Second, 1*time.Second).Should(BeNil())

		// Apply the necessary CRDs. There can sometimes be a delay between starting

		// the API server and when CRDs are apply-able, so retry here.

		apply := func() error {

			out, err := apiserver.ExecOutput("kubectl", "apply", "-f", "/crds/")

			if err != nil {

				return fmt.Errorf("%s: %s", err, out)

			}

			return nil

		}

		Eventually(apply, 10*time.Second).ShouldNot(HaveOccurred())

		// Make a Calico client and backend client.

		type accessor interface {

			Backend() backend.Client

		}


====================
		apiserver.Stop()

		etcd.Stop()

	})

	Context("Should migrate FV tests", func() {

		AfterEach(func() {

			migrationController.Stop()

		})

		It("Should report nothing to do if Flannel daemonset not exists", func() {

			// remove flannel daemonset

			_, err := apiserver.ExecOutput("kubectl", "delete", "daemonset", flannelDs, "-n", "kube-system")

			Expect(err).ShouldNot(HaveOccurred())

			startController()

			w := migrationController.WatchStderrFor(regexp.MustCompile(`.*no migration process is needed.*`))

			Eventually(w, "10s").Should(BeClosed(),

				"Timed out waiting for migration controller report 'no migration process is needed'")

		})

		It("Should report error if Flannel daemonset has addon manager label", func() {

			// add addon manager label

			_, err := apiserver.ExecOutput("kubectl", "label", "daemonset", flannelDs, "-n", "kube-system", "addonmanager.kubernetes.io/mode=EnsureExists")

			Expect(err).ShouldNot(HaveOccurred())


====================
			_, err := apiserver.ExecOutput("kubectl", "delete", "daemonset", flannelDs, "-n", "kube-system")

			Expect(err).ShouldNot(HaveOccurred())

			startController()

			w := migrationController.WatchStderrFor(regexp.MustCompile(`.*no migration process is needed.*`))

			Eventually(w, "10s").Should(BeClosed(),

				"Timed out waiting for migration controller report 'no migration process is needed'")

		})

		It("Should report error if Flannel daemonset has addon manager label", func() {

			// add addon manager label

			_, err := apiserver.ExecOutput("kubectl", "label", "daemonset", flannelDs, "-n", "kube-system", "addonmanager.kubernetes.io/mode=EnsureExists")

			Expect(err).ShouldNot(HaveOccurred())

			startController()

			w := migrationController.WatchStderrFor(regexp.MustCompile(`.*abort migration process.*`))

			Eventually(w, "10s").Should(BeClosed(),

				"Timed out waiting for migration controller report 'abort migration process'")

		})

	})

	Context("IPAM migrate FV tests", func() {

		checkCalicoIPAM := func() {

			// Wait for ipam migration is done.


====================
			p := api.NewIPPool()

			p.Name = "default-ipv4-ippool"

			p.Spec.CIDR = "192.168.0.0/16"

			p.Spec.BlockSize = 26

			p.Spec.NodeSelector = "all()"

			p.Spec.Disabled = false

			_, err := calicoClient.IPPools().Create(context.Background(), p, options.SetOptions{})

			Expect(err).NotTo(HaveOccurred())

			// Remove flannel daemonset, add Canal daemonet.

			_, err = apiserver.ExecOutput("kubectl", "delete", "daemonset", flannelDs, "-n", "kube-system")

			Expect(err).ShouldNot(HaveOccurred())

			flannelCluster.AddCanalDaemonset("canal")

			startController()

			checkCalicoIPAM()

		})

	})

	Context("Node ordering FV tests", func() {

		checkNodeOrdering := func() {

			// Set watch for node index.

			w0 := migrationController.WatchStderrFor(regexp.MustCompile(`.*node-2\[index 0\].*`))


====================
		logrus.WithFields(logrus.Fields{

			"numFailedAdds":    netPolsToAdd.Len(),

			"numFailedRemoves": netPolsToRemove.Len(),

		}).Error("Not all VXLAN route updates succeeded.")

		return ErrUpdatesFailed

	}

	return nil

}

func macToWindowsFormat(linuxFormat string) string {

	windowsFormat := strings.Replace(linuxFormat, ":", "-", -1)

	return windowsFormat

}

// Copyright (c) 2019-2020 Tigera, Inc. All rights reserved.

//

// Licensed under the Apache License, Version 2.0 (the "License");

// you may not use this file except in compliance with the License.

// You may obtain a copy of the License at

//

//     http://www.apache.org/licenses/LICENSE-2.0

//


====================
	}

	if (p.Action != hns.Allow) && (p.Action != hns.Block) {

		return nil, fmt.Errorf("'Action' %s is invalid", p.Action)

	}

	if (p.Direction != hns.In) && (p.Direction != hns.Out) {

		return nil, fmt.Errorf("'Direction' %s is invalid", p.Direction)

	}

	return &hns.ACLPolicy{

		Type:            p.Type,

		Id:              prefix + "-" + p.Id,

		Protocol:        p.Protocol,

		Action:          p.Action,

		Direction:       p.Direction,

		LocalAddresses:  p.LocalAddresses,

		RemoteAddresses: p.RemoteAddresses,

		LocalPorts:      p.LocalPorts,

		RemotePorts:     p.RemotePorts,

		RuleType:        p.RuleType,

		Priority:        p.Priority,

	}, nil


====================
	if err != nil {

		return fmt.Errorf("failed to update jump map: %w", err)

	}

	return nil

}

func FindJumpMap(progID int, ifaceName string) (mapFD bpf.MapFD, err error) {

	logCtx := log.WithField("progID", progID).WithField("iface", ifaceName)

	logCtx.Debugf("Looking up jump map")

	bpftool := exec.Command("bpftool", "prog", "show", "id",

		fmt.Sprintf("%d", progID), "--json")

	output, err := bpftool.Output()

	if err != nil {

		// We can hit this case if the interface was deleted underneath us; check that it's still there.

		if _, err := os.Stat(fmt.Sprintf("/proc/sys/net/ipv4/conf/%s", ifaceName)); os.IsNotExist(err) {

			return 0, tc.ErrDeviceNotFound

		}

		return 0, fmt.Errorf("failed to get map metadata: %w out=\n%v", err, string(output))

	}

	var prog struct {

		MapIDs []int `json:"map_ids"`


====================
			inRules = append(inRules, iptables.Rule{

				Match:   iptables.Match(),

				Action:  iptables.DropAction{},

				Comment: []string{"Drop if no profiles matched"},

			})

		}

		if tableKind == "preDNAT" {

			chains = append(chains,

				&iptables.Chain{

					Name:  inPrefix[:6] + hostOrWlLetter + "-" + ifaceName,

					Rules: inRules,

				},

			)

		} else {

			chains = append(chains,

				&iptables.Chain{

					Name:  outPrefix[:6] + hostOrWlLetter + "-" + ifaceName,

					Rules: outRules,

				},

			)


====================
			chains = append(chains,

				&iptables.Chain{

					Name:  inPrefix[:6] + hostOrWlLetter + "-" + ifaceName,

					Rules: inRules,

				},

			)

		} else {

			chains = append(chains,

				&iptables.Chain{

					Name:  outPrefix[:6] + hostOrWlLetter + "-" + ifaceName,

					Rules: outRules,

				},

			)

			if !egressOnly {

				chains = append(chains,

					&iptables.Chain{

						Name:  inPrefix[:6] + hostOrWlLetter + "-" + ifaceName,

						Rules: inRules,

					},

				)


====================
			chains = append(chains,

				&iptables.Chain{

					Name:  outPrefix[:6] + hostOrWlLetter + "-" + ifaceName,

					Rules: outRules,

				},

			)

			if !egressOnly {

				chains = append(chains,

					&iptables.Chain{

						Name:  inPrefix[:6] + hostOrWlLetter + "-" + ifaceName,

						Rules: inRules,

					},

				)

			}

		}

		if host {

			dispatchOut = append(dispatchOut,

				iptables.Rule{

					Match:  iptables.Match().OutInterface(ifaceName),

					Action: iptables.GotoAction{Target: outPrefix[:6] + hostOrWlLetter + "-" + ifaceName},


====================
						Rules: inRules,

					},

				)

			}

		}

		if host {

			dispatchOut = append(dispatchOut,

				iptables.Rule{

					Match:  iptables.Match().OutInterface(ifaceName),

					Action: iptables.GotoAction{Target: outPrefix[:6] + hostOrWlLetter + "-" + ifaceName},

				},

			)

			if !egressOnly {

				dispatchIn = append(dispatchIn,

					iptables.Rule{

						Match:  iptables.Match().InInterface(ifaceName),

						Action: iptables.GotoAction{Target: inPrefix[:6] + hostOrWlLetter + "-" + ifaceName},

					},

				)

			}


====================
				iptables.Rule{

					Match:  iptables.Match().OutInterface(ifaceName),

					Action: iptables.GotoAction{Target: outPrefix[:6] + hostOrWlLetter + "-" + ifaceName},

				},

			)

			if !egressOnly {

				dispatchIn = append(dispatchIn,

					iptables.Rule{

						Match:  iptables.Match().InInterface(ifaceName),

						Action: iptables.GotoAction{Target: inPrefix[:6] + hostOrWlLetter + "-" + ifaceName},

					},

				)

			}

		} else {

			dispatchOut = append(dispatchOut,

				iptables.Rule{

					Match:  iptables.Match().InInterface(ifaceName),

					Action: iptables.GotoAction{Target: outPrefix[:6] + hostOrWlLetter + "-" + ifaceName},

				},

			)


====================
						Match:  iptables.Match().InInterface(ifaceName),

						Action: iptables.GotoAction{Target: inPrefix[:6] + hostOrWlLetter + "-" + ifaceName},

					},

				)

			}

		} else {

			dispatchOut = append(dispatchOut,

				iptables.Rule{

					Match:  iptables.Match().InInterface(ifaceName),

					Action: iptables.GotoAction{Target: outPrefix[:6] + hostOrWlLetter + "-" + ifaceName},

				},

			)

			dispatchIn = append(dispatchIn,

				iptables.Rule{

					Match:  iptables.Match().OutInterface(ifaceName),

					Action: iptables.GotoAction{Target: inPrefix[:6] + hostOrWlLetter + "-" + ifaceName},

				},

			)

		}

		if tableKind != "preDNAT" && tableKind != "untracked" && !egressOnly {


====================
			dispatchOut = append(dispatchOut,

				iptables.Rule{

					Match:  iptables.Match().InInterface(ifaceName),

					Action: iptables.GotoAction{Target: outPrefix[:6] + hostOrWlLetter + "-" + ifaceName},

				},

			)

			dispatchIn = append(dispatchIn,

				iptables.Rule{

					Match:  iptables.Match().OutInterface(ifaceName),

					Action: iptables.GotoAction{Target: inPrefix[:6] + hostOrWlLetter + "-" + ifaceName},

				},

			)

		}

		if tableKind != "preDNAT" && tableKind != "untracked" && !egressOnly {

			chains = append(chains,

				&iptables.Chain{

					Name: epMarkSetOnePrefix + ifaceName,

					Rules: []iptables.Rule{

						iptables.Rule{

							Action: iptables.SetMaskedMarkAction{Mark: epMark, Mask: epMarkMapper.GetMask()},


====================
			epMarkSet = append(epMarkSet,

				iptables.Rule{

					Match:  iptables.Match().InInterface(ifaceName),

					Action: iptables.GotoAction{Target: epMarkSetOnePrefix + ifaceName},

				},

			)

			epMarkFrom = append(epMarkFrom,

				iptables.Rule{

					Match:  iptables.Match().MarkMatchesWithMask(epMark, epMarkMapper.GetMask()),

					Action: iptables.GotoAction{Target: epmarkFromPrefix + hostOrWlLetter + "-" + ifaceName},

				},

			)

		}

	}

	if !host {

		dispatchOut = append(dispatchOut,

			iptables.Rule{

				Match:   iptables.Match(),

				Action:  iptables.DropAction{},

				Comment: []string{"Unknown interface"},


====================
func (m MatchCriteria) InInterface(ifaceMatch string) MatchCriteria {

	return append(m, fmt.Sprintf("--in-interface %s", ifaceMatch))

}

func (m MatchCriteria) OutInterface(ifaceMatch string) MatchCriteria {

	return append(m, fmt.Sprintf("--out-interface %s", ifaceMatch))

}

func (m MatchCriteria) RPFCheckPassed(acceptLocal bool) MatchCriteria {

	ret := append(m, "-m rpfilter --validmark")

	if acceptLocal {

		ret = append(ret, "--accept-local")

	}

	return ret

}

func (m MatchCriteria) RPFCheckFailed(acceptLocal bool) MatchCriteria {

	ret := append(m, "-m rpfilter --invert --validmark")

	if acceptLocal {

		ret = append(ret, "--accept-local")

	}

	return ret

}


====================
	ret := append(m, "-m rpfilter --validmark")

	if acceptLocal {

		ret = append(ret, "--accept-local")

	}

	return ret

}

func (m MatchCriteria) RPFCheckFailed(acceptLocal bool) MatchCriteria {

	ret := append(m, "-m rpfilter --invert --validmark")

	if acceptLocal {

		ret = append(ret, "--accept-local")

	}

	return ret

}

func (m MatchCriteria) IPVSConnection() MatchCriteria {

	return append(m, "-m ipvs --ipvs")

}

func (m MatchCriteria) NotIPVSConnection() MatchCriteria {

	return append(m, "-m ipvs ! --ipvs")

}

type AddrType string


====================
	return append(m, fmt.Sprintf("-m set --match-set %s dst,dst", name))

}

func (m MatchCriteria) NotDestIPPortSet(name string) MatchCriteria {

	return append(m, fmt.Sprintf("-m set ! --match-set %s dst,dst", name))

}

func (m MatchCriteria) IPSetNames() (ipSetNames []string) {

	for _, matchString := range []string(m) {

		words := strings.Split(matchString, " ")

		for i := range words {

			if words[i] == "--match-set" && (i+1) < len(words) {

				ipSetNames = append(ipSetNames, words[i+1])

			}

		}

	}

	return

}

func (m MatchCriteria) SourcePorts(ports ...uint16) MatchCriteria {

	portsString := PortsToMultiport(ports)

	return append(m, fmt.Sprintf("-m multiport --source-ports %s", portsString))

}


====================
	HashLength = 16

)

type Rule struct {

	Match   MatchCriteria

	Action  Action

	Comment []string

}

func (r Rule) RenderAppend(chainName, prefixFragment string, features *environment.Features) string {

	fragments := make([]string, 0, 6)

	fragments = append(fragments, "-A", chainName)

	return r.renderInner(fragments, prefixFragment, features)

}

func (r Rule) RenderInsert(chainName, prefixFragment string, features *environment.Features) string {

	fragments := make([]string, 0, 6)

	fragments = append(fragments, "-I", chainName)

	return r.renderInner(fragments, prefixFragment, features)

}

func (r Rule) RenderInsertAtRuleNumber(chainName string, ruleNum int, prefixFragment string, features *environment.Features) string {

	fragments := make([]string, 0, 7)

	fragments = append(fragments, "-I", chainName, fmt.Sprintf("%d", ruleNum))


====================
	Comment []string

}

func (r Rule) RenderAppend(chainName, prefixFragment string, features *environment.Features) string {

	fragments := make([]string, 0, 6)

	fragments = append(fragments, "-A", chainName)

	return r.renderInner(fragments, prefixFragment, features)

}

func (r Rule) RenderInsert(chainName, prefixFragment string, features *environment.Features) string {

	fragments := make([]string, 0, 6)

	fragments = append(fragments, "-I", chainName)

	return r.renderInner(fragments, prefixFragment, features)

}

func (r Rule) RenderInsertAtRuleNumber(chainName string, ruleNum int, prefixFragment string, features *environment.Features) string {

	fragments := make([]string, 0, 7)

	fragments = append(fragments, "-I", chainName, fmt.Sprintf("%d", ruleNum))

	return r.renderInner(fragments, prefixFragment, features)

}

func (r Rule) RenderReplace(chainName string, ruleNum int, prefixFragment string, features *environment.Features) string {

	fragments := make([]string, 0, 7)

	fragments = append(fragments, "-R", chainName, fmt.Sprintf("%d", ruleNum))


====================
	return r.renderInner(fragments, prefixFragment, features)

}

func (r Rule) RenderInsert(chainName, prefixFragment string, features *environment.Features) string {

	fragments := make([]string, 0, 6)

	fragments = append(fragments, "-I", chainName)

	return r.renderInner(fragments, prefixFragment, features)

}

func (r Rule) RenderInsertAtRuleNumber(chainName string, ruleNum int, prefixFragment string, features *environment.Features) string {

	fragments := make([]string, 0, 7)

	fragments = append(fragments, "-I", chainName, fmt.Sprintf("%d", ruleNum))

	return r.renderInner(fragments, prefixFragment, features)

}

func (r Rule) RenderReplace(chainName string, ruleNum int, prefixFragment string, features *environment.Features) string {

	fragments := make([]string, 0, 7)

	fragments = append(fragments, "-R", chainName, fmt.Sprintf("%d", ruleNum))

	return r.renderInner(fragments, prefixFragment, features)

}

func (r Rule) renderInner(fragments []string, prefixFragment string, features *environment.Features) string {

	if prefixFragment != "" {

		fragments = append(fragments, prefixFragment)


====================
	return r.renderInner(fragments, prefixFragment, features)

}

func (r Rule) RenderInsertAtRuleNumber(chainName string, ruleNum int, prefixFragment string, features *environment.Features) string {

	fragments := make([]string, 0, 7)

	fragments = append(fragments, "-I", chainName, fmt.Sprintf("%d", ruleNum))

	return r.renderInner(fragments, prefixFragment, features)

}

func (r Rule) RenderReplace(chainName string, ruleNum int, prefixFragment string, features *environment.Features) string {

	fragments := make([]string, 0, 7)

	fragments = append(fragments, "-R", chainName, fmt.Sprintf("%d", ruleNum))

	return r.renderInner(fragments, prefixFragment, features)

}

func (r Rule) renderInner(fragments []string, prefixFragment string, features *environment.Features) string {

	if prefixFragment != "" {

		fragments = append(fragments, prefixFragment)

	}

	for _, c := range r.Comment {

		c = escapeComment(c)

		c = truncateComment(c)

		commentFragment := fmt.Sprintf("-m comment --comment \"%s\"", c)


====================
			log.WithFields(log.Fields{

				"ruleFragment": ruleForHashing,

				"action":       rule.Action,

				"position":     ii,

				"chain":        c.Name,

			}).WithError(err).Panic("Failed to write rule for hashing.")

		}

		hash = s.Sum(hash[0:0])

		// Encode the hash using a compact character set.  We use the URL-safe base64

		// variant because it uses '-' and '_', which are more shell-friendly.

		hashes[ii] = base64.RawURLEncoding.EncodeToString(hash)[:HashLength]

		if log.GetLevel() >= log.DebugLevel {

			log.WithFields(log.Fields{

				"ruleFragment": ruleForHashing,

				"action":       rule.Action,

				"position":     ii,

				"chain":        c.Name,

				"hash":         hashes[ii],

			}).Debug("Hashed rule")

		}


====================
		Expect(hashes).To(Equal(map[string][]string{

			"FORWARD": {

				"OLD INSERT RULE",

				"",

			},

		}))

		Expect(rules).To(Equal(map[string][]string{

			"FORWARD": {

				"-A FORWARD -j an-old-rule",

				"-",

			},

		}))

	})

	It("should extract a rule with a hash", func() {

		hashes, rules, err := table.readHashesAndRulesFrom(newClosableBuf(

			"-A FORWARD -m comment --comment \"cali:wUHhoiAYhphO9Mso\" -j cali-FORWARD\n"))

		Expect(err).NotTo(HaveOccurred())

		Expect(hashes).To(Equal(map[string][]string{

			"FORWARD": {"wUHhoiAYhphO9Mso"},

		}))


====================
				"abcdefghij1234-_",

				"",

				"1234567890093213",

			},

		}))

		Expect(rules).To(Equal(map[string][]string{

			"FORWARD": {

				"-A FORWARD -m comment --comment \"cali:wUHhoiAYhphO9Mso\" -j cali-FORWARD",

				"-A FORWARD -m comment --comment \"cali:abcdefghij1234-_\" -j cali-FORWARD",

				"-",

				"-A FORWARD -m comment --comment \"cali:1234567890093213\" -j cali-FORWARD",

			},

		}))

	})

	It("should handle multiple chains", func() {

		hashes, rules, err := table.readHashesAndRulesFrom(newClosableBuf(

			"-A cali-abcd -m comment --comment \"cali:wUHhoiAYhphO9Mso\" -j cali-FORWARD\n" +

				"-A cali-abcd -m comment --comment \"cali:abcdefghij1234-_\" -j cali-FORWARD\n" +

				"-A FORWARD --src '1.2.3.4'\n" +

				"-A FORWARD -m comment --comment \"cali:1234567890093213\" -j cali-FORWARD\n"))


====================
				"abcdefghij1234-_",

			},

			"FORWARD": {

				"",

				"1234567890093213",

			},

		}))

		Expect(rules).To(Equal(map[string][]string{

			"FORWARD": {

				"-",

				"-A FORWARD -m comment --comment \"cali:1234567890093213\" -j cali-FORWARD",

			},

		}))

	})

	It("should extract a rule with a hash and a label commeent", func() {

		hashes, rules, err := table.readHashesAndRulesFrom(newClosableBuf(

			"-A FORWARD -m comment --comment \"cali:wUHhoiAYhphO9Mso\" -m comment --comment \"key=value\" -j cali-FORWARD\n"))

		Expect(err).NotTo(HaveOccurred())

		Expect(hashes).To(Equal(map[string][]string{

			"FORWARD": {"wUHhoiAYhphO9Mso"},


====================
			}

			continue

		}

		return hashes, rules

	}

}

// attemptToGetHashesAndRulesFromDataplane starts an iptables-save subprocess and feeds its output to

// readHashesAndRulesFrom() via a pipe.  It handles the various error cases.

func (t *Table) attemptToGetHashesAndRulesFromDataplane() (hashes map[string][]string, rules map[string][]string, err error) {

	cmd := t.newCmd(t.iptablesSaveCmd, "-t", t.Name)

	countNumSaveCalls.Inc()

	stdout, err := cmd.StdoutPipe()

	if err != nil {

		log.WithError(err).Warnf("Failed to get stdout pipe for %s", t.iptablesSaveCmd)

		return

	}

	err = cmd.Start()

	if err != nil {

		// Failed even before we started, close the pipe.  (This would normally be done

		// by Wait().


====================
				"chainName": chainName,

			}).Info("Found inserted rule from previous Felix version, marking for cleanup.")

			hash = "OLD INSERT RULE"

			chainHasCalicoRule.Add(chainName)

		}

		hashes[chainName] = append(hashes[chainName], hash)

		// Not our chain so cache the full rule in case we need to generate deletes later on.

		// After scanning the input, we prune any chains of full rules that do not contain inserts.

		if !t.ourChainsRegexp.MatchString(chainName) {

			// Only store the full rule for Calico rules. Otherwise, we just use the placeholder "-".

			fullRule := "-"

			if captures := t.hashCommentRegexp.FindSubmatch(line); captures != nil {

				fullRule = string(line)

			} else if t.oldInsertRegexp.Find(line) != nil {

				fullRule = string(line)

			}

			rules[chainName] = append(rules[chainName], fullRule)

		}

	}

	if scanner.Err() != nil {


====================
			}).Info("Found inserted rule from previous Felix version, marking for cleanup.")

			hash = "OLD INSERT RULE"

			chainHasCalicoRule.Add(chainName)

		}

		hashes[chainName] = append(hashes[chainName], hash)

		// Not our chain so cache the full rule in case we need to generate deletes later on.

		// After scanning the input, we prune any chains of full rules that do not contain inserts.

		if !t.ourChainsRegexp.MatchString(chainName) {

			// Only store the full rule for Calico rules. Otherwise, we just use the placeholder "-".

			fullRule := "-"

			if captures := t.hashCommentRegexp.FindSubmatch(line); captures != nil {

				fullRule = string(line)

			} else if t.oldInsertRegexp.Find(line) != nil {

				fullRule = string(line)

			}

			rules[chainName] = append(rules[chainName], fullRule)

		}

	}

	if scanner.Err() != nil {

		log.WithError(scanner.Err()).Error("Failed to read hashes from dataplane")


====================
				retries--

				t.logCxt.WithError(err).Warn("Failed to program iptables, will retry")

				t.timeSleep(backoffTime)

				backoffTime *= 2

				t.logCxt.WithError(err).Warn("Retrying...")

				failedAtLeastOnce = true

				continue

			} else {

				t.logCxt.WithError(err).Error("Failed to program iptables, loading diags before panic.")

				cmd := t.newCmd(t.iptablesSaveCmd, "-t", t.Name)

				output, err2 := cmd.Output()

				if err2 != nil {

					t.logCxt.WithError(err2).Error("Failed to load iptables state")

				} else {

					t.logCxt.WithField("iptablesState", string(output)).Error("Current state of iptables")

				}

				t.logCxt.WithError(err).Panic("Failed to program iptables, giving up after retries")

			}

		}

		if failedAtLeastOnce {


====================
		// accessing the buffer's internal array; don't touch the buffer after this point.

		t.opReporter.RecordOperation(fmt.Sprintf("update-%v-v%d", t.Name, t.IPVersion))

		inputBytes := buf.GetBytesAndReset()

		if log.GetLevel() >= log.DebugLevel {

			// Only convert (potentially very large slice) to string at debug level.

			inputStr := string(inputBytes)

			t.logCxt.WithField("iptablesInput", inputStr).Debug("Writing to iptables")

		}

		var outputBuf, errBuf bytes.Buffer

		args := []string{"--noflush", "--verbose"}

		if features.RestoreSupportsLock {

			// Versions of iptables-restore that support the xtables lock also make it impossible to disable.  Make

			// sure that we configure it to retry and configure for a short retry interval (the default is to try to

			// acquire the lock only once).

			lockTimeout := t.lockTimeout.Seconds()

			if lockTimeout <= 0 {

				// Before iptables-restore added lock support, we were able to disable the lock completely, which

				// was indicated by a value <=0 (and was our default).  Newer versions of iptables-restore require the

				// lock so we override the default and set it to 10s.

				lockTimeout = 10


====================
				// Before iptables-restore added lock support, we were able to disable the lock completely, which

				// was indicated by a value <=0 (and was our default).  Newer versions of iptables-restore require the

				// lock so we override the default and set it to 10s.

				lockTimeout = 10

			}

			lockProbeMicros := t.lockProbeInterval.Nanoseconds() / 1000

			timeoutStr := fmt.Sprintf("%.0f", lockTimeout)

			intervalStr := fmt.Sprintf("%d", lockProbeMicros)

			args = append(args,

				"--wait", timeoutStr, // seconds

				"--wait-interval", intervalStr, // microseconds

			)

			log.WithFields(log.Fields{

				"timeoutSecs":         timeoutStr,

				"probeIntervalMicros": intervalStr,

			}).Debug("Using native iptables-restore xtables lock.")

		}

		cmd := t.newCmd(t.iptablesRestoreCmd, args...)

		cmd.SetStdin(bytes.NewReader(inputBytes))

		cmd.SetStdout(&outputBuf)


====================
				// was indicated by a value <=0 (and was our default).  Newer versions of iptables-restore require the

				// lock so we override the default and set it to 10s.

				lockTimeout = 10

			}

			lockProbeMicros := t.lockProbeInterval.Nanoseconds() / 1000

			timeoutStr := fmt.Sprintf("%.0f", lockTimeout)

			intervalStr := fmt.Sprintf("%d", lockProbeMicros)

			args = append(args,

				"--wait", timeoutStr, // seconds

				"--wait-interval", intervalStr, // microseconds

			)

			log.WithFields(log.Fields{

				"timeoutSecs":         timeoutStr,

				"probeIntervalMicros": intervalStr,

			}).Debug("Using native iptables-restore xtables lock.")

		}

		cmd := t.newCmd(t.iptablesRestoreCmd, args...)

		cmd.SetStdin(bytes.NewReader(inputBytes))

		cmd.SetStdout(&outputBuf)

		cmd.SetStderr(&errBuf)


====================
// used for non-Calico chains.

func (t *Table) renderDeleteByValueLine(chainName string, ruleNum int) (string, error) {

	// For non-cali chains, get the rule by number but delete using the full rule instead of rule number.

	rules, ok := t.chainToFullRules[chainName]

	if !ok || ruleNum >= len(rules) {

		return "", fmt.Errorf("Rendering delete for non-existent rule: Rule %d in %q", ruleNum, chainName)

	}

	rule := rules[ruleNum]

	// Make the append a delete.

	return strings.Replace(rule, "-A", "-D", 1), nil

}

func calculateRuleHashes(chainName string, rules []Rule, features *environment.Features) []string {

	chain := Chain{

		Name:  chainName,

		Rules: rules,

	}

	return (&chain).RuleHashes(features)

}

func numEmptyStrings(strs []string) int {

	count := 0


====================
		"FailNextKill":           d.FailNextKill,

		"FailNextSaveStdoutPipe": d.FailNextSaveStdoutPipe,

		"FailNextPipeClose":      d.FailNextPipeClose,

		"FailAllRestores":        d.FailAllRestores,

		"FailAllSaves":           d.FailAllSaves,

	}).Info("Simulating new command.")

	var cmd cmdshim.CmdIface

	d.CmdNames = append(d.CmdNames, name)

	if d.NftablesMode && name != "iptables" {

		Expect(name).To(ContainSubstring("-nft"))

	}

	switch name {

	case "iptables-restore", "ip6tables-restore",

		"iptables-legacy-restore", "ip6tables-legacy-restore",

		"iptables-nft-restore", "ip6tables-nft-restore":

		Expect(arg).To(Equal([]string{"--noflush", "--verbose"}))

		cmd = &restoreCmd{

			Dataplane: d,

		}

	case "iptables-save", "ip6tables-save",


====================
	var cmd cmdshim.CmdIface

	d.CmdNames = append(d.CmdNames, name)

	if d.NftablesMode && name != "iptables" {

		Expect(name).To(ContainSubstring("-nft"))

	}

	switch name {

	case "iptables-restore", "ip6tables-restore",

		"iptables-legacy-restore", "ip6tables-legacy-restore",

		"iptables-nft-restore", "ip6tables-nft-restore":

		Expect(arg).To(Equal([]string{"--noflush", "--verbose"}))

		cmd = &restoreCmd{

			Dataplane: d,

		}

	case "iptables-save", "ip6tables-save",

		"iptables-legacy-save", "ip6tables-legacy-save",

		"iptables-nft-save", "ip6tables-nft-save":

		Expect(arg).To(Equal([]string{"-t", d.Table}))

		cmd = &saveCmd{

			Dataplane: d,

		}


====================
		"iptables-legacy-restore", "ip6tables-legacy-restore",

		"iptables-nft-restore", "ip6tables-nft-restore":

		Expect(arg).To(Equal([]string{"--noflush", "--verbose"}))

		cmd = &restoreCmd{

			Dataplane: d,

		}

	case "iptables-save", "ip6tables-save",

		"iptables-legacy-save", "ip6tables-legacy-save",

		"iptables-nft-save", "ip6tables-nft-save":

		Expect(arg).To(Equal([]string{"-t", d.Table}))

		cmd = &saveCmd{

			Dataplane: d,

		}

	case "iptables":

		Expect(arg).To(Equal([]string{"--version"}))

		cmd = &versionCmd{

			Dataplane: d,

		}

	default:

		Fail(fmt.Sprintf("Unexpected command %v", name))


====================
		}

	case "iptables-save", "ip6tables-save",

		"iptables-legacy-save", "ip6tables-legacy-save",

		"iptables-nft-save", "ip6tables-nft-save":

		Expect(arg).To(Equal([]string{"-t", d.Table}))

		cmd = &saveCmd{

			Dataplane: d,

		}

	case "iptables":

		Expect(arg).To(Equal([]string{"--version"}))

		cmd = &versionCmd{

			Dataplane: d,

		}

	default:

		Fail(fmt.Sprintf("Unexpected command %v", name))

	}

	d.Cmds = append(d.Cmds, cmd)

	return cmd

}

func (d *MockDataplane) GetKernelVersionReader() (io.Reader, error) {


====================
		if line == "COMMIT" {

			commitSeen = true

			continue

		}

		chains := d.Dataplane.Chains

		if strings.HasPrefix(line, ":") {

			// Chain forward-ref, creates and flushes the chain as needed.

			parts := strings.Split(line[1:], " ")

			chainName := parts[0]

			Expect(parts[1:]).To(Equal([]string{"-", "-"}))

			chains[chainName] = []string{}

			d.Dataplane.FlushedChains.Add(chainName)

			continue

		}

		parts := strings.Split(line, " ")

		action := parts[0]

		var chainName string

		switch action {

		case "-A", "--append":

			chainName = parts[1]


====================
			Expect(parts[1:]).To(Equal([]string{"-", "-"}))

			chains[chainName] = []string{}

			d.Dataplane.FlushedChains.Add(chainName)

			continue

		}

		parts := strings.Split(line, " ")

		action := parts[0]

		var chainName string

		switch action {

		case "-A", "--append":

			chainName = parts[1]

			if strings.HasPrefix(chainName, "cali") && d.Dataplane.NftablesMode {

				Expect(d.Dataplane.FlushedChains.Contains(chainName)).To(BeTrue(),

					"In nft mode, it's not safe to modify chain without flushing")

			}

			rest := strings.Join(parts[2:], " ")

			Expect(chains[chainName]).NotTo(BeNil(), "Append to unknown chain: "+chainName)

			chains[chainName] = append(chains[chainName], rest)

			d.Dataplane.ChainMods.Add(chainMod{name: chainName, ruleNum: len(chains[chainName])})

		case "-I", "--insert":


====================
			chainName = parts[1]

			if strings.HasPrefix(chainName, "cali") && d.Dataplane.NftablesMode {

				Expect(d.Dataplane.FlushedChains.Contains(chainName)).To(BeTrue(),

					"In nft mode, it's not safe to modify chain without flushing")

			}

			rest := strings.Join(parts[2:], " ")

			Expect(chains[chainName]).NotTo(BeNil(), "Append to unknown chain: "+chainName)

			chains[chainName] = append(chains[chainName], rest)

			d.Dataplane.ChainMods.Add(chainMod{name: chainName, ruleNum: len(chains[chainName])})

		case "-I", "--insert":

			chainName = parts[1]

			rest := strings.Join(parts[2:], " ")

			Expect(chains[chainName]).NotTo(BeNil(), "Insert to unknown chain: "+chainName)

			chains[chainName] = append(chains[chainName], "") // Make room

			chain := chains[chainName]

			// If the first arg after the chain name is a line number, then insert by line number.

			if lineNum, err := strconv.Atoi(parts[2]); err == nil {

				ruleIdx := lineNum - 1 // 0-indexed

				chain = append(chain, "")

				copy(chain[ruleIdx+1:], chain[ruleIdx:])


====================
				d.Dataplane.ChainMods.Add(chainMod{name: chainName, ruleNum: lineNum})

			} else {

				// Otherwise insert at the top.

				for i := len(chain) - 1; i > 0; i-- {

					chain[i] = chain[i-1]

				}

				chain[0] = rest

				d.Dataplane.ChainMods.Add(chainMod{name: chainName, ruleNum: 1})

			}

		case "-R", "--replace":

			Expect(d.Dataplane.NftablesMode).To(BeFalse(), "Replace shouldn't be used in nft mode")

			chainName = parts[1]

			ruleNum, err := strconv.Atoi(parts[2]) // 1-indexed position of rule.

			Expect(err).NotTo(HaveOccurred())

			rest := strings.Join(parts[3:], " ")

			ruleIdx := ruleNum - 1 // 0-indexed array index of rule.

			chain := chains[chainName]

			Expect(len(chain)).To(BeNumerically(">", ruleIdx), "Replace of non-existent rule")

			chain[ruleIdx] = rest

			d.Dataplane.ChainMods.Add(chainMod{name: chainName, ruleNum: ruleNum})


====================
			chainName = parts[1]

			ruleNum, err := strconv.Atoi(parts[2]) // 1-indexed position of rule.

			Expect(err).NotTo(HaveOccurred())

			rest := strings.Join(parts[3:], " ")

			ruleIdx := ruleNum - 1 // 0-indexed array index of rule.

			chain := chains[chainName]

			Expect(len(chain)).To(BeNumerically(">", ruleIdx), "Replace of non-existent rule")

			chain[ruleIdx] = rest

			d.Dataplane.ChainMods.Add(chainMod{name: chainName, ruleNum: ruleNum})

		case "-D", "--delete":

			chainName = parts[1]

			// If second arg is numeric, this is a delete by line number.

			if ruleNum, err := strconv.Atoi(parts[2]); err == nil {

				Expect(parts).To(HaveLen(3), "Unexpected argument after rule position in --delete")

				Expect(chainName).To(HavePrefix("cali"), "Deleting rule from non-calico chain by number can cause races")

				ruleIdx := ruleNum - 1 // 0-indexed array index of rule.

				chain := chains[chainName]

				Expect(len(chain)).To(BeNumerically(">", ruleIdx), "Delete of non-existent rule")

				for i := ruleIdx; i < len(chain)-1; i++ {

					chain[i] = chain[i+1]


====================
						found = true

						continue

					}

					newChain = append(newChain, chain[i])

				}

				Expect(found).To(BeTrue(), "Delete of non-existent rule")

				chains[chainName] = newChain

				d.Dataplane.ChainMods.Add(chainMod{name: chainName, ruleNum: i})

			}

		case "-X", "--delete-chain":

			chainName = parts[1]

			Expect(parts).To(HaveLen(2), "--delete-chain only has one argument")

			Expect(chains[chainName]).To(Equal([]string{}), "Only empty chains can be deleted")

			delete(chains, chainName)

			d.Dataplane.DeletedChains.Add(chainName)

		default:

			Fail("Unknown action: " + action)

		}

		log.Debugf("Updated chain '%s' (len=%v); new contents:\n\t%v",

			chainName, len(chains[chainName]), strings.Join(chains[chainName], "\n\t"))


====================
	sockmapEndpointsMapVersion = "v1"

	sockmapEndpointsMapName    = "calico_sk_endpoints_" + sockmapEndpointsMapVersion

	DefaultBPFfsPath = "/sys/fs/bpf"

	CgroupV2Path     = "/run/calico/cgroup"

)

var (

	xdpFilename     = "filter.o"

	sockopsFilename = "sockops.o"

	redirFilename   = "redir.o"

	bpfCalicoSubdir = "calico"

	ifaceRegexp     = regexp.MustCompile(`(?m)^[0-9]+:\s+(?P<name>.+):`)

	// v4Dot16Dot0 is the first kernel version that has all the

	// required features we use for XDP filtering

	v4Dot16Dot0 = environment.MustParseVersion("4.16.0")

	// v4Dot18Dot0 is the kernel version in RHEL that has all the

	// required features for BPF dataplane, sidecar acceleration

	v4Dot18Dot0 = environment.MustParseVersion("4.18.0-193")

	// v4Dot20Dot0 is the first kernel version that has all the

	// required features we use for sidecar acceleration

	v4Dot20Dot0 = environment.MustParseVersion("4.20.0")


====================
	Err         string `json:"error"`

}

type ProtoPort struct {

	Proto labelindex.IPSetPortProtocol

	Port  uint16

}

func getMapStructGeneral(mapDesc []string) (*mapInfo, error) {

	prog := "bpftool"

	args := []string{

		"--json",

		"--pretty",

		"map",

		"show"}

	args = append(args, mapDesc...)

	printCommand(prog, args...)

	output, err := exec.Command(prog, args...).CombinedOutput()

	if err != nil {

		return nil, fmt.Errorf("failed to show map (%v): %s\n%s", mapDesc, err, output)

	}

	m := mapInfo{}


====================
}

type ProtoPort struct {

	Proto labelindex.IPSetPortProtocol

	Port  uint16

}

func getMapStructGeneral(mapDesc []string) (*mapInfo, error) {

	prog := "bpftool"

	args := []string{

		"--json",

		"--pretty",

		"map",

		"show"}

	args = append(args, mapDesc...)

	printCommand(prog, args...)

	output, err := exec.Command(prog, args...).CombinedOutput()

	if err != nil {

		return nil, fmt.Errorf("failed to show map (%v): %s\n%s", mapDesc, err, output)

	}

	m := mapInfo{}

	err = json.Unmarshal(output, &m)


====================
		return -1, err

	}

	return m.Id, nil

}

func (b *BPFLib) DumpFailsafeMap() ([]ProtoPort, error) {

	mapName := failsafeMapName

	mapPath := filepath.Join(b.calicoDir, mapName)

	prog := "bpftool"

	args := []string{

		"--json",

		"--pretty",

		"map",

		"dump",

		"pinned",

		mapPath}

	printCommand(prog, args...)

	output, err := exec.Command(prog, args...).CombinedOutput()

	if err != nil {

		return nil, fmt.Errorf("failed to dump map (%s): %s\n%s", mapPath, err, output)

	}


====================
	}

	return m.Id, nil

}

func (b *BPFLib) DumpFailsafeMap() ([]ProtoPort, error) {

	mapName := failsafeMapName

	mapPath := filepath.Join(b.calicoDir, mapName)

	prog := "bpftool"

	args := []string{

		"--json",

		"--pretty",

		"map",

		"dump",

		"pinned",

		mapPath}

	printCommand(prog, args...)

	output, err := exec.Command(prog, args...).CombinedOutput()

	if err != nil {

		return nil, fmt.Errorf("failed to dump map (%s): %s\n%s", mapPath, err, output)

	}

	l := []mapEntry{}


====================
	if err := os.MkdirAll(b.xdpDir, 0700); err != nil {

		return false, err

	}

	hexKey, err := failsafeToHex(proto, port)

	if err != nil {

		return false, err

	}

	prog := "bpftool"

	args := []string{

		"--json",

		"--pretty",

		"map",

		"lookup",

		"pinned",

		mapPath,

		"key",

		"hex"}

	args = append(args, hexKey...)

	printCommand(prog, args...)

	output, err := exec.Command(prog, args...).CombinedOutput()


====================
		return false, err

	}

	hexKey, err := failsafeToHex(proto, port)

	if err != nil {

		return false, err

	}

	prog := "bpftool"

	args := []string{

		"--json",

		"--pretty",

		"map",

		"lookup",

		"pinned",

		mapPath,

		"key",

		"hex"}

	args = append(args, hexKey...)

	printCommand(prog, args...)

	output, err := exec.Command(prog, args...).CombinedOutput()

	if err != nil {


====================
		return 0, err

	}

	cidr := fmt.Sprintf("%s/%d", ip.String(), mask)

	hexKey, err := CidrToHex(cidr)

	if err != nil {

		return 0, err

	}

	prog := "bpftool"

	args := []string{

		"--json",

		"--pretty",

		"map",

		"lookup",

		"pinned",

		mapPath,

		"key",

		"hex"}

	args = append(args, hexKey...)

	printCommand(prog, args...)

	output, err := exec.Command(prog, args...).CombinedOutput()


====================
	}

	cidr := fmt.Sprintf("%s/%d", ip.String(), mask)

	hexKey, err := CidrToHex(cidr)

	if err != nil {

		return 0, err

	}

	prog := "bpftool"

	args := []string{

		"--json",

		"--pretty",

		"map",

		"lookup",

		"pinned",

		mapPath,

		"key",

		"hex"}

	args = append(args, hexKey...)

	printCommand(prog, args...)

	output, err := exec.Command(prog, args...).CombinedOutput()

	if err != nil {


====================
}

func (b *BPFLib) DumpCIDRMap(ifName string, family IPFamily) (map[CIDRMapKey]uint32, error) {

	mapName := getCIDRMapName(ifName, family)

	mapPath := filepath.Join(b.xdpDir, mapName)

	if err := os.MkdirAll(b.xdpDir, 0700); err != nil {

		return nil, err

	}

	prog := "bpftool"

	args := []string{

		"--json",

		"--pretty",

		"map",

		"dump",

		"pinned",

		mapPath}

	printCommand(prog, args...)

	output, err := exec.Command(prog, args...).CombinedOutput()

	if err != nil {

		return nil, fmt.Errorf("failed to dump in map (%s): %s\n%s", mapName, err, output)

	}


====================
func (b *BPFLib) DumpCIDRMap(ifName string, family IPFamily) (map[CIDRMapKey]uint32, error) {

	mapName := getCIDRMapName(ifName, family)

	mapPath := filepath.Join(b.xdpDir, mapName)

	if err := os.MkdirAll(b.xdpDir, 0700); err != nil {

		return nil, err

	}

	prog := "bpftool"

	args := []string{

		"--json",

		"--pretty",

		"map",

		"dump",

		"pinned",

		mapPath}

	printCommand(prog, args...)

	output, err := exec.Command(prog, args...).CombinedOutput()

	if err != nil {

		return nil, fmt.Errorf("failed to dump in map (%s): %s\n%s", mapName, err, output)

	}

	var al []mapEntry


====================
		return fmt.Errorf("failed to detach XDP program (%s) from %s: %s\n%s", progPath, ifName, err, output)

	}

	return os.Remove(progPath)

}

func (b *BPFLib) GetXDPTag(ifName string) (string, error) {

	progName := getProgName(ifName)

	progPath := filepath.Join(b.xdpDir, progName)

	prog := "bpftool"

	args := []string{

		"--json",

		"--pretty",

		"prog",

		"show",

		"pinned",

		progPath}

	printCommand(prog, args...)

	output, err := exec.Command(prog, args...).CombinedOutput()

	if err != nil {

		return "", fmt.Errorf("failed to show XDP program (%s): %s\n%s", progPath, err, output)

	}


====================
	}

	return os.Remove(progPath)

}

func (b *BPFLib) GetXDPTag(ifName string) (string, error) {

	progName := getProgName(ifName)

	progPath := filepath.Join(b.xdpDir, progName)

	prog := "bpftool"

	args := []string{

		"--json",

		"--pretty",

		"prog",

		"show",

		"pinned",

		progPath}

	printCommand(prog, args...)

	output, err := exec.Command(prog, args...).CombinedOutput()

	if err != nil {

		return "", fmt.Errorf("failed to show XDP program (%s): %s\n%s", progPath, err, output)

	}

	p := ProgInfo{}


====================
}

func (b *BPFLib) GetXDPObjTagAuto() (string, error) {

	return b.GetXDPObjTag(xdpFilename)

}

func (b *BPFLib) GetMapsFromXDP(ifName string) ([]int, error) {

	progName := getProgName(ifName)

	progPath := filepath.Join(b.xdpDir, progName)

	prog := "bpftool"

	args := []string{

		"--json",

		"--pretty",

		"prog",

		"show",

		"pinned",

		progPath}

	printCommand(prog, args...)

	output, err := exec.Command(prog, args...).CombinedOutput()

	if err != nil {

		return nil, fmt.Errorf("failed to show XDP program (%s): %s\n%s", progPath, err, output)

	}


====================
func (b *BPFLib) GetXDPObjTagAuto() (string, error) {

	return b.GetXDPObjTag(xdpFilename)

}

func (b *BPFLib) GetMapsFromXDP(ifName string) ([]int, error) {

	progName := getProgName(ifName)

	progPath := filepath.Join(b.xdpDir, progName)

	prog := "bpftool"

	args := []string{

		"--json",

		"--pretty",

		"prog",

		"show",

		"pinned",

		progPath}

	printCommand(prog, args...)

	output, err := exec.Command(prog, args...).CombinedOutput()

	if err != nil {

		return nil, fmt.Errorf("failed to show XDP program (%s): %s\n%s", progPath, err, output)

	}

	p := ProgInfo{}


====================
		return nil, -1, fmt.Errorf("invalid member format %q", member)

	}

	ip := net.ParseIP(rawIP)

	if ip == nil {

		return nil, -1, fmt.Errorf("invalid IP %q", rawIP)

	}

	return &ip, mask, nil

}

func maybeDeleteIface(name string) error {

	args := []string{"-c", fmt.Sprintf("ip link del %s || true", name)}

	output, err := exec.Command("/bin/sh", args...).CombinedOutput()

	if err != nil {

		return fmt.Errorf("cannot run ip command: %v\n%s", err, output)

	}

	return nil

}

func SupportsXDP() error {

	if err := isAtLeastKernel(v4Dot16Dot0); err != nil {

		return err

	}


====================
	}

	return -1, nil

}

func GetAllProgs() ([]ProgInfo, error) {

	return getAllProgs()

}

func getAllProgs() ([]ProgInfo, error) {

	prog := "bpftool"

	args := []string{

		"--json",

		"--pretty",

		"prog",

		"show",

	}

	printCommand(prog, args...)

	output, err := exec.Command(prog, args...).CombinedOutput()

	if err != nil {

		return nil, fmt.Errorf("failed to get progs: %s\n%s", err, output)

	}

	var progs []ProgInfo


====================
	return -1, nil

}

func GetAllProgs() ([]ProgInfo, error) {

	return getAllProgs()

}

func getAllProgs() ([]ProgInfo, error) {

	prog := "bpftool"

	args := []string{

		"--json",

		"--pretty",

		"prog",

		"show",

	}

	printCommand(prog, args...)

	output, err := exec.Command(prog, args...).CombinedOutput()

	if err != nil {

		return nil, fmt.Errorf("failed to get progs: %s\n%s", err, output)

	}

	var progs []ProgInfo

	err = json.Unmarshal(output, &progs)


====================
	err = json.Unmarshal(output, &progs)

	if err != nil {

		return nil, fmt.Errorf("cannot parse json output: %v\n%s", err, output)

	}

	return progs, nil

}

func (b *BPFLib) getAttachedSockopsID() (int, error) {

	prog := "bpftool"

	args := []string{

		"--json",

		"--pretty",

		"cgroup",

		"show",

		b.cgroupV2Dir}

	printCommand(prog, args...)

	output, err := exec.Command(prog, args...).CombinedOutput()

	if err != nil {

		return -1, fmt.Errorf("failed to get attached sockmap id: %s\n%s", err, output)

	}

	var al []cgroupProgEntry


====================
	if err != nil {

		return nil, fmt.Errorf("cannot parse json output: %v\n%s", err, output)

	}

	return progs, nil

}

func (b *BPFLib) getAttachedSockopsID() (int, error) {

	prog := "bpftool"

	args := []string{

		"--json",

		"--pretty",

		"cgroup",

		"show",

		b.cgroupV2Dir}

	printCommand(prog, args...)

	output, err := exec.Command(prog, args...).CombinedOutput()

	if err != nil {

		return -1, fmt.Errorf("failed to get attached sockmap id: %s\n%s", err, output)

	}

	var al []cgroupProgEntry

	err = json.Unmarshal(output, &al)


====================
		if l.Name == "calico_sockops" && l.AttachType == "sock_ops" {

			return l.ID, nil

		}

	}

	return -1, nil

}

func (b *BPFLib) getSockMapID(progID int) (int, error) {

	prog := "bpftool"

	args := []string{

		"--json",

		"--pretty",

		"prog",

		"show",

		"id",

		fmt.Sprintf("%d", progID)}

	printCommand(prog, args...)

	output, err := exec.Command(prog, args...).CombinedOutput()

	if err != nil {

		return -1, fmt.Errorf("failed to get sockmap ID for prog %d: %s\n%s", progID, err, output)

	}


====================
			return l.ID, nil

		}

	}

	return -1, nil

}

func (b *BPFLib) getSockMapID(progID int) (int, error) {

	prog := "bpftool"

	args := []string{

		"--json",

		"--pretty",

		"prog",

		"show",

		"id",

		fmt.Sprintf("%d", progID)}

	printCommand(prog, args...)

	output, err := exec.Command(prog, args...).CombinedOutput()

	if err != nil {

		return -1, fmt.Errorf("failed to get sockmap ID for prog %d: %s\n%s", progID, err, output)

	}

	p := ProgInfo{}


====================
	}

	return ret

}

func clearSockmap(mapArgs []string) error {

	prog := "bpftool"

	var e getnextEntry

	for {

		args := []string{

			"map",

			"--json",

			"getnext"}

		args = append(args, mapArgs...)

		printCommand(prog, args...)

		// don't check error here, we'll catch them parsing the output

		output, _ := exec.Command(prog, args...).CombinedOutput()

		err := json.Unmarshal(output, &e)

		if err != nil {

			return fmt.Errorf("cannot parse json output: %v\n%s", err, output)

		}

		if e.Err == "can't get next key: No such file or directory" {


====================
			// reached the end

			return nil

		}

		if e.Err != "" {

			return fmt.Errorf("%s", e.Err)

		}

		keyArgs := jsonKeyToArgs(e.NextKey)

		args = []string{

			"map",

			"--json",

			"delete",

		}

		args = append(args, mapArgs...)

		args = append(args, "key", "hex")

		args = append(args, keyArgs...)

		printCommand(prog, args...)

		output, err = exec.Command(prog, args...).CombinedOutput()

		if err != nil {

			return fmt.Errorf("failed to delete item (%v) from map (%v): %s\n%s", e.NextKey, mapArgs, err, output)

		}


====================
				return err

			}

		}

	}

	return nil

}

func (b *BPFLib) getAllMaps() ([]mapInfo, error) {

	prog := "bpftool"

	args := []string{

		"--json",

		"--pretty",

		"map",

		"show"}

	printCommand(prog, args...)

	output, err := exec.Command(prog, args...).CombinedOutput()

	if err != nil {

		return nil, fmt.Errorf("failed to get all maps: %s\n%s", err, output)

	}

	var maps []mapInfo

	err = json.Unmarshal(output, &maps)


====================
			}

		}

	}

	return nil

}

func (b *BPFLib) getAllMaps() ([]mapInfo, error) {

	prog := "bpftool"

	args := []string{

		"--json",

		"--pretty",

		"map",

		"show"}

	printCommand(prog, args...)

	output, err := exec.Command(prog, args...).CombinedOutput()

	if err != nil {

		return nil, fmt.Errorf("failed to get all maps: %s\n%s", err, output)

	}

	var maps []mapInfo

	err = json.Unmarshal(output, &maps)

	if err != nil {


====================
	return nil

}

func (b *BPFLib) DumpSockmapEndpointsMap(family IPFamily) ([]CIDRMapKey, error) {

	mapPath := filepath.Join(b.sockmapDir, sockmapEndpointsMapName)

	if err := os.MkdirAll(b.sockmapDir, 0700); err != nil {

		return nil, err

	}

	prog := "bpftool"

	args := []string{

		"--json",

		"--pretty",

		"map",

		"dump",

		"pinned",

		mapPath}

	printCommand(prog, args...)

	output, err := exec.Command(prog, args...).CombinedOutput()

	if err != nil {

		return nil, fmt.Errorf("failed to dump in map (%s): %s\n%s", sockmapEndpointsMapName, err, output)

	}


====================
}

func (b *BPFLib) DumpSockmapEndpointsMap(family IPFamily) ([]CIDRMapKey, error) {

	mapPath := filepath.Join(b.sockmapDir, sockmapEndpointsMapName)

	if err := os.MkdirAll(b.sockmapDir, 0700); err != nil {

		return nil, err

	}

	prog := "bpftool"

	args := []string{

		"--json",

		"--pretty",

		"map",

		"dump",

		"pinned",

		mapPath}

	printCommand(prog, args...)

	output, err := exec.Command(prog, args...).CombinedOutput()

	if err != nil {

		return nil, fmt.Errorf("failed to dump in map (%s): %s\n%s", sockmapEndpointsMapName, err, output)

	}

	var al []mapEntry


====================
		return false, err

	}

	cidr := fmt.Sprintf("%s/%d", ip.String(), mask)

	hexKey, err := CidrToHex(cidr)

	if err != nil {

		return false, err

	}

	prog := "bpftool"

	args := []string{

		"--json",

		"--pretty",

		"map",

		"lookup",

		"pinned",

		mapPath,

		"key",

		"hex"}

	args = append(args, hexKey...)

	printCommand(prog, args...)

	output, err := exec.Command(prog, args...).CombinedOutput()


====================
	}

	cidr := fmt.Sprintf("%s/%d", ip.String(), mask)

	hexKey, err := CidrToHex(cidr)

	if err != nil {

		return false, err

	}

	prog := "bpftool"

	args := []string{

		"--json",

		"--pretty",

		"map",

		"lookup",

		"pinned",

		mapPath,

		"key",

		"hex"}

	args = append(args, hexKey...)

	printCommand(prog, args...)

	output, err := exec.Command(prog, args...).CombinedOutput()

	if err != nil {


====================
		return err

	}

	cidr := fmt.Sprintf("%s/%d", ip.String(), mask)

	hexKey, err := CidrToHex(cidr)

	if err != nil {

		return err

	}

	prog := "bpftool"

	args := []string{

		"--json",

		"--pretty",

		"map",

		"delete",

		"pinned",

		mapPath,

		"key",

		"hex"}

	args = append(args, hexKey...)

	printCommand(prog, args...)

	output, err := exec.Command(prog, args...).CombinedOutput()


====================
	}

	cidr := fmt.Sprintf("%s/%d", ip.String(), mask)

	hexKey, err := CidrToHex(cidr)

	if err != nil {

		return err

	}

	prog := "bpftool"

	args := []string{

		"--json",

		"--pretty",

		"map",

		"delete",

		"pinned",

		mapPath,

		"key",

		"hex"}

	args = append(args, hexKey...)

	printCommand(prog, args...)

	output, err := exec.Command(prog, args...).CombinedOutput()

	if err != nil {


====================
type XDPList []struct {

	DevName string `json:"devname"`

	IfIndex int    `json:"ifindex"`

	Mode    string `json:"mode"`

	ID      int    `json:"id"`

}

// ListTcXDPAttachedProgs returns all programs attached to TC or XDP hooks.

func ListTcXDPAttachedProgs() (TcList, XDPList, error) {

	// Find all the programs that are attached to interfaces.

	out, err := exec.Command("bpftool", "net", "-j").Output()

	if err != nil {

		return nil, nil, fmt.Errorf("failed to list attached bpf programs: %w", err)

	}

	var attached []struct {

		TC  TcList  `json:"tc"`

		XDP XDPList `json:"xdp"`

	}

	err = json.Unmarshal(out, &attached)

	if err != nil {

		return nil, nil, fmt.Errorf("failed to parse list of attached BPF programs: %w\n%s", err, out)


====================
	for _, prog := range aTc {

		log.WithField("prog", prog).Debug("Adding TC prog to attached set")

		attachedProgs.Add(prog.ID)

	}

	for _, prog := range aXdp {

		log.WithField("prog", prog).Debug("Adding XDP prog to attached set")

		attachedProgs.Add(prog.ID)

	}

	// Find all the maps that the attached programs refer to and remove them from consideration.

	progsJSON, err := exec.Command("bpftool", "prog", "list", "--json").Output()

	if err != nil {

		log.WithError(err).Info("Failed to list BPF programs, assuming there's nothing to clean up.")

		return

	}

	var progs []struct {

		ID   int    `json:"id"`

		Name string `json:"name"`

		Maps []int  `json:"map_ids"`

	}

	err = json.Unmarshal(progsJSON, &progs)


====================
	if b.context == nil {

		return false

	}

	return b.context.RepinningEnabled

}

func ShowMapCmd(m Map) ([]string, error) {

	if pm, ok := m.(*PinnedMap); ok {

		return []string{

			"bpftool",

			"--json",

			"--pretty",

			"map",

			"show",

			"pinned",

			pm.versionedFilename(),

		}, nil

	}

	return nil, errors.Errorf("unrecognized map type %T", m)

}

// DumpMapCmd returns the command that can be used to dump a map or an error


====================
		return false

	}

	return b.context.RepinningEnabled

}

func ShowMapCmd(m Map) ([]string, error) {

	if pm, ok := m.(*PinnedMap); ok {

		return []string{

			"bpftool",

			"--json",

			"--pretty",

			"map",

			"show",

			"pinned",

			pm.versionedFilename(),

		}, nil

	}

	return nil, errors.Errorf("unrecognized map type %T", m)

}

// DumpMapCmd returns the command that can be used to dump a map or an error

func DumpMapCmd(m Map) ([]string, error) {


====================
		}, nil

	}

	return nil, errors.Errorf("unrecognized map type %T", m)

}

// DumpMapCmd returns the command that can be used to dump a map or an error

func DumpMapCmd(m Map) ([]string, error) {

	if pm, ok := m.(*PinnedMap); ok {

		return []string{

			"bpftool",

			"--json",

			"--pretty",

			"map",

			"dump",

			"pinned",

			pm.versionedFilename(),

		}, nil

	}

	return nil, errors.Errorf("unrecognized map type %T", m)

}

func MapDeleteKeyCmd(m Map, key []byte) ([]string, error) {


====================
	}

	return nil, errors.Errorf("unrecognized map type %T", m)

}

// DumpMapCmd returns the command that can be used to dump a map or an error

func DumpMapCmd(m Map) ([]string, error) {

	if pm, ok := m.(*PinnedMap); ok {

		return []string{

			"bpftool",

			"--json",

			"--pretty",

			"map",

			"dump",

			"pinned",

			pm.versionedFilename(),

		}, nil

	}

	return nil, errors.Errorf("unrecognized map type %T", m)

}

func MapDeleteKeyCmd(m Map, key []byte) ([]string, error) {

	if pm, ok := m.(*PinnedMap); ok {


====================
}

func MapDeleteKeyCmd(m Map, key []byte) ([]string, error) {

	if pm, ok := m.(*PinnedMap); ok {

		keyData := make([]string, len(key))

		for i, b := range key {

			keyData[i] = fmt.Sprintf("%d", b)

		}

		cmd := []string{

			"bpftool",

			"--json",

			"--pretty",

			"map",

			"delete",

			"pinned",

			pm.versionedFilename(),

			"key",

		}

		cmd = append(cmd, keyData...)

		return cmd, nil

	}


====================
func MapDeleteKeyCmd(m Map, key []byte) ([]string, error) {

	if pm, ok := m.(*PinnedMap); ok {

		keyData := make([]string, len(key))

		for i, b := range key {

			keyData[i] = fmt.Sprintf("%d", b)

		}

		cmd := []string{

			"bpftool",

			"--json",

			"--pretty",

			"map",

			"delete",

			"pinned",

			pm.versionedFilename(),

			"key",

		}

		cmd = append(cmd, keyData...)

		return cmd, nil

	}

	return nil, errors.Errorf("unrecognized map type %T", m)


====================
			Info("Loaded map file descriptor.")

	}

	return err

}

type bpftoolMapMeta struct {

	ID   int    `json:"id"`

	Name string `json:"name"`

}

func GetMapIdFromPin(pinPath string) (int, error) {

	cmd := exec.Command("bpftool", "map", "list", "pinned", pinPath, "-j")

	out, err := cmd.Output()

	if err != nil {

		return -1, errors.Wrap(err, "bpftool map list failed")

	}

	var mapData bpftoolMapMeta

	err = json.Unmarshal(out, &mapData)

	if err != nil {

		return -1, errors.Wrap(err, "bpftool returned bad JSON")

	}

	return mapData.ID, nil


====================
		return -1, errors.Wrap(err, "bpftool returned bad JSON")

	}

	return mapData.ID, nil

}

func RepinMapFromId(id int, path string) error {

	cmd := exec.Command("bpftool", "map", "pin", "id", fmt.Sprint(id), path)

	return errors.Wrap(cmd.Run(), "bpftool failed to reping map from id")

}

func RepinMap(name string, filename string) error {

	cmd := exec.Command("bpftool", "map", "list", "-j")

	out, err := cmd.Output()

	if err != nil {

		return errors.Wrap(err, "bpftool map list failed")

	}

	logrus.WithField("maps", string(out)).Debug("Got map metadata.")

	var maps []bpftoolMapMeta

	err = json.Unmarshal(out, &maps)

	if err != nil {

		return errors.Wrap(err, "bpftool returned bad JSON")

	}


====================
	}

	t.Log("Looking up on a removed a CIDR map should fail")

	_, err = bpfDP.LookupCIDRMap("foo1", IPFamilyV4, ip2, mask)

	if err == nil {

		t.Fatalf("map should have been deleted")

	}

}

var objFile = "filter.o"

func TestXDP(t *testing.T) {

	cmdVethPairArgs := []string{"-c", "ip link add test_A type veth peer name test_B || true"}

	output, err := exec.Command("/bin/sh", cmdVethPairArgs...).CombinedOutput()

	if err != nil {

		t.Fatalf("cannot create veth pair: %v\n%s", err, output)

	}

	t.Log("Loading an XDP program to a veth iface should succeed")

	err = bpfDP.loadXDPRaw(objFile, "test_A", XDPGeneric, nil)

	if err != nil {

		t.Fatalf("cannot load xdp: %v", err)

	}

	t.Log("Removing an XDP program from a veth iface should succeed")


====================
	if err == nil {

		t.Fatalf("getting xdp id should have failed: tag=%v", id)

	}

}

func TestLoadXDP(t *testing.T) {

	err := cleanup(bpfDP.GetBPFCalicoDir())

	if err != nil {

		t.Fatalf("cannot cleanup: %v", err)

	}

	cmdVethPairArgs := []string{"-c", "ip link add test_E type veth peer name test_F || true"}

	output, err := exec.Command("/bin/sh", cmdVethPairArgs...).CombinedOutput()

	if err != nil {

		t.Fatalf("cannot create veth pair: %v\n%s", err, output)

	}

	t.Log("Creating a failsafe map should succeed")

	_, err = bpfDP.NewFailsafeMap()

	if err != nil {

		t.Fatalf("cannot create map: %v", err)

	}

	t.Log("Creating a CIDR map should succeed")


====================
		t.Fatalf("cannot delete map: %v", err)

	}

	t.Log("Looking up from a removed failsafe map should fail")

	exists, err = bpfDP.LookupFailsafeMap(uint8(labelindex.ProtocolTCP), port1)

	if err == nil || exists {

		t.Fatalf("map should have been deleted")

	}

}

func TestGetXDPIfaces(t *testing.T) {

	cmdVethPairArgs := []string{"-c", "ip link add test_C type veth peer name test_D || true"}

	output, err := exec.Command("/bin/sh", cmdVethPairArgs...).CombinedOutput()

	if err != nil {

		t.Fatalf("cannot create veth pair: %v\n%s", err, output)

	}

	err = bpfDP.loadXDPRaw(objFile, "test_C", XDPGeneric, nil)

	if err != nil {

		t.Fatalf("cannot load xdp: %v", err)

	}

	err = bpfDP.loadXDPRaw(objFile, "test_D", XDPGeneric, nil)

	if err != nil {


====================
func RemoveConnectTimeLoadBalancer(cgroupv2 string) error {

	if os.Getenv("FELIX_DebugSkipCTLBCleanup") == "true" {

		log.Info("FV special case: skipping CTLB cleanup")

		return nil

	}

	cgroupPath, err := ensureCgroupPath(cgroupv2)

	if err != nil {

		return errors.Wrap(err, "failed to set-up cgroupv2")

	}

	cmd := exec.Command("bpftool", "-j", "-p", "cgroup", "show", cgroupPath)

	log.WithField("args", cmd.Args).Info("Running bpftool to look up programs attached to cgroup")

	out, err := cmd.Output()

	if err != nil || strings.TrimSpace(string(out)) == "" {

		log.WithError(err).WithField("output", string(out)).Info(

			"Failed to list BPF programs.  Assuming not supported/nothing to clean up.")

		return err

	}

	var progs []cgroupProgs

	err = json.Unmarshal(out, &progs)

	if err != nil {


====================
	}, opts...)

}

type forceAllocator struct {

	alloc *idalloc.IDAllocator

}

func (a *forceAllocator) GetNoAlloc(id string) uint64 {

	return a.alloc.GetOrAlloc(id)

}

func bpftool(args ...string) ([]byte, error) {

	args = append([]string{"--json", "--pretty"}, args...)

	cmd := exec.Command("bpftool", args...)

	log.WithField("cmd", cmd.String()).Debugf("executing")

	out, err := cmd.Output()

	if err != nil {

		if e, ok := err.(*exec.ExitError); ok {

			log.WithField("stderr", string(e.Stderr)).Errorf("bpftool %s failed: %v out=\n%v", args, err, string(out))

			// to make the output reflect the new lines, logrus ignores it

			fmt.Print(fmt.Sprint(string(e.Stderr)))

		}

	}


====================
		return nil, fmt.Errorf("open object %s: %w", fname, err)

	}

	for m, err := obj.FirstMap(); m != nil && err == nil; m, err = m.NextMap() {

		if m.IsMapInternal() {

			if forXDP {

				if err := xdp.ConfigureProgram(m, bpfIfaceName); err != nil {

					return nil, err

				}

			} else {

				ifaceLog := topts.progLog + "-" + bpfIfaceName

				globals := libbpf.TcGlobalData{

					HostIP:       ipToU32(hostIP),

					IntfIP:       ipToU32(intfIP),

					Tmtu:         natTunnelMTU,

					VxlanPort:    testVxlanPort,

					PSNatStart:   uint16(topts.psnaStart),

					PSNatLen:     uint16(topts.psnatEnd-topts.psnaStart) + 1,

					Flags:        1,

					HostTunnelIP: ipToU32(node1tunIP),

				}


====================
const usage = `felix-xdp, dumping xdp state for Calico.

Usage:

  felix-xdp dump

  felix-xdp populate

Options:

  --version                    Print the version and exit.

`

var bpfLib bpf.BPFDataplane

func populate() {

	cmdVethPairArgs := []string{"-c", "ip link add eth42 type veth peer name eth43 || true"}

	_, _ = exec.Command("/bin/sh", cmdVethPairArgs...).CombinedOutput()

	_, _ = bpfLib.NewFailsafeMap()

	_ = bpfLib.UpdateFailsafeMap(uint8(labelindex.ProtocolTCP), 53)

	_ = bpfLib.UpdateFailsafeMap(uint8(labelindex.ProtocolTCP), 80)

	_ = bpfLib.UpdateFailsafeMap(uint8(labelindex.ProtocolTCP), 22)

	_ = bpfLib.UpdateFailsafeMap(uint8(labelindex.ProtocolUDP), 53)

	_ = bpfLib.RemoveXDP("eth42", bpf.XDPGeneric)

	_, _ = bpfLib.NewCIDRMap("eth42", bpf.IPFamilyV4)

	_ = bpfLib.UpdateCIDRMap("eth42", bpf.IPFamilyV4, net.ParseIP("1.1.1.1"), 16, 1)

	_ = bpfLib.UpdateCIDRMap("eth42", bpf.IPFamilyV4, net.ParseIP("8.8.8.8"), 16, 1)


====================
	for _, m := range maps {

		if strings.HasPrefix(m.Name, "cali_") || strings.HasPrefix(m.Name, "calico_") {

			log.WithField("name", m.Name).Debug("Found calico map")

			calicoMapIDs.Add(m.ID)

		}

	}

	calicoProgIDs := set.New[int]()

	if calicoMapIDs.Len() > 0 {

		// Have some calico maps, search for calico programs.

		bpftool := exec.Command("bpftool", "prog", "list", "--json")

		progsJSON, err := bpftool.Output()

		if err != nil {

			log.WithError(err).Info("Failed to list BPF programs, assuming there's nothing to clean up.")

			return

		}

		var progs []struct {

			ID   int    `json:"id"`

			Name string `json:"name"`

			Maps []int  `json:"map_ids"`

		}


====================
func (ap *AttachPoint) listAttachedPrograms() ([]attachedProg, error) {

	out, err := ExecTC("filter", "show", "dev", ap.Iface, string(ap.Hook))

	if err != nil {

		return nil, fmt.Errorf("failed to list tc filters on interface: %w", err)

	}

	// Lines look like this; the section name always includes calico.

	// filter protocol all pref 49152 bpf chain 0 handle 0x1 to_hep_no_log.o:[calico_to_host_ep] direct-action not_in_hw id 821 tag ee402594f8f85ac3 jited

	var progsToClean []attachedProg

	for _, line := range strings.Split(string(out), "\n") {

		if !strings.Contains(line, "calico") {

			continue

		}

		// find the pref and the handle

		if sm := prefHandleRe.FindStringSubmatch(line); len(sm) > 0 {

			p := attachedProg{

				pref:   sm[1],

				handle: sm[2],

			}

			log.WithField("prog", p).Debug("Found old calico program")

			progsToClean = append(progsToClean, p)


====================
	if ap.HostTunnelIP != nil {

		globalData.HostTunnelIP, err = convertIPToUint32(ap.HostTunnelIP)

		if err != nil {

			return err

		}

	}

	return ConfigureProgram(m, ap.Iface, &globalData)

}

func ConfigureProgram(m *libbpf.Map, iface string, globalData *libbpf.TcGlobalData) error {

	in := []byte("---------------")

	copy(in, iface)

	globalData.IfaceName = string(in)

	return libbpf.TcSetGlobals(m, globalData)

}

func (ap *AttachPoint) setMapSize(m *libbpf.Map) error {

	if size, ok := ap.MapSizes[m.Name()]; ok {

		return m.SetMapSize(size)

	}

	return nil

}


====================
		return -1, false

	}

	if isAttached && somethingAttached {

		return progID, true

	}

	return -1, false

}

func ConfigureProgram(m *libbpf.Map, iface string) error {

	var globalData libbpf.XDPGlobalData

	in := []byte("---------------")

	copy(in, iface)

	globalData.IfaceName = string(in)

	if err := libbpf.XDPSetGlobals(m, &globalData); err != nil {

		return fmt.Errorf("failed to configure xdp: %w", err)

	}

	return nil

}

func (ap *AttachPoint) AttachProgram() (int, error) {

	tempDir, err := os.MkdirTemp("", "calico-xdp")

	if err != nil {


====================
		return true

	default:

		if err := d.isAtLeastKernel(v5Dot14Dot0); err != nil {

			return false

		}

		return true

	}

}

func (d *FeatureDetector) getIptablesVersion() *Version {

	cmd := d.NewCmd("iptables", "--version")

	out, err := cmd.Output()

	if err != nil {

		log.WithError(err).Warn("Failed to get iptables version, assuming old version with no optional features")

		return v1Dot4Dot7

	}

	s := string(out)

	log.WithField("rawVersion", s).Debug("Ran iptables --version")

	matches := vXDotYDotZRegexp.FindStringSubmatch(s)

	if len(matches) == 0 {

		log.WithField("rawVersion", s).Warn(


====================
func FindBestBinary(lookPath func(file string) (string, error), ipVersion uint8, backendMode, saveOrRestore string) string {

	if lookPath == nil {

		lookPath = exec.LookPath

	}

	verInfix := ""

	if ipVersion == 6 {

		verInfix = "6"

	}

	candidates := []string{

		"ip" + verInfix + "tables-" + backendMode + "-" + saveOrRestore,

		"ip" + verInfix + "tables-" + saveOrRestore,

	}

	logCxt := log.WithFields(log.Fields{

		"ipVersion":     ipVersion,

		"backendMode":   backendMode,

		"saveOrRestore": saveOrRestore,

		"candidates":    candidates,

	})

	for _, candidate := range candidates {

		_, err := lookPath(candidate)


====================
	// Parse command-line args.

	version := "Version:            " + buildinfo.GitVersion + "\n" +

		"Full git commit ID: " + buildinfo.GitRevision + "\n" +

		"Build date:         " + buildinfo.BuildDate + "\n"

	arguments, err := docopt.ParseArgs(usage, nil, version)

	if err != nil {

		println(usage)

		log.Fatalf("Failed to parse usage, exiting: %v", err)

	}

	configFile := arguments["--config-file"].(string)

	// Execute felix.

	daemon.Run(configFile, buildinfo.GitVersion, buildinfo.GitRevision, buildinfo.BuildDate)

}

// Copyright (c) 2019 Tigera, Inc. All rights reserved.

//

// Licensed under the Apache License, Version 2.0 (the "License");

// you may not use this file except in compliance with the License.

// You may obtain a copy of the License at

//

//     http://www.apache.org/licenses/LICENSE-2.0


====================
	rootCmd.AddCommand(conntrackCmd)

}

// conntrackCmd represents the conntrack command

var conntrackCmd = &cobra.Command{

	Use:   "conntrack",

	Short: "Manipulates connection tracking",

}

type conntrackDumpCmd struct {

	*cobra.Command

	Version string `docopt:"--ver"`

	version string

}

func newConntrackDumpCmd() *cobra.Command {

	cmd := &conntrackDumpCmd{

		Command: &cobra.Command{

			Use:   "dump [--ver=<version>]",

			Short: "Dumps connection tracking table",

		},

	}

	cmd.Command.Flags().StringVarP((&cmd.version), "ver", "v", "", "version to dump from")


====================
		return bpf.IterDelete

	})

	log.SetLevel(loglevel)

	if err != nil {

		log.WithError(err).Fatal("Failed to iterate over conntrack entries")

	}

}

type conntrackCreateCmd struct {

	*cobra.Command

	Version string `docopt:"--ver"`

	version string

}

func newConntrackCreateCmd() *cobra.Command {

	cmd := &conntrackCreateCmd{

		Command: &cobra.Command{

			Use:   "create [--ver=<version>]",

			Short: "create a conntrack map of specified version",

		},

	}

	cmd.Command.Flags().StringVarP((&cmd.version), "ver", "v", "", "conntrack version to create")


====================
	default:

		ctMap = conntrack.Map(mc)

	}

	if err := ctMap.EnsureExists(); err != nil {

		log.WithError(err).Errorf("Failed to create conntrackMap version %s", cmd.version)

	}

}

type conntrackWriteCmd struct {

	*cobra.Command

	Version string `docopt:"--ver"`

	Key     string `docopt:"<key>"`

	Value   string `docopt:"<value>"`

	key     []byte

	val     []byte

	version string

}

func newConntrackWriteCmd() *cobra.Command {

	cmd := &conntrackWriteCmd{

		Command: &cobra.Command{

			Use:   "write [--ver=<version>] <key> <value>",


====================
				}

				if BPFMode() {

					ensureAllNodesBPFProgramsAttached(felixes)

				}

				cc = &connectivity.Checker{}

			})

			AfterEach(func() {

				if CurrentGinkgoTestDescription().Failed {

					for _, felix := range felixes {

						felix.Exec("iptables-save", "-c")

						felix.Exec("ipset", "list")

						felix.Exec("ip", "r")

						felix.Exec("ip", "a")

					}

				}

				for _, wl := range w {

					wl.Stop()

				}

				for _, wl := range hostW {

					wl.Stop()


====================
				}

				if CurrentGinkgoTestDescription().Failed {

					infra.DumpErrorData()

				}

				infra.Stop()

			})

			if brokenXSum {

				It("should disable checksum offload", func() {

					Eventually(func() string {

						out, err := felixes[0].ExecOutput("ethtool", "-k", "vxlan.calico")

						if err != nil {

							return fmt.Sprintf("ERROR: %v", err)

						}

						return out

					}, "10s", "100ms").Should(ContainSubstring("tx-checksumming: off"))

				})

			} else {

				It("should not disable checksum offload", func() {

					Eventually(func() string {

						out, err := felixes[0].ExecOutput("ethtool", "-k", "vxlan.calico")


====================
						if err != nil {

							return fmt.Sprintf("ERROR: %v", err)

						}

						return out

					}, "10s", "100ms").Should(ContainSubstring("tx-checksumming: off"))

				})

			} else {

				It("should not disable checksum offload", func() {

					Eventually(func() string {

						out, err := felixes[0].ExecOutput("ethtool", "-k", "vxlan.calico")

						if err != nil {

							return fmt.Sprintf("ERROR: %v", err)

						}

						return out

					}, "10s", "100ms").Should(ContainSubstring("tx-checksumming: on"))

				})

			}

			It("should use the --random-fully flag in the MASQUERADE rules", func() {

				for _, felix := range felixes {

					Eventually(func() string {


====================
							return fmt.Sprintf("ERROR: %v", err)

						}

						return out

					}, "10s", "100ms").Should(ContainSubstring("tx-checksumming: on"))

				})

			}

			It("should use the --random-fully flag in the MASQUERADE rules", func() {

				for _, felix := range felixes {

					Eventually(func() string {

						out, _ := felix.ExecOutput("iptables-save", "-c")

						return out

					}, "10s", "100ms").Should(ContainSubstring("--random-fully"))

				}

			})

			It("should have workload to workload connectivity", func() {

				cc.ExpectSome(w[0], w[1])

				cc.ExpectSome(w[1], w[0])

				cc.CheckConnectivity()

			})

			It("should have some blackhole routes installed", func() {


====================
						return out

					}, "10s", "100ms").Should(ContainSubstring("tx-checksumming: on"))

				})

			}

			It("should use the --random-fully flag in the MASQUERADE rules", func() {

				for _, felix := range felixes {

					Eventually(func() string {

						out, _ := felix.ExecOutput("iptables-save", "-c")

						return out

					}, "10s", "100ms").Should(ContainSubstring("--random-fully"))

				}

			})

			It("should have workload to workload connectivity", func() {

				cc.ExpectSome(w[0], w[1])

				cc.ExpectSome(w[1], w[0])

				cc.CheckConnectivity()

			})

			It("should have some blackhole routes installed", func() {

				if routeSource == "WorkloadIPs" {

					Skip("not applicable for workload ips")


====================
						return getNumIPSetMembers(felixes[0].Container, "cali40all-vxlan-net")

					}, "10s", "200ms").Should(Equal(len(felixes) - 1))

					ctx, cancel := context.WithTimeout(context.Background(), 20*time.Second)

					defer cancel()

					infra.RemoveNodeAddresses(felixes[2])

					node, err := client.Nodes().Get(ctx, felixes[2].Hostname, options.GetOptions{})

					Expect(err).NotTo(HaveOccurred())

					// Pause felix so it can't touch the dataplane!

					pid := felixes[2].GetFelixPID()

					felixes[2].Exec("kill", "-STOP", fmt.Sprint(pid))

					node.Spec.BGP = nil

					_, err = client.Nodes().Update(ctx, node, options.SetOptions{})

				})

				It("should have no connectivity from third felix and expected number of IPs in allow list", func() {

					Eventually(func() int {

						return getNumIPSetMembers(felixes[0].Container, "cali40all-vxlan-net")

					}, "5s", "200ms").Should(Equal(len(felixes) - 2))

					cc.ExpectSome(w[0], w[1])

					cc.ExpectSome(w[1], w[0])

					cc.ExpectNone(w[0], w[2])


====================
					// Wait until dataplane has settled.

					cc.ExpectSome(w[0], w[1])

					cc.ExpectSome(w[0], w[2])

					cc.ExpectSome(w[1], w[2])

					cc.CheckConnectivity()

					cc.ResetExpectations()

					// Then pause all the felixes.

					for _, f := range felixes {

						pid := f.GetFelixPID()

						f.Exec("kill", "-STOP", fmt.Sprint(pid))

					}

				})

				if vxlanMode == api.VXLANModeAlways {

					It("after manually removing third node from allow list should have expected connectivity", func() {

						felixes[0].Exec("ipset", "del", "cali40all-vxlan-net", felixes[2].IP)

						cc.ExpectSome(w[0], w[1])

						cc.ExpectSome(w[1], w[0])

						cc.ExpectSome(w[1], w[2])

						cc.ExpectNone(w[2], w[0])

						cc.CheckConnectivity()


====================
				}

			})

			It("should configure the vxlan device correctly", func() {

				// The VXLAN device should appear with default MTU, etc. FV environment uses MTU 1500,

				// which means that we should expect 1450 after subracting VXLAN overhead for IPv4 or 1430 for IPv6.

				mtuStr := "mtu 1450"

				mtuStrV6 := "mtu 1430"

				for _, felix := range felixes {

					Eventually(func() string {

						out, _ := felix.ExecOutput("ip", "-d", "link", "show", "vxlan.calico")

						return out

					}, "60s", "500ms").Should(ContainSubstring(mtuStr))

					Eventually(func() string {

						out, _ := felix.ExecOutput("ip", "-d", "link", "show", "vxlan.calico")

						return out

					}, "10s", "100ms").Should(ContainSubstring("vxlan id 4096"))

					Eventually(func() string {

						out, _ := felix.ExecOutput("ip", "-d", "link", "show", "vxlan.calico")

						return out

					}, "10s", "100ms").Should(ContainSubstring("dstport 4789"))


====================
				// which means that we should expect 1450 after subracting VXLAN overhead for IPv4 or 1430 for IPv6.

				mtuStr := "mtu 1450"

				mtuStrV6 := "mtu 1430"

				for _, felix := range felixes {

					Eventually(func() string {

						out, _ := felix.ExecOutput("ip", "-d", "link", "show", "vxlan.calico")

						return out

					}, "60s", "500ms").Should(ContainSubstring(mtuStr))

					Eventually(func() string {

						out, _ := felix.ExecOutput("ip", "-d", "link", "show", "vxlan.calico")

						return out

					}, "10s", "100ms").Should(ContainSubstring("vxlan id 4096"))

					Eventually(func() string {

						out, _ := felix.ExecOutput("ip", "-d", "link", "show", "vxlan.calico")

						return out

					}, "10s", "100ms").Should(ContainSubstring("dstport 4789"))

					if enableIPv6 {

						Eventually(func() string {

							out, _ := felix.ExecOutput("ip", "-d", "link", "show", "vxlan-v6.calico")

							return out


====================
					Eventually(func() string {

						out, _ := felix.ExecOutput("ip", "-d", "link", "show", "vxlan.calico")

						return out

					}, "60s", "500ms").Should(ContainSubstring(mtuStr))

					Eventually(func() string {

						out, _ := felix.ExecOutput("ip", "-d", "link", "show", "vxlan.calico")

						return out

					}, "10s", "100ms").Should(ContainSubstring("vxlan id 4096"))

					Eventually(func() string {

						out, _ := felix.ExecOutput("ip", "-d", "link", "show", "vxlan.calico")

						return out

					}, "10s", "100ms").Should(ContainSubstring("dstport 4789"))

					if enableIPv6 {

						Eventually(func() string {

							out, _ := felix.ExecOutput("ip", "-d", "link", "show", "vxlan-v6.calico")

							return out

						}, "60s", "500ms").Should(ContainSubstring(mtuStrV6))

						Eventually(func() string {

							out, _ := felix.ExecOutput("ip", "-d", "link", "show", "vxlan-v6.calico")

							return out


====================
						out, _ := felix.ExecOutput("ip", "-d", "link", "show", "vxlan.calico")

						return out

					}, "10s", "100ms").Should(ContainSubstring("vxlan id 4096"))

					Eventually(func() string {

						out, _ := felix.ExecOutput("ip", "-d", "link", "show", "vxlan.calico")

						return out

					}, "10s", "100ms").Should(ContainSubstring("dstport 4789"))

					if enableIPv6 {

						Eventually(func() string {

							out, _ := felix.ExecOutput("ip", "-d", "link", "show", "vxlan-v6.calico")

							return out

						}, "60s", "500ms").Should(ContainSubstring(mtuStrV6))

						Eventually(func() string {

							out, _ := felix.ExecOutput("ip", "-d", "link", "show", "vxlan-v6.calico")

							return out

						}, "10s", "100ms").Should(ContainSubstring("vxlan id 4096"))

						Eventually(func() string {

							out, _ := felix.ExecOutput("ip", "-d", "link", "show", "vxlan-v6.calico")

							return out

						}, "10s", "100ms").Should(ContainSubstring("dstport 4789"))


====================
						out, _ := felix.ExecOutput("ip", "-d", "link", "show", "vxlan.calico")

						return out

					}, "10s", "100ms").Should(ContainSubstring("dstport 4789"))

					if enableIPv6 {

						Eventually(func() string {

							out, _ := felix.ExecOutput("ip", "-d", "link", "show", "vxlan-v6.calico")

							return out

						}, "60s", "500ms").Should(ContainSubstring(mtuStrV6))

						Eventually(func() string {

							out, _ := felix.ExecOutput("ip", "-d", "link", "show", "vxlan-v6.calico")

							return out

						}, "10s", "100ms").Should(ContainSubstring("vxlan id 4096"))

						Eventually(func() string {

							out, _ := felix.ExecOutput("ip", "-d", "link", "show", "vxlan-v6.calico")

							return out

						}, "10s", "100ms").Should(ContainSubstring("dstport 4789"))

					}

				}

				// Change the host device's MTU, and expect the VXLAN device to be updated.

				for _, felix := range felixes {


====================
						Eventually(func() string {

							out, _ := felix.ExecOutput("ip", "-d", "link", "show", "vxlan-v6.calico")

							return out

						}, "60s", "500ms").Should(ContainSubstring(mtuStrV6))

						Eventually(func() string {

							out, _ := felix.ExecOutput("ip", "-d", "link", "show", "vxlan-v6.calico")

							return out

						}, "10s", "100ms").Should(ContainSubstring("vxlan id 4096"))

						Eventually(func() string {

							out, _ := felix.ExecOutput("ip", "-d", "link", "show", "vxlan-v6.calico")

							return out

						}, "10s", "100ms").Should(ContainSubstring("dstport 4789"))

					}

				}

				// Change the host device's MTU, and expect the VXLAN device to be updated.

				for _, felix := range felixes {

					Eventually(func() error {

						_, err := felix.ExecOutput("ip", "link", "set", "eth0", "mtu", "1400")

						return err

					}, "10s", "100ms").Should(BeNil())


====================
				mtuStr = "mtu 1350"

				mtuStrV6 = "mtu 1330"

				mtuValue := "1350"

				if enableIPv6 {

					mtuValue = "1330"

				}

				for _, felix := range felixes {

					// Felix checks host MTU every 30s

					Eventually(func() string {

						out, _ := felix.ExecOutput("ip", "-d", "link", "show", "vxlan.calico")

						return out

					}, "60s", "500ms").Should(ContainSubstring(mtuStr))

					if enableIPv6 {

						// Felix checks host MTU every 30s

						Eventually(func() string {

							out, _ := felix.ExecOutput("ip", "-d", "link", "show", "vxlan-v6.calico")

							return out

						}, "60s", "500ms").Should(ContainSubstring(mtuStrV6))

					}

					// And expect the MTU file on disk to be updated.


====================
				for _, felix := range felixes {

					// Felix checks host MTU every 30s

					Eventually(func() string {

						out, _ := felix.ExecOutput("ip", "-d", "link", "show", "vxlan.calico")

						return out

					}, "60s", "500ms").Should(ContainSubstring(mtuStr))

					if enableIPv6 {

						// Felix checks host MTU every 30s

						Eventually(func() string {

							out, _ := felix.ExecOutput("ip", "-d", "link", "show", "vxlan-v6.calico")

							return out

						}, "60s", "500ms").Should(ContainSubstring(mtuStrV6))

					}

					// And expect the MTU file on disk to be updated.

					Eventually(func() string {

						out, _ := felix.ExecOutput("cat", "/var/lib/calico/mtu")

						return out

					}, "30s", "100ms").Should(ContainSubstring(mtuValue))

				}

				// Explicitly configure the MTU.


====================
				felixConfig.Spec.VXLANMTUV6 = &mtu

				felixConfig.Spec.VXLANPort = &port

				felixConfig.Spec.VXLANVNI = &vni

				_, err := client.FelixConfigurations().Create(context.Background(), felixConfig, options.SetOptions{})

				Expect(err).NotTo(HaveOccurred())

				// Expect the settings to be changed on the device.

				for _, felix := range felixes {

					// Felix checks host MTU every 30s

					Eventually(func() string {

						out, _ := felix.ExecOutput("ip", "-d", "link", "show", "vxlan.calico")

						return out

					}, "60s", "500ms").Should(ContainSubstring("mtu 1300"))

					Eventually(func() string {

						out, _ := felix.ExecOutput("ip", "-d", "link", "show", "vxlan.calico")

						return out

					}, "10s", "100ms").Should(ContainSubstring("vxlan id 4097"))

					Eventually(func() string {

						out, _ := felix.ExecOutput("ip", "-d", "link", "show", "vxlan.calico")

						return out

					}, "10s", "100ms").Should(ContainSubstring("dstport 4790"))


====================
				Expect(err).NotTo(HaveOccurred())

				// Expect the settings to be changed on the device.

				for _, felix := range felixes {

					// Felix checks host MTU every 30s

					Eventually(func() string {

						out, _ := felix.ExecOutput("ip", "-d", "link", "show", "vxlan.calico")

						return out

					}, "60s", "500ms").Should(ContainSubstring("mtu 1300"))

					Eventually(func() string {

						out, _ := felix.ExecOutput("ip", "-d", "link", "show", "vxlan.calico")

						return out

					}, "10s", "100ms").Should(ContainSubstring("vxlan id 4097"))

					Eventually(func() string {

						out, _ := felix.ExecOutput("ip", "-d", "link", "show", "vxlan.calico")

						return out

					}, "10s", "100ms").Should(ContainSubstring("dstport 4790"))

					if enableIPv6 {

						// Felix checks host MTU every 30s

						Eventually(func() string {

							out, _ := felix.ExecOutput("ip", "-d", "link", "show", "vxlan-v6.calico")


====================
					Eventually(func() string {

						out, _ := felix.ExecOutput("ip", "-d", "link", "show", "vxlan.calico")

						return out

					}, "60s", "500ms").Should(ContainSubstring("mtu 1300"))

					Eventually(func() string {

						out, _ := felix.ExecOutput("ip", "-d", "link", "show", "vxlan.calico")

						return out

					}, "10s", "100ms").Should(ContainSubstring("vxlan id 4097"))

					Eventually(func() string {

						out, _ := felix.ExecOutput("ip", "-d", "link", "show", "vxlan.calico")

						return out

					}, "10s", "100ms").Should(ContainSubstring("dstport 4790"))

					if enableIPv6 {

						// Felix checks host MTU every 30s

						Eventually(func() string {

							out, _ := felix.ExecOutput("ip", "-d", "link", "show", "vxlan-v6.calico")

							return out

						}, "60s", "500ms").Should(ContainSubstring("mtu 1300"))

						Eventually(func() string {

							out, _ := felix.ExecOutput("ip", "-d", "link", "show", "vxlan-v6.calico")


====================
						return out

					}, "10s", "100ms").Should(ContainSubstring("vxlan id 4097"))

					Eventually(func() string {

						out, _ := felix.ExecOutput("ip", "-d", "link", "show", "vxlan.calico")

						return out

					}, "10s", "100ms").Should(ContainSubstring("dstport 4790"))

					if enableIPv6 {

						// Felix checks host MTU every 30s

						Eventually(func() string {

							out, _ := felix.ExecOutput("ip", "-d", "link", "show", "vxlan-v6.calico")

							return out

						}, "60s", "500ms").Should(ContainSubstring("mtu 1300"))

						Eventually(func() string {

							out, _ := felix.ExecOutput("ip", "-d", "link", "show", "vxlan-v6.calico")

							return out

						}, "10s", "100ms").Should(ContainSubstring("vxlan id 4097"))

						Eventually(func() string {

							out, _ := felix.ExecOutput("ip", "-d", "link", "show", "vxlan-v6.calico")

							return out

						}, "10s", "100ms").Should(ContainSubstring("dstport 4790"))


====================
						return out

					}, "10s", "100ms").Should(ContainSubstring("dstport 4790"))

					if enableIPv6 {

						// Felix checks host MTU every 30s

						Eventually(func() string {

							out, _ := felix.ExecOutput("ip", "-d", "link", "show", "vxlan-v6.calico")

							return out

						}, "60s", "500ms").Should(ContainSubstring("mtu 1300"))

						Eventually(func() string {

							out, _ := felix.ExecOutput("ip", "-d", "link", "show", "vxlan-v6.calico")

							return out

						}, "10s", "100ms").Should(ContainSubstring("vxlan id 4097"))

						Eventually(func() string {

							out, _ := felix.ExecOutput("ip", "-d", "link", "show", "vxlan-v6.calico")

							return out

						}, "10s", "100ms").Should(ContainSubstring("dstport 4790"))

					}

				}

			})

			It("should delete the vxlan device when vxlan is disabled", func() {


====================
						Eventually(func() string {

							out, _ := felix.ExecOutput("ip", "-d", "link", "show", "vxlan-v6.calico")

							return out

						}, "60s", "500ms").Should(ContainSubstring("mtu 1300"))

						Eventually(func() string {

							out, _ := felix.ExecOutput("ip", "-d", "link", "show", "vxlan-v6.calico")

							return out

						}, "10s", "100ms").Should(ContainSubstring("vxlan id 4097"))

						Eventually(func() string {

							out, _ := felix.ExecOutput("ip", "-d", "link", "show", "vxlan-v6.calico")

							return out

						}, "10s", "100ms").Should(ContainSubstring("dstport 4790"))

					}

				}

			})

			It("should delete the vxlan device when vxlan is disabled", func() {

				// Wait for the VXLAN device to be created.

				mtuStr := "mtu 1450"

				mtuStrV6 := "mtu 1430"

				for _, felix := range felixes {


====================
					}

				}

			})

			It("should delete the vxlan device when vxlan is disabled", func() {

				// Wait for the VXLAN device to be created.

				mtuStr := "mtu 1450"

				mtuStrV6 := "mtu 1430"

				for _, felix := range felixes {

					Eventually(func() string {

						out, _ := felix.ExecOutput("ip", "-d", "link", "show", "vxlan.calico")

						return out

					}, "60s", "500ms").Should(ContainSubstring(mtuStr))

					if enableIPv6 {

						Eventually(func() string {

							out, _ := felix.ExecOutput("ip", "-d", "link", "show", "vxlan-v6.calico")

							return out

						}, "60s", "500ms").Should(ContainSubstring(mtuStrV6))

					}

				}

				// Disable VXLAN in Felix.


====================
				mtuStr := "mtu 1450"

				mtuStrV6 := "mtu 1430"

				for _, felix := range felixes {

					Eventually(func() string {

						out, _ := felix.ExecOutput("ip", "-d", "link", "show", "vxlan.calico")

						return out

					}, "60s", "500ms").Should(ContainSubstring(mtuStr))

					if enableIPv6 {

						Eventually(func() string {

							out, _ := felix.ExecOutput("ip", "-d", "link", "show", "vxlan-v6.calico")

							return out

						}, "60s", "500ms").Should(ContainSubstring(mtuStrV6))

					}

				}

				// Disable VXLAN in Felix.

				felixConfig := api.NewFelixConfiguration()

				felixConfig.Name = "default"

				enabled := false

				felixConfig.Spec.VXLANEnabled = &enabled

				_, err := client.FelixConfigurations().Create(context.Background(), felixConfig, options.SetOptions{})


====================
				felixConfig := api.NewFelixConfiguration()

				felixConfig.Name = "default"

				enabled := false

				felixConfig.Spec.VXLANEnabled = &enabled

				_, err := client.FelixConfigurations().Create(context.Background(), felixConfig, options.SetOptions{})

				Expect(err).NotTo(HaveOccurred())

				// Expect the ipv4 VXLAN device to be deleted.

				for _, felix := range felixes {

					Eventually(func() string {

						out, _ := felix.ExecOutput("ip", "-d", "link", "show", "vxlan.calico")

						return out

					}, "60s", "500ms").ShouldNot(ContainSubstring(mtuStr))

					// IPv6 ignores the VXLAN enabled flag and must be disabled at the pool level. As such the ipv6

					// interfaces should still exist at this point

					if enableIPv6 {

						Eventually(func() string {

							out, _ := felix.ExecOutput("ip", "-d", "link", "show", "vxlan-v6.calico")

							return out

						}, "60s", "500ms").Should(ContainSubstring(mtuStrV6))

					}


====================
				for _, felix := range felixes {

					Eventually(func() string {

						out, _ := felix.ExecOutput("ip", "-d", "link", "show", "vxlan.calico")

						return out

					}, "60s", "500ms").ShouldNot(ContainSubstring(mtuStr))

					// IPv6 ignores the VXLAN enabled flag and must be disabled at the pool level. As such the ipv6

					// interfaces should still exist at this point

					if enableIPv6 {

						Eventually(func() string {

							out, _ := felix.ExecOutput("ip", "-d", "link", "show", "vxlan-v6.calico")

							return out

						}, "60s", "500ms").Should(ContainSubstring(mtuStrV6))

					}

				}

				if enableIPv6 {

					ip6pool, err := client.IPPools().Get(context.Background(), infrastructure.DefaultIPv6PoolName, options.GetOptions{})

					Expect(err).NotTo(HaveOccurred())

					ip6pool.Spec.VXLANMode = "Never"

					_, err = client.IPPools().Update(context.Background(), ip6pool, options.SetOptions{})

					Expect(err).NotTo(HaveOccurred())


====================
				if enableIPv6 {

					ip6pool, err := client.IPPools().Get(context.Background(), infrastructure.DefaultIPv6PoolName, options.GetOptions{})

					Expect(err).NotTo(HaveOccurred())

					ip6pool.Spec.VXLANMode = "Never"

					_, err = client.IPPools().Update(context.Background(), ip6pool, options.SetOptions{})

					Expect(err).NotTo(HaveOccurred())

					// Expect the ipv6 VXLAN device to be deleted.

					for _, felix := range felixes {

						Eventually(func() string {

							out, _ := felix.ExecOutput("ip", "-d", "link", "show", "vxlan-v6.calico")

							return out

						}, "60s", "500ms").ShouldNot(ContainSubstring(mtuStrV6))

					}

				}

			})

		})

	}

})

// Copyright (c) 2020-2021 Tigera, Inc. All rights reserved.

//


====================
		}

		if bpfEnabled {

			ensureAllNodesBPFProgramsAttached(felixes)

		}

		cc = &connectivity.Checker{}

	})

	AfterEach(func() {

		if CurrentGinkgoTestDescription().Failed {

			for _, felix := range felixes {

				felix.Exec("iptables-save", "-c")

				felix.Exec("ipset", "list")

				felix.Exec("ip", "r")

				felix.Exec("ip", "a")

				if BPFMode() {

					felix.Exec("calico-bpf", "policy", "dump", "eth0", "all")

				}

			}

		}

		for _, wl := range w {

			wl.Stop()


====================
		}

		if CurrentGinkgoTestDescription().Failed {

			infra.DumpErrorData()

		}

		infra.Stop()

	})

	It("should use the --random-fully flag in the MASQUERADE rules", func() {

		for _, felix := range felixes {

			Eventually(func() string {

				out, _ := felix.ExecOutput("iptables-save", "-c")

				return out

			}, "10s", "100ms").Should(ContainSubstring("--random-fully"))

		}

	})

	It("should have workload to workload connectivity", func() {

		cc.ExpectSome(w[0], w[1])

		cc.ExpectSome(w[1], w[0])

		cc.CheckConnectivity()

	})

	It("should have host to workload connectivity", func() {


====================
			infra.DumpErrorData()

		}

		infra.Stop()

	})

	It("should use the --random-fully flag in the MASQUERADE rules", func() {

		for _, felix := range felixes {

			Eventually(func() string {

				out, _ := felix.ExecOutput("iptables-save", "-c")

				return out

			}, "10s", "100ms").Should(ContainSubstring("--random-fully"))

		}

	})

	It("should have workload to workload connectivity", func() {

		cc.ExpectSome(w[0], w[1])

		cc.ExpectSome(w[1], w[0])

		cc.CheckConnectivity()

	})

	It("should have host to workload connectivity", func() {

		cc.ExpectSome(felixes[0], w[1])

		cc.ExpectSome(felixes[0], w[0])


====================
			wName := fmt.Sprintf("w%d", ii)

			w[ii] = workload.Run(felix, wName, "default", wIP, "8055", "tcp")

		}

		// Manually add routing between them.  We need FELIX_REMOVEEXTERNALROUTES and

		// FELIX_INTERFACEPREFIX other than "cali" (above) so that these manual routes

		// aren't removed again by Felix.

		felix.Exec("ip", "route", "add", w[0].IP+"/32", "dev", w[0].InterfaceName)

		felix.Exec("ip", "route", "add", w[1].IP+"/32", "dev", w[1].InterfaceName)

		// Also manually set up proxy ARP.

		felix.Exec("sysctl", "-w", "net.ipv4.conf."+w[0].InterfaceName+".proxy_arp=1")

		felix.Exec("sysctl", "-w", "net.ipv4.conf."+w[1].InterfaceName+".proxy_arp=1")

		felix.Exec("sysctl", "-w", "net.ipv4.neigh."+w[0].InterfaceName+".proxy_delay=0")

		felix.Exec("sysctl", "-w", "net.ipv4.neigh."+w[1].InterfaceName+".proxy_delay=0")

		cc = &connectivity.Checker{}

	})

	AfterEach(func() {

		felix.Stop()

		if CurrentGinkgoTestDescription().Failed {

			infra.DumpErrorData()

			felix.Exec("iptables-save", "-c")


====================
			w[ii] = workload.Run(felix, wName, "default", wIP, "8055", "tcp")

		}

		// Manually add routing between them.  We need FELIX_REMOVEEXTERNALROUTES and

		// FELIX_INTERFACEPREFIX other than "cali" (above) so that these manual routes

		// aren't removed again by Felix.

		felix.Exec("ip", "route", "add", w[0].IP+"/32", "dev", w[0].InterfaceName)

		felix.Exec("ip", "route", "add", w[1].IP+"/32", "dev", w[1].InterfaceName)

		// Also manually set up proxy ARP.

		felix.Exec("sysctl", "-w", "net.ipv4.conf."+w[0].InterfaceName+".proxy_arp=1")

		felix.Exec("sysctl", "-w", "net.ipv4.conf."+w[1].InterfaceName+".proxy_arp=1")

		felix.Exec("sysctl", "-w", "net.ipv4.neigh."+w[0].InterfaceName+".proxy_delay=0")

		felix.Exec("sysctl", "-w", "net.ipv4.neigh."+w[1].InterfaceName+".proxy_delay=0")

		cc = &connectivity.Checker{}

	})

	AfterEach(func() {

		felix.Stop()

		if CurrentGinkgoTestDescription().Failed {

			infra.DumpErrorData()

			felix.Exec("iptables-save", "-c")

			felix.Exec("ipset", "list")


====================
		}

		// Manually add routing between them.  We need FELIX_REMOVEEXTERNALROUTES and

		// FELIX_INTERFACEPREFIX other than "cali" (above) so that these manual routes

		// aren't removed again by Felix.

		felix.Exec("ip", "route", "add", w[0].IP+"/32", "dev", w[0].InterfaceName)

		felix.Exec("ip", "route", "add", w[1].IP+"/32", "dev", w[1].InterfaceName)

		// Also manually set up proxy ARP.

		felix.Exec("sysctl", "-w", "net.ipv4.conf."+w[0].InterfaceName+".proxy_arp=1")

		felix.Exec("sysctl", "-w", "net.ipv4.conf."+w[1].InterfaceName+".proxy_arp=1")

		felix.Exec("sysctl", "-w", "net.ipv4.neigh."+w[0].InterfaceName+".proxy_delay=0")

		felix.Exec("sysctl", "-w", "net.ipv4.neigh."+w[1].InterfaceName+".proxy_delay=0")

		cc = &connectivity.Checker{}

	})

	AfterEach(func() {

		felix.Stop()

		if CurrentGinkgoTestDescription().Failed {

			infra.DumpErrorData()

			felix.Exec("iptables-save", "-c")

			felix.Exec("ipset", "list")

			felix.Exec("ip", "r")


====================
		// Manually add routing between them.  We need FELIX_REMOVEEXTERNALROUTES and

		// FELIX_INTERFACEPREFIX other than "cali" (above) so that these manual routes

		// aren't removed again by Felix.

		felix.Exec("ip", "route", "add", w[0].IP+"/32", "dev", w[0].InterfaceName)

		felix.Exec("ip", "route", "add", w[1].IP+"/32", "dev", w[1].InterfaceName)

		// Also manually set up proxy ARP.

		felix.Exec("sysctl", "-w", "net.ipv4.conf."+w[0].InterfaceName+".proxy_arp=1")

		felix.Exec("sysctl", "-w", "net.ipv4.conf."+w[1].InterfaceName+".proxy_arp=1")

		felix.Exec("sysctl", "-w", "net.ipv4.neigh."+w[0].InterfaceName+".proxy_delay=0")

		felix.Exec("sysctl", "-w", "net.ipv4.neigh."+w[1].InterfaceName+".proxy_delay=0")

		cc = &connectivity.Checker{}

	})

	AfterEach(func() {

		felix.Stop()

		if CurrentGinkgoTestDescription().Failed {

			infra.DumpErrorData()

			felix.Exec("iptables-save", "-c")

			felix.Exec("ipset", "list")

			felix.Exec("ip", "r")

			felix.Exec("ip", "a")


====================
		felix.Exec("sysctl", "-w", "net.ipv4.conf."+w[1].InterfaceName+".proxy_arp=1")

		felix.Exec("sysctl", "-w", "net.ipv4.neigh."+w[0].InterfaceName+".proxy_delay=0")

		felix.Exec("sysctl", "-w", "net.ipv4.neigh."+w[1].InterfaceName+".proxy_delay=0")

		cc = &connectivity.Checker{}

	})

	AfterEach(func() {

		felix.Stop()

		if CurrentGinkgoTestDescription().Failed {

			infra.DumpErrorData()

			felix.Exec("iptables-save", "-c")

			felix.Exec("ipset", "list")

			felix.Exec("ip", "r")

			felix.Exec("ip", "a")

		}

		infra.Stop()

	})

	It("should not forward because of FORWARD DROP policy", func() {

		cc.ExpectNone(w[0], w[1])

		cc.ExpectNone(w[1], w[0])

		cc.CheckConnectivity()


====================
		infra.Stop()

	})

	It("should not forward because of FORWARD DROP policy", func() {

		cc.ExpectNone(w[0], w[1])

		cc.ExpectNone(w[1], w[0])

		cc.CheckConnectivity()

	})

	Context("with FORWARD ACCEPT policy", func() {

		BeforeEach(func() {

			felix.Exec("iptables", "-P", "FORWARD", "ACCEPT")

		})

		It("should now forward", func() {

			cc.ExpectSome(w[0], w[1])

			cc.ExpectSome(w[1], w[0])

			cc.CheckConnectivity()

		})

	})

})

// Copyright (c) 2020-2021 Tigera, Inc. All rights reserved.

//


====================
		cc = &connectivity.Checker{

			ReverseDirection: testSourcePorts,

			Protocol:         protocol,

		}

	})

	AfterEach(func() {

		if CurrentGinkgoTestDescription().Failed {

			log.Warn("Test failed, dumping diags...")

			utils.Run("docker", "logs", felix.Name)

			utils.Run("docker", "exec", felix.Name, "iptables-save", "-c")

			utils.Run("docker", "exec", felix.Name, "ipset", "list")

			utils.Run("docker", "exec", felix.Name, "ip", "r")

			profiles, err := client.Profiles().List(context.Background(), options.ListOptions{})

			if err == nil {

				log.Info("DIAGS: Calico Profiles:")

				for _, profile := range profiles.Items {

					log.Info(profile)

				}

			}

			policies, err := client.NetworkPolicies().List(context.Background(), options.ListOptions{})


====================
			felix.Exec("calico-bpf", "ipsets", "dump")

			felix.Exec("bpftool", "map")

			felix.Exec("bpftool", "prog")

		}

		for ii := range w {

			w[ii].Stop()

		}

		felix.Stop()

		if CurrentGinkgoTestDescription().Failed {

			utils.Run("docker", "exec", etcd.Name, "etcdctl", "get", "/", "--prefix", "--keys-only")

		}

		etcd.Stop()

		infra.Stop()

	})

	type ingressEgress int

	const (

		applyAtW0 ingressEgress = iota

		applyAtOthers

	)

	bpfEnabled := false


====================
		allowHTTPPolicy.Spec.Order = &thousand

		allowHTTPPolicy.Spec.Selector = "name == 'nginx'"

		allowHTTPPolicy.Spec.Types = []api.PolicyType{api.PolicyTypeIngress}

		cc = &connectivity.Checker{}

	})

	AfterEach(func() {

		if CurrentGinkgoTestDescription().Failed {

			log.Warn("Test failed, dumping diags...")

			utils.Run("docker", "logs", felix.Name)

			utils.Run("docker", "exec", felix.Name, "iptables-save", "-c")

			utils.Run("docker", "exec", felix.Name, "ipset", "list")

			utils.Run("docker", "exec", felix.Name, "ip", "r")

		}

		nginx.Stop()

		nginxClient.Stop()

		felix.Stop()

		if CurrentGinkgoTestDescription().Failed {

			utils.Run("docker", "exec", etcd.Name, "etcdctl", "get", "/", "--prefix", "--keys-only")

		}

		etcd.Stop()


====================
			utils.Run("docker", "logs", felix.Name)

			utils.Run("docker", "exec", felix.Name, "iptables-save", "-c")

			utils.Run("docker", "exec", felix.Name, "ipset", "list")

			utils.Run("docker", "exec", felix.Name, "ip", "r")

		}

		nginx.Stop()

		nginxClient.Stop()

		felix.Stop()

		if CurrentGinkgoTestDescription().Failed {

			utils.Run("docker", "exec", etcd.Name, "etcdctl", "get", "/", "--prefix", "--keys-only")

		}

		etcd.Stop()

		infra.Stop()

	})

	It("HTTP port policy should open up nginx port", func() {

		// The profile has a default allow so we should start with connectivity.

		cc.ExpectSome(nginxClient, nginx.Port(80))

		cc.ExpectSome(nginxClient, nginx.Port(81))

		cc.CheckConnectivity()

		// Then we add an (ingress) default deny policy, which should cut it off again.


====================
			}

			_, err = client.HostEndpoints().Create(utils.Ctx, hostEp, utils.NoOptions)

			Expect(err).NotTo(HaveOccurred())

		}

		cc = &connectivity.Checker{}

	})

	AfterEach(func() {

		if CurrentGinkgoTestDescription().Failed {

			for _, felix := range felixes {

				felix.Exec("iptables-save", "-c")

				felix.Exec("ipset", "list")

				felix.Exec("ip", "r")

				felix.Exec("ip", "a")

			}

		}

		for _, wl := range hostW {

			wl.Stop()

		}

		for _, felix := range felixes {

			felix.Stop()


====================
		allowConfusedProtocolPolicy.Spec.Selector = "name == 'nginx'"

		allowConfusedProtocolPolicy.Spec.Types = []api.PolicyType{api.PolicyTypeIngress}

		udpCC = &connectivity.Checker{Protocol: "udp"}

		tcpCC = &connectivity.Checker{Protocol: "tcp"}

	})

	AfterEach(func() {

		if CurrentGinkgoTestDescription().Failed {

			log.Warn("Test failed, dumping diags...")

			utils.Run("docker", "logs", felix.Name)

			utils.Run("docker", "exec", felix.Name, "iptables-save", "-c")

			utils.Run("docker", "exec", felix.Name, "ipset", "list")

			utils.Run("docker", "exec", felix.Name, "ip", "r")

		}

		targetTCPWorkload.Stop()

		targetUDPWorkload.Stop()

		clientWorkload.Stop()

		felix.Stop()

		if CurrentGinkgoTestDescription().Failed {

			utils.Run("docker", "exec", etcd.Name, "etcdctl", "get", "/", "--prefix", "--keys-only")

		}


====================
			utils.Run("docker", "exec", felix.Name, "iptables-save", "-c")

			utils.Run("docker", "exec", felix.Name, "ipset", "list")

			utils.Run("docker", "exec", felix.Name, "ip", "r")

		}

		targetTCPWorkload.Stop()

		targetUDPWorkload.Stop()

		clientWorkload.Stop()

		felix.Stop()

		if CurrentGinkgoTestDescription().Failed {

			utils.Run("docker", "exec", etcd.Name, "etcdctl", "get", "/", "--prefix", "--keys-only")

		}

		etcd.Stop()

		infra.Stop()

	})

	It("shouldn't confuse TCP and UDP ports", func() {

		// The profile has a default allow so we should start with connectivity.

		tcpCC.ExpectSome(clientWorkload, targetTCPWorkload.Port(80))

		tcpCC.ExpectSome(clientWorkload, targetTCPWorkload.Port(81))

		tcpCC.CheckConnectivity()

		udpCC.ExpectSome(clientWorkload, targetUDPWorkload.Port(80))


====================
			w[ii] = workload.Run(felixes[ii], wName, "default", wIP, "8055", "tcp")

			w[ii].ConfigureInInfra(infra)

			hostW[ii] = workload.Run(felixes[ii], fmt.Sprintf("host%d", ii), "", felixes[ii].IP, "8055", "tcp")

		}

		cc = &connectivity.Checker{}

	})

	AfterEach(func() {

		if CurrentGinkgoTestDescription().Failed {

			for _, felix := range felixes {

				felix.Exec("iptables-save", "-c")

				felix.Exec("ipset", "list")

				felix.Exec("ip", "r")

				felix.Exec("ip", "a")

			}

		}

		for _, wl := range w {

			wl.Stop()

		}

		for _, wl := range hostW {

			wl.Stop()


====================
					hep.Spec.Node = f.Hostname

					hep.Spec.ExpectedIPs = []string{f.IP}

					_, err := client.HostEndpoints().Create(ctx, hep, options.SetOptions{})

					Expect(err).NotTo(HaveOccurred())

					// Wait for felix to see and program that host endpoint.

					hostEndpointProgrammed := func() bool {

						if bpfEnabled {

							return f.NumTCBPFProgsEth0() == 2

						} else {

							out, err := f.ExecOutput("iptables-save", "-t", "filter")

							Expect(err).NotTo(HaveOccurred())

							return (strings.Count(out, "cali-thfw-eth0") > 0)

						}

					}

					Eventually(hostEndpointProgrammed, "10s", "1s").Should(BeTrue(),

						"Expected HostEndpoint iptables rules to appear")

				}

			})

			itShouldHaveWorkloadToWorkloadAndHostConnectivity()

		})


====================
					hep.Spec.InterfaceName = "*"

					hep.Spec.ExpectedIPs = []string{f.IP}

					_, err := client.HostEndpoints().Create(ctx, hep, options.SetOptions{})

					Expect(err).NotTo(HaveOccurred())

					// Wait for felix to see and program that host endpoint.

					hostEndpointProgrammed := func() bool {

						if bpfEnabled {

							return f.NumTCBPFProgsEth0() == 2

						} else {

							out, err := f.ExecOutput("iptables-save", "-t", "filter")

							Expect(err).NotTo(HaveOccurred())

							expectedName := rules.EndpointChainName("cali-thfw-", "any-interface-at-all")

							return (strings.Count(out, expectedName) > 0)

						}

					}

					Eventually(hostEndpointProgrammed, "10s", "1s").Should(BeTrue(),

						"Expected HostEndpoint iptables rules to appear")

				}

			})

			itShouldHaveWorkloadToWorkloadAndHostConnectivity()


====================
			wName := fmt.Sprintf("w%d", ii)

			w[ii] = workload.Run(felixes[ii], wName, "default", wIP, "8055", "tcp")

			w[ii].Configure(client)

		}

		cc = &connectivity.Checker{}

	})

	AfterEach(func() {

		if CurrentGinkgoTestDescription().Failed {

			for _, felix := range felixes {

				felix.Exec("iptables-save", "-c")

				felix.Exec("ipset", "list")

				felix.Exec("ip", "r")

			}

		}

		for _, wl := range w {

			wl.Stop()

		}

		for _, felix := range felixes {

			felix.Stop()

		}


====================
			}

		}

		for _, wl := range w {

			wl.Stop()

		}

		for _, felix := range felixes {

			felix.Stop()

		}

		if CurrentGinkgoTestDescription().Failed {

			etcd.Exec("etcdctl", "get", "/", "--prefix", "--keys-only")

		}

		etcd.Stop()

		infra.Stop()

	})

	It("shouldn't use excessive CPU when etcd is stopped", func() {

		By("having initial workload to workload connectivity", func() {

			cc.ExpectSome(w[0], w[1])

			cc.ExpectSome(w[1], w[0])

			cc.CheckConnectivity()

		})


====================
		})

		By("silently dropping etcd packets", func() {

			// Normally, if a connection closes at either end, the other peer's traffic will get

			// FIN or RST responses, which cleanly shut down the connection.  However, in order

			// to test the GRPC-level keep-alive, we want to simulate a network or NAT change that

			// starts to black-hole the TCP connection so that there are no responses of any kind.

			var portRegexp = regexp.MustCompile(`sport=(\d+).*dport=2379`)

			for _, felix := range felixes {

				// Use conntrack to identify the source port that Felix is using.

				out, err := felix.ExecOutput("conntrack", "-L")

				Expect(err).NotTo(HaveOccurred())

				logrus.WithField("output", out).WithError(err).Info("Conntrack entries")

				found := false

				for _, line := range strings.Split(out, "\n") {

					matches := portRegexp.FindStringSubmatch(line)

					if len(matches) < 2 {

						continue

					}

					found = true

					// Use the raw table to drop the TCP connections (to etcd) that felix is using,


====================
				for _, line := range strings.Split(out, "\n") {

					matches := portRegexp.FindStringSubmatch(line)

					if len(matches) < 2 {

						continue

					}

					found = true

					// Use the raw table to drop the TCP connections (to etcd) that felix is using,

					// in both directions, based on source and destination port.

					felix.Exec("iptables",

						"-w", "10", // Retry this for 10 seconds, e.g. if something else is holding the lock

						"-W", "100000", // How often to probe the lock in microsecs.

						"-t", "raw", "-I", "PREROUTING",

						"-p", "tcp",

						"-s", etcd.IP,

						"-m", "multiport", "--destination-ports", matches[1],

						"-j", "DROP")

					felix.Exec("iptables",

						"-w", "10", // Retry this for 10 seconds, e.g. if something else is holding the lock

						"-W", "100000", // How often to probe the lock in microsecs.

						"-t", "raw", "-I", "OUTPUT",


====================
					matches := portRegexp.FindStringSubmatch(line)

					if len(matches) < 2 {

						continue

					}

					found = true

					// Use the raw table to drop the TCP connections (to etcd) that felix is using,

					// in both directions, based on source and destination port.

					felix.Exec("iptables",

						"-w", "10", // Retry this for 10 seconds, e.g. if something else is holding the lock

						"-W", "100000", // How often to probe the lock in microsecs.

						"-t", "raw", "-I", "PREROUTING",

						"-p", "tcp",

						"-s", etcd.IP,

						"-m", "multiport", "--destination-ports", matches[1],

						"-j", "DROP")

					felix.Exec("iptables",

						"-w", "10", // Retry this for 10 seconds, e.g. if something else is holding the lock

						"-W", "100000", // How often to probe the lock in microsecs.

						"-t", "raw", "-I", "OUTPUT",

						"-p", "tcp",


====================
					if len(matches) < 2 {

						continue

					}

					found = true

					// Use the raw table to drop the TCP connections (to etcd) that felix is using,

					// in both directions, based on source and destination port.

					felix.Exec("iptables",

						"-w", "10", // Retry this for 10 seconds, e.g. if something else is holding the lock

						"-W", "100000", // How often to probe the lock in microsecs.

						"-t", "raw", "-I", "PREROUTING",

						"-p", "tcp",

						"-s", etcd.IP,

						"-m", "multiport", "--destination-ports", matches[1],

						"-j", "DROP")

					felix.Exec("iptables",

						"-w", "10", // Retry this for 10 seconds, e.g. if something else is holding the lock

						"-W", "100000", // How often to probe the lock in microsecs.

						"-t", "raw", "-I", "OUTPUT",

						"-p", "tcp",

						"-d", etcd.IP,


====================
						continue

					}

					found = true

					// Use the raw table to drop the TCP connections (to etcd) that felix is using,

					// in both directions, based on source and destination port.

					felix.Exec("iptables",

						"-w", "10", // Retry this for 10 seconds, e.g. if something else is holding the lock

						"-W", "100000", // How often to probe the lock in microsecs.

						"-t", "raw", "-I", "PREROUTING",

						"-p", "tcp",

						"-s", etcd.IP,

						"-m", "multiport", "--destination-ports", matches[1],

						"-j", "DROP")

					felix.Exec("iptables",

						"-w", "10", // Retry this for 10 seconds, e.g. if something else is holding the lock

						"-W", "100000", // How often to probe the lock in microsecs.

						"-t", "raw", "-I", "OUTPUT",

						"-p", "tcp",

						"-d", etcd.IP,

						"-m", "multiport", "--source-ports", matches[1],


====================
					}

					found = true

					// Use the raw table to drop the TCP connections (to etcd) that felix is using,

					// in both directions, based on source and destination port.

					felix.Exec("iptables",

						"-w", "10", // Retry this for 10 seconds, e.g. if something else is holding the lock

						"-W", "100000", // How often to probe the lock in microsecs.

						"-t", "raw", "-I", "PREROUTING",

						"-p", "tcp",

						"-s", etcd.IP,

						"-m", "multiport", "--destination-ports", matches[1],

						"-j", "DROP")

					felix.Exec("iptables",

						"-w", "10", // Retry this for 10 seconds, e.g. if something else is holding the lock

						"-W", "100000", // How often to probe the lock in microsecs.

						"-t", "raw", "-I", "OUTPUT",

						"-p", "tcp",

						"-d", etcd.IP,

						"-m", "multiport", "--source-ports", matches[1],

						"-j", "DROP")


====================
					found = true

					// Use the raw table to drop the TCP connections (to etcd) that felix is using,

					// in both directions, based on source and destination port.

					felix.Exec("iptables",

						"-w", "10", // Retry this for 10 seconds, e.g. if something else is holding the lock

						"-W", "100000", // How often to probe the lock in microsecs.

						"-t", "raw", "-I", "PREROUTING",

						"-p", "tcp",

						"-s", etcd.IP,

						"-m", "multiport", "--destination-ports", matches[1],

						"-j", "DROP")

					felix.Exec("iptables",

						"-w", "10", // Retry this for 10 seconds, e.g. if something else is holding the lock

						"-W", "100000", // How often to probe the lock in microsecs.

						"-t", "raw", "-I", "OUTPUT",

						"-p", "tcp",

						"-d", etcd.IP,

						"-m", "multiport", "--source-ports", matches[1],

						"-j", "DROP")

				}


====================
					// Use the raw table to drop the TCP connections (to etcd) that felix is using,

					// in both directions, based on source and destination port.

					felix.Exec("iptables",

						"-w", "10", // Retry this for 10 seconds, e.g. if something else is holding the lock

						"-W", "100000", // How often to probe the lock in microsecs.

						"-t", "raw", "-I", "PREROUTING",

						"-p", "tcp",

						"-s", etcd.IP,

						"-m", "multiport", "--destination-ports", matches[1],

						"-j", "DROP")

					felix.Exec("iptables",

						"-w", "10", // Retry this for 10 seconds, e.g. if something else is holding the lock

						"-W", "100000", // How often to probe the lock in microsecs.

						"-t", "raw", "-I", "OUTPUT",

						"-p", "tcp",

						"-d", etcd.IP,

						"-m", "multiport", "--source-ports", matches[1],

						"-j", "DROP")

				}

				Expect(found).To(BeTrue(), "Failed to detect any felix->etcd connections")


====================
					felix.Exec("iptables",

						"-w", "10", // Retry this for 10 seconds, e.g. if something else is holding the lock

						"-W", "100000", // How often to probe the lock in microsecs.

						"-t", "raw", "-I", "PREROUTING",

						"-p", "tcp",

						"-s", etcd.IP,

						"-m", "multiport", "--destination-ports", matches[1],

						"-j", "DROP")

					felix.Exec("iptables",

						"-w", "10", // Retry this for 10 seconds, e.g. if something else is holding the lock

						"-W", "100000", // How often to probe the lock in microsecs.

						"-t", "raw", "-I", "OUTPUT",

						"-p", "tcp",

						"-d", etcd.IP,

						"-m", "multiport", "--source-ports", matches[1],

						"-j", "DROP")

				}

				Expect(found).To(BeTrue(), "Failed to detect any felix->etcd connections")

				felix.Exec("conntrack", "-D", "--orig-dst", etcd.IP)

			}


====================
						"-w", "10", // Retry this for 10 seconds, e.g. if something else is holding the lock

						"-W", "100000", // How often to probe the lock in microsecs.

						"-t", "raw", "-I", "PREROUTING",

						"-p", "tcp",

						"-s", etcd.IP,

						"-m", "multiport", "--destination-ports", matches[1],

						"-j", "DROP")

					felix.Exec("iptables",

						"-w", "10", // Retry this for 10 seconds, e.g. if something else is holding the lock

						"-W", "100000", // How often to probe the lock in microsecs.

						"-t", "raw", "-I", "OUTPUT",

						"-p", "tcp",

						"-d", etcd.IP,

						"-m", "multiport", "--source-ports", matches[1],

						"-j", "DROP")

				}

				Expect(found).To(BeTrue(), "Failed to detect any felix->etcd connections")

				felix.Exec("conntrack", "-D", "--orig-dst", etcd.IP)

			}

		})


====================
						"-W", "100000", // How often to probe the lock in microsecs.

						"-t", "raw", "-I", "PREROUTING",

						"-p", "tcp",

						"-s", etcd.IP,

						"-m", "multiport", "--destination-ports", matches[1],

						"-j", "DROP")

					felix.Exec("iptables",

						"-w", "10", // Retry this for 10 seconds, e.g. if something else is holding the lock

						"-W", "100000", // How often to probe the lock in microsecs.

						"-t", "raw", "-I", "OUTPUT",

						"-p", "tcp",

						"-d", etcd.IP,

						"-m", "multiport", "--source-ports", matches[1],

						"-j", "DROP")

				}

				Expect(found).To(BeTrue(), "Failed to detect any felix->etcd connections")

				felix.Exec("conntrack", "-D", "--orig-dst", etcd.IP)

			}

		})

		By("updating policy again", func() {


====================
						"-t", "raw", "-I", "PREROUTING",

						"-p", "tcp",

						"-s", etcd.IP,

						"-m", "multiport", "--destination-ports", matches[1],

						"-j", "DROP")

					felix.Exec("iptables",

						"-w", "10", // Retry this for 10 seconds, e.g. if something else is holding the lock

						"-W", "100000", // How often to probe the lock in microsecs.

						"-t", "raw", "-I", "OUTPUT",

						"-p", "tcp",

						"-d", etcd.IP,

						"-m", "multiport", "--source-ports", matches[1],

						"-j", "DROP")

				}

				Expect(found).To(BeTrue(), "Failed to detect any felix->etcd connections")

				felix.Exec("conntrack", "-D", "--orig-dst", etcd.IP)

			}

		})

		By("updating policy again", func() {

			// Create a Policy that denies all traffic, after we've already cut the etcd connection.


====================
						"-p", "tcp",

						"-s", etcd.IP,

						"-m", "multiport", "--destination-ports", matches[1],

						"-j", "DROP")

					felix.Exec("iptables",

						"-w", "10", // Retry this for 10 seconds, e.g. if something else is holding the lock

						"-W", "100000", // How often to probe the lock in microsecs.

						"-t", "raw", "-I", "OUTPUT",

						"-p", "tcp",

						"-d", etcd.IP,

						"-m", "multiport", "--source-ports", matches[1],

						"-j", "DROP")

				}

				Expect(found).To(BeTrue(), "Failed to detect any felix->etcd connections")

				felix.Exec("conntrack", "-D", "--orig-dst", etcd.IP)

			}

		})

		By("updating policy again", func() {

			// Create a Policy that denies all traffic, after we've already cut the etcd connection.

			deny := api.NewGlobalNetworkPolicy()


====================
						"-s", etcd.IP,

						"-m", "multiport", "--destination-ports", matches[1],

						"-j", "DROP")

					felix.Exec("iptables",

						"-w", "10", // Retry this for 10 seconds, e.g. if something else is holding the lock

						"-W", "100000", // How often to probe the lock in microsecs.

						"-t", "raw", "-I", "OUTPUT",

						"-p", "tcp",

						"-d", etcd.IP,

						"-m", "multiport", "--source-ports", matches[1],

						"-j", "DROP")

				}

				Expect(found).To(BeTrue(), "Failed to detect any felix->etcd connections")

				felix.Exec("conntrack", "-D", "--orig-dst", etcd.IP)

			}

		})

		By("updating policy again", func() {

			// Create a Policy that denies all traffic, after we've already cut the etcd connection.

			deny := api.NewGlobalNetworkPolicy()

			deny.Name = "deny-all"


====================
						"-m", "multiport", "--destination-ports", matches[1],

						"-j", "DROP")

					felix.Exec("iptables",

						"-w", "10", // Retry this for 10 seconds, e.g. if something else is holding the lock

						"-W", "100000", // How often to probe the lock in microsecs.

						"-t", "raw", "-I", "OUTPUT",

						"-p", "tcp",

						"-d", etcd.IP,

						"-m", "multiport", "--source-ports", matches[1],

						"-j", "DROP")

				}

				Expect(found).To(BeTrue(), "Failed to detect any felix->etcd connections")

				felix.Exec("conntrack", "-D", "--orig-dst", etcd.IP)

			}

		})

		By("updating policy again", func() {

			// Create a Policy that denies all traffic, after we've already cut the etcd connection.

			deny := api.NewGlobalNetworkPolicy()

			deny.Name = "deny-all"

			deny.Spec.Selector = "all()"


====================
						"-w", "10", // Retry this for 10 seconds, e.g. if something else is holding the lock

						"-W", "100000", // How often to probe the lock in microsecs.

						"-t", "raw", "-I", "OUTPUT",

						"-p", "tcp",

						"-d", etcd.IP,

						"-m", "multiport", "--source-ports", matches[1],

						"-j", "DROP")

				}

				Expect(found).To(BeTrue(), "Failed to detect any felix->etcd connections")

				felix.Exec("conntrack", "-D", "--orig-dst", etcd.IP)

			}

		})

		By("updating policy again", func() {

			// Create a Policy that denies all traffic, after we've already cut the etcd connection.

			deny := api.NewGlobalNetworkPolicy()

			deny.Name = "deny-all"

			deny.Spec.Selector = "all()"

			deny.Spec.Egress = []api.Rule{{Action: api.Deny}}

			deny.Spec.Ingress = []api.Rule{{Action: api.Deny}}

			_, err := client.GlobalNetworkPolicies().Create(utils.Ctx, deny, utils.NoOptions)


====================
				Consistently(dumpIptables, "5s").Should(MatchRegexp(kubeChainsThatShouldBeCleanedUp))

			})

		}

		It("should clean up our rules", func() {

			Eventually(dumpIptables, "5s").ShouldNot(MatchRegexp(caliChainsThatShouldBeCleanedUp))

		})

	})

	JustAfterEach(func() {

		if CurrentGinkgoTestDescription().Failed {

			felix.Exec("iptables-save", "-c")

			felix.Exec("ip", "r")

		}

	})

	AfterEach(func() {

		log.Info("AfterEach starting")

		felix.Exec("calico-bpf", "connect-time", "clean")

		felix.Stop()

		infra.Stop()

		log.Info("AfterEach done")

	})


====================
			return MetricsPortReachable(felix, bpfEnabled)

		}

		if bpfEnabled {

			Eventually(felix.NumTCBPFProgsEth0, "5s", "200ms").Should(Equal(2))

		}

	})

	AfterEach(func() {

		if CurrentGinkgoTestDescription().Failed {

			infra.DumpErrorData()

			felix.Exec("iptables-save", "-c")

			felix.Exec("ip", "r")

			felix.Exec("ip", "a")

		}

		felix.Stop()

		infra.Stop()

	})

	It("with no endpoints or policy, port should be reachable", func() {

		Eventually(metricsPortReachable, "10s", "1s").Should(BeTrue())

	})

	It("with a local workload, port should be reachable", func() {


====================
	AfterEach(func() {

		if CurrentGinkgoTestDescription().Failed {

			infra.DumpErrorData()

		}

		felixes[0].Stop()

		infra.Stop()

	})

	It("should upgrade conntrack entries from v2 to v3", func() {

		// create conntrack v2 map

		felixes[0].Exec("calico-bpf", "conntrack", "create", "--ver=2")

		srcIP := net.IPv4(123, 123, 123, 123)

		dstIP := net.IPv4(121, 121, 121, 121)

		now := time.Duration(timeshim.RealTime().KTimeNanos())

		leg := v2.Leg{SynSeen: true, AckSeen: true, Opener: true}

		val := v2.NewValueNormal(now, now, 0, leg, leg)

		val64 := base64.StdEncoding.EncodeToString(val[:])

		key := v2.NewKey(6 /* TCP */, srcIP, 0, dstIP, 0)

		key64 := base64.StdEncoding.EncodeToString(key[:])

		// write a normal key

		felixes[0].Exec("calico-bpf", "conntrack", "write", "--ver=2", key64, val64)


====================
		srcIP := net.IPv4(123, 123, 123, 123)

		dstIP := net.IPv4(121, 121, 121, 121)

		now := time.Duration(timeshim.RealTime().KTimeNanos())

		leg := v2.Leg{SynSeen: true, AckSeen: true, Opener: true}

		val := v2.NewValueNormal(now, now, 0, leg, leg)

		val64 := base64.StdEncoding.EncodeToString(val[:])

		key := v2.NewKey(6 /* TCP */, srcIP, 0, dstIP, 0)

		key64 := base64.StdEncoding.EncodeToString(key[:])

		// write a normal key

		felixes[0].Exec("calico-bpf", "conntrack", "write", "--ver=2", key64, val64)

		k3Normal := conntrack.NewKey(6, srcIP, 0, dstIP, 0)

		leg3Normal := conntrack.Leg{SynSeen: true, AckSeen: true, Opener: true}

		val3Normal := conntrack.NewValueNormal(now, now, 0, leg3Normal, leg3Normal)

		srcIP = net.IPv4(121, 123, 125, 124)

		dstIP = net.IPv4(120, 121, 121, 119)

		key = v2.NewKey(11, srcIP, 0, dstIP, 0)

		key64 = base64.StdEncoding.EncodeToString(key[:])

		val = v2.NewValueNATForward(now, now, 0, key)

		val.SetNATSport(4321)

		val64 = base64.StdEncoding.EncodeToString(val[:])


====================
		leg3Normal := conntrack.Leg{SynSeen: true, AckSeen: true, Opener: true}

		val3Normal := conntrack.NewValueNormal(now, now, 0, leg3Normal, leg3Normal)

		srcIP = net.IPv4(121, 123, 125, 124)

		dstIP = net.IPv4(120, 121, 121, 119)

		key = v2.NewKey(11, srcIP, 0, dstIP, 0)

		key64 = base64.StdEncoding.EncodeToString(key[:])

		val = v2.NewValueNATForward(now, now, 0, key)

		val.SetNATSport(4321)

		val64 = base64.StdEncoding.EncodeToString(val[:])

		felixes[0].Exec("calico-bpf", "conntrack", "write", "--ver=2", key64, val64)

		k3NatFwd := conntrack.NewKey(11, srcIP, 0, dstIP, 0)

		val3NatFwd := conntrack.NewValueNATForward(now, now, 0, k3NatFwd)

		val3NatFwd.SetNATSport(4321)

		srcIP = net.IPv4(1, 2, 3, 4)

		dstIP = net.IPv4(5, 6, 7, 8)

		tunIP := net.IPv4(121, 123, 125, 127)

		origIP := net.IPv4(120, 121, 121, 115)

		key = v2.NewKey(11, srcIP, 0, dstIP, 0)

		key64 = base64.StdEncoding.EncodeToString(key[:])

		val = v2.NewValueNATReverse(now, now, 0, leg, leg, tunIP, origIP, 1234)


====================
		val3NatFwd.SetNATSport(4321)

		srcIP = net.IPv4(1, 2, 3, 4)

		dstIP = net.IPv4(5, 6, 7, 8)

		tunIP := net.IPv4(121, 123, 125, 127)

		origIP := net.IPv4(120, 121, 121, 115)

		key = v2.NewKey(11, srcIP, 0, dstIP, 0)

		key64 = base64.StdEncoding.EncodeToString(key[:])

		val = v2.NewValueNATReverse(now, now, 0, leg, leg, tunIP, origIP, 1234)

		val64 = base64.StdEncoding.EncodeToString(val[:])

		felixes[0].Exec("calico-bpf", "conntrack", "write", "--ver=2", key64, val64)

		k3NatRev := conntrack.NewKey(11, srcIP, 0, dstIP, 0)

		val3NatRev := conntrack.NewValueNATReverse(now, now, 0, leg3Normal, leg3Normal, tunIP, origIP, 1234)

		srcIP = net.IPv4(5, 6, 7, 8)

		dstIP = net.IPv4(55, 66, 77, 88)

		key = v2.NewKey(11, srcIP, 0, dstIP, 0)

		tunIP = net.IPv4(12, 13, 15, 17)

		origIP = net.IPv4(10, 11, 12, 15)

		origSIP := net.IPv4(16, 17, 18, 19)

		key = v2.NewKey(11, srcIP, 0, dstIP, 0)

		key64 = base64.StdEncoding.EncodeToString(key[:])


====================
		dstIP = net.IPv4(55, 66, 77, 88)

		key = v2.NewKey(11, srcIP, 0, dstIP, 0)

		tunIP = net.IPv4(12, 13, 15, 17)

		origIP = net.IPv4(10, 11, 12, 15)

		origSIP := net.IPv4(16, 17, 18, 19)

		key = v2.NewKey(11, srcIP, 0, dstIP, 0)

		key64 = base64.StdEncoding.EncodeToString(key[:])

		val = v2.NewValueNATReverseSNAT(now, now, 0, leg, leg, tunIP, origIP, origSIP, 1234)

		val64 = base64.StdEncoding.EncodeToString(val[:])

		felixes[0].Exec("calico-bpf", "conntrack", "write", "--ver=2", key64, val64)

		k3NatRevSnat := conntrack.NewKey(11, srcIP, 0, dstIP, 0)

		val3NatRevSnat := conntrack.NewValueNATReverseSNAT(now, now, 0, leg3Normal, leg3Normal, tunIP, origIP, origSIP, 1234)

		felixes[0].Restart()

		Eventually(func() conntrack.MapMem { return dumpCTMap(felixes[0]) }, "10s", "100ms").Should(HaveKeyWithValue(k3Normal, val3Normal))

		Eventually(func() conntrack.MapMem { return dumpCTMap(felixes[0]) }, "10s", "100ms").Should(HaveKeyWithValue(k3NatFwd, val3NatFwd))

		Eventually(func() conntrack.MapMem { return dumpCTMap(felixes[0]) }, "10s", "100ms").Should(HaveKeyWithValue(k3NatRev, val3NatRev))

		Eventually(func() conntrack.MapMem { return dumpCTMap(felixes[0]) }, "10s", "100ms").Should(HaveKeyWithValue(k3NatRevSnat, val3NatRevSnat))

	})

})

// Copyright (c) 2020-2021 Tigera, Inc. All rights reserved.


====================
		}

		// We will use this container to model an external client trying to connect into

		// workloads on a host.  Create a route in the container for the workload CIDR.

		externalClient = infrastructure.RunExtClient("ext-client")

		externalClient.Exec("ip", "r", "add", "10.65.0.0/24", "via", felix.IP)

	})

	AfterEach(func() {

		if CurrentGinkgoTestDescription().Failed {

			infra.DumpErrorData()

			felix.Exec("iptables-save", "-c")

			felix.Exec("ip", "r")

			felix.Exec("ip", "a")

		}

		for ii := range w {

			w[ii].Stop()

		}

		felix.Stop()

		infra.Stop()

		externalClient.Stop()

	})


====================
			w[ii].Stop()

		}

		felix.Stop()

		infra.Stop()

		externalClient.Stop()

	})

	Context("with node port DNATs", func() {

		BeforeEach(func() {

			felix.Exec(

				"iptables", "-t", "nat",

				"-w", "10", // Retry this for 10 seconds, e.g. if something else is holding the lock

				"-W", "100000", // How often to probe the lock in microsecs.

				"-A", "PREROUTING",

				"-p", "tcp",

				"-d", "10.65.0.10", "--dport", "32010",

				"-j", "DNAT", "--to", "10.65.0.10:8055",

			)

			felix.Exec(

				"iptables", "-t", "nat",

				"-w", "10", // Retry this for 10 seconds, e.g. if something else is holding the lock


====================
		}

		felix.Stop()

		infra.Stop()

		externalClient.Stop()

	})

	Context("with node port DNATs", func() {

		BeforeEach(func() {

			felix.Exec(

				"iptables", "-t", "nat",

				"-w", "10", // Retry this for 10 seconds, e.g. if something else is holding the lock

				"-W", "100000", // How often to probe the lock in microsecs.

				"-A", "PREROUTING",

				"-p", "tcp",

				"-d", "10.65.0.10", "--dport", "32010",

				"-j", "DNAT", "--to", "10.65.0.10:8055",

			)

			felix.Exec(

				"iptables", "-t", "nat",

				"-w", "10", // Retry this for 10 seconds, e.g. if something else is holding the lock

				"-W", "100000", // How often to probe the lock in microsecs.


====================
		felix.Stop()

		infra.Stop()

		externalClient.Stop()

	})

	Context("with node port DNATs", func() {

		BeforeEach(func() {

			felix.Exec(

				"iptables", "-t", "nat",

				"-w", "10", // Retry this for 10 seconds, e.g. if something else is holding the lock

				"-W", "100000", // How often to probe the lock in microsecs.

				"-A", "PREROUTING",

				"-p", "tcp",

				"-d", "10.65.0.10", "--dport", "32010",

				"-j", "DNAT", "--to", "10.65.0.10:8055",

			)

			felix.Exec(

				"iptables", "-t", "nat",

				"-w", "10", // Retry this for 10 seconds, e.g. if something else is holding the lock

				"-W", "100000", // How often to probe the lock in microsecs.

				"-A", "PREROUTING",


====================
		infra.Stop()

		externalClient.Stop()

	})

	Context("with node port DNATs", func() {

		BeforeEach(func() {

			felix.Exec(

				"iptables", "-t", "nat",

				"-w", "10", // Retry this for 10 seconds, e.g. if something else is holding the lock

				"-W", "100000", // How often to probe the lock in microsecs.

				"-A", "PREROUTING",

				"-p", "tcp",

				"-d", "10.65.0.10", "--dport", "32010",

				"-j", "DNAT", "--to", "10.65.0.10:8055",

			)

			felix.Exec(

				"iptables", "-t", "nat",

				"-w", "10", // Retry this for 10 seconds, e.g. if something else is holding the lock

				"-W", "100000", // How often to probe the lock in microsecs.

				"-A", "PREROUTING",

				"-p", "tcp",


====================
		externalClient.Stop()

	})

	Context("with node port DNATs", func() {

		BeforeEach(func() {

			felix.Exec(

				"iptables", "-t", "nat",

				"-w", "10", // Retry this for 10 seconds, e.g. if something else is holding the lock

				"-W", "100000", // How often to probe the lock in microsecs.

				"-A", "PREROUTING",

				"-p", "tcp",

				"-d", "10.65.0.10", "--dport", "32010",

				"-j", "DNAT", "--to", "10.65.0.10:8055",

			)

			felix.Exec(

				"iptables", "-t", "nat",

				"-w", "10", // Retry this for 10 seconds, e.g. if something else is holding the lock

				"-W", "100000", // How often to probe the lock in microsecs.

				"-A", "PREROUTING",

				"-p", "tcp",

				"-d", "10.65.0.11", "--dport", "32011",


====================
	})

	Context("with node port DNATs", func() {

		BeforeEach(func() {

			felix.Exec(

				"iptables", "-t", "nat",

				"-w", "10", // Retry this for 10 seconds, e.g. if something else is holding the lock

				"-W", "100000", // How often to probe the lock in microsecs.

				"-A", "PREROUTING",

				"-p", "tcp",

				"-d", "10.65.0.10", "--dport", "32010",

				"-j", "DNAT", "--to", "10.65.0.10:8055",

			)

			felix.Exec(

				"iptables", "-t", "nat",

				"-w", "10", // Retry this for 10 seconds, e.g. if something else is holding the lock

				"-W", "100000", // How often to probe the lock in microsecs.

				"-A", "PREROUTING",

				"-p", "tcp",

				"-d", "10.65.0.11", "--dport", "32011",

				"-j", "DNAT", "--to", "10.65.0.11:8055",


====================
	Context("with node port DNATs", func() {

		BeforeEach(func() {

			felix.Exec(

				"iptables", "-t", "nat",

				"-w", "10", // Retry this for 10 seconds, e.g. if something else is holding the lock

				"-W", "100000", // How often to probe the lock in microsecs.

				"-A", "PREROUTING",

				"-p", "tcp",

				"-d", "10.65.0.10", "--dport", "32010",

				"-j", "DNAT", "--to", "10.65.0.10:8055",

			)

			felix.Exec(

				"iptables", "-t", "nat",

				"-w", "10", // Retry this for 10 seconds, e.g. if something else is holding the lock

				"-W", "100000", // How often to probe the lock in microsecs.

				"-A", "PREROUTING",

				"-p", "tcp",

				"-d", "10.65.0.11", "--dport", "32011",

				"-j", "DNAT", "--to", "10.65.0.11:8055",

			)


====================
				"iptables", "-t", "nat",

				"-w", "10", // Retry this for 10 seconds, e.g. if something else is holding the lock

				"-W", "100000", // How often to probe the lock in microsecs.

				"-A", "PREROUTING",

				"-p", "tcp",

				"-d", "10.65.0.10", "--dport", "32010",

				"-j", "DNAT", "--to", "10.65.0.10:8055",

			)

			felix.Exec(

				"iptables", "-t", "nat",

				"-w", "10", // Retry this for 10 seconds, e.g. if something else is holding the lock

				"-W", "100000", // How often to probe the lock in microsecs.

				"-A", "PREROUTING",

				"-p", "tcp",

				"-d", "10.65.0.11", "--dport", "32011",

				"-j", "DNAT", "--to", "10.65.0.11:8055",

			)

		})

		It("everyone can connect to node ports", func() {

			cc := &connectivity.Checker{}


====================
				"-w", "10", // Retry this for 10 seconds, e.g. if something else is holding the lock

				"-W", "100000", // How often to probe the lock in microsecs.

				"-A", "PREROUTING",

				"-p", "tcp",

				"-d", "10.65.0.10", "--dport", "32010",

				"-j", "DNAT", "--to", "10.65.0.10:8055",

			)

			felix.Exec(

				"iptables", "-t", "nat",

				"-w", "10", // Retry this for 10 seconds, e.g. if something else is holding the lock

				"-W", "100000", // How often to probe the lock in microsecs.

				"-A", "PREROUTING",

				"-p", "tcp",

				"-d", "10.65.0.11", "--dport", "32011",

				"-j", "DNAT", "--to", "10.65.0.11:8055",

			)

		})

		It("everyone can connect to node ports", func() {

			cc := &connectivity.Checker{}

			cc.ExpectSome(w[0], w[1], 32011)


====================
				"-W", "100000", // How often to probe the lock in microsecs.

				"-A", "PREROUTING",

				"-p", "tcp",

				"-d", "10.65.0.10", "--dport", "32010",

				"-j", "DNAT", "--to", "10.65.0.10:8055",

			)

			felix.Exec(

				"iptables", "-t", "nat",

				"-w", "10", // Retry this for 10 seconds, e.g. if something else is holding the lock

				"-W", "100000", // How often to probe the lock in microsecs.

				"-A", "PREROUTING",

				"-p", "tcp",

				"-d", "10.65.0.11", "--dport", "32011",

				"-j", "DNAT", "--to", "10.65.0.11:8055",

			)

		})

		It("everyone can connect to node ports", func() {

			cc := &connectivity.Checker{}

			cc.ExpectSome(w[0], w[1], 32011)

			cc.ExpectSome(w[1], w[0], 32010)


====================
				"-A", "PREROUTING",

				"-p", "tcp",

				"-d", "10.65.0.10", "--dport", "32010",

				"-j", "DNAT", "--to", "10.65.0.10:8055",

			)

			felix.Exec(

				"iptables", "-t", "nat",

				"-w", "10", // Retry this for 10 seconds, e.g. if something else is holding the lock

				"-W", "100000", // How often to probe the lock in microsecs.

				"-A", "PREROUTING",

				"-p", "tcp",

				"-d", "10.65.0.11", "--dport", "32011",

				"-j", "DNAT", "--to", "10.65.0.11:8055",

			)

		})

		It("everyone can connect to node ports", func() {

			cc := &connectivity.Checker{}

			cc.ExpectSome(w[0], w[1], 32011)

			cc.ExpectSome(w[1], w[0], 32010)

			cc.ExpectSome(externalClient, w[1], 32011)


====================
				"-p", "tcp",

				"-d", "10.65.0.10", "--dport", "32010",

				"-j", "DNAT", "--to", "10.65.0.10:8055",

			)

			felix.Exec(

				"iptables", "-t", "nat",

				"-w", "10", // Retry this for 10 seconds, e.g. if something else is holding the lock

				"-W", "100000", // How often to probe the lock in microsecs.

				"-A", "PREROUTING",

				"-p", "tcp",

				"-d", "10.65.0.11", "--dport", "32011",

				"-j", "DNAT", "--to", "10.65.0.11:8055",

			)

		})

		It("everyone can connect to node ports", func() {

			cc := &connectivity.Checker{}

			cc.ExpectSome(w[0], w[1], 32011)

			cc.ExpectSome(w[1], w[0], 32010)

			cc.ExpectSome(externalClient, w[1], 32011)

			cc.ExpectSome(externalClient, w[0], 32010)


====================
				"-d", "10.65.0.10", "--dport", "32010",

				"-j", "DNAT", "--to", "10.65.0.10:8055",

			)

			felix.Exec(

				"iptables", "-t", "nat",

				"-w", "10", // Retry this for 10 seconds, e.g. if something else is holding the lock

				"-W", "100000", // How often to probe the lock in microsecs.

				"-A", "PREROUTING",

				"-p", "tcp",

				"-d", "10.65.0.11", "--dport", "32011",

				"-j", "DNAT", "--to", "10.65.0.11:8055",

			)

		})

		It("everyone can connect to node ports", func() {

			cc := &connectivity.Checker{}

			cc.ExpectSome(w[0], w[1], 32011)

			cc.ExpectSome(w[1], w[0], 32010)

			cc.ExpectSome(externalClient, w[1], 32011)

			cc.ExpectSome(externalClient, w[0], 32010)

			cc.CheckConnectivityWithTimeout(30 * time.Second)


====================
				"-j", "DNAT", "--to", "10.65.0.10:8055",

			)

			felix.Exec(

				"iptables", "-t", "nat",

				"-w", "10", // Retry this for 10 seconds, e.g. if something else is holding the lock

				"-W", "100000", // How often to probe the lock in microsecs.

				"-A", "PREROUTING",

				"-p", "tcp",

				"-d", "10.65.0.11", "--dport", "32011",

				"-j", "DNAT", "--to", "10.65.0.11:8055",

			)

		})

		It("everyone can connect to node ports", func() {

			cc := &connectivity.Checker{}

			cc.ExpectSome(w[0], w[1], 32011)

			cc.ExpectSome(w[1], w[0], 32010)

			cc.ExpectSome(externalClient, w[1], 32011)

			cc.ExpectSome(externalClient, w[0], 32010)

			cc.CheckConnectivityWithTimeout(30 * time.Second)

		})


====================
		Eventually(secondRunProg1, "10s", "100ms").Should(BeClosed())

		Eventually(secondRunProg2, "10s", "100ms").Should(BeClosed())

		Expect(secondRunBase).NotTo(BeClosed())

	})

	It("should clean up programs when BPFDataIfacePattern changes", func() {

		By("Starting Felix")

		felix.TriggerDelayedStart()

		By("Checking that eth0 has a program")

		Eventually(func() string {

			out, _ := felix.ExecOutput("bpftool", "-jp", "net")

			return out

		}, "15s", "1s").Should(ContainSubstring("eth0"))

		By("Changing env and restarting felix")

		felix.SetEvn(map[string]string{"FELIX_BPFDataIfacePattern": "eth1"})

		felix.Restart()

		By("Checking that eth0 does not have a program anymore")

		Eventually(func() string {

			out, _ := felix.ExecOutput("bpftool", "-jp", "net")

			return out

		}, "15s", "1s").ShouldNot(ContainSubstring("eth0"))


====================
		Eventually(func() string {

			out, _ := felix.ExecOutput("bpftool", "-jp", "net")

			return out

		}, "15s", "1s").Should(ContainSubstring("eth0"))

		By("Changing env and restarting felix")

		felix.SetEvn(map[string]string{"FELIX_BPFDataIfacePattern": "eth1"})

		felix.Restart()

		By("Checking that eth0 does not have a program anymore")

		Eventually(func() string {

			out, _ := felix.ExecOutput("bpftool", "-jp", "net")

			return out

		}, "15s", "1s").ShouldNot(ContainSubstring("eth0"))

	})

})

//go:build fvtests

// Copyright (c) 2017,2022 Tigera, Inc. All rights reserved.

//

// Licensed under the Apache License, Version 2.0 (the "License");

// you may not use this file except in compliance with the License.

// You may obtain a copy of the License at


====================
		// check the lock behaviour.  Note: we don't map the host's iptables lock into the

		// container so the scope of the lock is limited to the container.

		wd, err := os.Getwd()

		Expect(err).NotTo(HaveOccurred(), "failed to get working directory")

		fvBin := os.Getenv("FV_BINARY")

		if fvBin == "" {

			fvBin = "bin/calico-felix-amd64"

		}

		felixCmd = utils.Command("docker", "run",

			"--rm",

			"--name", containerName,

			"-v", fmt.Sprintf("%s/..:/codebase", myDir),

			"-v", fmt.Sprintf("%s:/usr/local/bin/calico-felix", path.Join(wd, "..", fvBin)),

			"--privileged",

			utils.Config.FelixImage)

		err = felixCmd.Start()

		Expect(err).NotTo(HaveOccurred())

		log.Info("Waiting for container to be listed in docker ps")

		start := time.Now()

		for {


====================
		// container so the scope of the lock is limited to the container.

		wd, err := os.Getwd()

		Expect(err).NotTo(HaveOccurred(), "failed to get working directory")

		fvBin := os.Getenv("FV_BINARY")

		if fvBin == "" {

			fvBin = "bin/calico-felix-amd64"

		}

		felixCmd = utils.Command("docker", "run",

			"--rm",

			"--name", containerName,

			"-v", fmt.Sprintf("%s/..:/codebase", myDir),

			"-v", fmt.Sprintf("%s:/usr/local/bin/calico-felix", path.Join(wd, "..", fvBin)),

			"--privileged",

			utils.Config.FelixImage)

		err = felixCmd.Start()

		Expect(err).NotTo(HaveOccurred())

		log.Info("Waiting for container to be listed in docker ps")

		start := time.Now()

		for {

			cmd := utils.Command("docker", "ps")


====================
		wd, err := os.Getwd()

		Expect(err).NotTo(HaveOccurred(), "failed to get working directory")

		fvBin := os.Getenv("FV_BINARY")

		if fvBin == "" {

			fvBin = "bin/calico-felix-amd64"

		}

		felixCmd = utils.Command("docker", "run",

			"--rm",

			"--name", containerName,

			"-v", fmt.Sprintf("%s/..:/codebase", myDir),

			"-v", fmt.Sprintf("%s:/usr/local/bin/calico-felix", path.Join(wd, "..", fvBin)),

			"--privileged",

			utils.Config.FelixImage)

		err = felixCmd.Start()

		Expect(err).NotTo(HaveOccurred())

		log.Info("Waiting for container to be listed in docker ps")

		start := time.Now()

		for {

			cmd := utils.Command("docker", "ps")

			out, err := cmd.CombinedOutput()


====================
		Expect(err).NotTo(HaveOccurred(), "failed to get working directory")

		fvBin := os.Getenv("FV_BINARY")

		if fvBin == "" {

			fvBin = "bin/calico-felix-amd64"

		}

		felixCmd = utils.Command("docker", "run",

			"--rm",

			"--name", containerName,

			"-v", fmt.Sprintf("%s/..:/codebase", myDir),

			"-v", fmt.Sprintf("%s:/usr/local/bin/calico-felix", path.Join(wd, "..", fvBin)),

			"--privileged",

			utils.Config.FelixImage)

		err = felixCmd.Start()

		Expect(err).NotTo(HaveOccurred())

		log.Info("Waiting for container to be listed in docker ps")

		start := time.Now()

		for {

			cmd := utils.Command("docker", "ps")

			out, err := cmd.CombinedOutput()

			Expect(err).NotTo(HaveOccurred())


====================
		fvBin := os.Getenv("FV_BINARY")

		if fvBin == "" {

			fvBin = "bin/calico-felix-amd64"

		}

		felixCmd = utils.Command("docker", "run",

			"--rm",

			"--name", containerName,

			"-v", fmt.Sprintf("%s/..:/codebase", myDir),

			"-v", fmt.Sprintf("%s:/usr/local/bin/calico-felix", path.Join(wd, "..", fvBin)),

			"--privileged",

			utils.Config.FelixImage)

		err = felixCmd.Start()

		Expect(err).NotTo(HaveOccurred())

		log.Info("Waiting for container to be listed in docker ps")

		start := time.Now()

		for {

			cmd := utils.Command("docker", "ps")

			out, err := cmd.CombinedOutput()

			Expect(err).NotTo(HaveOccurred())

			if strings.Contains(string(out), containerName) {


====================
			if !scanResult {

				log.WithError(scanner.Err()).Warning("Scan failed")

			}

			Expect(scanResult).To(BeTrue())

			Expect(scanner.Text()).To(Equal("LOCKED"))

			Expect(scanner.Err()).NotTo(HaveOccurred())

			log.Info("iptables-locker acquired lock")

		})

		It("iptables should fail to get the lock in 1s", func() {

			iptCmd := cmdInContainer("iptables", "-w", "1", "-A", "FORWARD")

			out, err := iptCmd.CombinedOutput()

			Expect(string(out)).To(ContainSubstring("Stopped waiting"))

			Expect(err).To(HaveOccurred())

		})

		It("iptables should succeed in getting the lock after 3s", func() {

			iptCmd := cmdInContainer("iptables", "-w", "3", "-A", "FORWARD")

			out, err := iptCmd.CombinedOutput()

			log.Infof("iptables output='%s'", out)

			Expect(err).NotTo(HaveOccurred())

		})


====================
			log.Info("iptables-locker acquired lock")

		})

		It("iptables should fail to get the lock in 1s", func() {

			iptCmd := cmdInContainer("iptables", "-w", "1", "-A", "FORWARD")

			out, err := iptCmd.CombinedOutput()

			Expect(string(out)).To(ContainSubstring("Stopped waiting"))

			Expect(err).To(HaveOccurred())

		})

		It("iptables should succeed in getting the lock after 3s", func() {

			iptCmd := cmdInContainer("iptables", "-w", "3", "-A", "FORWARD")

			out, err := iptCmd.CombinedOutput()

			log.Infof("iptables output='%s'", out)

			Expect(err).NotTo(HaveOccurred())

		})

		AfterEach(func() {

			if lockCmd != nil {

				log.Info("waiting for iptables-locker to finish")

				err := lockCmd.Wait()

				Expect(err).NotTo(HaveOccurred())

			}


====================
			w[ii] = workload.Run(felixes[ii], wName, "default", wIP, "80,81", "tcp")

			w[ii].ConfigureInInfra(infra)

			hostW[ii] = workload.Run(felixes[ii], fmt.Sprintf("host%d", ii), "", felixes[ii].IP, "8055", "tcp")

		}

		cc = &connectivity.Checker{}

	})

	AfterEach(func() {

		if CurrentGinkgoTestDescription().Failed {

			for _, felix := range felixes {

				felix.Exec("iptables-save", "-c")

				felix.Exec("ipset", "list")

				felix.Exec("ip", "r")

				felix.Exec("ip", "a")

			}

		}

		for _, wl := range w {

			wl.Stop()

		}

		for _, wl := range hostW {

			wl.Stop()


====================
				// Run these tests only when the Host has Wireguard kernel module installed.

				if os.Getenv("FELIX_FV_WIREGUARD_AVAILABLE") != "true" {

					Skip("Skipping Wireguard supported tests.")

				}

				// IPv6 Wireguard is not supported on BPF dataplane, so skip in this case

				if wireguardEnabledV6 && os.Getenv("FELIX_FV_ENABLE_BPF") == "true" {

					Skip("Skipping IPv6 Wireguard testing on BPF dataplane")

				}

				// Enable Wireguard module debugging.

				utils.Run("sudo", "sh", "-c", "echo module wireguard +p > /sys/kernel/debug/dynamic_debug/control")

				// Start a process tailing the dmesg log.

				ctx, cancel := context.WithCancel(context.Background())

				dmesgCmd = exec.CommandContext(ctx, "sudo", "dmesg", "-wH")

				dmesgCmd.Stdout = &dmesgBuf

				dmesgCmd.Stderr = &dmesgBuf

				err := dmesgCmd.Start()

				Expect(err).NotTo(HaveOccurred())

				dmesgKill = cancel

				log.Info("Started dmesg log capture")

				infra = getInfra()


====================
				}

				// IPv6 Wireguard is not supported on BPF dataplane, so skip in this case

				if wireguardEnabledV6 && os.Getenv("FELIX_FV_ENABLE_BPF") == "true" {

					Skip("Skipping IPv6 Wireguard testing on BPF dataplane")

				}

				// Enable Wireguard module debugging.

				utils.Run("sudo", "sh", "-c", "echo module wireguard +p > /sys/kernel/debug/dynamic_debug/control")

				// Start a process tailing the dmesg log.

				ctx, cancel := context.WithCancel(context.Background())

				dmesgCmd = exec.CommandContext(ctx, "sudo", "dmesg", "-wH")

				dmesgCmd.Stdout = &dmesgBuf

				dmesgCmd.Stderr = &dmesgBuf

				err := dmesgCmd.Start()

				Expect(err).NotTo(HaveOccurred())

				dmesgKill = cancel

				log.Info("Started dmesg log capture")

				infra = getInfra()

				topologyOptions := wireguardTopologyOptions(

					"CalicoIPAM", true, wireguardEnabledV4, wireguardEnabledV6,

					map[string]string{


====================
						}

					}

				})

				It("the Wireguard device should be configurable", func() {

					disableWireguard(client)

					// Old configuration should disappear.

					for _, felix := range felixes {

						if wireguardEnabledV4 {

							Eventually(func() string {

								out, _ := felix.ExecOutput("ip", "-d", "link", "show", wireguardInterfaceNameDefault)

								return out

							}, "10s", "100ms").Should(BeEmpty())

							Eventually(func() string {

								out, err := felix.ExecOutput("ip", "rule", "show", "pref", wireguardRoutingRulePriorityDefault)

								Expect(err).NotTo(HaveOccurred())

								return out

							}, "10s", "100ms").Should(BeEmpty())

						}

						if wireguardEnabledV6 {

							Eventually(func() string {


====================
							}, "10s", "100ms").Should(BeEmpty())

							Eventually(func() string {

								out, err := felix.ExecOutput("ip", "rule", "show", "pref", wireguardRoutingRulePriorityDefault)

								Expect(err).NotTo(HaveOccurred())

								return out

							}, "10s", "100ms").Should(BeEmpty())

						}

						if wireguardEnabledV6 {

							Eventually(func() string {

								out, _ := felix.ExecOutput("ip", "-d", "link", "show", wireguardInterfaceNameV6Default)

								return out

							}, "10s", "100ms").Should(BeEmpty())

							Eventually(func() string {

								out, err := felix.ExecOutput("ip", "-6", "rule", "show", "pref", wireguardRoutingRulePriorityDefault)

								Expect(err).NotTo(HaveOccurred())

								return out

							}, "10s", "100ms").Should(BeEmpty())

						}

					}

					// Change Wireguard configuration.


====================
								return out

							}, "10s", "100ms").Should(BeEmpty())

						}

						if wireguardEnabledV6 {

							Eventually(func() string {

								out, _ := felix.ExecOutput("ip", "-d", "link", "show", wireguardInterfaceNameV6Default)

								return out

							}, "10s", "100ms").Should(BeEmpty())

							Eventually(func() string {

								out, err := felix.ExecOutput("ip", "-6", "rule", "show", "pref", wireguardRoutingRulePriorityDefault)

								Expect(err).NotTo(HaveOccurred())

								return out

							}, "10s", "100ms").Should(BeEmpty())

						}

					}

					// Change Wireguard configuration.

					ifaceName := "wg0"

					ifaceNameV6 := "wg1"

					mtu := 1400

					mtuV6 := 1380


====================
					fc.Spec.WireguardListeningPortV6 = &portV6

					fc.Spec.WireguardRoutingRulePriority = &rule

					_, err = client.FelixConfigurations().Update(ctx, fc, options.SetOptions{})

					Expect(err).NotTo(HaveOccurred())

					updateWireguardEnabledConfig(client, wireguardEnabledV4, wireguardEnabledV6)

					// New Wireguard device should appear with default MTU, etc.

					for _, felix := range felixes {

						if wireguardEnabledV4 {

							Eventually(func() string {

								out, _ := felix.ExecOutput("ip", "-d", "link", "show", ifaceName)

								return out

							}, "10s", "100ms").Should(ContainSubstring(fmt.Sprintf("mtu %d", mtu)))

						}

						if wireguardEnabledV6 {

							Eventually(func() string {

								out, _ := felix.ExecOutput("ip", "-d", "link", "show", ifaceNameV6)

								return out

							}, "10s", "100ms").Should(ContainSubstring(fmt.Sprintf("mtu %d", mtuV6)))

						}

					}


====================
					for _, felix := range felixes {

						if wireguardEnabledV4 {

							Eventually(func() string {

								out, _ := felix.ExecOutput("ip", "-d", "link", "show", ifaceName)

								return out

							}, "10s", "100ms").Should(ContainSubstring(fmt.Sprintf("mtu %d", mtu)))

						}

						if wireguardEnabledV6 {

							Eventually(func() string {

								out, _ := felix.ExecOutput("ip", "-d", "link", "show", ifaceNameV6)

								return out

							}, "10s", "100ms").Should(ContainSubstring(fmt.Sprintf("mtu %d", mtuV6)))

						}

					}

					// Expect the settings to be changed on the device.

					for _, felix := range felixes {

						if wireguardEnabledV4 {

							Eventually(func() string {

								out, err := felix.ExecOutput("wg", "show", ifaceName)

								Expect(err).NotTo(HaveOccurred())


====================
							}, "10s", "100ms").ShouldNot(BeEmpty())

						}

						if wireguardEnabledV6 {

							Eventually(func() string {

								out, err := felix.ExecOutput("wg", "show", ifaceNameV6)

								Expect(err).NotTo(HaveOccurred())

								return out

							}, "10s", "100ms").Should(ContainSubstring(fmt.Sprintf("listening port: %d", portV6)))

							Eventually(func() string {

								out, err := felix.ExecOutput("ip", "-6", "rule", "show", "pref", fmt.Sprintf("%d", rule))

								Expect(err).NotTo(HaveOccurred())

								return out

							}, "10s", "100ms").ShouldNot(BeEmpty())

						}

					}

				})

				It("v3 node resource annotations should contain public-keys", func() {

					for _, felix := range felixes {

						if wireguardEnabledV4 {

							Eventually(func() string {


====================
							if wireguardEnabledV6 {

								hep.Spec.ExpectedIPs = append(hep.Spec.ExpectedIPs, f.IPv6)

							}

							hep.Spec.InterfaceName = tc.hep

							_, err := client.HostEndpoints().Create(utils.Ctx, hep, options.SetOptions{})

							Expect(err).NotTo(HaveOccurred())

						}

						By("Setting iptables INPUT chain policy to " + tc.iptablesPolicy)

						for _, felix := range felixes {

							_, err := felix.ExecOutput("iptables", "-w", "10", "-W", "100000", "-P", "INPUT", tc.iptablesPolicy)

							Expect(err).NotTo(HaveOccurred())

						}

						By("Waiting for the policy to apply")

						// XXX this is lame, but will have to do until we have a way do

						// XXX to confirm policy applied in BPF. Then we will fix both

						// XXX iptables and BPF properly.

						time.Sleep(30 * time.Second)

						By("Checking there is eventually and consistently connectivity between the workloads using wg")

						Eventually(checkConn, "5s", "100ms").ShouldNot(HaveOccurred())

						Consistently(checkConn, "2s", "100ms").ShouldNot(HaveOccurred())


====================
		cc = &connectivity.Checker{

			// If two nodes send their first packet within a few milliseconds then any on-demand Wireguard

			// handshake can fail and back off if the handshakes cross on the wire.

			StaggerStartBy: 100 * time.Millisecond,

		}

		// Ping other felix nodes from each node to trigger Wireguard handshakes.

		for i, felix := range felixes {

			for j := range felixes {

				if i != j {

					if err := felix.ExecMayFail("ping", "-c", "1", "-W", "1", "-s", "1", felixes[j].IP); err != nil {

						log.WithError(err).Warning("felix.ExecMayFail returned err")

					}

				}

			}

		}

		// Check felix nodes have performed Wireguard handshakes.

		for i, felix := range felixes {

			var matchers []types.GomegaMatcher

			for j := range felixes {

				if i != j {


====================
	})

	AfterEach(func() {

		if CurrentGinkgoTestDescription().Failed {

			for _, felix := range felixes {

				felix.Exec("ip", "addr")

				felix.Exec("ip", "rule", "list")

				felix.Exec("ip", "route", "show", "table", "all")

				felix.Exec("ip", "route", "show", "cached")

				felix.Exec("wg")

				felix.Exec("iptables-save", "-c", "-t", "raw")

				felix.Exec("iptables", "-L", "-vx")

				felix.Exec("cat", "/proc/sys/net/ipv4/conf/all/src_valid_mark")

			}

		}

		for felixIdx, felixWls := range wlsByHost {

			for i := range felixWls {

				wlsByHost[felixIdx][i].Stop()

			}

		}

		externalClient.Stop()


====================
	AfterEach(func() {

		if CurrentGinkgoTestDescription().Failed {

			for _, felix := range felixes {

				felix.Exec("ip", "addr")

				felix.Exec("ip", "rule", "list")

				felix.Exec("ip", "route", "show", "table", "all")

				felix.Exec("ip", "route", "show", "cached")

				felix.Exec("wg")

				felix.Exec("iptables-save", "-c", "-t", "raw")

				felix.Exec("iptables", "-L", "-vx")

				felix.Exec("cat", "/proc/sys/net/ipv4/conf/all/src_valid_mark")

			}

		}

		for felixIdx, felixWls := range wlsByHost {

			for i := range felixWls {

				wlsByHost[felixIdx][i].Stop()

			}

		}

		externalClient.Stop()

		for _, tcpdump := range tcpdumps {


====================
				}

			}

			Eventually(func() []string {

				return strings.Split(getWireguardRouteEntry(felixes[i], 4), "\n")

			}, "10s", "100ms").Should(ContainElements(matchers))

		}

		By("Checking the iptables raw chain cali-wireguard-incoming-mark exists")

		for _, felix := range felixes {

			Eventually(func() string {

				s, _ := felix.ExecCombinedOutput("iptables", "-L", "cali-wireguard-incoming-mark", "-t", "raw")

				return s

			}, "10s", "100ms").Should(ContainSubstring("Chain cali-wireguard-incoming-mark"))

		}

		By("Checking the proc/sys src valid mark entries")

		for _, felix := range felixes {

			Eventually(func() string {

				s, _ := felix.ExecCombinedOutput("cat", "/proc/sys/net/ipv4/conf/all/src_valid_mark")

				return s

			}, "10s", "100ms").Should(ContainSubstring("1"))

		}


====================
		for _, wl := range hostNetworkedWls {

			for j := range wlsByHost {

				cc.ExpectSome(wl, wlsByHost[j][0])

			}

		}

		By("checking external node to pod connectivity")

		cc.ExpectSome(externalClient, wlsByHost[0][0])

		By("checking prometheus metrics render")

		for _, felix := range felixes {

			s, err := felix.ExecCombinedOutput("wget", "localhost:9091/metrics", "-O", "-")

			Expect(err).ToNot(HaveOccurred())

			// quick and dirty comparison to see if metrics we want exist and with correct type

			for _, expectedMetric := range []string{

				"# TYPE wireguard_meta gauge",

				"# TYPE wireguard_latest_handshake_seconds gauge",

				"# TYPE wireguard_bytes_rcvd counter",

				"# TYPE wireguard_bytes_sent counter",

			} {

				Expect(s).To(ContainSubstring(expectedMetric))

			}


====================
}

func getWireguardRoutingRule(felix *infrastructure.Felix, ipVersion int) string {

	Expect(ipVersion == 4 || ipVersion == 6).To(BeTrue())

	var rule string

	var err error

	switch ipVersion {

	case 4:

		rule, err = felix.ExecOutput("ip", "rule", "show", "pref", wireguardRoutingRulePriorityDefault)

	case 6:

		rule, err = felix.ExecOutput("ip", "-6", "rule", "show", "pref", wireguardRoutingRulePriorityDefault)

	}

	Expect(err).NotTo(HaveOccurred())

	return strings.TrimSpace(rule)

}

func getWireguardRouteEntry(felix *infrastructure.Felix, ipVersion int) string {

	Expect(ipVersion == 4 || ipVersion == 6).To(BeTrue())

	rule := getWireguardRoutingRule(felix, ipVersion)

	// Get route table index from rule.

	routingRuleRegExp := regexp.MustCompile(`\d+$`)

	tableId := routingRuleRegExp.FindString(rule)


====================
		return ""

	}

	// Check route table entry.

	var routes string

	var err error

	switch ipVersion {

	case 4:

		routes, err = felix.ExecOutput("ip", "route", "show", "table", tableId)

	case 6:

		routes, err = felix.ExecOutput("ip", "-6", "route", "show", "table", tableId)

	}

	Expect(err).NotTo(HaveOccurred())

	return routes

}

func disableWireguardForFelix(client clientv3.Interface, felixName string) {

	ctx, cancel := context.WithTimeout(context.Background(), 10*time.Second)

	defer cancel()

	felixConfig := api.NewFelixConfiguration()

	felixConfig.SetName(felixName)

	disabled := false


====================
		tunnel:      "none",

	}

	for _, o := range opts {

		o(&testOpts)

	}

	testIfTCP := testOpts.protocol == "tcp"

	testIfNotUDPUConnected := (!testOpts.udpUnConnected)

	protoExt := ""

	if testOpts.udpUnConnected {

		protoExt = "-unconnected"

	}

	if testOpts.udpConnRecvMsg {

		protoExt = "-conn-recvmsg"

	}

	desc := fmt.Sprintf("_BPF_ _BPF-SAFE_ BPF tests (%s%s, ct=%v, log=%s, tunnel=%s, dsr=%v)",

		testOpts.protocol, protoExt, testOpts.connTimeEnabled,

		testOpts.bpfLogLevel, testOpts.tunnel, testOpts.dsr,

	)

	return infrastructure.DatastoreDescribe(desc, []apiconfig.DatastoreType{apiconfig.Kubernetes}, func(getInfra infrastructure.InfraFactory) {

		var (


====================
		o(&testOpts)

	}

	testIfTCP := testOpts.protocol == "tcp"

	testIfNotUDPUConnected := (!testOpts.udpUnConnected)

	protoExt := ""

	if testOpts.udpUnConnected {

		protoExt = "-unconnected"

	}

	if testOpts.udpConnRecvMsg {

		protoExt = "-conn-recvmsg"

	}

	desc := fmt.Sprintf("_BPF_ _BPF-SAFE_ BPF tests (%s%s, ct=%v, log=%s, tunnel=%s, dsr=%v)",

		testOpts.protocol, protoExt, testOpts.connTimeEnabled,

		testOpts.bpfLogLevel, testOpts.tunnel, testOpts.dsr,

	)

	return infrastructure.DatastoreDescribe(desc, []apiconfig.DatastoreType{apiconfig.Kubernetes}, func(getInfra infrastructure.InfraFactory) {

		var (

			infra              infrastructure.DatastoreInfra

			felixes            []*infrastructure.Felix

			calicoClient       client.Interface


====================
		}

		BeforeEach(func() {

			felixPanicExpected = false

			infra = getInfra()

			cc = &Checker{

				CheckSNAT: true,

			}

			cc.Protocol = testOpts.protocol

			if testOpts.protocol == "udp" && testOpts.udpUnConnected {

				cc.Protocol += "-noconn"

			}

			if testOpts.protocol == "udp" && testOpts.udpConnRecvMsg {

				cc.Protocol += "-recvmsg"

			}

			options = infrastructure.DefaultTopologyOptions()

			options.NATOutgoingEnabled = true

			options.AutoHEPsEnabled = true

			// override IPIP being enabled by default

			options.IPIPEnabled = false

			options.IPIPRoutesEnabled = false


====================
			infra = getInfra()

			cc = &Checker{

				CheckSNAT: true,

			}

			cc.Protocol = testOpts.protocol

			if testOpts.protocol == "udp" && testOpts.udpUnConnected {

				cc.Protocol += "-noconn"

			}

			if testOpts.protocol == "udp" && testOpts.udpConnRecvMsg {

				cc.Protocol += "-recvmsg"

			}

			options = infrastructure.DefaultTopologyOptions()

			options.NATOutgoingEnabled = true

			options.AutoHEPsEnabled = true

			// override IPIP being enabled by default

			options.IPIPEnabled = false

			options.IPIPRoutesEnabled = false

			// BPF doesn't support IPv6, disable it.

			options.EnableIPv6 = false

			switch testOpts.tunnel {


====================
				} else {

					options.ExtraEnvVars["FELIX_FeatureGates"] = "BPFConnectTimeLoadBalancingWorkaround=enabled"

				}

			}

		})

		JustAfterEach(func() {

			if CurrentGinkgoTestDescription().Failed {

				currBpfsvcs, currBpfeps := dumpNATmaps(felixes)

				for i, felix := range felixes {

					felix.Exec("iptables-save", "-c")

					felix.Exec("conntrack", "-L")

					felix.Exec("ip", "link")

					felix.Exec("ip", "addr")

					felix.Exec("ip", "rule")

					felix.Exec("ip", "route")

					felix.Exec("ip", "neigh")

					felix.Exec("arp")

					felix.Exec("calico-bpf", "ipsets", "dump")

					felix.Exec("calico-bpf", "routes", "dump")

					felix.Exec("calico-bpf", "nat", "dump")


====================
					options.ExtraEnvVars["FELIX_FeatureGates"] = "BPFConnectTimeLoadBalancingWorkaround=enabled"

				}

			}

		})

		JustAfterEach(func() {

			if CurrentGinkgoTestDescription().Failed {

				currBpfsvcs, currBpfeps := dumpNATmaps(felixes)

				for i, felix := range felixes {

					felix.Exec("iptables-save", "-c")

					felix.Exec("conntrack", "-L")

					felix.Exec("ip", "link")

					felix.Exec("ip", "addr")

					felix.Exec("ip", "rule")

					felix.Exec("ip", "route")

					felix.Exec("ip", "neigh")

					felix.Exec("arp")

					felix.Exec("calico-bpf", "ipsets", "dump")

					felix.Exec("calico-bpf", "routes", "dump")

					felix.Exec("calico-bpf", "nat", "dump")

					felix.Exec("calico-bpf", "nat", "aff")


====================
				It("should only allow traffic from workload to workload", func() {

					cc.ExpectSome(w[0], w[1])

					cc.ExpectSome(w[1], w[0])

					cc.ExpectNone(w[1], hostW)

					cc.ExpectSome(hostW, w[0])

					cc.CheckConnectivity(conntrackChecks(felixes)...)

				})

			})

			getMapIDByPath := func(felix *infrastructure.Felix, filename string) (int, error) {

				out, err := felix.ExecOutput("bpftool", "map", "show", "pinned", filename, "-j")

				if err != nil {

					return 0, err

				}

				var mapMeta struct {

					ID    int    `json:"id"`

					Error string `json:"error"`

				}

				err = json.Unmarshal([]byte(out), &mapMeta)

				if err != nil {

					return 0, err


====================
						defer extraFelix.Stop()

						secondMapID := mustGetMapIDByPath(extraFelix, mapPath)

						Expect(mapID).NotTo(BeNumerically("==", 0))

						Expect(mapID).NotTo(BeNumerically("==", secondMapID))

					})

				})

				It("should clean up jump maps", func() {

					numJumpMaps := func() int {

						command := fmt.Sprintf("find /sys/fs/bpf/tc -name %s", bpf.JumpMapName())

						output, err := felixes[0].ExecOutput("sh", "-c", command)

						Expect(err).NotTo(HaveOccurred())

						return strings.Count(output, bpf.JumpMapName())

					}

					expJumpMaps := func(numWorkloads int) int {

						numHostIfaces := 1

						specialIfaces := 0

						if ctlbWorkaround {

							specialIfaces = 2 /* nat + lo */

						}

						expectedNumMaps := 2*numWorkloads + 2*numHostIfaces + 2*specialIfaces


====================
					defer cancelFn()

					go func() {

						defer wg.Done()

						defer GinkgoRecover()

						for {

							if ctx.Err() != nil {

								return

							}

							_, err = w[1][0].RunCmd("pktgen", w[1][0].IP, dpOnlyWorkload.IP, "udp",

								"--port-src", "30444", "--port-dst", "8057")

							Expect(err).NotTo(HaveOccurred())

							time.Sleep(100 * (time.Millisecond))

						}

					}()

					defer wg.Wait()

					Consistently(tcpdump.MatchCountFn("UDP-8057"), "5s", "200ms").Should(

						BeNumerically("==", 0),

						"Traffic to the workload should be blocked before datastore is configured")

					dpOnlyWorkload.ConfigureInInfra(infra)

					Eventually(tcpdump.MatchCountFn("UDP-8057"), "5s", "200ms").Should(


====================
						By("Should get pongs again after switching WEP to spoof iface")

						expectPongs()

					})

				}

				// Test doesn't use services so ignore the runs with those turned on.

				if testOpts.protocol == "udp" && !testOpts.connTimeEnabled && !testOpts.dsr {

					It("should not be able to spoof UDP", func() {

						By("Disabling dev RPF")

						setRPF(felixes, testOpts.tunnel, 0, 0)

						felixes[1].Exec("sysctl", "-w", "net.ipv4.conf."+w[1][0].InterfaceName+".rp_filter=0")

						felixes[1].Exec("sysctl", "-w", "net.ipv4.conf."+w[1][1].InterfaceName+".rp_filter=0")

						By("allowing any traffic", func() {

							pol.Spec.Ingress = []api.Rule{

								{

									Action: "Allow",

									Source: api.EntityRule{

										Nets: []string{

											"0.0.0.0/0",

										},

									},


====================
						expectPongs()

					})

				}

				// Test doesn't use services so ignore the runs with those turned on.

				if testOpts.protocol == "udp" && !testOpts.connTimeEnabled && !testOpts.dsr {

					It("should not be able to spoof UDP", func() {

						By("Disabling dev RPF")

						setRPF(felixes, testOpts.tunnel, 0, 0)

						felixes[1].Exec("sysctl", "-w", "net.ipv4.conf."+w[1][0].InterfaceName+".rp_filter=0")

						felixes[1].Exec("sysctl", "-w", "net.ipv4.conf."+w[1][1].InterfaceName+".rp_filter=0")

						By("allowing any traffic", func() {

							pol.Spec.Ingress = []api.Rule{

								{

									Action: "Allow",

									Source: api.EntityRule{

										Nets: []string{

											"0.0.0.0/0",

										},

									},

								},


====================
						By("testing that packet sent by another workload is dropped", func() {

							tcpdump := w[0][0].AttachTCPDump()

							tcpdump.SetLogEnabled(true)

							matcher := fmt.Sprintf("IP %s\\.30444 > %s\\.30444: UDP", w[1][0].IP, w[0][0].IP)

							tcpdump.AddMatcher("UDP-30444", regexp.MustCompile(matcher))

							tcpdump.Start(testOpts.protocol, "port", "30444", "or", "port", "30445")

							defer tcpdump.Stop()

							// send a packet from the correct workload to create a conntrack entry

							_, err := w[1][0].RunCmd("pktgen", w[1][0].IP, w[0][0].IP, "udp",

								"--port-src", "30444", "--port-dst", "30444")

							Expect(err).NotTo(HaveOccurred())

							// We must eventually see the packet at the target

							Eventually(func() int { return tcpdump.MatchCount("UDP-30444") }).

								Should(BeNumerically("==", 1), matcher)

							// Send a spoofed packet from a different pod. Since we hit the

							// conntrack we would not do the WEP only RPF check.

							_, err = w[1][1].RunCmd("pktgen", w[1][0].IP, w[0][0].IP, "udp",

								"--port-src", "30444", "--port-dst", "30444")

							Expect(err).NotTo(HaveOccurred())

							// Since the packet will get dropped, we would not see it at the dest.


====================
							_, err := w[1][0].RunCmd("pktgen", w[1][0].IP, w[0][0].IP, "udp",

								"--port-src", "30444", "--port-dst", "30444")

							Expect(err).NotTo(HaveOccurred())

							// We must eventually see the packet at the target

							Eventually(func() int { return tcpdump.MatchCount("UDP-30444") }).

								Should(BeNumerically("==", 1), matcher)

							// Send a spoofed packet from a different pod. Since we hit the

							// conntrack we would not do the WEP only RPF check.

							_, err = w[1][1].RunCmd("pktgen", w[1][0].IP, w[0][0].IP, "udp",

								"--port-src", "30444", "--port-dst", "30444")

							Expect(err).NotTo(HaveOccurred())

							// Since the packet will get dropped, we would not see it at the dest.

							// So we send another good packet from the spoofing workload, that we

							// will see at the dest.

							matcher2 := fmt.Sprintf("IP %s\\.30445 > %s\\.30445: UDP", w[1][1].IP, w[0][0].IP)

							tcpdump.AddMatcher("UDP-30445", regexp.MustCompile(matcher2))

							_, err = w[1][1].RunCmd("pktgen", w[1][1].IP, w[0][0].IP, "udp",

								"--port-src", "30445", "--port-dst", "30445")

							Expect(err).NotTo(HaveOccurred())

							// Wait for the good packet from the bad workload


====================
							_, err = w[1][1].RunCmd("pktgen", w[1][0].IP, w[0][0].IP, "udp",

								"--port-src", "30444", "--port-dst", "30444")

							Expect(err).NotTo(HaveOccurred())

							// Since the packet will get dropped, we would not see it at the dest.

							// So we send another good packet from the spoofing workload, that we

							// will see at the dest.

							matcher2 := fmt.Sprintf("IP %s\\.30445 > %s\\.30445: UDP", w[1][1].IP, w[0][0].IP)

							tcpdump.AddMatcher("UDP-30445", regexp.MustCompile(matcher2))

							_, err = w[1][1].RunCmd("pktgen", w[1][1].IP, w[0][0].IP, "udp",

								"--port-src", "30445", "--port-dst", "30445")

							Expect(err).NotTo(HaveOccurred())

							// Wait for the good packet from the bad workload

							Eventually(func() int { return tcpdump.MatchCount("UDP-30445") }).

								Should(BeNumerically("==", 1), matcher2)

							// Check that we have not seen the spoofed packet. If there was not

							// packet reordering, which in our setup is guaranteed not to happen,

							// we know that the spoofed packet was dropped.

							Expect(tcpdump.MatchCount("UDP-30444")).To(BeNumerically("==", 1), matcher)

						})

						var eth20, eth30 *workload.Workload


====================
							// set the route to the fake workload to .20 network

							felixes[1].Exec("ip", "route", "add", fakeWorkloadIP+"/32", "dev", "eth20")

							tcpdump := w[1][1].AttachTCPDump()

							tcpdump.SetLogEnabled(true)

							matcher := fmt.Sprintf("IP %s\\.30446 > %s\\.30446: UDP", fakeWorkloadIP, w[1][1].IP)

							tcpdump.AddMatcher("UDP-30446", regexp.MustCompile(matcher))

							tcpdump.Start()

							defer tcpdump.Stop()

							_, err := eth20.RunCmd("pktgen", fakeWorkloadIP, w[1][1].IP, "udp",

								"--port-src", "30446", "--port-dst", "30446")

							Expect(err).NotTo(HaveOccurred())

							// Expect to receive the packet from the .20 as the routing is correct

							Eventually(func() int { return tcpdump.MatchCount("UDP-30446") }).

								Should(BeNumerically("==", 1), matcher)

							ctBefore := dumpCTMap(felixes[1])

							k := conntrack.NewKey(17, net.ParseIP(w[1][1].IP).To4(), 30446,

								net.ParseIP(fakeWorkloadIP).To4(), 30446)

							Expect(ctBefore).To(HaveKey(k))

							// XXX Since the same code is used to do the drop of spoofed

							// packet between pods, we do not repeat it here as it is not 100%


====================
							// packet between pods, we do not repeat it here as it is not 100%

							// bulletproof.

							//

							// We should perhaps compare the iptables counter and see if the

							// packet was dropped by the RPF check.

							// Change the routing to be from the .30

							felixes[1].Exec("ip", "route", "del", fakeWorkloadIP+"/32", "dev", "eth20")

							felixes[1].Exec("ip", "route", "add", fakeWorkloadIP+"/32", "dev", "eth30")

							_, err = eth30.RunCmd("pktgen", fakeWorkloadIP, w[1][1].IP, "udp",

								"--port-src", "30446", "--port-dst", "30446")

							Expect(err).NotTo(HaveOccurred())

							// Expect the packet from the .30 to make it through as RPF will

							// allow it and we will update the expected interface

							Eventually(func() int { return tcpdump.MatchCount("UDP-30446") }).

								Should(BeNumerically("==", 2), matcher)

							ctAfter := dumpCTMap(felixes[1])

							Expect(ctAfter).To(HaveKey(k))

							// Ifindex must have changed

							// B2A because of IPA > IPB - deterministic

							Expect(ctBefore[k].Data().B2A.Ifindex).NotTo(BeNumerically("==", 0))


====================
						cc.ExpectSome(w[0][1], TargetIP(ip[0]), port)

						cc.ExpectSome(externalClient, TargetIP(ip[0]), port)

						cc.CheckConnectivity()

					})

					It("should handle temporary overlap of external IPs", func() {

						By("Having connectivity to external IP initially")

						cc.ExpectSome(externalClient, TargetIP(ip[0]), port)

						cc.CheckConnectivity()

						By("Adding second service with same external IP")

						testSvc = k8sCreateLBServiceWithEndPoints(k8sClient, testSvcName+"-2", "10.101.0.11", w[0][0], 80, tgtPort,

							testOpts.protocol, externalIP, srcIPRange)

						By("Deleting first service")

						err := k8sClient.CoreV1().Services(testSvc.ObjectMeta.Namespace).Delete(context.Background(), testSvcName, metav1.DeleteOptions{})

						Expect(err).NotTo(HaveOccurred())

						By("Sleeping")

						time.Sleep(20 * time.Second)

						By("And still having connectivity...")

						cc.ExpectSome(externalClient, TargetIP(ip[0]), port)

						cc.CheckConnectivity()

					})


====================
									hostW0SrcIP = ExpectWithSrcIPs(felixes[0].ExpectedIPIPTunnelAddr)

									hostW1SrcIP = ExpectWithSrcIPs(felixes[1].ExpectedIPIPTunnelAddr)

								case "wireguard":

									hostW1SrcIP = ExpectWithSrcIPs(felixes[1].ExpectedWireguardTunnelAddr)

								case "vxlan":

									hostW1SrcIP = ExpectWithSrcIPs(felixes[1].ExpectedVXLANTunnelAddr)

								}

								clusterIP := testSvc.Spec.ClusterIP

								ports := ExpectWithPorts(uint16(testSvc.Spec.Ports[0].Port))

								felixes[0].Exec("sysctl", "-w", "net.ipv6.conf.eth0.disable_ipv6=0")

								felixes[1].Exec("sysctl", "-w", "net.ipv6.conf.eth0.disable_ipv6=0")

								// Also try host networked pods, both on a local and remote node.

								cc.Expect(Some, hostW[0], TargetIP(clusterIP), ports, hostW0SrcIP)

								cc.Expect(Some, hostW[1], TargetIP(clusterIP), ports, hostW1SrcIP)

								if testOpts.protocol == "tcp" {

									// Also excercise ipv4 as ipv6

									cc.Expect(Some, hostW[0], TargetIPv4AsIPv6(clusterIP), ports, hostW0SrcIP)

									cc.Expect(Some, hostW[1], TargetIPv4AsIPv6(clusterIP), ports, hostW1SrcIP)

								}

								cc.CheckConnectivity()


====================
									hostW1SrcIP = ExpectWithSrcIPs(felixes[1].ExpectedIPIPTunnelAddr)

								case "wireguard":

									hostW1SrcIP = ExpectWithSrcIPs(felixes[1].ExpectedWireguardTunnelAddr)

								case "vxlan":

									hostW1SrcIP = ExpectWithSrcIPs(felixes[1].ExpectedVXLANTunnelAddr)

								}

								clusterIP := testSvc.Spec.ClusterIP

								ports := ExpectWithPorts(uint16(testSvc.Spec.Ports[0].Port))

								felixes[0].Exec("sysctl", "-w", "net.ipv6.conf.eth0.disable_ipv6=0")

								felixes[1].Exec("sysctl", "-w", "net.ipv6.conf.eth0.disable_ipv6=0")

								// Also try host networked pods, both on a local and remote node.

								cc.Expect(Some, hostW[0], TargetIP(clusterIP), ports, hostW0SrcIP)

								cc.Expect(Some, hostW[1], TargetIP(clusterIP), ports, hostW1SrcIP)

								if testOpts.protocol == "tcp" {

									// Also excercise ipv4 as ipv6

									cc.Expect(Some, hostW[0], TargetIPv4AsIPv6(clusterIP), ports, hostW0SrcIP)

									cc.Expect(Some, hostW[1], TargetIPv4AsIPv6(clusterIP), ports, hostW1SrcIP)

								}

								cc.CheckConnectivity()

							})


====================
										Expect(dstMAC).NotTo(Equal(""))

									})

									// Since local-host networking ignores L2 addresses, we

									// need to make sure by other means that they are set

									// correctly.

									By("making sure that return VXLAN has the right MACs using tcpdump", func() {

										tcpdump := felixes[0].AttachTCPDump("eth0")

										tcpdump.SetLogEnabled(true)

										tcpdump.AddMatcher("MACs", regexp.MustCompile(fmt.Sprintf("%s > %s", srcMAC, dstMAC)))

										tcpdump.Start("-e", "udp", "and", "src", felixes[0].IP, "and", "port", "4789")

										defer tcpdump.Stop()

										cc.ExpectSome(externalClient, TargetIP(felixes[1].IP), npPort)

										cc.CheckConnectivity()

										Eventually(func() int { return tcpdump.MatchCount("MACs") }).

											Should(BeNumerically(">", 0), "MACs do not match")

									})

								}

							})

							// Our unconnected test client cannot handle multiple streams. Two

							// clients cannot use the same local address. The connected case shows


====================
										_, err = eth20.RunCmd("ip", "route", "add", "10.0.0.20/32", "dev", "eth0")

										Expect(err).NotTo(HaveOccurred())

										// Add a route to felix[1] to be able to reach the nodeport

										_, err = eth20.RunCmd("ip", "route", "add", felixes[1].IP+"/32", "via", "10.0.0.20")

										Expect(err).NotTo(HaveOccurred())

										// This multi-NIC scenario works only if the kernel's RPF check

										// is not strict so we need to override it for the test and must

										// be set properly when product is deployed. We reply on

										// iptables to do require check for us.

										felixes[1].Exec("sysctl", "-w", "net.ipv4.conf.eth0.rp_filter=2")

										felixes[1].Exec("sysctl", "-w", "net.ipv4.conf.eth20.rp_filter=2")

									})

									By("setting up routes to .20 net on dest node to trigger RPF check", func() {

										// set up a dummy interface just for the routing purpose

										felixes[0].Exec("ip", "link", "add", "dummy1", "type", "dummy")

										felixes[0].Exec("ip", "link", "set", "dummy1", "up")

										// set up route to the .20 net through the dummy iface. This

										// makes the .20 a universally reachable external world from the

										// internal/private eth0 network

										felixes[0].Exec("ip", "route", "add", "192.168.20.0/24", "dev", "dummy1")


====================
										Expect(err).NotTo(HaveOccurred())

										// Add a route to felix[1] to be able to reach the nodeport

										_, err = eth20.RunCmd("ip", "route", "add", felixes[1].IP+"/32", "via", "10.0.0.20")

										Expect(err).NotTo(HaveOccurred())

										// This multi-NIC scenario works only if the kernel's RPF check

										// is not strict so we need to override it for the test and must

										// be set properly when product is deployed. We reply on

										// iptables to do require check for us.

										felixes[1].Exec("sysctl", "-w", "net.ipv4.conf.eth0.rp_filter=2")

										felixes[1].Exec("sysctl", "-w", "net.ipv4.conf.eth20.rp_filter=2")

									})

									By("setting up routes to .20 net on dest node to trigger RPF check", func() {

										// set up a dummy interface just for the routing purpose

										felixes[0].Exec("ip", "link", "add", "dummy1", "type", "dummy")

										felixes[0].Exec("ip", "link", "set", "dummy1", "up")

										// set up route to the .20 net through the dummy iface. This

										// makes the .20 a universally reachable external world from the

										// internal/private eth0 network

										felixes[0].Exec("ip", "route", "add", "192.168.20.0/24", "dev", "dummy1")

										// This multi-NIC scenario works only if the kernel's RPF check


====================
										felixes[0].Exec("ip", "link", "set", "dummy1", "up")

										// set up route to the .20 net through the dummy iface. This

										// makes the .20 a universally reachable external world from the

										// internal/private eth0 network

										felixes[0].Exec("ip", "route", "add", "192.168.20.0/24", "dev", "dummy1")

										// This multi-NIC scenario works only if the kernel's RPF check

										// is not strict so we need to override it for the test and must

										// be set properly when product is deployed. We reply on

										// iptables to do require check for us.

										felixes[0].Exec("sysctl", "-w", "net.ipv4.conf.eth0.rp_filter=2")

										felixes[0].Exec("sysctl", "-w", "net.ipv4.conf.dummy1.rp_filter=2")

									})

									By("Allowing traffic from the eth20 network", func() {

										pol.Spec.Ingress = []api.Rule{

											{

												Action: "Allow",

												Source: api.EntityRule{

													Nets: []string{

														eth20.IP + "/32",

													},


====================
										// set up route to the .20 net through the dummy iface. This

										// makes the .20 a universally reachable external world from the

										// internal/private eth0 network

										felixes[0].Exec("ip", "route", "add", "192.168.20.0/24", "dev", "dummy1")

										// This multi-NIC scenario works only if the kernel's RPF check

										// is not strict so we need to override it for the test and must

										// be set properly when product is deployed. We reply on

										// iptables to do require check for us.

										felixes[0].Exec("sysctl", "-w", "net.ipv4.conf.eth0.rp_filter=2")

										felixes[0].Exec("sysctl", "-w", "net.ipv4.conf.dummy1.rp_filter=2")

									})

									By("Allowing traffic from the eth20 network", func() {

										pol.Spec.Ingress = []api.Rule{

											{

												Action: "Allow",

												Source: api.EntityRule{

													Nets: []string{

														eth20.IP + "/32",

													},

												},


====================
								const (

									hostIfaceMTU = 1500

									podIfaceMTU  = 1450

									sendLen      = hostIfaceMTU

									recvLen      = podIfaceMTU

								)

								Context("with TCP, tx/rx close to MTU size on NP via node1->node0 ", func() {

									It("should not adjust MTU on client side if GRO off on nodes", func() {

										// force non-GSO packets on node ingress

										err := felixes[1].ExecMayFail("ethtool", "-K", "eth0", "gro", "off")

										Expect(err).NotTo(HaveOccurred())

										cc.Expect(Some, externalClient, TargetIP(felixes[1].IP),

											ExpectWithPorts(npPort),

											ExpectWithSendLen(sendLen),

											ExpectWithRecvLen(recvLen),

											ExpectWithClientAdjustedMTU(hostIfaceMTU, hostIfaceMTU),

										)

										cc.CheckConnectivity()

									})

								})


====================
					cc.CheckConnectivity()

					cc.ResetExpectations()

				}

				By("checking initial connectivity", func() {

					expectNormalConnectivity()

				})

				By("installing 3rd party DNAT rules", func() {

					// Install a DNAT in first felix

					felixes[0].Exec(

						"iptables", "-w", "10", "-W", "100000", "-t", "nat", "-A", "PREROUTING", "-p", protocol, "-m", protocol,

						"--dport", fmt.Sprintf("%d", hostPort), "-j", "DNAT", "--to-destination", target)

					cc.ResetExpectations()

					cc.ExpectSome(felixes[1], hostIP0, hostPort)

					cc.ExpectSome(externalClient, hostIP0, hostPort)

					cc.ExpectSome(w[1][0], hostIP0, hostPort)

					cc.CheckConnectivity()

					cc.ResetExpectations()

				})

				By("removing 3rd party rules and check connectivity is back to normal again", func() {

					felixes[0].Exec(


====================
					cc.ResetExpectations()

				}

				By("checking initial connectivity", func() {

					expectNormalConnectivity()

				})

				By("installing 3rd party DNAT rules", func() {

					// Install a DNAT in first felix

					felixes[0].Exec(

						"iptables", "-w", "10", "-W", "100000", "-t", "nat", "-A", "PREROUTING", "-p", protocol, "-m", protocol,

						"--dport", fmt.Sprintf("%d", hostPort), "-j", "DNAT", "--to-destination", target)

					cc.ResetExpectations()

					cc.ExpectSome(felixes[1], hostIP0, hostPort)

					cc.ExpectSome(externalClient, hostIP0, hostPort)

					cc.ExpectSome(w[1][0], hostIP0, hostPort)

					cc.CheckConnectivity()

					cc.ResetExpectations()

				})

				By("removing 3rd party rules and check connectivity is back to normal again", func() {

					felixes[0].Exec(

						"iptables", "-w", "10", "-W", "100000", "-t", "nat", "-D", "PREROUTING", "-p", protocol, "-m", protocol,


====================
					cc.ResetExpectations()

					cc.ExpectSome(felixes[1], hostIP0, hostPort)

					cc.ExpectSome(externalClient, hostIP0, hostPort)

					cc.ExpectSome(w[1][0], hostIP0, hostPort)

					cc.CheckConnectivity()

					cc.ResetExpectations()

				})

				By("removing 3rd party rules and check connectivity is back to normal again", func() {

					felixes[0].Exec(

						"iptables", "-w", "10", "-W", "100000", "-t", "nat", "-D", "PREROUTING", "-p", protocol, "-m", protocol,

						"--dport", fmt.Sprintf("%d", hostPort), "-j", "DNAT", "--to-destination", target)

					expectNormalConnectivity()

				})

			})

		})

		Describe("with BPF disabled to begin with", func() {

			var pc *PersistentConnection

			BeforeEach(func() {

				options.TestManagesBPF = true

				setupCluster()


====================
					cc.ExpectSome(felixes[1], hostIP0, hostPort)

					cc.ExpectSome(externalClient, hostIP0, hostPort)

					cc.ExpectSome(w[1][0], hostIP0, hostPort)

					cc.CheckConnectivity()

					cc.ResetExpectations()

				})

				By("removing 3rd party rules and check connectivity is back to normal again", func() {

					felixes[0].Exec(

						"iptables", "-w", "10", "-W", "100000", "-t", "nat", "-D", "PREROUTING", "-p", protocol, "-m", protocol,

						"--dport", fmt.Sprintf("%d", hostPort), "-j", "DNAT", "--to-destination", target)

					expectNormalConnectivity()

				})

			})

		})

		Describe("with BPF disabled to begin with", func() {

			var pc *PersistentConnection

			BeforeEach(func() {

				options.TestManagesBPF = true

				setupCluster()

				// Default to Allow...


====================
						C:        c,

						Name:     "ext-workload",

						Ports:    "4321",

						Protocol: testOpts.protocol,

						IP:       c.IP,

					}

					err := extWorkload.Start()

					Expect(err).NotTo(HaveOccurred())

					for _, felix := range felixes {

						felix.Exec("iptables", "-t", "nat", "-A", "POSTROUTING", "-d", extWorkload.IP, "-j", "MASQUERADE")

					}

				})

				It("should have connectivity to external workload", func() {

					By("allowing any traffic", func() {

						pol := api.NewGlobalNetworkPolicy()

						pol.Namespace = "fv"

						pol.Name = "policy-1"

						pol.Spec.Ingress = []api.Rule{{Action: "Allow"}}

						pol.Spec.Egress = []api.Rule{{Action: "Allow"}}

						pol.Spec.Selector = "all()"


====================
	testSvcNamespace = testSvc.ObjectMeta.Namespace

	_, err := k8sClient.CoreV1().Services(testSvcNamespace).Create(context.Background(), testSvc, metav1.CreateOptions{})

	Expect(err).NotTo(HaveOccurred())

	Eventually(k8sGetEpsForServiceFunc(k8sClient, testSvc), "10s").Should(HaveLen(epslen),

		"Service endpoints didn't get created? Is controller-manager happy?")

	return testSvc

}

func checkNodeConntrack(felixes []*infrastructure.Felix) error {

	for i, felix := range felixes {

		conntrackOut, err := felix.ExecOutput("conntrack", "-L")

		ExpectWithOffset(1, err).NotTo(HaveOccurred(), "conntrack -L failed")

		lines := strings.Split(conntrackOut, "\n")

	lineLoop:

		for _, line := range lines {

			line = strings.Trim(line, " ")

			if strings.Contains(line, "src=") {

				// Whether traffic is generated in host namespace, or involves NAT, each

				// contrack entry should be related to node's address

				if strings.Contains(line, felix.IP) {

					continue lineLoop


====================
	}

}

func conntrackFlushWorkloadEntries(felixes []*infrastructure.Felix) func() {

	return func() {

		for _, felix := range felixes {

			for _, w := range felix.Workloads {

				if w.GetIP() == felix.GetIP() {

					continue // Skip host-networked workloads.

				}

				for _, dirn := range []string{"--orig-src", "--orig-dst", "--reply-dst", "--reply-src"} {

					err := felix.ExecMayFail("conntrack", "-D", dirn, w.GetIP())

					if err != nil && strings.Contains(err.Error(), "0 flow entries have been deleted") {

						// Expected "error" when there are no matching flows.

						continue

					}

					ExpectWithOffset(1, err).NotTo(HaveOccurred(), "conntrack -D failed")

				}

			}

		}

	}


====================
}

func conntrackFlushWorkloadEntries(felixes []*infrastructure.Felix) func() {

	return func() {

		for _, felix := range felixes {

			for _, w := range felix.Workloads {

				if w.GetIP() == felix.GetIP() {

					continue // Skip host-networked workloads.

				}

				for _, dirn := range []string{"--orig-src", "--orig-dst", "--reply-dst", "--reply-src"} {

					err := felix.ExecMayFail("conntrack", "-D", dirn, w.GetIP())

					if err != nil && strings.Contains(err.Error(), "0 flow entries have been deleted") {

						// Expected "error" when there are no matching flows.

						continue

					}

					ExpectWithOffset(1, err).NotTo(HaveOccurred(), "conntrack -D failed")

				}

			}

		}

	}

}


====================
	mainStr := strconv.Itoa(main)

	var wg sync.WaitGroup

	for _, felix := range felixes {

		wg.Add(1)

		go func(felix *infrastructure.Felix) {

			defer wg.Done()

			Eventually(func() error {

				// N.B. we only support environment with not so strict RPF - can be

				// strict per iface, but not for all.

				if err := felix.ExecMayFail("sysctl", "-w", "net.ipv4.conf.all.rp_filter="+allStr); err != nil {

					return err

				}

				switch tunnel {

				case "none":

					if err := felix.ExecMayFail("sysctl", "-w", "net.ipv4.conf.eth0.rp_filter="+mainStr); err != nil {

						return err

					}

				case "ipip":

					if err := felix.ExecMayFail("sysctl", "-w", "net.ipv4.conf.tunl0.rp_filter="+mainStr); err != nil {

						return err


====================
			defer wg.Done()

			Eventually(func() error {

				// N.B. we only support environment with not so strict RPF - can be

				// strict per iface, but not for all.

				if err := felix.ExecMayFail("sysctl", "-w", "net.ipv4.conf.all.rp_filter="+allStr); err != nil {

					return err

				}

				switch tunnel {

				case "none":

					if err := felix.ExecMayFail("sysctl", "-w", "net.ipv4.conf.eth0.rp_filter="+mainStr); err != nil {

						return err

					}

				case "ipip":

					if err := felix.ExecMayFail("sysctl", "-w", "net.ipv4.conf.tunl0.rp_filter="+mainStr); err != nil {

						return err

					}

				case "wireguard":

					if err := felix.ExecMayFail("sysctl", "-w", "net.ipv4.conf.wireguard/cali.rp_filter="+mainStr); err != nil {

						return err

					}


====================
				if err := felix.ExecMayFail("sysctl", "-w", "net.ipv4.conf.all.rp_filter="+allStr); err != nil {

					return err

				}

				switch tunnel {

				case "none":

					if err := felix.ExecMayFail("sysctl", "-w", "net.ipv4.conf.eth0.rp_filter="+mainStr); err != nil {

						return err

					}

				case "ipip":

					if err := felix.ExecMayFail("sysctl", "-w", "net.ipv4.conf.tunl0.rp_filter="+mainStr); err != nil {

						return err

					}

				case "wireguard":

					if err := felix.ExecMayFail("sysctl", "-w", "net.ipv4.conf.wireguard/cali.rp_filter="+mainStr); err != nil {

						return err

					}

				case "vxlan":

					if err := felix.ExecMayFail("sysctl", "-w", "net.ipv4.conf.vxlan/calico.rp_filter="+mainStr); err != nil {

						return err

					}


====================
				case "none":

					if err := felix.ExecMayFail("sysctl", "-w", "net.ipv4.conf.eth0.rp_filter="+mainStr); err != nil {

						return err

					}

				case "ipip":

					if err := felix.ExecMayFail("sysctl", "-w", "net.ipv4.conf.tunl0.rp_filter="+mainStr); err != nil {

						return err

					}

				case "wireguard":

					if err := felix.ExecMayFail("sysctl", "-w", "net.ipv4.conf.wireguard/cali.rp_filter="+mainStr); err != nil {

						return err

					}

				case "vxlan":

					if err := felix.ExecMayFail("sysctl", "-w", "net.ipv4.conf.vxlan/calico.rp_filter="+mainStr); err != nil {

						return err

					}

				}

				return nil

			}, "5s", "200ms").Should(Succeed())

		}(felix)


====================
				case "ipip":

					if err := felix.ExecMayFail("sysctl", "-w", "net.ipv4.conf.tunl0.rp_filter="+mainStr); err != nil {

						return err

					}

				case "wireguard":

					if err := felix.ExecMayFail("sysctl", "-w", "net.ipv4.conf.wireguard/cali.rp_filter="+mainStr); err != nil {

						return err

					}

				case "vxlan":

					if err := felix.ExecMayFail("sysctl", "-w", "net.ipv4.conf.vxlan/calico.rp_filter="+mainStr); err != nil {

						return err

					}

				}

				return nil

			}, "5s", "200ms").Should(Succeed())

		}(felix)

	}

	wg.Wait()

}

func checkServiceRoute(felix *infrastructure.Felix, ip string) bool {


====================
			_, err = client.HostEndpoints().Create(utils.Ctx, hostEp, utils.NoOptions)

			Expect(err).NotTo(HaveOccurred())

		}

		cc = &connectivity.Checker{Protocol: proto}

	})

	AfterEach(func() {

		if CurrentGinkgoTestDescription().Failed {

			infra.DumpErrorData()

			for _, felix := range felixes {

				felix.Exec("iptables-save", "-c")

			}

		}

		for _, wl := range hostW {

			wl.Stop()

		}

		for _, felix := range felixes {

			felix.Stop()

		}

		infra.Stop()

	})


====================
			})

			// NJ: this is odd; no blocklist testing here.

		})

		Context("blocking full IP", func() {

			BeforeEach(func() {

				hostHexCIDR = applyGlobalNetworkSets("xdpblocklist", hostW[clnt].IP, "/32", false)

			})

			It("should block packets smaller than UDP", func() {

				doHping := func() error {

					return utils.RunMayFail("docker", "exec", felixes[clnt].Name, "hping3", "--rawip", "-c", "1", "-H", "254", "-d", "1", hostW[srvr].IP)

				}

				Eventually(doHping, "20s", "100ms").Should(HaveOccurred())

				Expect(utils.LastRunOutput).To(ContainSubstring(`100% packet loss`))

				Expect(doHping()).To(HaveOccurred())

				if !BPFMode() {

					output, err := felixes[srvr].ExecOutput("iptables", "-t", "raw", "-v", "-n", "-L", "cali-pi-default.xdp-filter")

					// the only rule that refers to a cali40-prefixed ipset should

					// have 0 packets/bytes because the raw small packets should've been

					// blocked by XDP

					Expect(err).NotTo(HaveOccurred())


====================
			})

			It("should block packets smaller than UDP", func() {

				doHping := func() error {

					return utils.RunMayFail("docker", "exec", felixes[clnt].Name, "hping3", "--rawip", "-c", "1", "-H", "254", "-d", "1", hostW[srvr].IP)

				}

				Eventually(doHping, "20s", "100ms").Should(HaveOccurred())

				Expect(utils.LastRunOutput).To(ContainSubstring(`100% packet loss`))

				Expect(doHping()).To(HaveOccurred())

				if !BPFMode() {

					output, err := felixes[srvr].ExecOutput("iptables", "-t", "raw", "-v", "-n", "-L", "cali-pi-default.xdp-filter")

					// the only rule that refers to a cali40-prefixed ipset should

					// have 0 packets/bytes because the raw small packets should've been

					// blocked by XDP

					Expect(err).NotTo(HaveOccurred())

					Expect(output).To(MatchRegexp(`(?m)^\s+0\s+0.*cali40s:`))

				}

			})

			if BPFMode() {

				// The following test case only works for the old iptables-mode XDP

				// implementation of untracked ingress deny policy.  The BPF mode


====================
				// program.  It isn't worth fixing the old XDP program now, as it's

				// likely it will be replaced with the new XDP as used in BPF mode.

			} else {

				It("should block connections even if the source port is a failsafe port", func() {

					expectSourceFailsafePortBlocked(cc)

				})

			}

			It("should block ICMP too", func() {

				doPing := func() error {

					return utils.RunMayFail("docker", "exec", felixes[clnt].Name, "ping", "-c", "1", "-w", "1", hostW[srvr].IP)

				}

				Eventually(doPing, "20s", "100ms").Should(HaveOccurred())

				Expect(utils.LastRunOutput).To(ContainSubstring(`100% packet loss`))

				Expect(doPing()).To(HaveOccurred())

				if !BPFMode() {

					output, err := felixes[srvr].ExecOutput("iptables", "-t", "raw", "-v", "-n", "-L", "cali-pi-default.xdp-filter")

					// the only rule that refers to a cali40-prefixed ipset should

					// have 0 packets/bytes because the icmp packets should've been

					// blocked by XDP

					Expect(err).NotTo(HaveOccurred())


====================
			}

			It("should block ICMP too", func() {

				doPing := func() error {

					return utils.RunMayFail("docker", "exec", felixes[clnt].Name, "ping", "-c", "1", "-w", "1", hostW[srvr].IP)

				}

				Eventually(doPing, "20s", "100ms").Should(HaveOccurred())

				Expect(utils.LastRunOutput).To(ContainSubstring(`100% packet loss`))

				Expect(doPing()).To(HaveOccurred())

				if !BPFMode() {

					output, err := felixes[srvr].ExecOutput("iptables", "-t", "raw", "-v", "-n", "-L", "cali-pi-default.xdp-filter")

					// the only rule that refers to a cali40-prefixed ipset should

					// have 0 packets/bytes because the icmp packets should've been

					// blocked by XDP

					Expect(err).NotTo(HaveOccurred())

					Expect(output).To(MatchRegexp(`(?m)^\s+0\s+0.*cali40s:`))

				}

			})

			if !BPFMode() {

				It("should have expected felixes[clnt] IP in BPF blocklist", func() {

					args := append([]string{"bpftool", "map", "lookup", "pinned", "/sys/fs/bpf/calico/xdp/eth0_ipv4_v1_blacklist", "key", "hex"}, hostHexCIDR...)


====================
				Expect(err).NotTo(HaveOccurred())

				if proto == "tcp" && kernelVersion.Compare(environment.MustParseVersion("4.19.0")) < 0 {

					Skip(fmt.Sprintf("Skipping TCP test on Linux %v (needs 4.19)", kernelVersion))

					return

				}

				expectBlocked(cc)

				if !BPFMode() {

					// the only rule that refers to a cali40-prefixed ipset should have 0 packets/bytes

					Eventually(func() string {

						out, _ := felixes[srvr].ExecOutput("iptables", "-t", "raw", "-v", "-n", "-L",

							"cali-pi-default.xdp-filter")

						return out

					}).Should(MatchRegexp(`(?m)^\s+0\s+0.*cali40s:`))

				}

			})

			It("should have expected failsafe port 1234 to be open on felix[srvr] with XDP blocklist", func() {

				expectFailsafePortsOpen(cc)

			})

			It("should have expected connectivity after removing the policy", func() {

				expectBlocked(cc)


====================
				Expect(err).NotTo(HaveOccurred())

				if proto == "tcp" && kernelVersion.Compare(environment.MustParseVersion("4.19.0")) < 0 {

					Skip(fmt.Sprintf("Skipping TCP test on Linux %v (needs 4.19)", kernelVersion))

					return

				}

				expectBlocked(cc)

				if !BPFMode() {

					// the only rule that refers to a cali40-prefixed ipset should have 0 packets/bytes

					Eventually(func() string {

						out, _ := felixes[srvr].ExecOutput("iptables", "-t", "raw", "-v", "-n", "-L",

							"cali-pi-default.xdp-filter")

						return out

					}).Should(MatchRegexp(`(?m)^\s+0\s+0.*cali40s:`))

				}

			})

			It("should have expected failsafe port 1234 to be open on felix[srvr] with XDP blocklist", func() {

				expectFailsafePortsOpen(cc)

			})

		})

	})


====================
				cc      *connectivity.Checker

			)

			BeforeEach(func() {

				infra = getInfra()

				felixes, _ = infrastructure.StartNNodeTopology(2, infrastructure.DefaultTopologyOptions(), infra)

				// Create host-networked "workloads", one on each "host".

				for ii := range felixes {

					// Workload doesn't understand the extra connectivity types that test-connection tries.

					wlProto := protocol

					if strings.Contains(protocol, "-") {

						wlProto = strings.Split(protocol, "-")[0]

					}

					hostW[ii] = workload.Run(felixes[ii], fmt.Sprintf("host%d", ii), "", felixes[ii].IP, "8055", wlProto)

				}

				cc = &connectivity.Checker{}

				cc.Protocol = protocol

			})

			AfterEach(func() {

				for _, wl := range hostW {

					wl.Stop()


====================
			)

			BeforeEach(func() {

				infra = getInfra()

				felixes, _ = infrastructure.StartNNodeTopology(2, infrastructure.DefaultTopologyOptions(), infra)

				// Create host-networked "workloads", one on each "host".

				for ii := range felixes {

					// Workload doesn't understand the extra connectivity types that test-connection tries.

					wlProto := protocol

					if strings.Contains(protocol, "-") {

						wlProto = strings.Split(protocol, "-")[0]

					}

					hostW[ii] = workload.Run(felixes[ii], fmt.Sprintf("host%d", ii), "", felixes[ii].IP, "8055", wlProto)

				}

				cc = &connectivity.Checker{}

				cc.Protocol = protocol

			})

			AfterEach(func() {

				for _, wl := range hostW {

					wl.Stop()

				}


====================
		Expect(err).NotTo(HaveOccurred())

	})

	// Utility function to dump diags if the test failed.  Should be called in the inner-most

	// AfterEach() to dump diags before the test is torn down.  Only the first call for a given

	// test has any effect.

	dumpDiags := func() {

		if !CurrentGinkgoTestDescription().Failed || dumpedDiags {

			return

		}

		iptSave, err := felix.ExecOutput("iptables-save", "-c")

		if err == nil {

			log.Info("iptables-save:\n" + iptSave)

		}

		dumpedDiags = true

		infra.DumpErrorData()

	}

	AfterEach(func() {

		dumpDiags()

		felix.Stop()

		infra.Stop()


====================
	}

	AfterEach(func() {

		dumpDiags()

		felix.Stop()

		infra.Stop()

		externalClient.Stop()

	})

	It("should have expected restriction on the nat outgoing rule", func() {

		Eventually(func() string {

			output, _ := felix.ExecOutput("iptables-save", "-t", "nat")

			return output

		}, 5*time.Second, 100*time.Millisecond).Should(MatchRegexp("-A cali-nat-outgoing .*-o eth\\+ "))

	})

})

// Copyright (c) 2022 Tigera, Inc. All rights reserved.

//

// Licensed under the Apache License, Version 2.0 (the "License");

// you may not use this file except in compliance with the License.

// You may obtain a copy of the License at

//


====================
		pol = createPolicy(pol)

		By("flushing counters")

		out, err := felixes[0].ExecOutput("calico-bpf", "counters", "flush")

		Expect(err).NotTo(HaveOccurred())

		Expect(out).Should(BeZero())

		checkDroppedByPolicyCounters(felixes[0], w[1].InterfaceName, 0, 0)

		By("generating packets and checking the counter")

		numberOfpackets := 10

		for i := 0; i < numberOfpackets; i++ {

			_, err := w[0].RunCmd("pktgen", w[0].IP, w[1].IP, "udp", "--port-dst", "8055")

			Expect(err).NotTo(HaveOccurred())

			_, err = w[0].RunCmd("pktgen", w[0].IP, felixes[0].IP, "udp", "--port-dst", "8055")

			Expect(err).NotTo(HaveOccurred())

		}

		checkDroppedByPolicyCounters(felixes[0], w[1].InterfaceName, 0, numberOfpackets)

	})

	It("should update rule counters", func() {

		pol := api.NewGlobalNetworkPolicy()

		pol.Namespace = "fv"

		pol.Name = "policy-test"


====================
		out, err := felixes[0].ExecOutput("calico-bpf", "counters", "flush")

		Expect(err).NotTo(HaveOccurred())

		Expect(out).Should(BeZero())

		checkDroppedByPolicyCounters(felixes[0], w[1].InterfaceName, 0, 0)

		By("generating packets and checking the counter")

		numberOfpackets := 10

		for i := 0; i < numberOfpackets; i++ {

			_, err := w[0].RunCmd("pktgen", w[0].IP, w[1].IP, "udp", "--port-dst", "8055")

			Expect(err).NotTo(HaveOccurred())

			_, err = w[0].RunCmd("pktgen", w[0].IP, felixes[0].IP, "udp", "--port-dst", "8055")

			Expect(err).NotTo(HaveOccurred())

		}

		checkDroppedByPolicyCounters(felixes[0], w[1].InterfaceName, 0, numberOfpackets)

	})

	It("should update rule counters", func() {

		pol := api.NewGlobalNetworkPolicy()

		pol.Namespace = "fv"

		pol.Name = "policy-test"

		pol.Spec.Selector = "all()"

		pol.Spec.Ingress = []api.Rule{{Action: "Deny"}}


====================
			return bpfCheckIfPolicyProgrammed(felixes[0], w[0].InterfaceName, "egress", "default.policy-test", "deny", true)

		}, "2s", "200ms").Should(BeTrue())

		Eventually(func() bool {

			return bpfCheckIfPolicyProgrammed(felixes[0], w[1].InterfaceName, "ingress", "default.policy-test", "deny", true)

		}, "2s", "200ms").Should(BeTrue())

		Eventually(func() bool {

			return bpfCheckIfPolicyProgrammed(felixes[0], w[1].InterfaceName, "egress", "default.policy-test", "deny", true)

		}, "2s", "200ms").Should(BeTrue())

		for i := 0; i < 10; i++ {

			_, err := w[1].RunCmd("pktgen", w[1].IP, w[0].IP, "udp", "--port-src", "8055", "--port-dst", "8055")

			Expect(err).NotTo(HaveOccurred())

		}

		m := dumpRuleCounterMap(felixes[0])

		Expect(len(m)).To(Equal(1))

		for _, v := range m {

			Expect(v).To(Equal(uint64(10)))

		}

		checkRuleCounters(felixes[0], w[1].InterfaceName, "egress", "default.policy-test", 10)

		pol.Spec.Ingress = []api.Rule{{Action: "Allow"}}

		pol.Spec.Egress = []api.Rule{{Action: "Allow"}}


====================
			return bpfCheckIfPolicyProgrammed(felixes[0], w[0].InterfaceName, "egress", "default.policy-test", "allow", true)

		}, "2s", "200ms").Should(BeTrue())

		Eventually(func() bool {

			return bpfCheckIfPolicyProgrammed(felixes[0], w[1].InterfaceName, "ingress", "default.policy-test", "allow", true)

		}, "2s", "200ms").Should(BeTrue())

		Eventually(func() bool {

			return bpfCheckIfPolicyProgrammed(felixes[0], w[1].InterfaceName, "egress", "default.policy-test", "allow", true)

		}, "2s", "200ms").Should(BeTrue())

		for i := 0; i < 10; i++ {

			_, err := w[1].RunCmd("pktgen", w[1].IP, w[0].IP, "udp", "--port-src", "8055", "--port-dst", "8055")

			Expect(err).NotTo(HaveOccurred())

		}

		Eventually(func() int {

			m = dumpRuleCounterMap(felixes[0])

			return len(m)

		}, "2s", "200ms").Should(Equal(2))

		for _, v := range m {

			Expect(v).To(Equal(uint64(1)))

		}

		checkRuleCounters(felixes[0], w[1].InterfaceName, "egress", "default.policy-test", 1)


====================
		if strings.Contains(str, fmt.Sprintf("Start of policy %s", polName)) {

			startOfPol = idx

			break

		}

	}

	Expect(startOfPol).NotTo(Equal(-1))

	Expect(strings.Contains(strOut[startOfPol+2], fmt.Sprintf("count = %d", count))).To(BeTrue())

}

func checkDroppedByPolicyCounters(felix *infrastructure.Felix, ifName string, iCount, eCount int) {

	out, err := felix.ExecOutput("calico-bpf", "counters", "dump", fmt.Sprintf("--iface=%s", ifName))

	Expect(err).NotTo(HaveOccurred())

	strOut := strings.Split(out, "\n")

	f := func(c rune) bool {

		return c == '|'

	}

	var iCounter, eCounter, xCounter string

	for _, line := range strOut {

		fields := strings.FieldsFunc(line, f)

		if len(fields) < 5 {

			continue


====================
			pol.Spec.Selector = "all()"

			log.WithField("policy", dumpResource(pol)).Info("Creating policy")

			pol, err := calicoClient.GlobalNetworkPolicies().Create(utils.Ctx, pol, utils.NoOptions)

			Expect(err).NotTo(HaveOccurred())

			cc = &Checker{

				CheckSNAT: true,

				Protocol:  "udp",

			}

			By("turning off RPF per device", func() {

				felixes[0].Exec("sysctl", "-w", "net.ipv4.conf.all.rp_filter=0")

				felixes[0].Exec("sysctl", "-w", "net.ipv4.conf.default.rp_filter=0")

				felixes[0].Exec("sysctl", "-w", "net.ipv4.conf.eth0.rp_filter=0")

			})

			By("setting up node's fake external ifaces", func() {

				// We name the ifaces ethXY since such ifaces are

				// treated by felix as external to the node

				//

				// Using a test-workload creates the namespaces and the

				// interfaces to emulate the host NICs

				external = &workload.Workload{


====================
			log.WithField("policy", dumpResource(pol)).Info("Creating policy")

			pol, err := calicoClient.GlobalNetworkPolicies().Create(utils.Ctx, pol, utils.NoOptions)

			Expect(err).NotTo(HaveOccurred())

			cc = &Checker{

				CheckSNAT: true,

				Protocol:  "udp",

			}

			By("turning off RPF per device", func() {

				felixes[0].Exec("sysctl", "-w", "net.ipv4.conf.all.rp_filter=0")

				felixes[0].Exec("sysctl", "-w", "net.ipv4.conf.default.rp_filter=0")

				felixes[0].Exec("sysctl", "-w", "net.ipv4.conf.eth0.rp_filter=0")

			})

			By("setting up node's fake external ifaces", func() {

				// We name the ifaces ethXY since such ifaces are

				// treated by felix as external to the node

				//

				// Using a test-workload creates the namespaces and the

				// interfaces to emulate the host NICs

				external = &workload.Workload{

					Name:          "eth20",


====================
			pol, err := calicoClient.GlobalNetworkPolicies().Create(utils.Ctx, pol, utils.NoOptions)

			Expect(err).NotTo(HaveOccurred())

			cc = &Checker{

				CheckSNAT: true,

				Protocol:  "udp",

			}

			By("turning off RPF per device", func() {

				felixes[0].Exec("sysctl", "-w", "net.ipv4.conf.all.rp_filter=0")

				felixes[0].Exec("sysctl", "-w", "net.ipv4.conf.default.rp_filter=0")

				felixes[0].Exec("sysctl", "-w", "net.ipv4.conf.eth0.rp_filter=0")

			})

			By("setting up node's fake external ifaces", func() {

				// We name the ifaces ethXY since such ifaces are

				// treated by felix as external to the node

				//

				// Using a test-workload creates the namespaces and the

				// interfaces to emulate the host NICs

				external = &workload.Workload{

					Name:          "eth20",

					C:             felixes[0].Container,


====================
				// Make sure that networking with the .20 network works

				cc.ResetExpectations()

				cc.Expect(Some, external, w)

				cc.CheckConnectivity()

			})

		})

		JustAfterEach(func() {

			if CurrentGinkgoTestDescription().Failed {

				for _, felix := range felixes {

					felix.Exec("iptables-save", "-c")

					felix.Exec("ip", "link")

					felix.Exec("ip", "addr")

					felix.Exec("ip", "rule")

					felix.Exec("ip", "route")

				}

			}

		})

		AfterEach(func() {

			log.Info("AfterEach starting")

			for _, f := range felixes {


====================
				tcpdumpHEP.Start()

				defer tcpdumpHEP.Stop()

				tcpdumpWl := w.AttachTCPDump()

				tcpdumpWl.SetLogEnabled(true)

				matcherWl := fmt.Sprintf("IP %s\\.30446 > %s\\.30446: UDP", fakeWorkloadIP, w.IP)

				tcpdumpWl.AddMatcher("UDP-30446", regexp.MustCompile(matcherWl))

				tcpdumpWl.Start()

				defer tcpdumpWl.Stop()

				_, err := external.RunCmd("pktgen", fakeWorkloadIP, w.IP, "udp",

					"--port-src", "30446", "--port-dst", "30446", "--ip-id", "666")

				Expect(err).NotTo(HaveOccurred())

				// Expect to see the packet from the .20 network at eth20 before RPF

				Eventually(func() int { return tcpdumpHEP.MatchCount("UDP-30446") }, "1s", "100ms").

					Should(BeNumerically("==", 1), "HEP - "+matcherHEP)

				// Expect to receive the packet from the .20 as it is not dropped by RPF.

				Eventually(func() int { return tcpdumpWl.MatchCount("UDP-30446") }, "1s", "100ms").

					Should(BeNumerically("==", 1), "Wl - "+matcherWl)

			})

		})

		Context("With BPFEnforceRPF=Strict", func() {


====================
				tcpdumpHEP.Start()

				defer tcpdumpHEP.Stop()

				tcpdumpWl := w.AttachTCPDump()

				tcpdumpWl.SetLogEnabled(true)

				matcherWl := fmt.Sprintf("IP %s\\.30446 > %s\\.30446: UDP", fakeWorkloadIP, w.IP)

				tcpdumpWl.AddMatcher("UDP-30446", regexp.MustCompile(matcherWl))

				tcpdumpWl.Start()

				defer tcpdumpWl.Stop()

				_, err := external.RunCmd("pktgen", fakeWorkloadIP, w.IP, "udp",

					"--port-src", "30446", "--port-dst", "30446", "--ip-id", "666")

				Expect(err).NotTo(HaveOccurred())

				// Expect to see the packet from the .20 network at eth20 before RPF

				Eventually(func() int { return tcpdumpHEP.MatchCount("UDP-30446") }, "1s", "100ms").

					Should(BeNumerically("==", 1), "HEP - "+matcherHEP)

				// Expect not to receive the packet from the .20 as it is dropped by RPF.

				Consistently(func() int { return tcpdumpWl.MatchCount("UDP-30446") }, "1s", "100ms").

					Should(BeNumerically("==", 0), "Wl - "+matcherWl)

			})

		})

		Context("With BPFEnforceRPF=Loose", func() {


====================
				tcpdumpHEP.Start()

				defer tcpdumpHEP.Stop()

				tcpdumpWl := w.AttachTCPDump()

				tcpdumpWl.SetLogEnabled(true)

				matcherWl := fmt.Sprintf("IP %s\\.30446 > %s\\.30446: UDP", fakeWorkloadIP, w.IP)

				tcpdumpWl.AddMatcher("UDP-30446", regexp.MustCompile(matcherWl))

				tcpdumpWl.Start()

				defer tcpdumpWl.Stop()

				_, err := external.RunCmd("pktgen", fakeWorkloadIP, w.IP, "udp",

					"--port-src", "30446", "--port-dst", "30446", "--ip-id", "666")

				Expect(err).NotTo(HaveOccurred())

				// Expect to see the packet from the .20 network at eth20 before RPF

				Eventually(func() int { return tcpdumpHEP.MatchCount("UDP-30446") }, "1s", "100ms").

					Should(BeNumerically("==", 1), "HEP - "+matcherHEP)

				// Expect to receive the packet from the .20 as it is not dropped by RPF.

				Eventually(func() int { return tcpdumpWl.MatchCount("UDP-30446") }, "1s", "100ms").

					Should(BeNumerically("==", 1), "Wl - "+matcherWl)

				// Reset TCP dump counts

				tcpdumpHEP.ResetCount("UDP-30446")

				tcpdumpWl.ResetCount("UDP-30446")


====================
				// Reset TCP dump counts

				tcpdumpHEP.ResetCount("UDP-30446")

				tcpdumpWl.ResetCount("UDP-30446")

				// Flush conntrack table thus next packet will not be able to "re-use".

				felixes[0].Exec("calico-bpf", "conntrack", "clean")

				// Remove default route from Felix and test scenario again

				felixes[0].Exec("ip", "route", "del", "default", "dev", "eth0")

				//  Generate another packet...

				_, err = external.RunCmd("pktgen", fakeWorkloadIP, w.IP, "udp",

					"--port-src", "30446", "--port-dst", "30446", "--ip-id", "667")

				Expect(err).NotTo(HaveOccurred())

				// Expect to see the packet from the .20 network at eth20 before RPF

				Eventually(func() int { return tcpdumpHEP.MatchCount("UDP-30446") }, "1s", "100ms").

					Should(BeNumerically("==", 1), "HEP - "+matcherHEP)

				// Expect not to receive the packet from the .20 as it is dropped by RPF.

				Consistently(func() int { return tcpdumpWl.MatchCount("UDP-30446") }, "1s", "100ms").

					Should(BeNumerically("==", 0), "Wl - "+matcherWl)

			})

		})

	})


====================
				Protocol:         "tcp",

			}

			cc.ExpectSome(wl0, wl1.Port(80))

			cc.CheckConnectivity()

		})

	})

})

func getIPTables(name string) func() string {

	return func() string {

		cmd := utils.Command("docker", "exec", name, "iptables-save", "-c")

		out, err := cmd.Output()

		Expect(err).ToNot(HaveOccurred())

		return string(out)

	}

}

// Copyright (c) 2020 Tigera, Inc. All rights reserved.

//

// Licensed under the Apache License, Version 2.0 (the "License");

// you may not use this file except in compliance with the License.

// You may obtain a copy of the License at


====================
	var (

		infra   infrastructure.DatastoreInfra

		felixes []*infrastructure.Felix

		w       [3]*workload.Workload

		cc      *connectivity.Checker

	)

	teardownInfra := func() {

		if CurrentGinkgoTestDescription().Failed {

			for _, felix := range felixes {

				felix.Exec("iptables-save", "-c")

				felix.Exec("ip6tables-save", "-c")

				felix.Exec("ipset", "list")

				felix.Exec("ip", "r")

				felix.Exec("ip", "-6", "r")

				felix.Exec("ip", "a")

				felix.Exec("ip", "-6", "a")

			}

		}

		for _, wl := range w {

			wl.Stop()


====================
		infra   infrastructure.DatastoreInfra

		felixes []*infrastructure.Felix

		w       [3]*workload.Workload

		cc      *connectivity.Checker

	)

	teardownInfra := func() {

		if CurrentGinkgoTestDescription().Failed {

			for _, felix := range felixes {

				felix.Exec("iptables-save", "-c")

				felix.Exec("ip6tables-save", "-c")

				felix.Exec("ipset", "list")

				felix.Exec("ip", "r")

				felix.Exec("ip", "-6", "r")

				felix.Exec("ip", "a")

				felix.Exec("ip", "-6", "a")

			}

		}

		for _, wl := range w {

			wl.Stop()

		}


====================
		cc      *connectivity.Checker

	)

	teardownInfra := func() {

		if CurrentGinkgoTestDescription().Failed {

			for _, felix := range felixes {

				felix.Exec("iptables-save", "-c")

				felix.Exec("ip6tables-save", "-c")

				felix.Exec("ipset", "list")

				felix.Exec("ip", "r")

				felix.Exec("ip", "-6", "r")

				felix.Exec("ip", "a")

				felix.Exec("ip", "-6", "a")

			}

		}

		for _, wl := range w {

			wl.Stop()

		}

		for _, felix := range felixes {

			felix.Stop()

		}


====================
	teardownInfra := func() {

		if CurrentGinkgoTestDescription().Failed {

			for _, felix := range felixes {

				felix.Exec("iptables-save", "-c")

				felix.Exec("ip6tables-save", "-c")

				felix.Exec("ipset", "list")

				felix.Exec("ip", "r")

				felix.Exec("ip", "-6", "r")

				felix.Exec("ip", "a")

				felix.Exec("ip", "-6", "a")

			}

		}

		for _, wl := range w {

			wl.Stop()

		}

		for _, felix := range felixes {

			felix.Stop()

		}

		if CurrentGinkgoTestDescription().Failed {

			infra.DumpErrorData()


====================
							}

							return fmt.Errorf("felix %d has no vxlan device", i)

						}

						return nil

					}, "30s", "100ms").ShouldNot(HaveOccurred())

				})

				AfterEach(func() {

					if CurrentGinkgoTestDescription().Failed {

						for _, felix := range felixes {

							felix.Exec("iptables-save", "-c")

							felix.Exec("ipset", "list")

							felix.Exec("ip", "r")

							felix.Exec("ip", "a")

						}

					}

					for _, felix := range felixes {

						felix.Stop()

					}

					if CurrentGinkgoTestDescription().Failed {

						infra.DumpErrorData()


====================
		for ii := range w {

			iiStr := strconv.Itoa(ii)

			w[ii] = workload.Run(felix, "w"+iiStr, "default", "10.65.0.1"+iiStr, "8055", "tcp")

			w[ii].Configure(client)

		}

		cc = &connectivity.Checker{}

	})

	AfterEach(func() {

		if CurrentGinkgoTestDescription().Failed {

			felix.Exec("iptables-save", "-c")

			felix.Exec("ip", "r")

		}

		for ii := range w {

			w[ii].Stop()

		}

		felix.Stop()

		if CurrentGinkgoTestDescription().Failed {

			etcd.Exec("etcdctl", "get", "/", "--prefix", "--keys-only")

		}

		etcd.Stop()


====================
		if CurrentGinkgoTestDescription().Failed {

			felix.Exec("iptables-save", "-c")

			felix.Exec("ip", "r")

		}

		for ii := range w {

			w[ii].Stop()

		}

		felix.Stop()

		if CurrentGinkgoTestDescription().Failed {

			etcd.Exec("etcdctl", "get", "/", "--prefix", "--keys-only")

		}

		etcd.Stop()

		infra.Stop()

	})

	It("full connectivity to and from workload 0", func() {

		cc.ExpectSome(w[1], w[0])

		cc.ExpectSome(w[2], w[0])

		cc.ExpectSome(w[0], w[1])

		cc.ExpectSome(w[0], w[2])

		cc.CheckConnectivity()


====================
		for ii := range w {

			iiStr := strconv.Itoa(ii)

			w[ii] = workload.Run(felix, "w"+iiStr, "default", "10.65.0.1"+iiStr, "8055", "tcp")

			w[ii].Configure(client)

		}

		cc = &connectivity.Checker{}

	})

	AfterEach(func() {

		if CurrentGinkgoTestDescription().Failed {

			felix.Exec("iptables-save", "-c")

			felix.Exec("ip", "r")

		}

		for ii := range w {

			w[ii].Stop()

		}

		felix.Stop()

		if CurrentGinkgoTestDescription().Failed {

			etcd.Exec("etcdctl", "get", "/", "--prefix", "--keys-only")

		}

		etcd.Stop()


====================
		if CurrentGinkgoTestDescription().Failed {

			felix.Exec("iptables-save", "-c")

			felix.Exec("ip", "r")

		}

		for ii := range w {

			w[ii].Stop()

		}

		felix.Stop()

		if CurrentGinkgoTestDescription().Failed {

			etcd.Exec("etcdctl", "get", "/", "--prefix", "--keys-only")

		}

		etcd.Stop()

		infra.Stop()

	})

	Context("with an ingress policy with no rules", func() {

		BeforeEach(func() {

			policy := api.NewNetworkPolicy()

			policy.Namespace = "fv"

			policy.Name = "policy-1"

			policy.Spec.Ingress = []api.Rule{}


====================
		for ii := range w {

			iiStr := strconv.Itoa(ii)

			w[ii] = workload.Run(felix, "w"+iiStr, "default", "10.65.0.1"+iiStr, "8055", "tcp")

			w[ii].Configure(client)

		}

		cc = &connectivity.Checker{}

	})

	AfterEach(func() {

		if CurrentGinkgoTestDescription().Failed {

			felix.Exec("iptables-save", "-c")

			felix.Exec("ip", "r")

		}

		for ii := range w {

			w[ii].Stop()

		}

		felix.Stop()

		if CurrentGinkgoTestDescription().Failed {

			etcd.Exec("etcdctl", "get", "/", "--prefix", "--keys-only")

		}

		etcd.Stop()


====================
		if CurrentGinkgoTestDescription().Failed {

			felix.Exec("iptables-save", "-c")

			felix.Exec("ip", "r")

		}

		for ii := range w {

			w[ii].Stop()

		}

		felix.Stop()

		if CurrentGinkgoTestDescription().Failed {

			etcd.Exec("etcdctl", "get", "/", "--prefix", "--keys-only")

		}

		etcd.Stop()

		infra.Stop()

	})

	It("full connectivity to and from workload 0", func() {

		cc.ExpectSome(w[1], w[0])

		cc.ExpectSome(w[2], w[0])

		cc.ExpectSome(w[0], w[1])

		cc.ExpectSome(w[0], w[2])

		cc.CheckConnectivity()


====================
	cidr := fmt.Sprintf("%s/32", ip)

	hexen, err := bpf.CidrToHex(cidr)

	Expect(err).NotTo(HaveOccurred())

	prepend0xInPlace(hexen)

	return hexen

}

func getEndpointsMapContents(felix *infrastructure.Felix) [][]string {

	output, err := felix.Container.ExecOutput(

		"bpftool",

		"--json",

		"--pretty",

		"map",

		"dump",

		"pinned",

		"/sys/fs/bpf/calico/sockmap/calico_sk_endpoints_v1",

	)

	logCtx := log.WithField("output", output)

	if err != nil {

		logCtx.WithError(err).Warn("Failed to dump the calico_sk_endpoints_v1 map")

		return nil


====================
	hexen, err := bpf.CidrToHex(cidr)

	Expect(err).NotTo(HaveOccurred())

	prepend0xInPlace(hexen)

	return hexen

}

func getEndpointsMapContents(felix *infrastructure.Felix) [][]string {

	output, err := felix.Container.ExecOutput(

		"bpftool",

		"--json",

		"--pretty",

		"map",

		"dump",

		"pinned",

		"/sys/fs/bpf/calico/sockmap/calico_sk_endpoints_v1",

	)

	logCtx := log.WithField("output", output)

	if err != nil {

		logCtx.WithError(err).Warn("Failed to dump the calico_sk_endpoints_v1 map")

		return nil

	}


====================
		// kill felix. This should drop all the references to

		// programs and maps, so the kernel will just delete

		// them. That way we will have no leftovers.

		func() {

			opts := getSockmapOpts()

			felix, _ = infrastructure.StartSingleNodeTopology(opts, infra)

			defer felix.Stop()

			output, err := felix.Container.ExecOutput(

				"bpftool",

				"--json",

				"--pretty",

				"map",

				"dump",

				"pinned",

				"/sys/fs/bpf/calico/sockmap/calico_sock_map_v1",

			)

			if err != nil {

				log.WithFields(log.Fields{

					"containerID": felix.Container.Name,

					"output":      output,


====================
		// programs and maps, so the kernel will just delete

		// them. That way we will have no leftovers.

		func() {

			opts := getSockmapOpts()

			felix, _ = infrastructure.StartSingleNodeTopology(opts, infra)

			defer felix.Stop()

			output, err := felix.Container.ExecOutput(

				"bpftool",

				"--json",

				"--pretty",

				"map",

				"dump",

				"pinned",

				"/sys/fs/bpf/calico/sockmap/calico_sock_map_v1",

			)

			if err != nil {

				log.WithFields(log.Fields{

					"containerID": felix.Container.Name,

					"output":      output,

				}).WithError(err).Info("Failed to dump the contents of the sock map, skipping cleanup")


====================
		infra    infrastructure.DatastoreInfra

	)

	BeforeEach(func() {

		topologyOptions := infrastructure.DefaultTopologyOptions()

		felix, etcd, client, infra = infrastructure.StartSingleNodeEtcdTopology(topologyOptions)

		felixPID = felix.GetFelixPID()

	})

	AfterEach(func() {

		if CurrentGinkgoTestDescription().Failed {

			felix.Exec("iptables-save", "-c")

		}

		felix.Stop()

		if CurrentGinkgoTestDescription().Failed {

			etcd.Exec("etcdctl", "get", "/", "--prefix", "--keys-only")

		}

		etcd.Stop()

		infra.Stop()

	})

	describeConnTests := func(c netsetsConfig) {

		var (


====================
		felix, etcd, client, infra = infrastructure.StartSingleNodeEtcdTopology(topologyOptions)

		felixPID = felix.GetFelixPID()

	})

	AfterEach(func() {

		if CurrentGinkgoTestDescription().Failed {

			felix.Exec("iptables-save", "-c")

		}

		felix.Stop()

		if CurrentGinkgoTestDescription().Failed {

			etcd.Exec("etcdctl", "get", "/", "--prefix", "--keys-only")

		}

		etcd.Stop()

		infra.Stop()

	})

	describeConnTests := func(c netsetsConfig) {

		var (

			w, nw [4]*workload.Workload

			cc    *connectivity.Checker

			pol   *api.GlobalNetworkPolicy

		)


====================
		w             [3]*workload.Workload

		cfgChangeTime time.Time

	)

	BeforeEach(func() {

		felix, etcd, client, infra = infrastructure.StartSingleNodeEtcdTopology(infrastructure.DefaultTopologyOptions())

		felixPID = felix.GetSinglePID("calico-felix")

	})

	AfterEach(func() {

		if CurrentGinkgoTestDescription().Failed {

			felix.Exec("iptables-save", "-c")

			felix.Exec("ip", "r")

		}

		for ii := range w {

			w[ii].Stop()

		}

		felix.Stop()

		if CurrentGinkgoTestDescription().Failed {

			etcd.Exec("etcdctl", "get", "/", "--prefix", "--keys-only")

		}

		etcd.Stop()


====================
		if CurrentGinkgoTestDescription().Failed {

			felix.Exec("iptables-save", "-c")

			felix.Exec("ip", "r")

		}

		for ii := range w {

			w[ii].Stop()

		}

		felix.Stop()

		if CurrentGinkgoTestDescription().Failed {

			etcd.Exec("etcdctl", "get", "/", "--prefix", "--keys-only")

		}

		etcd.Stop()

		infra.Stop()

	})

	shouldStayUp := func() {

		// Felix has a 2s timer before it restarts so need to monitor for > 2s.

		// We use ContainElement because Felix regularly forks off subprocesses and those

		// subprocesses initially have name "calico-felix".

		Consistently(felix.GetFelixPIDs, "3s", "200ms").Should(ContainElement(felixPID))

		// We know the initial PID has continued to be active, check that none of the extra


====================
	})

	AfterEach(func() {

		felix.Stop()

		if CurrentGinkgoTestDescription().Failed {

			infra.DumpErrorData()

		}

		infra.Stop()

	})

	getHTTPStatus := func(url string) (string, error) {

		op, err := felix.Container.ExecOutput("wget", "-S", "-T", "2", "-O", "-", "-o", "/dev/stdout", url)

		// Return output even when the error is set.

		// this is useful when wget sets err, in case of bad health status.

		return op, err

	}

	It("felix must be marked not-ready if source-destination-check setting fails", func() {

		// Without the correct credentials, AWS ec2 src-dst-check is bound to fail.

		// Make sure by looking at logs that the necessary logs messages exist.

		Eventually(startEC2ContactLogC, "10s", "100ms").Should(BeClosed())

		Eventually(failedEC2ContactLogC, "10s", "100ms").Should(BeClosed())

		// Felix is live...


====================
		// We will use this container to model an external client trying to connect into

		// workloads on a host.  Create a route in the container for the workload CIDR.

		externalClient = infrastructure.RunExtClient("ext-client")

		err = infra.AddDefaultDeny()

		Expect(err).To(BeNil())

	})

	JustAfterEach(func() {

		if CurrentGinkgoTestDescription().Failed {

			for _, felix := range felixes {

				felix.Exec("iptables-save", "-c")

				felix.Exec("ip", "r")

				felix.Exec("calico-bpf", "policy", "dump", "eth0", "all")

			}

		}

	})

	AfterEach(func() {

		for _, f := range felixes {

			f.Stop()

		}

		infra.Stop()


====================
	BeforeEach(func() {

		infra = getInfra()

		options := infrastructure.DefaultTopologyOptions()

		options.IPIPEnabled = false

		felixes, client = infrastructure.StartNNodeTopology(2, options, infra)

	})

	AfterEach(func() {

		if CurrentGinkgoTestDescription().Failed {

			for _, felix := range felixes {

				felix.Exec("iptables-save", "-c")

				felix.Exec("ipset", "list")

				felix.Exec("ip", "r")

				felix.Exec("ip", "a")

			}

		}

		for _, felix := range felixes {

			felix.Stop()

		}

		if CurrentGinkgoTestDescription().Failed {

			infra.DumpErrorData()


====================
		} else {

			Expect(err).NotTo(HaveOccurred())

			deltaFn(cfg)

			_, err = client.BGPConfigurations().Update(ctx, cfg, options.SetOptions{})

			Expect(err).NotTo(HaveOccurred())

		}

	}

	getCIDRBlockRules := func(felix *infrastructure.Felix, saveCommand string) func() []string {

		return func() []string {

			out, err := felix.ExecOutput(saveCommand, "-t", "filter")

			Expect(err).NotTo(HaveOccurred())

			var cidrBlockLines []string

			for _, line := range strings.Split(out, "\n") {

				if strings.Contains(line, "-A cali-cidr-block") {

					cidrBlockLines = append(cidrBlockLines, line)

				}

			}

			return cidrBlockLines

		}

	}


====================
		defer externalClient.Stop()

		// Add a service CIDR route in those containers, similar to the routes that they

		// would have via BGP per our service advertisement feature.  (This should really be

		// an ECMP route to both Felixes, but busybox's ip can't program ECMP routes, and a

		// non-ECMP route is sufficient to demonstrate the looping issue.)

		externalClient.Exec("ip", "r", "a", "10.96.0.0/17", "via", externalGW.IP)

		externalGW.Exec("ip", "r", "a", "10.96.0.0/17", "via", felixes[0].IP)

		// Configure the external gateway client to forward, in order to create the

		// conditions for looping.

		externalClient.Exec("sysctl", "-w", "net.ipv4.ip_forward=1")

		externalGW.Exec("sysctl", "-w", "net.ipv4.ip_forward=1")

		// Also tell Felix to route that CIDR to the external gateway.

		felixes[0].ExecMayFail("ip", "r", "d", "10.96.0.0/17")

		felixes[0].Exec("ip", "r", "a", "10.96.0.0/17", "via", externalGW.IP)

		felixes[0].Exec("iptables", "-P", "FORWARD", "ACCEPT")

		// Start monitoring all packets, on the Felix, to or from a specific (but

		// unused) service IP.

		tcpdumpF := felixes[0].AttachTCPDump("eth0")

		tcpdumpF.AddMatcher("serviceIPPackets", regexp.MustCompile("10\\.96\\.0\\.19"))

		tcpdumpF.Start()


====================
		// Add a service CIDR route in those containers, similar to the routes that they

		// would have via BGP per our service advertisement feature.  (This should really be

		// an ECMP route to both Felixes, but busybox's ip can't program ECMP routes, and a

		// non-ECMP route is sufficient to demonstrate the looping issue.)

		externalClient.Exec("ip", "r", "a", "10.96.0.0/17", "via", externalGW.IP)

		externalGW.Exec("ip", "r", "a", "10.96.0.0/17", "via", felixes[0].IP)

		// Configure the external gateway client to forward, in order to create the

		// conditions for looping.

		externalClient.Exec("sysctl", "-w", "net.ipv4.ip_forward=1")

		externalGW.Exec("sysctl", "-w", "net.ipv4.ip_forward=1")

		// Also tell Felix to route that CIDR to the external gateway.

		felixes[0].ExecMayFail("ip", "r", "d", "10.96.0.0/17")

		felixes[0].Exec("ip", "r", "a", "10.96.0.0/17", "via", externalGW.IP)

		felixes[0].Exec("iptables", "-P", "FORWARD", "ACCEPT")

		// Start monitoring all packets, on the Felix, to or from a specific (but

		// unused) service IP.

		tcpdumpF := felixes[0].AttachTCPDump("eth0")

		tcpdumpF.AddMatcher("serviceIPPackets", regexp.MustCompile("10\\.96\\.0\\.19"))

		tcpdumpF.Start()

		defer tcpdumpF.Stop()


====================
		externalClient.Exec("ip", "r", "a", "10.96.0.0/17", "via", externalGW.IP)

		externalGW.Exec("ip", "r", "a", "10.96.0.0/17", "via", felixes[0].IP)

		// Configure the external gateway client to forward, in order to create the

		// conditions for looping.

		externalClient.Exec("sysctl", "-w", "net.ipv4.ip_forward=1")

		externalGW.Exec("sysctl", "-w", "net.ipv4.ip_forward=1")

		// Also tell Felix to route that CIDR to the external gateway.

		felixes[0].ExecMayFail("ip", "r", "d", "10.96.0.0/17")

		felixes[0].Exec("ip", "r", "a", "10.96.0.0/17", "via", externalGW.IP)

		felixes[0].Exec("iptables", "-P", "FORWARD", "ACCEPT")

		// Start monitoring all packets, on the Felix, to or from a specific (but

		// unused) service IP.

		tcpdumpF := felixes[0].AttachTCPDump("eth0")

		tcpdumpF.AddMatcher("serviceIPPackets", regexp.MustCompile("10\\.96\\.0\\.19"))

		tcpdumpF.Start()

		defer tcpdumpF.Stop()

		// Send a single ping from the external client to the unused service IP.

		err := externalClient.ExecMayFail("ping", "-c", "1", "-W", "1", "10.96.0.19")

		Expect(err).To(HaveOccurred())

		countServiceIPPackets := func() int {


====================
		felixes[0].Exec("ip", "r", "a", "10.96.0.0/17", "via", externalGW.IP)

		felixes[0].Exec("iptables", "-P", "FORWARD", "ACCEPT")

		// Start monitoring all packets, on the Felix, to or from a specific (but

		// unused) service IP.

		tcpdumpF := felixes[0].AttachTCPDump("eth0")

		tcpdumpF.AddMatcher("serviceIPPackets", regexp.MustCompile("10\\.96\\.0\\.19"))

		tcpdumpF.Start()

		defer tcpdumpF.Stop()

		// Send a single ping from the external client to the unused service IP.

		err := externalClient.ExecMayFail("ping", "-c", "1", "-W", "1", "10.96.0.19")

		Expect(err).To(HaveOccurred())

		countServiceIPPackets := func() int {

			// Return the number of packets observed to/from 10.96.0.19.

			return tcpdumpF.MatchCount("serviceIPPackets")

		}

		if expectLoop {

			// Tcpdump should see more than 2 packets, because of looping.  Note: 2

			// packets would be Felix receiving the ping and then forwarding it out

			// again.  I want to check here that it's also looped around again by the

			// gateway, resulting in MORE THAN 2 packets.


====================
		}

		hostMgmtCredsPath = filepath.Join(tempDir, binder.CredentialsSubdir)

	})

	AfterEach(func() {

		for ii := range w {

			w[ii].Stop()

		}

		felix.Stop()

		if CurrentGinkgoTestDescription().Failed {

			etcd.Exec("etcdctl", "get", "/", "--prefix", "--keys-only")

		}

		etcd.Stop()

		infra.Stop()

	})

	AfterEach(func() {

		if tempDir != "" {

			err := os.RemoveAll(tempDir)

			Expect(err).NotTo(HaveOccurred(), "Failed to clean up temp dir")

		}

	})


====================
			rawIPHostW254[ii] = workload.Run(felixes[ii], fmt.Sprintf("raw-host%d", ii), "", felixes[ii].IP, "", "ip4:254")

		}

		cc = &connectivity.Checker{}

		cc253 = &connectivity.Checker{Protocol: "ip4:253"}

		cc254 = &connectivity.Checker{Protocol: "ip4:254"}

	})

	AfterEach(func() {

		if CurrentGinkgoTestDescription().Failed {

			for _, felix := range felixes {

				felix.Exec("iptables-save", "-c")

				felix.Exec("ipset", "list")

				felix.Exec("ip", "r")

				felix.Exec("ip", "a")

			}

		}

		for _, wl := range w {

			wl.Stop()

		}

		for _, wl := range hostW {

			wl.Stop()


====================
		resultsFile, err = os.OpenFile("latency.log", os.O_WRONLY|os.O_APPEND|os.O_CREATE, 0644)

		Expect(err).NotTo(HaveOccurred())

	})

	AfterEach(func() {

		err := resultsFile.Close()

		if err != nil {

			log.WithError(err).Error("Close returned error")

		}

		if CurrentGinkgoTestDescription().Failed {

			felix.Exec("iptables-save", "-c")

		}

		felix.Stop()

		if CurrentGinkgoTestDescription().Failed {

			etcd.Exec("etcdctl", "get", "/", "--prefix", "--keys-only")

		}

		etcd.Stop()

		infra.Stop()

	})

	describeLatencyTests := func(c latencyConfig) {

		var (


====================
		err := resultsFile.Close()

		if err != nil {

			log.WithError(err).Error("Close returned error")

		}

		if CurrentGinkgoTestDescription().Failed {

			felix.Exec("iptables-save", "-c")

		}

		felix.Stop()

		if CurrentGinkgoTestDescription().Failed {

			etcd.Exec("etcdctl", "get", "/", "--prefix", "--keys-only")

		}

		etcd.Stop()

		infra.Stop()

	})

	describeLatencyTests := func(c latencyConfig) {

		var (

			w   [2]*workload.Workload

			cc  *connectivity.Checker

			pol *api.GlobalNetworkPolicy

		)


====================
			})

		})

	}

	var typhaContainer *containers.Container

	var typhaReady, typhaLiveness func() int

	startTypha := func(getDockerArgs func() []string) {

		typhaContainer = containers.Run("typha",

			containers.RunOpts{AutoRemove: true},

			append(getDockerArgs(),

				"--privileged",

				"-e", "TYPHA_HEALTHENABLED=true",

				"-e", "TYPHA_HEALTHHOST=0.0.0.0",

				"-e", "TYPHA_LOGSEVERITYSCREEN=info",

				"-e", "TYPHA_DATASTORETYPE=kubernetes",

				"-e", "TYPHA_PROMETHEUSMETRICSENABLED=true",

				"-e", "TYPHA_USAGEREPORTINGENABLED=false",

				"-e", "TYPHA_DEBUGMEMORYPROFILEPATH=\"heap-<timestamp>\"",

				utils.Config.TyphaImage,

				"calico-typha")...)

		Expect(typhaContainer).NotTo(BeNil())


====================
		})

	}

	var typhaContainer *containers.Container

	var typhaReady, typhaLiveness func() int

	startTypha := func(getDockerArgs func() []string) {

		typhaContainer = containers.Run("typha",

			containers.RunOpts{AutoRemove: true},

			append(getDockerArgs(),

				"--privileged",

				"-e", "TYPHA_HEALTHENABLED=true",

				"-e", "TYPHA_HEALTHHOST=0.0.0.0",

				"-e", "TYPHA_LOGSEVERITYSCREEN=info",

				"-e", "TYPHA_DATASTORETYPE=kubernetes",

				"-e", "TYPHA_PROMETHEUSMETRICSENABLED=true",

				"-e", "TYPHA_USAGEREPORTINGENABLED=false",

				"-e", "TYPHA_DEBUGMEMORYPROFILEPATH=\"heap-<timestamp>\"",

				utils.Config.TyphaImage,

				"calico-typha")...)

		Expect(typhaContainer).NotTo(BeNil())

		typhaReady = getHealthStatus(typhaContainer.IP, "9098", "readiness")


====================
	}

	var typhaContainer *containers.Container

	var typhaReady, typhaLiveness func() int

	startTypha := func(getDockerArgs func() []string) {

		typhaContainer = containers.Run("typha",

			containers.RunOpts{AutoRemove: true},

			append(getDockerArgs(),

				"--privileged",

				"-e", "TYPHA_HEALTHENABLED=true",

				"-e", "TYPHA_HEALTHHOST=0.0.0.0",

				"-e", "TYPHA_LOGSEVERITYSCREEN=info",

				"-e", "TYPHA_DATASTORETYPE=kubernetes",

				"-e", "TYPHA_PROMETHEUSMETRICSENABLED=true",

				"-e", "TYPHA_USAGEREPORTINGENABLED=false",

				"-e", "TYPHA_DEBUGMEMORYPROFILEPATH=\"heap-<timestamp>\"",

				utils.Config.TyphaImage,

				"calico-typha")...)

		Expect(typhaContainer).NotTo(BeNil())

		typhaReady = getHealthStatus(typhaContainer.IP, "9098", "readiness")

		typhaLiveness = getHealthStatus(typhaContainer.IP, "9098", "liveness")


====================
	var typhaContainer *containers.Container

	var typhaReady, typhaLiveness func() int

	startTypha := func(getDockerArgs func() []string) {

		typhaContainer = containers.Run("typha",

			containers.RunOpts{AutoRemove: true},

			append(getDockerArgs(),

				"--privileged",

				"-e", "TYPHA_HEALTHENABLED=true",

				"-e", "TYPHA_HEALTHHOST=0.0.0.0",

				"-e", "TYPHA_LOGSEVERITYSCREEN=info",

				"-e", "TYPHA_DATASTORETYPE=kubernetes",

				"-e", "TYPHA_PROMETHEUSMETRICSENABLED=true",

				"-e", "TYPHA_USAGEREPORTINGENABLED=false",

				"-e", "TYPHA_DEBUGMEMORYPROFILEPATH=\"heap-<timestamp>\"",

				utils.Config.TyphaImage,

				"calico-typha")...)

		Expect(typhaContainer).NotTo(BeNil())

		typhaReady = getHealthStatus(typhaContainer.IP, "9098", "readiness")

		typhaLiveness = getHealthStatus(typhaContainer.IP, "9098", "liveness")

	}


====================
	var typhaReady, typhaLiveness func() int

	startTypha := func(getDockerArgs func() []string) {

		typhaContainer = containers.Run("typha",

			containers.RunOpts{AutoRemove: true},

			append(getDockerArgs(),

				"--privileged",

				"-e", "TYPHA_HEALTHENABLED=true",

				"-e", "TYPHA_HEALTHHOST=0.0.0.0",

				"-e", "TYPHA_LOGSEVERITYSCREEN=info",

				"-e", "TYPHA_DATASTORETYPE=kubernetes",

				"-e", "TYPHA_PROMETHEUSMETRICSENABLED=true",

				"-e", "TYPHA_USAGEREPORTINGENABLED=false",

				"-e", "TYPHA_DEBUGMEMORYPROFILEPATH=\"heap-<timestamp>\"",

				utils.Config.TyphaImage,

				"calico-typha")...)

		Expect(typhaContainer).NotTo(BeNil())

		typhaReady = getHealthStatus(typhaContainer.IP, "9098", "readiness")

		typhaLiveness = getHealthStatus(typhaContainer.IP, "9098", "liveness")

	}

	type felixParams struct {


====================
	startTypha := func(getDockerArgs func() []string) {

		typhaContainer = containers.Run("typha",

			containers.RunOpts{AutoRemove: true},

			append(getDockerArgs(),

				"--privileged",

				"-e", "TYPHA_HEALTHENABLED=true",

				"-e", "TYPHA_HEALTHHOST=0.0.0.0",

				"-e", "TYPHA_LOGSEVERITYSCREEN=info",

				"-e", "TYPHA_DATASTORETYPE=kubernetes",

				"-e", "TYPHA_PROMETHEUSMETRICSENABLED=true",

				"-e", "TYPHA_USAGEREPORTINGENABLED=false",

				"-e", "TYPHA_DEBUGMEMORYPROFILEPATH=\"heap-<timestamp>\"",

				utils.Config.TyphaImage,

				"calico-typha")...)

		Expect(typhaContainer).NotTo(BeNil())

		typhaReady = getHealthStatus(typhaContainer.IP, "9098", "readiness")

		typhaLiveness = getHealthStatus(typhaContainer.IP, "9098", "liveness")

	}

	type felixParams struct {

		dataplaneTimeout, calcGraphTimeout, calcGraphHangTime, dataplaneHangTime, healthHost string


====================
		typhaContainer = containers.Run("typha",

			containers.RunOpts{AutoRemove: true},

			append(getDockerArgs(),

				"--privileged",

				"-e", "TYPHA_HEALTHENABLED=true",

				"-e", "TYPHA_HEALTHHOST=0.0.0.0",

				"-e", "TYPHA_LOGSEVERITYSCREEN=info",

				"-e", "TYPHA_DATASTORETYPE=kubernetes",

				"-e", "TYPHA_PROMETHEUSMETRICSENABLED=true",

				"-e", "TYPHA_USAGEREPORTINGENABLED=false",

				"-e", "TYPHA_DEBUGMEMORYPROFILEPATH=\"heap-<timestamp>\"",

				utils.Config.TyphaImage,

				"calico-typha")...)

		Expect(typhaContainer).NotTo(BeNil())

		typhaReady = getHealthStatus(typhaContainer.IP, "9098", "readiness")

		typhaLiveness = getHealthStatus(typhaContainer.IP, "9098", "liveness")

	}

	type felixParams struct {

		dataplaneTimeout, calcGraphTimeout, calcGraphHangTime, dataplaneHangTime, healthHost string

	}


====================
			containers.RunOpts{AutoRemove: true},

			append(getDockerArgs(),

				"--privileged",

				"-e", "TYPHA_HEALTHENABLED=true",

				"-e", "TYPHA_HEALTHHOST=0.0.0.0",

				"-e", "TYPHA_LOGSEVERITYSCREEN=info",

				"-e", "TYPHA_DATASTORETYPE=kubernetes",

				"-e", "TYPHA_PROMETHEUSMETRICSENABLED=true",

				"-e", "TYPHA_USAGEREPORTINGENABLED=false",

				"-e", "TYPHA_DEBUGMEMORYPROFILEPATH=\"heap-<timestamp>\"",

				utils.Config.TyphaImage,

				"calico-typha")...)

		Expect(typhaContainer).NotTo(BeNil())

		typhaReady = getHealthStatus(typhaContainer.IP, "9098", "readiness")

		typhaLiveness = getHealthStatus(typhaContainer.IP, "9098", "liveness")

	}

	type felixParams struct {

		dataplaneTimeout, calcGraphTimeout, calcGraphHangTime, dataplaneHangTime, healthHost string

	}

	startFelix := func(typhaAddr string, getDockerArgs func() []string, params felixParams) {


====================
				EnableIPv6:   false,

				ExtraEnvVars: envVars,

			},

		)

		felixReady = getHealthStatus(felix.IP, "9099", "readiness")

		felixLiveness = getHealthStatus(felix.IP, "9099", "liveness")

	}

	Describe("healthHost not 'all interfaces'", func() {

		checkHealthInternally := func() error {

			_, err := felix.ExecOutput("wget", "-S", "-T", "2", "http://127.0.0.1:9099/readiness", "-O", "-")

			return err

		}

		It("should run healthchecks on localhost by default", func() {

			startFelix("", k8sInfra.GetDockerArgs, felixParams{dataplaneTimeout: "20s"})

			Eventually(checkHealthInternally, "10s", "100ms").ShouldNot(HaveOccurred())

		})

		It("should run support running healthchecks on '127.0.0.1'", func() {

			startFelix("", k8sInfra.GetDockerArgs, felixParams{dataplaneTimeout: "20", healthHost: "127.0.0.1"})

			Eventually(checkHealthInternally, "10s", "100ms").ShouldNot(HaveOccurred())

		})


====================
		})

		AfterEach(func() {

			felix.Stop()

			typhaContainer.Stop()

		})

		It("should report not ready until it connects to Typha, then report ready", func() {

			Eventually(felixReady, "5s", "100ms").Should(BeBad())

			Consistently(felixReady, "5s", "100ms").Should(BeBad())

			// Add a NAT rule to steer traffic from the port that Felix is using to the correct Typha port.

			felix.Exec("iptables", "-t", "nat", "-A", "OUTPUT", "-p", "tcp",

				"--destination", typhaContainer.IP, "--dport", "5474", "-j", "DNAT", "--to-destination", ":5473")

			Eventually(felixReady, "5s", "100ms").Should(BeGood())

		})

	})

	Describe("with typha connected to bad API endpoint", func() {

		BeforeEach(func() {

			startTypha(k8sInfra.GetBadEndpointDockerArgs)

		})

		AfterEach(func() {

			typhaContainer.Stop()


====================
		AfterEach(func() {

			felix.Stop()

			typhaContainer.Stop()

		})

		It("should report not ready until it connects to Typha, then report ready", func() {

			Eventually(felixReady, "5s", "100ms").Should(BeBad())

			Consistently(felixReady, "5s", "100ms").Should(BeBad())

			// Add a NAT rule to steer traffic from the port that Felix is using to the correct Typha port.

			felix.Exec("iptables", "-t", "nat", "-A", "OUTPUT", "-p", "tcp",

				"--destination", typhaContainer.IP, "--dport", "5474", "-j", "DNAT", "--to-destination", ":5473")

			Eventually(felixReady, "5s", "100ms").Should(BeGood())

		})

	})

	Describe("with typha connected to bad API endpoint", func() {

		BeforeEach(func() {

			startTypha(k8sInfra.GetBadEndpointDockerArgs)

		})

		AfterEach(func() {

			typhaContainer.Stop()

		})


====================
	}

	ipdst := net.ParseIP(args["<ip_dst>"].(string))

	if ipdst == nil {

		log.Fatal("invalid destination IP")

	}

	if ipsrc.To4() == nil || ipdst.To4() == nil {

		log.Fatal("cannot handle IPv6")

	}

	ipID := uint16(0)

	if args["--ip-id"] != nil {

		id, err := strconv.Atoi(args["--ip-id"].(string))

		if err != nil {

			log.WithError(err).Fatal("IP id not a number")

		}

		if id > math.MaxUint16 || id < 0 {

			log.Fatal("IP id should be between 0 and 65535")

		}

		ipID = uint16(id)

	}

	sport := uint16(0)


====================
	ipdst := net.ParseIP(args["<ip_dst>"].(string))

	if ipdst == nil {

		log.Fatal("invalid destination IP")

	}

	if ipsrc.To4() == nil || ipdst.To4() == nil {

		log.Fatal("cannot handle IPv6")

	}

	ipID := uint16(0)

	if args["--ip-id"] != nil {

		id, err := strconv.Atoi(args["--ip-id"].(string))

		if err != nil {

			log.WithError(err).Fatal("IP id not a number")

		}

		if id > math.MaxUint16 || id < 0 {

			log.Fatal("IP id should be between 0 and 65535")

		}

		ipID = uint16(id)

	}

	sport := uint16(0)

	if args["--port-src"] != nil {


====================
		if err != nil {

			log.WithError(err).Fatal("IP id not a number")

		}

		if id > math.MaxUint16 || id < 0 {

			log.Fatal("IP id should be between 0 and 65535")

		}

		ipID = uint16(id)

	}

	sport := uint16(0)

	if args["--port-src"] != nil {

		p, err := strconv.Atoi(args["--port-src"].(string))

		if err != nil {

			log.WithError(err).Fatal("source port not a number")

		}

		if p > math.MaxUint16 || p < 0 {

			log.Fatal("source port should be between 0 and 65535")

		}

		sport = uint16(p)

	}

	dport := uint16(0)


====================
			log.WithError(err).Fatal("IP id not a number")

		}

		if id > math.MaxUint16 || id < 0 {

			log.Fatal("IP id should be between 0 and 65535")

		}

		ipID = uint16(id)

	}

	sport := uint16(0)

	if args["--port-src"] != nil {

		p, err := strconv.Atoi(args["--port-src"].(string))

		if err != nil {

			log.WithError(err).Fatal("source port not a number")

		}

		if p > math.MaxUint16 || p < 0 {

			log.Fatal("source port should be between 0 and 65535")

		}

		sport = uint16(p)

	}

	dport := uint16(0)

	if args["--port-dst"] != nil {


====================
		if err != nil {

			log.WithError(err).Fatal("source port not a number")

		}

		if p > math.MaxUint16 || p < 0 {

			log.Fatal("source port should be between 0 and 65535")

		}

		sport = uint16(p)

	}

	dport := uint16(0)

	if args["--port-dst"] != nil {

		p, err := strconv.Atoi(args["--port-dst"].(string))

		if err != nil {

			log.WithError(err).Fatal("destination port not a number")

		}

		if p > math.MaxUint16 || p < 0 {

			log.Fatal("destination port should be between 0 and 65535")

		}

		dport = uint16(p)

	}

	var proto layers.IPProtocol


====================
			log.WithError(err).Fatal("source port not a number")

		}

		if p > math.MaxUint16 || p < 0 {

			log.Fatal("source port should be between 0 and 65535")

		}

		sport = uint16(p)

	}

	dport := uint16(0)

	if args["--port-dst"] != nil {

		p, err := strconv.Atoi(args["--port-dst"].(string))

		if err != nil {

			log.WithError(err).Fatal("destination port not a number")

		}

		if p > math.MaxUint16 || p < 0 {

			log.Fatal("destination port should be between 0 and 65535")

		}

		dport = uint16(p)

	}

	var proto layers.IPProtocol

	switch args["<proto>"] {


====================
	}

	arch := utils.GetSysArch()

	// In BPF mode, start BPF logging.

	if os.Getenv("FELIX_FV_ENABLE_BPF") == "true" {

		eds.bpfLog = containers.Run("bpf-log",

			containers.RunOpts{

				AutoRemove:       true,

				IgnoreEmptyLines: true,

			},

			"--privileged",

			"calico/bpftool:v5.3-"+arch, "/bpftool", "prog", "tracelog")

	}

	eds.Endpoint = fmt.Sprintf("https://%s:6443", eds.etcdContainer.IP)

	eds.BadEndpoint = fmt.Sprintf("https://%s:1234", eds.etcdContainer.IP)

	return eds, nil

}

func (eds *EtcdDatastoreInfra) GetDockerArgs() []string {

	return []string{

		"-e", "CALICO_DATASTORE_TYPE=etcdv3",

		"-e", "FELIX_DATASTORETYPE=etcdv3",


====================
			"--privileged",

			"calico/bpftool:v5.3-"+arch, "/bpftool", "prog", "tracelog")

	}

	eds.Endpoint = fmt.Sprintf("https://%s:6443", eds.etcdContainer.IP)

	eds.BadEndpoint = fmt.Sprintf("https://%s:1234", eds.etcdContainer.IP)

	return eds, nil

}

func (eds *EtcdDatastoreInfra) GetDockerArgs() []string {

	return []string{

		"-e", "CALICO_DATASTORE_TYPE=etcdv3",

		"-e", "FELIX_DATASTORETYPE=etcdv3",

		"-e", "TYPHA_DATASTORETYPE=etcdv3",

		"-e", "TYPHA_ETCDENDPOINTS=http://" + eds.etcdContainer.IP + ":2379",

		"-e", "CALICO_ETCD_ENDPOINTS=http://" + eds.etcdContainer.IP + ":2379",

	}

}

func (eds *EtcdDatastoreInfra) GetBadEndpointDockerArgs() []string {

	return []string{

		"-e", "CALICO_DATASTORE_TYPE=etcdv3",

		"-e", "FELIX_DATASTORETYPE=etcdv3",


====================
			"calico/bpftool:v5.3-"+arch, "/bpftool", "prog", "tracelog")

	}

	eds.Endpoint = fmt.Sprintf("https://%s:6443", eds.etcdContainer.IP)

	eds.BadEndpoint = fmt.Sprintf("https://%s:1234", eds.etcdContainer.IP)

	return eds, nil

}

func (eds *EtcdDatastoreInfra) GetDockerArgs() []string {

	return []string{

		"-e", "CALICO_DATASTORE_TYPE=etcdv3",

		"-e", "FELIX_DATASTORETYPE=etcdv3",

		"-e", "TYPHA_DATASTORETYPE=etcdv3",

		"-e", "TYPHA_ETCDENDPOINTS=http://" + eds.etcdContainer.IP + ":2379",

		"-e", "CALICO_ETCD_ENDPOINTS=http://" + eds.etcdContainer.IP + ":2379",

	}

}

func (eds *EtcdDatastoreInfra) GetBadEndpointDockerArgs() []string {

	return []string{

		"-e", "CALICO_DATASTORE_TYPE=etcdv3",

		"-e", "FELIX_DATASTORETYPE=etcdv3",

		"-e", "TYPHA_DATASTORETYPE=etcdv3",


====================
	}

	eds.Endpoint = fmt.Sprintf("https://%s:6443", eds.etcdContainer.IP)

	eds.BadEndpoint = fmt.Sprintf("https://%s:1234", eds.etcdContainer.IP)

	return eds, nil

}

func (eds *EtcdDatastoreInfra) GetDockerArgs() []string {

	return []string{

		"-e", "CALICO_DATASTORE_TYPE=etcdv3",

		"-e", "FELIX_DATASTORETYPE=etcdv3",

		"-e", "TYPHA_DATASTORETYPE=etcdv3",

		"-e", "TYPHA_ETCDENDPOINTS=http://" + eds.etcdContainer.IP + ":2379",

		"-e", "CALICO_ETCD_ENDPOINTS=http://" + eds.etcdContainer.IP + ":2379",

	}

}

func (eds *EtcdDatastoreInfra) GetBadEndpointDockerArgs() []string {

	return []string{

		"-e", "CALICO_DATASTORE_TYPE=etcdv3",

		"-e", "FELIX_DATASTORETYPE=etcdv3",

		"-e", "TYPHA_DATASTORETYPE=etcdv3",

		"-e", "TYPHA_ETCDENDPOINTS=http://" + eds.etcdContainer.IP + ":2379",


====================
	eds.Endpoint = fmt.Sprintf("https://%s:6443", eds.etcdContainer.IP)

	eds.BadEndpoint = fmt.Sprintf("https://%s:1234", eds.etcdContainer.IP)

	return eds, nil

}

func (eds *EtcdDatastoreInfra) GetDockerArgs() []string {

	return []string{

		"-e", "CALICO_DATASTORE_TYPE=etcdv3",

		"-e", "FELIX_DATASTORETYPE=etcdv3",

		"-e", "TYPHA_DATASTORETYPE=etcdv3",

		"-e", "TYPHA_ETCDENDPOINTS=http://" + eds.etcdContainer.IP + ":2379",

		"-e", "CALICO_ETCD_ENDPOINTS=http://" + eds.etcdContainer.IP + ":2379",

	}

}

func (eds *EtcdDatastoreInfra) GetBadEndpointDockerArgs() []string {

	return []string{

		"-e", "CALICO_DATASTORE_TYPE=etcdv3",

		"-e", "FELIX_DATASTORETYPE=etcdv3",

		"-e", "TYPHA_DATASTORETYPE=etcdv3",

		"-e", "TYPHA_ETCDENDPOINTS=http://" + eds.etcdContainer.IP + ":2379",

		"-e", "CALICO_ETCD_ENDPOINTS=http://" + eds.etcdContainer.IP + ":1234",


====================
	eds.BadEndpoint = fmt.Sprintf("https://%s:1234", eds.etcdContainer.IP)

	return eds, nil

}

func (eds *EtcdDatastoreInfra) GetDockerArgs() []string {

	return []string{

		"-e", "CALICO_DATASTORE_TYPE=etcdv3",

		"-e", "FELIX_DATASTORETYPE=etcdv3",

		"-e", "TYPHA_DATASTORETYPE=etcdv3",

		"-e", "TYPHA_ETCDENDPOINTS=http://" + eds.etcdContainer.IP + ":2379",

		"-e", "CALICO_ETCD_ENDPOINTS=http://" + eds.etcdContainer.IP + ":2379",

	}

}

func (eds *EtcdDatastoreInfra) GetBadEndpointDockerArgs() []string {

	return []string{

		"-e", "CALICO_DATASTORE_TYPE=etcdv3",

		"-e", "FELIX_DATASTORETYPE=etcdv3",

		"-e", "TYPHA_DATASTORETYPE=etcdv3",

		"-e", "TYPHA_ETCDENDPOINTS=http://" + eds.etcdContainer.IP + ":2379",

		"-e", "CALICO_ETCD_ENDPOINTS=http://" + eds.etcdContainer.IP + ":1234",

	}


====================
		"-e", "CALICO_DATASTORE_TYPE=etcdv3",

		"-e", "FELIX_DATASTORETYPE=etcdv3",

		"-e", "TYPHA_DATASTORETYPE=etcdv3",

		"-e", "TYPHA_ETCDENDPOINTS=http://" + eds.etcdContainer.IP + ":2379",

		"-e", "CALICO_ETCD_ENDPOINTS=http://" + eds.etcdContainer.IP + ":2379",

	}

}

func (eds *EtcdDatastoreInfra) GetBadEndpointDockerArgs() []string {

	return []string{

		"-e", "CALICO_DATASTORE_TYPE=etcdv3",

		"-e", "FELIX_DATASTORETYPE=etcdv3",

		"-e", "TYPHA_DATASTORETYPE=etcdv3",

		"-e", "TYPHA_ETCDENDPOINTS=http://" + eds.etcdContainer.IP + ":2379",

		"-e", "CALICO_ETCD_ENDPOINTS=http://" + eds.etcdContainer.IP + ":1234",

	}

}

func (eds *EtcdDatastoreInfra) GetCalicoClient() client.Interface {

	return utils.GetEtcdClient(eds.etcdContainer.IP)

}

func (eds *EtcdDatastoreInfra) GetClusterGUID() string {


====================
		"-e", "FELIX_DATASTORETYPE=etcdv3",

		"-e", "TYPHA_DATASTORETYPE=etcdv3",

		"-e", "TYPHA_ETCDENDPOINTS=http://" + eds.etcdContainer.IP + ":2379",

		"-e", "CALICO_ETCD_ENDPOINTS=http://" + eds.etcdContainer.IP + ":2379",

	}

}

func (eds *EtcdDatastoreInfra) GetBadEndpointDockerArgs() []string {

	return []string{

		"-e", "CALICO_DATASTORE_TYPE=etcdv3",

		"-e", "FELIX_DATASTORETYPE=etcdv3",

		"-e", "TYPHA_DATASTORETYPE=etcdv3",

		"-e", "TYPHA_ETCDENDPOINTS=http://" + eds.etcdContainer.IP + ":2379",

		"-e", "CALICO_ETCD_ENDPOINTS=http://" + eds.etcdContainer.IP + ":1234",

	}

}

func (eds *EtcdDatastoreInfra) GetCalicoClient() client.Interface {

	return utils.GetEtcdClient(eds.etcdContainer.IP)

}

func (eds *EtcdDatastoreInfra) GetClusterGUID() string {

	ci, err := eds.GetCalicoClient().ClusterInformation().Get(


====================
		"-e", "TYPHA_DATASTORETYPE=etcdv3",

		"-e", "TYPHA_ETCDENDPOINTS=http://" + eds.etcdContainer.IP + ":2379",

		"-e", "CALICO_ETCD_ENDPOINTS=http://" + eds.etcdContainer.IP + ":2379",

	}

}

func (eds *EtcdDatastoreInfra) GetBadEndpointDockerArgs() []string {

	return []string{

		"-e", "CALICO_DATASTORE_TYPE=etcdv3",

		"-e", "FELIX_DATASTORETYPE=etcdv3",

		"-e", "TYPHA_DATASTORETYPE=etcdv3",

		"-e", "TYPHA_ETCDENDPOINTS=http://" + eds.etcdContainer.IP + ":2379",

		"-e", "CALICO_ETCD_ENDPOINTS=http://" + eds.etcdContainer.IP + ":1234",

	}

}

func (eds *EtcdDatastoreInfra) GetCalicoClient() client.Interface {

	return utils.GetEtcdClient(eds.etcdContainer.IP)

}

func (eds *EtcdDatastoreInfra) GetClusterGUID() string {

	ci, err := eds.GetCalicoClient().ClusterInformation().Get(

		context.Background(),


====================
		"-e", "TYPHA_ETCDENDPOINTS=http://" + eds.etcdContainer.IP + ":2379",

		"-e", "CALICO_ETCD_ENDPOINTS=http://" + eds.etcdContainer.IP + ":2379",

	}

}

func (eds *EtcdDatastoreInfra) GetBadEndpointDockerArgs() []string {

	return []string{

		"-e", "CALICO_DATASTORE_TYPE=etcdv3",

		"-e", "FELIX_DATASTORETYPE=etcdv3",

		"-e", "TYPHA_DATASTORETYPE=etcdv3",

		"-e", "TYPHA_ETCDENDPOINTS=http://" + eds.etcdContainer.IP + ":2379",

		"-e", "CALICO_ETCD_ENDPOINTS=http://" + eds.etcdContainer.IP + ":1234",

	}

}

func (eds *EtcdDatastoreInfra) GetCalicoClient() client.Interface {

	return utils.GetEtcdClient(eds.etcdContainer.IP)

}

func (eds *EtcdDatastoreInfra) GetClusterGUID() string {

	ci, err := eds.GetCalicoClient().ClusterInformation().Get(

		context.Background(),

		"default",


====================
		"-e", "CALICO_ETCD_ENDPOINTS=http://" + eds.etcdContainer.IP + ":2379",

	}

}

func (eds *EtcdDatastoreInfra) GetBadEndpointDockerArgs() []string {

	return []string{

		"-e", "CALICO_DATASTORE_TYPE=etcdv3",

		"-e", "FELIX_DATASTORETYPE=etcdv3",

		"-e", "TYPHA_DATASTORETYPE=etcdv3",

		"-e", "TYPHA_ETCDENDPOINTS=http://" + eds.etcdContainer.IP + ":2379",

		"-e", "CALICO_ETCD_ENDPOINTS=http://" + eds.etcdContainer.IP + ":1234",

	}

}

func (eds *EtcdDatastoreInfra) GetCalicoClient() client.Interface {

	return utils.GetEtcdClient(eds.etcdContainer.IP)

}

func (eds *EtcdDatastoreInfra) GetClusterGUID() string {

	ci, err := eds.GetCalicoClient().ClusterInformation().Get(

		context.Background(),

		"default",

		options.GetOptions{},


====================
	defaultProfile.Spec.Ingress = []api.Rule{{Action: api.Allow}}

	_, err := eds.GetCalicoClient().Profiles().Create(utils.Ctx, defaultProfile, utils.NoOptions)

	Expect(err).NotTo(HaveOccurred())

	return defaultProfile.Name

}

func (eds *EtcdDatastoreInfra) AddDefaultDeny() error {

	return nil

}

func (eds *EtcdDatastoreInfra) DumpErrorData() {

	eds.etcdContainer.Exec("etcdctl", "get", "/", "--prefix", "--keys-only")

}

func (eds *EtcdDatastoreInfra) Stop() {

	eds.bpfLog.StopLogs()

	eds.etcdContainer.StopLogs()

	eds.bpfLog.Stop()

	eds.etcdContainer.Stop()

}

// Copyright (c) 2017-2018,2020 Tigera, Inc. All rights reserved.

//

// Licensed under the Apache License, Version 2.0 (the "License");


====================
)

func RunEtcd() *containers.Container {

	args := []string{

		"--privileged", // So that we can add routes inside the etcd container,

		// when using the etcd container to model an external client connecting

		// into the cluster.

		utils.Config.EtcdImage,

		"etcd",

		"--advertise-client-urls", "http://127.0.0.1:2379",

		"--listen-client-urls", "http://0.0.0.0:2379"}

	arch := utils.GetSysArch()

	if arch != "amd64" {

		args = append([]string{"-e", fmt.Sprintf("ETCD_UNSUPPORTED_ARCH=%s", arch)},

			args...)

	}

	log.Info("Starting etcd")

	return containers.Run("etcd",

		containers.RunOpts{

			AutoRemove: true,

			StopSignal: "SIGKILL",


====================
		"--privileged", // So that we can add routes inside the etcd container,

		// when using the etcd container to model an external client connecting

		// into the cluster.

		utils.Config.EtcdImage,

		"etcd",

		"--advertise-client-urls", "http://127.0.0.1:2379",

		"--listen-client-urls", "http://0.0.0.0:2379"}

	arch := utils.GetSysArch()

	if arch != "amd64" {

		args = append([]string{"-e", fmt.Sprintf("ETCD_UNSUPPORTED_ARCH=%s", arch)},

			args...)

	}

	log.Info("Starting etcd")

	return containers.Run("etcd",

		containers.RunOpts{

			AutoRemove: true,

			StopSignal: "SIGKILL",

		},

		args...)

}


====================
)

func RunExtClient(namePrefix string) *containers.Container {

	wd, err := os.Getwd()

	Expect(err).NotTo(HaveOccurred(), "failed to get working directory")

	externalClient := containers.Run(

		namePrefix,

		containers.RunOpts{

			AutoRemove: true,

		},

		"--privileged",                    // So that we can add routes inside the container.

		"-v", wd+"/../bin:/usr/local/bin", // Map in the test-connectivity binary etc.

		utils.Config.BusyboxImage,

		"/bin/sh", "-c", "sleep 1000")

	return externalClient

}

// Copyright (c) 2017-2022 Tigera, Inc. All rights reserved.

//

// Licensed under the Apache License, Version 2.0 (the "License");

// you may not use this file except in compliance with the License.

// You may obtain a copy of the License at


====================
func RunExtClient(namePrefix string) *containers.Container {

	wd, err := os.Getwd()

	Expect(err).NotTo(HaveOccurred(), "failed to get working directory")

	externalClient := containers.Run(

		namePrefix,

		containers.RunOpts{

			AutoRemove: true,

		},

		"--privileged",                    // So that we can add routes inside the container.

		"-v", wd+"/../bin:/usr/local/bin", // Map in the test-connectivity binary etc.

		utils.Config.BusyboxImage,

		"/bin/sh", "-c", "sleep 1000")

	return externalClient

}

// Copyright (c) 2017-2022 Tigera, Inc. All rights reserved.

//

// Licensed under the Apache License, Version 2.0 (the "License");

// you may not use this file except in compliance with the License.

// You may obtain a copy of the License at

//


====================
	Expect(err).NotTo(HaveOccurred(), "failed to get working directory")

	externalClient := containers.Run(

		namePrefix,

		containers.RunOpts{

			AutoRemove: true,

		},

		"--privileged",                    // So that we can add routes inside the container.

		"-v", wd+"/../bin:/usr/local/bin", // Map in the test-connectivity binary etc.

		utils.Config.BusyboxImage,

		"/bin/sh", "-c", "sleep 1000")

	return externalClient

}

// Copyright (c) 2017-2022 Tigera, Inc. All rights reserved.

//

// Licensed under the Apache License, Version 2.0 (the "License");

// you may not use this file except in compliance with the License.

// You may obtain a copy of the License at

//

//     http://www.apache.org/licenses/LICENSE-2.0

//


====================
		}

	}

	if options.DelayFelixStart {

		envVars["DELAY_FELIX_START"] = "true"

	}

	for k, v := range options.ExtraEnvVars {

		envVars[k] = v

	}

	for k, v := range envVars {

		args = append(args, "-e", fmt.Sprintf("%s=%s", k, v))

	}

	// Add in the volumes.

	for k, v := range options.ExtraVolumes {

		volumes[k] = v

	}

	for k, v := range volumes {

		args = append(args, "-v", fmt.Sprintf("%s:%s", k, v))

	}

	args = append(args,

		utils.Config.FelixImage,


====================
	}

	for k, v := range envVars {

		args = append(args, "-e", fmt.Sprintf("%s=%s", k, v))

	}

	// Add in the volumes.

	for k, v := range options.ExtraVolumes {

		volumes[k] = v

	}

	for k, v := range volumes {

		args = append(args, "-v", fmt.Sprintf("%s:%s", k, v))

	}

	args = append(args,

		utils.Config.FelixImage,

	)

	felixOpts := containers.RunOpts{

		AutoRemove: true,

	}

	if options.FelixStopGraceful {

		// Leave StopSignal defaulting to SIGTERM, and allow 10 seconds for Felix

		// to handle that gracefully.


====================
		// Leave StopSignal defaulting to SIGTERM, and allow 10 seconds for Felix

		// to handle that gracefully.

		felixOpts.StopTimeoutSecs = 10

	} else {

		// Use SIGKILL to stop Felix immediately.

		felixOpts.StopSignal = "SIGKILL"

	}

	c := containers.RunWithFixedName(containerName, felixOpts, args...)

	if options.EnableIPv6 {

		c.Exec("sysctl", "-w", "net.ipv6.conf.all.disable_ipv6=0")

		c.Exec("sysctl", "-w", "net.ipv6.conf.default.disable_ipv6=0")

		c.Exec("sysctl", "-w", "net.ipv6.conf.lo.disable_ipv6=0")

		c.Exec("sysctl", "-w", "net.ipv6.conf.all.forwarding=1")

	} else {

		c.Exec("sysctl", "-w", "net.ipv6.conf.all.disable_ipv6=1")

		c.Exec("sysctl", "-w", "net.ipv6.conf.default.disable_ipv6=1")

		c.Exec("sysctl", "-w", "net.ipv6.conf.lo.disable_ipv6=1")

		c.Exec("sysctl", "-w", "net.ipv6.conf.all.forwarding=0")

	}

	// Configure our model host to drop forwarded traffic by default.  Modern


====================
		// to handle that gracefully.

		felixOpts.StopTimeoutSecs = 10

	} else {

		// Use SIGKILL to stop Felix immediately.

		felixOpts.StopSignal = "SIGKILL"

	}

	c := containers.RunWithFixedName(containerName, felixOpts, args...)

	if options.EnableIPv6 {

		c.Exec("sysctl", "-w", "net.ipv6.conf.all.disable_ipv6=0")

		c.Exec("sysctl", "-w", "net.ipv6.conf.default.disable_ipv6=0")

		c.Exec("sysctl", "-w", "net.ipv6.conf.lo.disable_ipv6=0")

		c.Exec("sysctl", "-w", "net.ipv6.conf.all.forwarding=1")

	} else {

		c.Exec("sysctl", "-w", "net.ipv6.conf.all.disable_ipv6=1")

		c.Exec("sysctl", "-w", "net.ipv6.conf.default.disable_ipv6=1")

		c.Exec("sysctl", "-w", "net.ipv6.conf.lo.disable_ipv6=1")

		c.Exec("sysctl", "-w", "net.ipv6.conf.all.forwarding=0")

	}

	// Configure our model host to drop forwarded traffic by default.  Modern

	// Kubernetes/Docker hosts now have this setting, and the consequence is that


====================
		felixOpts.StopTimeoutSecs = 10

	} else {

		// Use SIGKILL to stop Felix immediately.

		felixOpts.StopSignal = "SIGKILL"

	}

	c := containers.RunWithFixedName(containerName, felixOpts, args...)

	if options.EnableIPv6 {

		c.Exec("sysctl", "-w", "net.ipv6.conf.all.disable_ipv6=0")

		c.Exec("sysctl", "-w", "net.ipv6.conf.default.disable_ipv6=0")

		c.Exec("sysctl", "-w", "net.ipv6.conf.lo.disable_ipv6=0")

		c.Exec("sysctl", "-w", "net.ipv6.conf.all.forwarding=1")

	} else {

		c.Exec("sysctl", "-w", "net.ipv6.conf.all.disable_ipv6=1")

		c.Exec("sysctl", "-w", "net.ipv6.conf.default.disable_ipv6=1")

		c.Exec("sysctl", "-w", "net.ipv6.conf.lo.disable_ipv6=1")

		c.Exec("sysctl", "-w", "net.ipv6.conf.all.forwarding=0")

	}

	// Configure our model host to drop forwarded traffic by default.  Modern

	// Kubernetes/Docker hosts now have this setting, and the consequence is that

	// whenever Calico policy intends to allow a packet, it must explicitly ACCEPT


====================
	} else {

		// Use SIGKILL to stop Felix immediately.

		felixOpts.StopSignal = "SIGKILL"

	}

	c := containers.RunWithFixedName(containerName, felixOpts, args...)

	if options.EnableIPv6 {

		c.Exec("sysctl", "-w", "net.ipv6.conf.all.disable_ipv6=0")

		c.Exec("sysctl", "-w", "net.ipv6.conf.default.disable_ipv6=0")

		c.Exec("sysctl", "-w", "net.ipv6.conf.lo.disable_ipv6=0")

		c.Exec("sysctl", "-w", "net.ipv6.conf.all.forwarding=1")

	} else {

		c.Exec("sysctl", "-w", "net.ipv6.conf.all.disable_ipv6=1")

		c.Exec("sysctl", "-w", "net.ipv6.conf.default.disable_ipv6=1")

		c.Exec("sysctl", "-w", "net.ipv6.conf.lo.disable_ipv6=1")

		c.Exec("sysctl", "-w", "net.ipv6.conf.all.forwarding=0")

	}

	// Configure our model host to drop forwarded traffic by default.  Modern

	// Kubernetes/Docker hosts now have this setting, and the consequence is that

	// whenever Calico policy intends to allow a packet, it must explicitly ACCEPT

	// that packet, not just allow it to pass through cali-FORWARD and assume it will


====================
		felixOpts.StopSignal = "SIGKILL"

	}

	c := containers.RunWithFixedName(containerName, felixOpts, args...)

	if options.EnableIPv6 {

		c.Exec("sysctl", "-w", "net.ipv6.conf.all.disable_ipv6=0")

		c.Exec("sysctl", "-w", "net.ipv6.conf.default.disable_ipv6=0")

		c.Exec("sysctl", "-w", "net.ipv6.conf.lo.disable_ipv6=0")

		c.Exec("sysctl", "-w", "net.ipv6.conf.all.forwarding=1")

	} else {

		c.Exec("sysctl", "-w", "net.ipv6.conf.all.disable_ipv6=1")

		c.Exec("sysctl", "-w", "net.ipv6.conf.default.disable_ipv6=1")

		c.Exec("sysctl", "-w", "net.ipv6.conf.lo.disable_ipv6=1")

		c.Exec("sysctl", "-w", "net.ipv6.conf.all.forwarding=0")

	}

	// Configure our model host to drop forwarded traffic by default.  Modern

	// Kubernetes/Docker hosts now have this setting, and the consequence is that

	// whenever Calico policy intends to allow a packet, it must explicitly ACCEPT

	// that packet, not just allow it to pass through cali-FORWARD and assume it will

	// be accepted by the rest of the chain.  Establishing that setting in this FV

	// allows us to test that.


====================
	}

	c := containers.RunWithFixedName(containerName, felixOpts, args...)

	if options.EnableIPv6 {

		c.Exec("sysctl", "-w", "net.ipv6.conf.all.disable_ipv6=0")

		c.Exec("sysctl", "-w", "net.ipv6.conf.default.disable_ipv6=0")

		c.Exec("sysctl", "-w", "net.ipv6.conf.lo.disable_ipv6=0")

		c.Exec("sysctl", "-w", "net.ipv6.conf.all.forwarding=1")

	} else {

		c.Exec("sysctl", "-w", "net.ipv6.conf.all.disable_ipv6=1")

		c.Exec("sysctl", "-w", "net.ipv6.conf.default.disable_ipv6=1")

		c.Exec("sysctl", "-w", "net.ipv6.conf.lo.disable_ipv6=1")

		c.Exec("sysctl", "-w", "net.ipv6.conf.all.forwarding=0")

	}

	// Configure our model host to drop forwarded traffic by default.  Modern

	// Kubernetes/Docker hosts now have this setting, and the consequence is that

	// whenever Calico policy intends to allow a packet, it must explicitly ACCEPT

	// that packet, not just allow it to pass through cali-FORWARD and assume it will

	// be accepted by the rest of the chain.  Establishing that setting in this FV

	// allows us to test that.

	c.Exec("iptables",


====================
	c := containers.RunWithFixedName(containerName, felixOpts, args...)

	if options.EnableIPv6 {

		c.Exec("sysctl", "-w", "net.ipv6.conf.all.disable_ipv6=0")

		c.Exec("sysctl", "-w", "net.ipv6.conf.default.disable_ipv6=0")

		c.Exec("sysctl", "-w", "net.ipv6.conf.lo.disable_ipv6=0")

		c.Exec("sysctl", "-w", "net.ipv6.conf.all.forwarding=1")

	} else {

		c.Exec("sysctl", "-w", "net.ipv6.conf.all.disable_ipv6=1")

		c.Exec("sysctl", "-w", "net.ipv6.conf.default.disable_ipv6=1")

		c.Exec("sysctl", "-w", "net.ipv6.conf.lo.disable_ipv6=1")

		c.Exec("sysctl", "-w", "net.ipv6.conf.all.forwarding=0")

	}

	// Configure our model host to drop forwarded traffic by default.  Modern

	// Kubernetes/Docker hosts now have this setting, and the consequence is that

	// whenever Calico policy intends to allow a packet, it must explicitly ACCEPT

	// that packet, not just allow it to pass through cali-FORWARD and assume it will

	// be accepted by the rest of the chain.  Establishing that setting in this FV

	// allows us to test that.

	c.Exec("iptables",

		"-w", "10", // Retry this for 10 seconds, e.g. if something else is holding the lock


====================
	if options.EnableIPv6 {

		c.Exec("sysctl", "-w", "net.ipv6.conf.all.disable_ipv6=0")

		c.Exec("sysctl", "-w", "net.ipv6.conf.default.disable_ipv6=0")

		c.Exec("sysctl", "-w", "net.ipv6.conf.lo.disable_ipv6=0")

		c.Exec("sysctl", "-w", "net.ipv6.conf.all.forwarding=1")

	} else {

		c.Exec("sysctl", "-w", "net.ipv6.conf.all.disable_ipv6=1")

		c.Exec("sysctl", "-w", "net.ipv6.conf.default.disable_ipv6=1")

		c.Exec("sysctl", "-w", "net.ipv6.conf.lo.disable_ipv6=1")

		c.Exec("sysctl", "-w", "net.ipv6.conf.all.forwarding=0")

	}

	// Configure our model host to drop forwarded traffic by default.  Modern

	// Kubernetes/Docker hosts now have this setting, and the consequence is that

	// whenever Calico policy intends to allow a packet, it must explicitly ACCEPT

	// that packet, not just allow it to pass through cali-FORWARD and assume it will

	// be accepted by the rest of the chain.  Establishing that setting in this FV

	// allows us to test that.

	c.Exec("iptables",

		"-w", "10", // Retry this for 10 seconds, e.g. if something else is holding the lock

		"-W", "100000", // How often to probe the lock in microsecs.


====================
		c.Exec("sysctl", "-w", "net.ipv6.conf.all.forwarding=0")

	}

	// Configure our model host to drop forwarded traffic by default.  Modern

	// Kubernetes/Docker hosts now have this setting, and the consequence is that

	// whenever Calico policy intends to allow a packet, it must explicitly ACCEPT

	// that packet, not just allow it to pass through cali-FORWARD and assume it will

	// be accepted by the rest of the chain.  Establishing that setting in this FV

	// allows us to test that.

	c.Exec("iptables",

		"-w", "10", // Retry this for 10 seconds, e.g. if something else is holding the lock

		"-W", "100000", // How often to probe the lock in microsecs.

		"-P", "FORWARD", "DROP")

	return &Felix{

		Container:      c,

		startupDelayed: options.DelayFelixStart,

	}

}

func (f *Felix) Stop() {

	if CreateCgroupV2 {

		_ = f.ExecMayFail("rmdir", path.Join("/run/calico/cgroup/", f.Name))


====================
	}

	// Configure our model host to drop forwarded traffic by default.  Modern

	// Kubernetes/Docker hosts now have this setting, and the consequence is that

	// whenever Calico policy intends to allow a packet, it must explicitly ACCEPT

	// that packet, not just allow it to pass through cali-FORWARD and assume it will

	// be accepted by the rest of the chain.  Establishing that setting in this FV

	// allows us to test that.

	c.Exec("iptables",

		"-w", "10", // Retry this for 10 seconds, e.g. if something else is holding the lock

		"-W", "100000", // How often to probe the lock in microsecs.

		"-P", "FORWARD", "DROP")

	return &Felix{

		Container:      c,

		startupDelayed: options.DelayFelixStart,

	}

}

func (f *Felix) Stop() {

	if CreateCgroupV2 {

		_ = f.ExecMayFail("rmdir", path.Join("/run/calico/cgroup/", f.Name))

	}


====================
	// Configure our model host to drop forwarded traffic by default.  Modern

	// Kubernetes/Docker hosts now have this setting, and the consequence is that

	// whenever Calico policy intends to allow a packet, it must explicitly ACCEPT

	// that packet, not just allow it to pass through cali-FORWARD and assume it will

	// be accepted by the rest of the chain.  Establishing that setting in this FV

	// allows us to test that.

	c.Exec("iptables",

		"-w", "10", // Retry this for 10 seconds, e.g. if something else is holding the lock

		"-W", "100000", // How often to probe the lock in microsecs.

		"-P", "FORWARD", "DROP")

	return &Felix{

		Container:      c,

		startupDelayed: options.DelayFelixStart,

	}

}

func (f *Felix) Stop() {

	if CreateCgroupV2 {

		_ = f.ExecMayFail("rmdir", path.Join("/run/calico/cgroup/", f.Name))

	}

	f.Container.Stop()


====================
}

func (f *Felix) Stop() {

	if CreateCgroupV2 {

		_ = f.ExecMayFail("rmdir", path.Join("/run/calico/cgroup/", f.Name))

	}

	f.Container.Stop()

}

func (f *Felix) Restart() {

	oldPID := f.GetFelixPID()

	f.Exec("kill", "-HUP", fmt.Sprint(oldPID))

	Eventually(f.GetFelixPID, "10s", "100ms").ShouldNot(Equal(oldPID))

}

func (f *Felix) SetEvn(env map[string]string) {

	fn := "extra-env.sh"

	file, err := os.OpenFile("./"+fn, os.O_TRUNC|os.O_CREATE|os.O_WRONLY, 0644)

	Expect(err).NotTo(HaveOccurred())

	fw := bufio.NewWriter(file)

	for k, v := range env {

		fmt.Fprintf(fw, "export %s=%v\n", k, v)

	}


====================
	Expect(err).NotTo(HaveOccurred())

}

// AttachTCPDump returns tcpdump attached to the container

func (f *Felix) AttachTCPDump(iface string) *tcpdump.TCPDump {

	return tcpdump.Attach(f.Container.Name, "", iface)

}

func (f *Felix) ProgramIptablesDNAT(serviceIP, targetIP, chain string) {

	f.Exec(

		"iptables",

		"-w", "10", // Retry this for 10 seconds, e.g. if something else is holding the lock

		"-W", "100000", // How often to probe the lock in microsecs.

		"-t", "nat", "-A", chain,

		"--destination", serviceIP,

		"-j", "DNAT", "--to-destination", targetIP,

	)

}

type BPFIfState struct {

	IfIndex  int

	Workload bool

	Ready    bool


====================
}

// AttachTCPDump returns tcpdump attached to the container

func (f *Felix) AttachTCPDump(iface string) *tcpdump.TCPDump {

	return tcpdump.Attach(f.Container.Name, "", iface)

}

func (f *Felix) ProgramIptablesDNAT(serviceIP, targetIP, chain string) {

	f.Exec(

		"iptables",

		"-w", "10", // Retry this for 10 seconds, e.g. if something else is holding the lock

		"-W", "100000", // How often to probe the lock in microsecs.

		"-t", "nat", "-A", chain,

		"--destination", serviceIP,

		"-j", "DNAT", "--to-destination", targetIP,

	)

}

type BPFIfState struct {

	IfIndex  int

	Workload bool

	Ready    bool

}


====================
// AttachTCPDump returns tcpdump attached to the container

func (f *Felix) AttachTCPDump(iface string) *tcpdump.TCPDump {

	return tcpdump.Attach(f.Container.Name, "", iface)

}

func (f *Felix) ProgramIptablesDNAT(serviceIP, targetIP, chain string) {

	f.Exec(

		"iptables",

		"-w", "10", // Retry this for 10 seconds, e.g. if something else is holding the lock

		"-W", "100000", // How often to probe the lock in microsecs.

		"-t", "nat", "-A", chain,

		"--destination", serviceIP,

		"-j", "DNAT", "--to-destination", targetIP,

	)

}

type BPFIfState struct {

	IfIndex  int

	Workload bool

	Ready    bool

}

var bpfIfStateRegexp = regexp.MustCompile(`.*([0-9]+) : \{flags: (.*) name: (.*)\}`)


====================
func (f *Felix) AttachTCPDump(iface string) *tcpdump.TCPDump {

	return tcpdump.Attach(f.Container.Name, "", iface)

}

func (f *Felix) ProgramIptablesDNAT(serviceIP, targetIP, chain string) {

	f.Exec(

		"iptables",

		"-w", "10", // Retry this for 10 seconds, e.g. if something else is holding the lock

		"-W", "100000", // How often to probe the lock in microsecs.

		"-t", "nat", "-A", chain,

		"--destination", serviceIP,

		"-j", "DNAT", "--to-destination", targetIP,

	)

}

type BPFIfState struct {

	IfIndex  int

	Workload bool

	Ready    bool

}

var bpfIfStateRegexp = regexp.MustCompile(`.*([0-9]+) : \{flags: (.*) name: (.*)\}`)

func (f *Felix) BPFIfState() map[string]BPFIfState {


====================
	return tcpdump.Attach(f.Container.Name, "", iface)

}

func (f *Felix) ProgramIptablesDNAT(serviceIP, targetIP, chain string) {

	f.Exec(

		"iptables",

		"-w", "10", // Retry this for 10 seconds, e.g. if something else is holding the lock

		"-W", "100000", // How often to probe the lock in microsecs.

		"-t", "nat", "-A", chain,

		"--destination", serviceIP,

		"-j", "DNAT", "--to-destination", targetIP,

	)

}

type BPFIfState struct {

	IfIndex  int

	Workload bool

	Ready    bool

}

var bpfIfStateRegexp = regexp.MustCompile(`.*([0-9]+) : \{flags: (.*) name: (.*)\}`)

func (f *Felix) BPFIfState() map[string]BPFIfState {

	out, err := f.ExecOutput("calico-bpf", "ifstate", "dump")


====================
	return f.GetSinglePID("calico-typha")

}

func (f *Typha) GetTyphaPIDs() []int {

	return f.GetPIDs("calico-typha")

}

func RunTypha(infra DatastoreInfra, options TopologyOptions) *Typha {

	log.Info("Starting typha")

	args := infra.GetDockerArgs()

	args = append(args,

		"--privileged",

		"-e", "TYPHA_LOGSEVERITYSCREEN="+options.TyphaLogSeverity,

		"-e", "TYPHA_PROMETHEUSMETRICSENABLED=true",

	)

	if options.WithFelixTyphaTLS {

		EnsureTLSCredentials()

		args = append(args, "-v", CertDir+":"+CertDir)

	}

	if options.WithFelixTyphaTLS {

		args = append(args,

			"-e", "TYPHA_CAFILE="+filepath.Join(CertDir, "ca.crt"),


====================
}

func (f *Typha) GetTyphaPIDs() []int {

	return f.GetPIDs("calico-typha")

}

func RunTypha(infra DatastoreInfra, options TopologyOptions) *Typha {

	log.Info("Starting typha")

	args := infra.GetDockerArgs()

	args = append(args,

		"--privileged",

		"-e", "TYPHA_LOGSEVERITYSCREEN="+options.TyphaLogSeverity,

		"-e", "TYPHA_PROMETHEUSMETRICSENABLED=true",

	)

	if options.WithFelixTyphaTLS {

		EnsureTLSCredentials()

		args = append(args, "-v", CertDir+":"+CertDir)

	}

	if options.WithFelixTyphaTLS {

		args = append(args,

			"-e", "TYPHA_CAFILE="+filepath.Join(CertDir, "ca.crt"),

			"-e", "TYPHA_SERVERKEYFILE="+filepath.Join(CertDir, "server.key"),


====================
func (f *Typha) GetTyphaPIDs() []int {

	return f.GetPIDs("calico-typha")

}

func RunTypha(infra DatastoreInfra, options TopologyOptions) *Typha {

	log.Info("Starting typha")

	args := infra.GetDockerArgs()

	args = append(args,

		"--privileged",

		"-e", "TYPHA_LOGSEVERITYSCREEN="+options.TyphaLogSeverity,

		"-e", "TYPHA_PROMETHEUSMETRICSENABLED=true",

	)

	if options.WithFelixTyphaTLS {

		EnsureTLSCredentials()

		args = append(args, "-v", CertDir+":"+CertDir)

	}

	if options.WithFelixTyphaTLS {

		args = append(args,

			"-e", "TYPHA_CAFILE="+filepath.Join(CertDir, "ca.crt"),

			"-e", "TYPHA_SERVERKEYFILE="+filepath.Join(CertDir, "server.key"),

			"-e", "TYPHA_SERVERCERTFILE="+filepath.Join(CertDir, "server.crt"),


====================
	log.Info("Starting typha")

	args := infra.GetDockerArgs()

	args = append(args,

		"--privileged",

		"-e", "TYPHA_LOGSEVERITYSCREEN="+options.TyphaLogSeverity,

		"-e", "TYPHA_PROMETHEUSMETRICSENABLED=true",

	)

	if options.WithFelixTyphaTLS {

		EnsureTLSCredentials()

		args = append(args, "-v", CertDir+":"+CertDir)

	}

	if options.WithFelixTyphaTLS {

		args = append(args,

			"-e", "TYPHA_CAFILE="+filepath.Join(CertDir, "ca.crt"),

			"-e", "TYPHA_SERVERKEYFILE="+filepath.Join(CertDir, "server.key"),

			"-e", "TYPHA_SERVERCERTFILE="+filepath.Join(CertDir, "server.crt"),

			"-e", "TYPHA_CLIENTCN=typha-client",

		)

		options.ExtraEnvVars["FELIX_TYPHACAFILE"] = filepath.Join(CertDir, "ca.crt")

		options.ExtraEnvVars["FELIX_TYPHAKEYFILE"] = filepath.Join(CertDir, "client.key")


====================
		"-e", "TYPHA_LOGSEVERITYSCREEN="+options.TyphaLogSeverity,

		"-e", "TYPHA_PROMETHEUSMETRICSENABLED=true",

	)

	if options.WithFelixTyphaTLS {

		EnsureTLSCredentials()

		args = append(args, "-v", CertDir+":"+CertDir)

	}

	if options.WithFelixTyphaTLS {

		args = append(args,

			"-e", "TYPHA_CAFILE="+filepath.Join(CertDir, "ca.crt"),

			"-e", "TYPHA_SERVERKEYFILE="+filepath.Join(CertDir, "server.key"),

			"-e", "TYPHA_SERVERCERTFILE="+filepath.Join(CertDir, "server.crt"),

			"-e", "TYPHA_CLIENTCN=typha-client",

		)

		options.ExtraEnvVars["FELIX_TYPHACAFILE"] = filepath.Join(CertDir, "ca.crt")

		options.ExtraEnvVars["FELIX_TYPHAKEYFILE"] = filepath.Join(CertDir, "client.key")

		options.ExtraEnvVars["FELIX_TYPHACERTFILE"] = filepath.Join(CertDir, "client.crt")

		options.ExtraEnvVars["FELIX_TYPHACN"] = "typha-server"

		options.ExtraVolumes[CertDir] = CertDir

	}


====================
		"-e", "TYPHA_PROMETHEUSMETRICSENABLED=true",

	)

	if options.WithFelixTyphaTLS {

		EnsureTLSCredentials()

		args = append(args, "-v", CertDir+":"+CertDir)

	}

	if options.WithFelixTyphaTLS {

		args = append(args,

			"-e", "TYPHA_CAFILE="+filepath.Join(CertDir, "ca.crt"),

			"-e", "TYPHA_SERVERKEYFILE="+filepath.Join(CertDir, "server.key"),

			"-e", "TYPHA_SERVERCERTFILE="+filepath.Join(CertDir, "server.crt"),

			"-e", "TYPHA_CLIENTCN=typha-client",

		)

		options.ExtraEnvVars["FELIX_TYPHACAFILE"] = filepath.Join(CertDir, "ca.crt")

		options.ExtraEnvVars["FELIX_TYPHAKEYFILE"] = filepath.Join(CertDir, "client.key")

		options.ExtraEnvVars["FELIX_TYPHACERTFILE"] = filepath.Join(CertDir, "client.crt")

		options.ExtraEnvVars["FELIX_TYPHACN"] = "typha-server"

		options.ExtraVolumes[CertDir] = CertDir

	}

	args = append(args,


====================
	)

	if options.WithFelixTyphaTLS {

		EnsureTLSCredentials()

		args = append(args, "-v", CertDir+":"+CertDir)

	}

	if options.WithFelixTyphaTLS {

		args = append(args,

			"-e", "TYPHA_CAFILE="+filepath.Join(CertDir, "ca.crt"),

			"-e", "TYPHA_SERVERKEYFILE="+filepath.Join(CertDir, "server.key"),

			"-e", "TYPHA_SERVERCERTFILE="+filepath.Join(CertDir, "server.crt"),

			"-e", "TYPHA_CLIENTCN=typha-client",

		)

		options.ExtraEnvVars["FELIX_TYPHACAFILE"] = filepath.Join(CertDir, "ca.crt")

		options.ExtraEnvVars["FELIX_TYPHAKEYFILE"] = filepath.Join(CertDir, "client.key")

		options.ExtraEnvVars["FELIX_TYPHACERTFILE"] = filepath.Join(CertDir, "client.crt")

		options.ExtraEnvVars["FELIX_TYPHACN"] = "typha-server"

		options.ExtraVolumes[CertDir] = CertDir

	}

	args = append(args,

		utils.Config.TyphaImage,


====================
	if options.WithFelixTyphaTLS {

		EnsureTLSCredentials()

		args = append(args, "-v", CertDir+":"+CertDir)

	}

	if options.WithFelixTyphaTLS {

		args = append(args,

			"-e", "TYPHA_CAFILE="+filepath.Join(CertDir, "ca.crt"),

			"-e", "TYPHA_SERVERKEYFILE="+filepath.Join(CertDir, "server.key"),

			"-e", "TYPHA_SERVERCERTFILE="+filepath.Join(CertDir, "server.crt"),

			"-e", "TYPHA_CLIENTCN=typha-client",

		)

		options.ExtraEnvVars["FELIX_TYPHACAFILE"] = filepath.Join(CertDir, "ca.crt")

		options.ExtraEnvVars["FELIX_TYPHAKEYFILE"] = filepath.Join(CertDir, "client.key")

		options.ExtraEnvVars["FELIX_TYPHACERTFILE"] = filepath.Join(CertDir, "client.crt")

		options.ExtraEnvVars["FELIX_TYPHACN"] = "typha-server"

		options.ExtraVolumes[CertDir] = CertDir

	}

	args = append(args,

		utils.Config.TyphaImage,

	)


====================
	clientCert, clientKey := tlsutils.MakePeerCert("typha-client", "", x509.ExtKeyUsageClientAuth, caCert, caKey)

	tlsutils.WriteKey(clientKey, filepath.Join(CertDir, "client.key"))

	tlsutils.WriteCert(clientCert, filepath.Join(CertDir, "client.crt"))

	// Untrusted Typha client.

	clientUntrustedCert, clientUntrustedKey := tlsutils.MakePeerCert("typha-client", "", x509.ExtKeyUsageClientAuth, untrustedCert, untrustedKey)

	tlsutils.WriteKey(clientUntrustedKey, filepath.Join(CertDir, "client-untrusted.key"))

	tlsutils.WriteCert(clientUntrustedCert, filepath.Join(CertDir, "client-untrusted.crt"))

	// Ensure that all users can read these credentials.  (Needed because Typha now

	// runs as non-root.)

	err = exec.Command("chmod", "-R", "a+rx", CertDir).Run()

	tlsutils.PanicIfErr(err)

}

func RemoveTLSCredentials() {

	if CertDir != "" {

		err := os.RemoveAll(CertDir)

		tlsutils.PanicIfErr(err)

	}

}

// Copyright (c) 2018-2021 Tigera, Inc. All rights reserved.

//


====================
}

func (kds *K8sDatastoreInfra) PerTestSetup() {

	// In BPF mode, start BPF logging.

	arch := utils.GetSysArch()

	if os.Getenv("FELIX_FV_ENABLE_BPF") == "true" {

		kds.bpfLog = containers.Run("bpf-log",

			containers.RunOpts{

				AutoRemove:       true,

				IgnoreEmptyLines: true,

			}, "--privileged",

			"calico/bpftool:v5.3-"+arch, "/bpftool", "prog", "tracelog")

	}

	K8sInfra.runningTest = ginkgo.CurrentGinkgoTestDescription().FullTestText

}

func runK8sApiserver(etcdIp string) *containers.Container {

	return containers.Run("apiserver",

		containers.RunOpts{

			AutoRemove: true,

			StopSignal: "SIGKILL",

		},


====================
	}

	K8sInfra.runningTest = ginkgo.CurrentGinkgoTestDescription().FullTestText

}

func runK8sApiserver(etcdIp string) *containers.Container {

	return containers.Run("apiserver",

		containers.RunOpts{

			AutoRemove: true,

			StopSignal: "SIGKILL",

		},

		"-v", os.Getenv("CERTS_PATH")+":/home/user/certs", // Mount in location of certificates.

		utils.Config.K8sImage,

		"kube-apiserver",

		"--v=0",

		"--service-cluster-ip-range=10.101.0.0/16",

		"--authorization-mode=RBAC",

		fmt.Sprintf("--etcd-servers=http://%s:2379", etcdIp),

		"--service-account-key-file=/home/user/certs/service-account.pem",

		"--service-account-signing-key-file=/home/user/certs/service-account-key.pem",

		"--service-account-issuer=https://localhost:443",

		"--api-audiences=kubernetes.default",


====================
func runK8sApiserver(etcdIp string) *containers.Container {

	return containers.Run("apiserver",

		containers.RunOpts{

			AutoRemove: true,

			StopSignal: "SIGKILL",

		},

		"-v", os.Getenv("CERTS_PATH")+":/home/user/certs", // Mount in location of certificates.

		utils.Config.K8sImage,

		"kube-apiserver",

		"--v=0",

		"--service-cluster-ip-range=10.101.0.0/16",

		"--authorization-mode=RBAC",

		fmt.Sprintf("--etcd-servers=http://%s:2379", etcdIp),

		"--service-account-key-file=/home/user/certs/service-account.pem",

		"--service-account-signing-key-file=/home/user/certs/service-account-key.pem",

		"--service-account-issuer=https://localhost:443",

		"--api-audiences=kubernetes.default",

		"--client-ca-file=/home/user/certs/ca.pem",

		"--tls-cert-file=/home/user/certs/kubernetes.pem",

		"--tls-private-key-file=/home/user/certs/kubernetes-key.pem",


====================
	return containers.Run("apiserver",

		containers.RunOpts{

			AutoRemove: true,

			StopSignal: "SIGKILL",

		},

		"-v", os.Getenv("CERTS_PATH")+":/home/user/certs", // Mount in location of certificates.

		utils.Config.K8sImage,

		"kube-apiserver",

		"--v=0",

		"--service-cluster-ip-range=10.101.0.0/16",

		"--authorization-mode=RBAC",

		fmt.Sprintf("--etcd-servers=http://%s:2379", etcdIp),

		"--service-account-key-file=/home/user/certs/service-account.pem",

		"--service-account-signing-key-file=/home/user/certs/service-account-key.pem",

		"--service-account-issuer=https://localhost:443",

		"--api-audiences=kubernetes.default",

		"--client-ca-file=/home/user/certs/ca.pem",

		"--tls-cert-file=/home/user/certs/kubernetes.pem",

		"--tls-private-key-file=/home/user/certs/kubernetes-key.pem",

		"--enable-priority-and-fairness=false",


====================
		containers.RunOpts{

			AutoRemove: true,

			StopSignal: "SIGKILL",

		},

		"-v", os.Getenv("CERTS_PATH")+":/home/user/certs", // Mount in location of certificates.

		utils.Config.K8sImage,

		"kube-apiserver",

		"--v=0",

		"--service-cluster-ip-range=10.101.0.0/16",

		"--authorization-mode=RBAC",

		fmt.Sprintf("--etcd-servers=http://%s:2379", etcdIp),

		"--service-account-key-file=/home/user/certs/service-account.pem",

		"--service-account-signing-key-file=/home/user/certs/service-account-key.pem",

		"--service-account-issuer=https://localhost:443",

		"--api-audiences=kubernetes.default",

		"--client-ca-file=/home/user/certs/ca.pem",

		"--tls-cert-file=/home/user/certs/kubernetes.pem",

		"--tls-private-key-file=/home/user/certs/kubernetes-key.pem",

		"--enable-priority-and-fairness=false",

		"--max-mutating-requests-inflight=0",


====================
			AutoRemove: true,

			StopSignal: "SIGKILL",

		},

		"-v", os.Getenv("CERTS_PATH")+":/home/user/certs", // Mount in location of certificates.

		utils.Config.K8sImage,

		"kube-apiserver",

		"--v=0",

		"--service-cluster-ip-range=10.101.0.0/16",

		"--authorization-mode=RBAC",

		fmt.Sprintf("--etcd-servers=http://%s:2379", etcdIp),

		"--service-account-key-file=/home/user/certs/service-account.pem",

		"--service-account-signing-key-file=/home/user/certs/service-account-key.pem",

		"--service-account-issuer=https://localhost:443",

		"--api-audiences=kubernetes.default",

		"--client-ca-file=/home/user/certs/ca.pem",

		"--tls-cert-file=/home/user/certs/kubernetes.pem",

		"--tls-private-key-file=/home/user/certs/kubernetes-key.pem",

		"--enable-priority-and-fairness=false",

		"--max-mutating-requests-inflight=0",

		"--max-requests-inflight=0",


====================
			StopSignal: "SIGKILL",

		},

		"-v", os.Getenv("CERTS_PATH")+":/home/user/certs", // Mount in location of certificates.

		utils.Config.K8sImage,

		"kube-apiserver",

		"--v=0",

		"--service-cluster-ip-range=10.101.0.0/16",

		"--authorization-mode=RBAC",

		fmt.Sprintf("--etcd-servers=http://%s:2379", etcdIp),

		"--service-account-key-file=/home/user/certs/service-account.pem",

		"--service-account-signing-key-file=/home/user/certs/service-account-key.pem",

		"--service-account-issuer=https://localhost:443",

		"--api-audiences=kubernetes.default",

		"--client-ca-file=/home/user/certs/ca.pem",

		"--tls-cert-file=/home/user/certs/kubernetes.pem",

		"--tls-private-key-file=/home/user/certs/kubernetes-key.pem",

		"--enable-priority-and-fairness=false",

		"--max-mutating-requests-inflight=0",

		"--max-requests-inflight=0",

	)


====================
		},

		"-v", os.Getenv("CERTS_PATH")+":/home/user/certs", // Mount in location of certificates.

		utils.Config.K8sImage,

		"kube-apiserver",

		"--v=0",

		"--service-cluster-ip-range=10.101.0.0/16",

		"--authorization-mode=RBAC",

		fmt.Sprintf("--etcd-servers=http://%s:2379", etcdIp),

		"--service-account-key-file=/home/user/certs/service-account.pem",

		"--service-account-signing-key-file=/home/user/certs/service-account-key.pem",

		"--service-account-issuer=https://localhost:443",

		"--api-audiences=kubernetes.default",

		"--client-ca-file=/home/user/certs/ca.pem",

		"--tls-cert-file=/home/user/certs/kubernetes.pem",

		"--tls-private-key-file=/home/user/certs/kubernetes-key.pem",

		"--enable-priority-and-fairness=false",

		"--max-mutating-requests-inflight=0",

		"--max-requests-inflight=0",

	)

}


====================
		"-v", os.Getenv("CERTS_PATH")+":/home/user/certs", // Mount in location of certificates.

		utils.Config.K8sImage,

		"kube-apiserver",

		"--v=0",

		"--service-cluster-ip-range=10.101.0.0/16",

		"--authorization-mode=RBAC",

		fmt.Sprintf("--etcd-servers=http://%s:2379", etcdIp),

		"--service-account-key-file=/home/user/certs/service-account.pem",

		"--service-account-signing-key-file=/home/user/certs/service-account-key.pem",

		"--service-account-issuer=https://localhost:443",

		"--api-audiences=kubernetes.default",

		"--client-ca-file=/home/user/certs/ca.pem",

		"--tls-cert-file=/home/user/certs/kubernetes.pem",

		"--tls-private-key-file=/home/user/certs/kubernetes-key.pem",

		"--enable-priority-and-fairness=false",

		"--max-mutating-requests-inflight=0",

		"--max-requests-inflight=0",

	)

}

func runK8sControllerManager(apiserverIp string) *containers.Container {


====================
		utils.Config.K8sImage,

		"kube-apiserver",

		"--v=0",

		"--service-cluster-ip-range=10.101.0.0/16",

		"--authorization-mode=RBAC",

		fmt.Sprintf("--etcd-servers=http://%s:2379", etcdIp),

		"--service-account-key-file=/home/user/certs/service-account.pem",

		"--service-account-signing-key-file=/home/user/certs/service-account-key.pem",

		"--service-account-issuer=https://localhost:443",

		"--api-audiences=kubernetes.default",

		"--client-ca-file=/home/user/certs/ca.pem",

		"--tls-cert-file=/home/user/certs/kubernetes.pem",

		"--tls-private-key-file=/home/user/certs/kubernetes-key.pem",

		"--enable-priority-and-fairness=false",

		"--max-mutating-requests-inflight=0",

		"--max-requests-inflight=0",

	)

}

func runK8sControllerManager(apiserverIp string) *containers.Container {

	c := containers.Run("controller-manager",


====================
		"kube-apiserver",

		"--v=0",

		"--service-cluster-ip-range=10.101.0.0/16",

		"--authorization-mode=RBAC",

		fmt.Sprintf("--etcd-servers=http://%s:2379", etcdIp),

		"--service-account-key-file=/home/user/certs/service-account.pem",

		"--service-account-signing-key-file=/home/user/certs/service-account-key.pem",

		"--service-account-issuer=https://localhost:443",

		"--api-audiences=kubernetes.default",

		"--client-ca-file=/home/user/certs/ca.pem",

		"--tls-cert-file=/home/user/certs/kubernetes.pem",

		"--tls-private-key-file=/home/user/certs/kubernetes-key.pem",

		"--enable-priority-and-fairness=false",

		"--max-mutating-requests-inflight=0",

		"--max-requests-inflight=0",

	)

}

func runK8sControllerManager(apiserverIp string) *containers.Container {

	c := containers.Run("controller-manager",

		containers.RunOpts{


====================
		"--v=0",

		"--service-cluster-ip-range=10.101.0.0/16",

		"--authorization-mode=RBAC",

		fmt.Sprintf("--etcd-servers=http://%s:2379", etcdIp),

		"--service-account-key-file=/home/user/certs/service-account.pem",

		"--service-account-signing-key-file=/home/user/certs/service-account-key.pem",

		"--service-account-issuer=https://localhost:443",

		"--api-audiences=kubernetes.default",

		"--client-ca-file=/home/user/certs/ca.pem",

		"--tls-cert-file=/home/user/certs/kubernetes.pem",

		"--tls-private-key-file=/home/user/certs/kubernetes-key.pem",

		"--enable-priority-and-fairness=false",

		"--max-mutating-requests-inflight=0",

		"--max-requests-inflight=0",

	)

}

func runK8sControllerManager(apiserverIp string) *containers.Container {

	c := containers.Run("controller-manager",

		containers.RunOpts{

			AutoRemove: true,


====================
		"--service-cluster-ip-range=10.101.0.0/16",

		"--authorization-mode=RBAC",

		fmt.Sprintf("--etcd-servers=http://%s:2379", etcdIp),

		"--service-account-key-file=/home/user/certs/service-account.pem",

		"--service-account-signing-key-file=/home/user/certs/service-account-key.pem",

		"--service-account-issuer=https://localhost:443",

		"--api-audiences=kubernetes.default",

		"--client-ca-file=/home/user/certs/ca.pem",

		"--tls-cert-file=/home/user/certs/kubernetes.pem",

		"--tls-private-key-file=/home/user/certs/kubernetes-key.pem",

		"--enable-priority-and-fairness=false",

		"--max-mutating-requests-inflight=0",

		"--max-requests-inflight=0",

	)

}

func runK8sControllerManager(apiserverIp string) *containers.Container {

	c := containers.Run("controller-manager",

		containers.RunOpts{

			AutoRemove: true,

			StopSignal: "SIGKILL",


====================
		"--authorization-mode=RBAC",

		fmt.Sprintf("--etcd-servers=http://%s:2379", etcdIp),

		"--service-account-key-file=/home/user/certs/service-account.pem",

		"--service-account-signing-key-file=/home/user/certs/service-account-key.pem",

		"--service-account-issuer=https://localhost:443",

		"--api-audiences=kubernetes.default",

		"--client-ca-file=/home/user/certs/ca.pem",

		"--tls-cert-file=/home/user/certs/kubernetes.pem",

		"--tls-private-key-file=/home/user/certs/kubernetes-key.pem",

		"--enable-priority-and-fairness=false",

		"--max-mutating-requests-inflight=0",

		"--max-requests-inflight=0",

	)

}

func runK8sControllerManager(apiserverIp string) *containers.Container {

	c := containers.Run("controller-manager",

		containers.RunOpts{

			AutoRemove: true,

			StopSignal: "SIGKILL",

		},


====================
		fmt.Sprintf("--etcd-servers=http://%s:2379", etcdIp),

		"--service-account-key-file=/home/user/certs/service-account.pem",

		"--service-account-signing-key-file=/home/user/certs/service-account-key.pem",

		"--service-account-issuer=https://localhost:443",

		"--api-audiences=kubernetes.default",

		"--client-ca-file=/home/user/certs/ca.pem",

		"--tls-cert-file=/home/user/certs/kubernetes.pem",

		"--tls-private-key-file=/home/user/certs/kubernetes-key.pem",

		"--enable-priority-and-fairness=false",

		"--max-mutating-requests-inflight=0",

		"--max-requests-inflight=0",

	)

}

func runK8sControllerManager(apiserverIp string) *containers.Container {

	c := containers.Run("controller-manager",

		containers.RunOpts{

			AutoRemove: true,

			StopSignal: "SIGKILL",

		},

		"-v", os.Getenv("CERTS_PATH")+"/:/home/user/certs", // Mount in location of certificates.


====================
		"--service-account-key-file=/home/user/certs/service-account.pem",

		"--service-account-signing-key-file=/home/user/certs/service-account-key.pem",

		"--service-account-issuer=https://localhost:443",

		"--api-audiences=kubernetes.default",

		"--client-ca-file=/home/user/certs/ca.pem",

		"--tls-cert-file=/home/user/certs/kubernetes.pem",

		"--tls-private-key-file=/home/user/certs/kubernetes-key.pem",

		"--enable-priority-and-fairness=false",

		"--max-mutating-requests-inflight=0",

		"--max-requests-inflight=0",

	)

}

func runK8sControllerManager(apiserverIp string) *containers.Container {

	c := containers.Run("controller-manager",

		containers.RunOpts{

			AutoRemove: true,

			StopSignal: "SIGKILL",

		},

		"-v", os.Getenv("CERTS_PATH")+"/:/home/user/certs", // Mount in location of certificates.

		utils.Config.K8sImage,


====================
		"--max-requests-inflight=0",

	)

}

func runK8sControllerManager(apiserverIp string) *containers.Container {

	c := containers.Run("controller-manager",

		containers.RunOpts{

			AutoRemove: true,

			StopSignal: "SIGKILL",

		},

		"-v", os.Getenv("CERTS_PATH")+"/:/home/user/certs", // Mount in location of certificates.

		utils.Config.K8sImage,

		"kube-controller-manager",

		fmt.Sprintf("--master=https://%v:6443", apiserverIp),

		"--kubeconfig=/home/user/certs/kube-controller-manager.kubeconfig",

		// We run trivially small clusters, so increase the QPS to get the

		// cluster to start up as fast as possible.

		"--kube-api-qps=100",

		"--kube-api-burst=200",

		"--min-resync-period=3m",

		// Disable node CIDRs since the controller manager stalls for 10s if


====================
func runK8sControllerManager(apiserverIp string) *containers.Container {

	c := containers.Run("controller-manager",

		containers.RunOpts{

			AutoRemove: true,

			StopSignal: "SIGKILL",

		},

		"-v", os.Getenv("CERTS_PATH")+"/:/home/user/certs", // Mount in location of certificates.

		utils.Config.K8sImage,

		"kube-controller-manager",

		fmt.Sprintf("--master=https://%v:6443", apiserverIp),

		"--kubeconfig=/home/user/certs/kube-controller-manager.kubeconfig",

		// We run trivially small clusters, so increase the QPS to get the

		// cluster to start up as fast as possible.

		"--kube-api-qps=100",

		"--kube-api-burst=200",

		"--min-resync-period=3m",

		// Disable node CIDRs since the controller manager stalls for 10s if

		// they are enabled.

		"--allocate-node-cidrs=false",

		"--leader-elect=false",


====================
	c := containers.Run("controller-manager",

		containers.RunOpts{

			AutoRemove: true,

			StopSignal: "SIGKILL",

		},

		"-v", os.Getenv("CERTS_PATH")+"/:/home/user/certs", // Mount in location of certificates.

		utils.Config.K8sImage,

		"kube-controller-manager",

		fmt.Sprintf("--master=https://%v:6443", apiserverIp),

		"--kubeconfig=/home/user/certs/kube-controller-manager.kubeconfig",

		// We run trivially small clusters, so increase the QPS to get the

		// cluster to start up as fast as possible.

		"--kube-api-qps=100",

		"--kube-api-burst=200",

		"--min-resync-period=3m",

		// Disable node CIDRs since the controller manager stalls for 10s if

		// they are enabled.

		"--allocate-node-cidrs=false",

		"--leader-elect=false",

		"--v=0",


====================
			StopSignal: "SIGKILL",

		},

		"-v", os.Getenv("CERTS_PATH")+"/:/home/user/certs", // Mount in location of certificates.

		utils.Config.K8sImage,

		"kube-controller-manager",

		fmt.Sprintf("--master=https://%v:6443", apiserverIp),

		"--kubeconfig=/home/user/certs/kube-controller-manager.kubeconfig",

		// We run trivially small clusters, so increase the QPS to get the

		// cluster to start up as fast as possible.

		"--kube-api-qps=100",

		"--kube-api-burst=200",

		"--min-resync-period=3m",

		// Disable node CIDRs since the controller manager stalls for 10s if

		// they are enabled.

		"--allocate-node-cidrs=false",

		"--leader-elect=false",

		"--v=0",

		"--service-account-private-key-file=/home/user/certs/service-account-key.pem",

		"--root-ca-file=/home/user/certs/ca.pem",

		"--concurrent-gc-syncs=50",


====================
		},

		"-v", os.Getenv("CERTS_PATH")+"/:/home/user/certs", // Mount in location of certificates.

		utils.Config.K8sImage,

		"kube-controller-manager",

		fmt.Sprintf("--master=https://%v:6443", apiserverIp),

		"--kubeconfig=/home/user/certs/kube-controller-manager.kubeconfig",

		// We run trivially small clusters, so increase the QPS to get the

		// cluster to start up as fast as possible.

		"--kube-api-qps=100",

		"--kube-api-burst=200",

		"--min-resync-period=3m",

		// Disable node CIDRs since the controller manager stalls for 10s if

		// they are enabled.

		"--allocate-node-cidrs=false",

		"--leader-elect=false",

		"--v=0",

		"--service-account-private-key-file=/home/user/certs/service-account-key.pem",

		"--root-ca-file=/home/user/certs/ca.pem",

		"--concurrent-gc-syncs=50",

	)


====================
		"-v", os.Getenv("CERTS_PATH")+"/:/home/user/certs", // Mount in location of certificates.

		utils.Config.K8sImage,

		"kube-controller-manager",

		fmt.Sprintf("--master=https://%v:6443", apiserverIp),

		"--kubeconfig=/home/user/certs/kube-controller-manager.kubeconfig",

		// We run trivially small clusters, so increase the QPS to get the

		// cluster to start up as fast as possible.

		"--kube-api-qps=100",

		"--kube-api-burst=200",

		"--min-resync-period=3m",

		// Disable node CIDRs since the controller manager stalls for 10s if

		// they are enabled.

		"--allocate-node-cidrs=false",

		"--leader-elect=false",

		"--v=0",

		"--service-account-private-key-file=/home/user/certs/service-account-key.pem",

		"--root-ca-file=/home/user/certs/ca.pem",

		"--concurrent-gc-syncs=50",

	)

	return c


====================
		fmt.Sprintf("--master=https://%v:6443", apiserverIp),

		"--kubeconfig=/home/user/certs/kube-controller-manager.kubeconfig",

		// We run trivially small clusters, so increase the QPS to get the

		// cluster to start up as fast as possible.

		"--kube-api-qps=100",

		"--kube-api-burst=200",

		"--min-resync-period=3m",

		// Disable node CIDRs since the controller manager stalls for 10s if

		// they are enabled.

		"--allocate-node-cidrs=false",

		"--leader-elect=false",

		"--v=0",

		"--service-account-private-key-file=/home/user/certs/service-account-key.pem",

		"--root-ca-file=/home/user/certs/ca.pem",

		"--concurrent-gc-syncs=50",

	)

	return c

}

func setupK8sDatastoreInfra() (*K8sDatastoreInfra, error) {

	log.Info("Starting Kubernetes infrastructure")


====================
		"--kubeconfig=/home/user/certs/kube-controller-manager.kubeconfig",

		// We run trivially small clusters, so increase the QPS to get the

		// cluster to start up as fast as possible.

		"--kube-api-qps=100",

		"--kube-api-burst=200",

		"--min-resync-period=3m",

		// Disable node CIDRs since the controller manager stalls for 10s if

		// they are enabled.

		"--allocate-node-cidrs=false",

		"--leader-elect=false",

		"--v=0",

		"--service-account-private-key-file=/home/user/certs/service-account-key.pem",

		"--root-ca-file=/home/user/certs/ca.pem",

		"--concurrent-gc-syncs=50",

	)

	return c

}

func setupK8sDatastoreInfra() (*K8sDatastoreInfra, error) {

	log.Info("Starting Kubernetes infrastructure")

	log.Info("Starting etcd")


====================
		// We run trivially small clusters, so increase the QPS to get the

		// cluster to start up as fast as possible.

		"--kube-api-qps=100",

		"--kube-api-burst=200",

		"--min-resync-period=3m",

		// Disable node CIDRs since the controller manager stalls for 10s if

		// they are enabled.

		"--allocate-node-cidrs=false",

		"--leader-elect=false",

		"--v=0",

		"--service-account-private-key-file=/home/user/certs/service-account-key.pem",

		"--root-ca-file=/home/user/certs/ca.pem",

		"--concurrent-gc-syncs=50",

	)

	return c

}

func setupK8sDatastoreInfra() (*K8sDatastoreInfra, error) {

	log.Info("Starting Kubernetes infrastructure")

	log.Info("Starting etcd")

	kds := &K8sDatastoreInfra{}


====================
		// cluster to start up as fast as possible.

		"--kube-api-qps=100",

		"--kube-api-burst=200",

		"--min-resync-period=3m",

		// Disable node CIDRs since the controller manager stalls for 10s if

		// they are enabled.

		"--allocate-node-cidrs=false",

		"--leader-elect=false",

		"--v=0",

		"--service-account-private-key-file=/home/user/certs/service-account-key.pem",

		"--root-ca-file=/home/user/certs/ca.pem",

		"--concurrent-gc-syncs=50",

	)

	return c

}

func setupK8sDatastoreInfra() (*K8sDatastoreInfra, error) {

	log.Info("Starting Kubernetes infrastructure")

	log.Info("Starting etcd")

	kds := &K8sDatastoreInfra{}

	// Start etcd, which will back the k8s API server.


====================
		"--kube-api-qps=100",

		"--kube-api-burst=200",

		"--min-resync-period=3m",

		// Disable node CIDRs since the controller manager stalls for 10s if

		// they are enabled.

		"--allocate-node-cidrs=false",

		"--leader-elect=false",

		"--v=0",

		"--service-account-private-key-file=/home/user/certs/service-account-key.pem",

		"--root-ca-file=/home/user/certs/ca.pem",

		"--concurrent-gc-syncs=50",

	)

	return c

}

func setupK8sDatastoreInfra() (*K8sDatastoreInfra, error) {

	log.Info("Starting Kubernetes infrastructure")

	log.Info("Starting etcd")

	kds := &K8sDatastoreInfra{}

	// Start etcd, which will back the k8s API server.

	kds.etcdContainer = RunEtcd()


====================
		"--kube-api-burst=200",

		"--min-resync-period=3m",

		// Disable node CIDRs since the controller manager stalls for 10s if

		// they are enabled.

		"--allocate-node-cidrs=false",

		"--leader-elect=false",

		"--v=0",

		"--service-account-private-key-file=/home/user/certs/service-account-key.pem",

		"--root-ca-file=/home/user/certs/ca.pem",

		"--concurrent-gc-syncs=50",

	)

	return c

}

func setupK8sDatastoreInfra() (*K8sDatastoreInfra, error) {

	log.Info("Starting Kubernetes infrastructure")

	log.Info("Starting etcd")

	kds := &K8sDatastoreInfra{}

	// Start etcd, which will back the k8s API server.

	kds.etcdContainer = RunEtcd()

	if kds.etcdContainer == nil {


====================
	}

	log.Info("Got k8s client")

	// Allow anonymous connections to the API server.  We also use this command to wait

	// for the API server to be up.

	start = time.Now()

	for {

		err := kds.k8sApiContainer.ExecMayFail(

			"kubectl", "create", "clusterrolebinding",

			"anonymous-admin",

			"--insecure-skip-tls-verify=true",

			"--client-key=/home/user/certs/admin-key.pem",

			"--client-certificate=/home/user/certs/admin.pem",

			fmt.Sprintf("--server=https://%s:6443", kds.k8sApiContainer.IP),

			"--clusterrole=cluster-admin",

			"--user=system:anonymous",

		)

		if err == nil {

			break

		}

		if strings.Contains(err.Error(), "already exists") {


====================
	log.Info("Got k8s client")

	// Allow anonymous connections to the API server.  We also use this command to wait

	// for the API server to be up.

	start = time.Now()

	for {

		err := kds.k8sApiContainer.ExecMayFail(

			"kubectl", "create", "clusterrolebinding",

			"anonymous-admin",

			"--insecure-skip-tls-verify=true",

			"--client-key=/home/user/certs/admin-key.pem",

			"--client-certificate=/home/user/certs/admin.pem",

			fmt.Sprintf("--server=https://%s:6443", kds.k8sApiContainer.IP),

			"--clusterrole=cluster-admin",

			"--user=system:anonymous",

		)

		if err == nil {

			break

		}

		if strings.Contains(err.Error(), "already exists") {

			// Sometimes hit an "already exists" error here; I suspect the account we create is


====================
	// Allow anonymous connections to the API server.  We also use this command to wait

	// for the API server to be up.

	start = time.Now()

	for {

		err := kds.k8sApiContainer.ExecMayFail(

			"kubectl", "create", "clusterrolebinding",

			"anonymous-admin",

			"--insecure-skip-tls-verify=true",

			"--client-key=/home/user/certs/admin-key.pem",

			"--client-certificate=/home/user/certs/admin.pem",

			fmt.Sprintf("--server=https://%s:6443", kds.k8sApiContainer.IP),

			"--clusterrole=cluster-admin",

			"--user=system:anonymous",

		)

		if err == nil {

			break

		}

		if strings.Contains(err.Error(), "already exists") {

			// Sometimes hit an "already exists" error here; I suspect the account we create is

			// also added by the controller manager.  It doesn't matter who wins.


====================
	// for the API server to be up.

	start = time.Now()

	for {

		err := kds.k8sApiContainer.ExecMayFail(

			"kubectl", "create", "clusterrolebinding",

			"anonymous-admin",

			"--insecure-skip-tls-verify=true",

			"--client-key=/home/user/certs/admin-key.pem",

			"--client-certificate=/home/user/certs/admin.pem",

			fmt.Sprintf("--server=https://%s:6443", kds.k8sApiContainer.IP),

			"--clusterrole=cluster-admin",

			"--user=system:anonymous",

		)

		if err == nil {

			break

		}

		if strings.Contains(err.Error(), "already exists") {

			// Sometimes hit an "already exists" error here; I suspect the account we create is

			// also added by the controller manager.  It doesn't matter who wins.

			break


====================
	start = time.Now()

	for {

		err := kds.k8sApiContainer.ExecMayFail(

			"kubectl", "create", "clusterrolebinding",

			"anonymous-admin",

			"--insecure-skip-tls-verify=true",

			"--client-key=/home/user/certs/admin-key.pem",

			"--client-certificate=/home/user/certs/admin.pem",

			fmt.Sprintf("--server=https://%s:6443", kds.k8sApiContainer.IP),

			"--clusterrole=cluster-admin",

			"--user=system:anonymous",

		)

		if err == nil {

			break

		}

		if strings.Contains(err.Error(), "already exists") {

			// Sometimes hit an "already exists" error here; I suspect the account we create is

			// also added by the controller manager.  It doesn't matter who wins.

			break

		}


====================
	for {

		err := kds.k8sApiContainer.ExecMayFail(

			"kubectl", "create", "clusterrolebinding",

			"anonymous-admin",

			"--insecure-skip-tls-verify=true",

			"--client-key=/home/user/certs/admin-key.pem",

			"--client-certificate=/home/user/certs/admin.pem",

			fmt.Sprintf("--server=https://%s:6443", kds.k8sApiContainer.IP),

			"--clusterrole=cluster-admin",

			"--user=system:anonymous",

		)

		if err == nil {

			break

		}

		if strings.Contains(err.Error(), "already exists") {

			// Sometimes hit an "already exists" error here; I suspect the account we create is

			// also added by the controller manager.  It doesn't matter who wins.

			break

		}

		if time.Since(start) > 90*time.Second {


====================
		return nil, errors.New("failed to create k8s controller manager container")

	}

	log.Info("Started controller manager.")

	// Copy CRD registration manifests into the API server container, and apply it.

	err := kds.k8sApiContainer.CopyFileIntoContainer("../../libcalico-go/config/crd", "/crds")

	if err != nil {

		TearDownK8sInfra(kds)

		return nil, err

	}

	err = kds.k8sApiContainer.ExecMayFail("kubectl", "--kubeconfig=/home/user/certs/kubeconfig", "apply", "-f", "/crds/")

	if err != nil {

		TearDownK8sInfra(kds)

		return nil, err

	}

	kds.EndpointIP = kds.k8sApiContainer.IP

	kds.Endpoint = fmt.Sprintf("https://%s:6443", kds.k8sApiContainer.IP)

	kds.BadEndpoint = fmt.Sprintf("https://%s:1234", kds.k8sApiContainer.IP)

	start = time.Now()

	for {

		var resp *http.Response


====================
				if _, err = c.DeleteKVP(context.Background(), r); err != nil {

					log.WithError(err).WithField("Key", r.Key).Warning("Failed to delete entry from KDD")

				}

			}

		}

	}

}

func (kds *K8sDatastoreInfra) GetDockerArgs() []string {

	return []string{

		"-e", "CALICO_DATASTORE_TYPE=kubernetes",

		"-e", "FELIX_DATASTORETYPE=kubernetes",

		"-e", "TYPHA_DATASTORETYPE=kubernetes",

		"-e", "K8S_API_ENDPOINT=" + kds.Endpoint,

		"-e", "K8S_INSECURE_SKIP_TLS_VERIFY=true",

		"-v", kds.CertFileName + ":/tmp/apiserver.crt",

	}

}

func (kds *K8sDatastoreInfra) GetBadEndpointDockerArgs() []string {

	return []string{

		"-e", "CALICO_DATASTORE_TYPE=kubernetes",


====================
					log.WithError(err).WithField("Key", r.Key).Warning("Failed to delete entry from KDD")

				}

			}

		}

	}

}

func (kds *K8sDatastoreInfra) GetDockerArgs() []string {

	return []string{

		"-e", "CALICO_DATASTORE_TYPE=kubernetes",

		"-e", "FELIX_DATASTORETYPE=kubernetes",

		"-e", "TYPHA_DATASTORETYPE=kubernetes",

		"-e", "K8S_API_ENDPOINT=" + kds.Endpoint,

		"-e", "K8S_INSECURE_SKIP_TLS_VERIFY=true",

		"-v", kds.CertFileName + ":/tmp/apiserver.crt",

	}

}

func (kds *K8sDatastoreInfra) GetBadEndpointDockerArgs() []string {

	return []string{

		"-e", "CALICO_DATASTORE_TYPE=kubernetes",

		"-e", "FELIX_DATASTORETYPE=kubernetes",


====================
				}

			}

		}

	}

}

func (kds *K8sDatastoreInfra) GetDockerArgs() []string {

	return []string{

		"-e", "CALICO_DATASTORE_TYPE=kubernetes",

		"-e", "FELIX_DATASTORETYPE=kubernetes",

		"-e", "TYPHA_DATASTORETYPE=kubernetes",

		"-e", "K8S_API_ENDPOINT=" + kds.Endpoint,

		"-e", "K8S_INSECURE_SKIP_TLS_VERIFY=true",

		"-v", kds.CertFileName + ":/tmp/apiserver.crt",

	}

}

func (kds *K8sDatastoreInfra) GetBadEndpointDockerArgs() []string {

	return []string{

		"-e", "CALICO_DATASTORE_TYPE=kubernetes",

		"-e", "FELIX_DATASTORETYPE=kubernetes",

		"-e", "TYPHA_DATASTORETYPE=kubernetes",


====================
			}

		}

	}

}

func (kds *K8sDatastoreInfra) GetDockerArgs() []string {

	return []string{

		"-e", "CALICO_DATASTORE_TYPE=kubernetes",

		"-e", "FELIX_DATASTORETYPE=kubernetes",

		"-e", "TYPHA_DATASTORETYPE=kubernetes",

		"-e", "K8S_API_ENDPOINT=" + kds.Endpoint,

		"-e", "K8S_INSECURE_SKIP_TLS_VERIFY=true",

		"-v", kds.CertFileName + ":/tmp/apiserver.crt",

	}

}

func (kds *K8sDatastoreInfra) GetBadEndpointDockerArgs() []string {

	return []string{

		"-e", "CALICO_DATASTORE_TYPE=kubernetes",

		"-e", "FELIX_DATASTORETYPE=kubernetes",

		"-e", "TYPHA_DATASTORETYPE=kubernetes",

		"-e", "K8S_API_ENDPOINT=" + kds.BadEndpoint,


====================
		}

	}

}

func (kds *K8sDatastoreInfra) GetDockerArgs() []string {

	return []string{

		"-e", "CALICO_DATASTORE_TYPE=kubernetes",

		"-e", "FELIX_DATASTORETYPE=kubernetes",

		"-e", "TYPHA_DATASTORETYPE=kubernetes",

		"-e", "K8S_API_ENDPOINT=" + kds.Endpoint,

		"-e", "K8S_INSECURE_SKIP_TLS_VERIFY=true",

		"-v", kds.CertFileName + ":/tmp/apiserver.crt",

	}

}

func (kds *K8sDatastoreInfra) GetBadEndpointDockerArgs() []string {

	return []string{

		"-e", "CALICO_DATASTORE_TYPE=kubernetes",

		"-e", "FELIX_DATASTORETYPE=kubernetes",

		"-e", "TYPHA_DATASTORETYPE=kubernetes",

		"-e", "K8S_API_ENDPOINT=" + kds.BadEndpoint,

		"-e", "K8S_INSECURE_SKIP_TLS_VERIFY=true",


====================
	}

}

func (kds *K8sDatastoreInfra) GetDockerArgs() []string {

	return []string{

		"-e", "CALICO_DATASTORE_TYPE=kubernetes",

		"-e", "FELIX_DATASTORETYPE=kubernetes",

		"-e", "TYPHA_DATASTORETYPE=kubernetes",

		"-e", "K8S_API_ENDPOINT=" + kds.Endpoint,

		"-e", "K8S_INSECURE_SKIP_TLS_VERIFY=true",

		"-v", kds.CertFileName + ":/tmp/apiserver.crt",

	}

}

func (kds *K8sDatastoreInfra) GetBadEndpointDockerArgs() []string {

	return []string{

		"-e", "CALICO_DATASTORE_TYPE=kubernetes",

		"-e", "FELIX_DATASTORETYPE=kubernetes",

		"-e", "TYPHA_DATASTORETYPE=kubernetes",

		"-e", "K8S_API_ENDPOINT=" + kds.BadEndpoint,

		"-e", "K8S_INSECURE_SKIP_TLS_VERIFY=true",

		"-v", kds.CertFileName + ":/tmp/apiserver.crt",


====================
		"-e", "FELIX_DATASTORETYPE=kubernetes",

		"-e", "TYPHA_DATASTORETYPE=kubernetes",

		"-e", "K8S_API_ENDPOINT=" + kds.Endpoint,

		"-e", "K8S_INSECURE_SKIP_TLS_VERIFY=true",

		"-v", kds.CertFileName + ":/tmp/apiserver.crt",

	}

}

func (kds *K8sDatastoreInfra) GetBadEndpointDockerArgs() []string {

	return []string{

		"-e", "CALICO_DATASTORE_TYPE=kubernetes",

		"-e", "FELIX_DATASTORETYPE=kubernetes",

		"-e", "TYPHA_DATASTORETYPE=kubernetes",

		"-e", "K8S_API_ENDPOINT=" + kds.BadEndpoint,

		"-e", "K8S_INSECURE_SKIP_TLS_VERIFY=true",

		"-v", kds.CertFileName + ":/tmp/apiserver.crt",

	}

}

func (kds *K8sDatastoreInfra) GetCalicoClient() client.Interface {

	return kds.calicoClient

}


====================
		"-e", "TYPHA_DATASTORETYPE=kubernetes",

		"-e", "K8S_API_ENDPOINT=" + kds.Endpoint,

		"-e", "K8S_INSECURE_SKIP_TLS_VERIFY=true",

		"-v", kds.CertFileName + ":/tmp/apiserver.crt",

	}

}

func (kds *K8sDatastoreInfra) GetBadEndpointDockerArgs() []string {

	return []string{

		"-e", "CALICO_DATASTORE_TYPE=kubernetes",

		"-e", "FELIX_DATASTORETYPE=kubernetes",

		"-e", "TYPHA_DATASTORETYPE=kubernetes",

		"-e", "K8S_API_ENDPOINT=" + kds.BadEndpoint,

		"-e", "K8S_INSECURE_SKIP_TLS_VERIFY=true",

		"-v", kds.CertFileName + ":/tmp/apiserver.crt",

	}

}

func (kds *K8sDatastoreInfra) GetCalicoClient() client.Interface {

	return kds.calicoClient

}

func (kds *K8sDatastoreInfra) GetClusterGUID() string {


====================
		"-e", "K8S_API_ENDPOINT=" + kds.Endpoint,

		"-e", "K8S_INSECURE_SKIP_TLS_VERIFY=true",

		"-v", kds.CertFileName + ":/tmp/apiserver.crt",

	}

}

func (kds *K8sDatastoreInfra) GetBadEndpointDockerArgs() []string {

	return []string{

		"-e", "CALICO_DATASTORE_TYPE=kubernetes",

		"-e", "FELIX_DATASTORETYPE=kubernetes",

		"-e", "TYPHA_DATASTORETYPE=kubernetes",

		"-e", "K8S_API_ENDPOINT=" + kds.BadEndpoint,

		"-e", "K8S_INSECURE_SKIP_TLS_VERIFY=true",

		"-v", kds.CertFileName + ":/tmp/apiserver.crt",

	}

}

func (kds *K8sDatastoreInfra) GetCalicoClient() client.Interface {

	return kds.calicoClient

}

func (kds *K8sDatastoreInfra) GetClusterGUID() string {

	ci, err := kds.GetCalicoClient().ClusterInformation().Get(


====================
		"-e", "K8S_INSECURE_SKIP_TLS_VERIFY=true",

		"-v", kds.CertFileName + ":/tmp/apiserver.crt",

	}

}

func (kds *K8sDatastoreInfra) GetBadEndpointDockerArgs() []string {

	return []string{

		"-e", "CALICO_DATASTORE_TYPE=kubernetes",

		"-e", "FELIX_DATASTORETYPE=kubernetes",

		"-e", "TYPHA_DATASTORETYPE=kubernetes",

		"-e", "K8S_API_ENDPOINT=" + kds.BadEndpoint,

		"-e", "K8S_INSECURE_SKIP_TLS_VERIFY=true",

		"-v", kds.CertFileName + ":/tmp/apiserver.crt",

	}

}

func (kds *K8sDatastoreInfra) GetCalicoClient() client.Interface {

	return kds.calicoClient

}

func (kds *K8sDatastoreInfra) GetClusterGUID() string {

	ci, err := kds.GetCalicoClient().ClusterInformation().Get(

		context.Background(),


====================
		"-v", kds.CertFileName + ":/tmp/apiserver.crt",

	}

}

func (kds *K8sDatastoreInfra) GetBadEndpointDockerArgs() []string {

	return []string{

		"-e", "CALICO_DATASTORE_TYPE=kubernetes",

		"-e", "FELIX_DATASTORETYPE=kubernetes",

		"-e", "TYPHA_DATASTORETYPE=kubernetes",

		"-e", "K8S_API_ENDPOINT=" + kds.BadEndpoint,

		"-e", "K8S_INSECURE_SKIP_TLS_VERIFY=true",

		"-v", kds.CertFileName + ":/tmp/apiserver.crt",

	}

}

func (kds *K8sDatastoreInfra) GetCalicoClient() client.Interface {

	return kds.calicoClient

}

func (kds *K8sDatastoreInfra) GetClusterGUID() string {

	ci, err := kds.GetCalicoClient().ClusterInformation().Get(

		context.Background(),

		"default",


====================
	}

}

func (kds *K8sDatastoreInfra) GetBadEndpointDockerArgs() []string {

	return []string{

		"-e", "CALICO_DATASTORE_TYPE=kubernetes",

		"-e", "FELIX_DATASTORETYPE=kubernetes",

		"-e", "TYPHA_DATASTORETYPE=kubernetes",

		"-e", "K8S_API_ENDPOINT=" + kds.BadEndpoint,

		"-e", "K8S_INSECURE_SKIP_TLS_VERIFY=true",

		"-v", kds.CertFileName + ":/tmp/apiserver.crt",

	}

}

func (kds *K8sDatastoreInfra) GetCalicoClient() client.Interface {

	return kds.calicoClient

}

func (kds *K8sDatastoreInfra) GetClusterGUID() string {

	ci, err := kds.GetCalicoClient().ClusterInformation().Get(

		context.Background(),

		"default",

		options.GetOptions{},


====================
					// If VXLAN is enabled, Felix will program these routes itself.

					err := iFelix.ExecMayFail("ip", "route", "add", jBlock, "via", jFelix.IP, "dev", "eth0")

					Expect(err).ToNot(HaveOccurred())

				}

				if opts.EnableIPv6 {

					jBlockV6 := fmt.Sprintf("dead:beef::100:%d:0/96", j)

					if opts.VXLANMode == api.VXLANModeNever && !opts.IPIPRoutesEnabled {

						// If VXLAN is enabled, Felix will program these routes itself.

						// If IPIP routes are enabled, these routes will conflict with configured ones and a 'RTNETLINK answers: File exists' error would occur.

						err := iFelix.ExecMayFail("ip", "-6", "route", "add", jBlockV6, "via", jFelix.IPv6, "dev", "eth0")

						Expect(err).ToNot(HaveOccurred())

					}

				}

			}(i, j, iFelix, jFelix)

		}

	}

	wg.Wait()

	success = true

	return

}


====================
	cgroup.MaybeMoveToFelixCgroupv2()

	arguments, err := docopt.ParseArgs(usage, nil, "v0.1")

	if err != nil {

		println(usage)

		log.WithError(err).Fatal("Failed to parse usage")

	}

	log.WithField("args", arguments).Info("Parsed arguments")

	namespacePath := arguments["<namespace-path>"].(string)

	ipAddress := arguments["<ip-address>"].(string)

	protocol := arguments["--protocol"].(string)

	port := ""

	sourcePort := ""

	// No such thing as a port for raw IP.

	if !strings.HasPrefix(protocol, "ip") {

		port = arguments["<port>"].(string)

		sourcePort = arguments["--source-port"].(string)

	}

	sourceIpAddress := arguments["--source-ip"].(string)

	if debug, err := arguments.Bool("--debug"); err == nil && debug {

		log.SetLevel(log.DebugLevel)


====================
	log.WithField("args", arguments).Info("Parsed arguments")

	namespacePath := arguments["<namespace-path>"].(string)

	ipAddress := arguments["<ip-address>"].(string)

	protocol := arguments["--protocol"].(string)

	port := ""

	sourcePort := ""

	// No such thing as a port for raw IP.

	if !strings.HasPrefix(protocol, "ip") {

		port = arguments["<port>"].(string)

		sourcePort = arguments["--source-port"].(string)

	}

	sourceIpAddress := arguments["--source-ip"].(string)

	if debug, err := arguments.Bool("--debug"); err == nil && debug {

		log.SetLevel(log.DebugLevel)

		log.Debug("Debug logging enabled")

	}

	sendLenStr, _ := arguments["--sendlen"].(string)

	recvLenStr, _ := arguments["--recvlen"].(string)

	sendLen := 0

	if sendLenStr != "" {


====================
	ipAddress := arguments["<ip-address>"].(string)

	protocol := arguments["--protocol"].(string)

	port := ""

	sourcePort := ""

	// No such thing as a port for raw IP.

	if !strings.HasPrefix(protocol, "ip") {

		port = arguments["<port>"].(string)

		sourcePort = arguments["--source-port"].(string)

	}

	sourceIpAddress := arguments["--source-ip"].(string)

	if debug, err := arguments.Bool("--debug"); err == nil && debug {

		log.SetLevel(log.DebugLevel)

		log.Debug("Debug logging enabled")

	}

	sendLenStr, _ := arguments["--sendlen"].(string)

	recvLenStr, _ := arguments["--recvlen"].(string)

	sendLen := 0

	if sendLenStr != "" {

		sendLen, _ = strconv.Atoi(sendLenStr)

	}


====================
	protocol := arguments["--protocol"].(string)

	port := ""

	sourcePort := ""

	// No such thing as a port for raw IP.

	if !strings.HasPrefix(protocol, "ip") {

		port = arguments["<port>"].(string)

		sourcePort = arguments["--source-port"].(string)

	}

	sourceIpAddress := arguments["--source-ip"].(string)

	if debug, err := arguments.Bool("--debug"); err == nil && debug {

		log.SetLevel(log.DebugLevel)

		log.Debug("Debug logging enabled")

	}

	sendLenStr, _ := arguments["--sendlen"].(string)

	recvLenStr, _ := arguments["--recvlen"].(string)

	sendLen := 0

	if sendLenStr != "" {

		sendLen, _ = strconv.Atoi(sendLenStr)

	}

	recvLen := 0


====================
	if !strings.HasPrefix(protocol, "ip") {

		port = arguments["<port>"].(string)

		sourcePort = arguments["--source-port"].(string)

	}

	sourceIpAddress := arguments["--source-ip"].(string)

	if debug, err := arguments.Bool("--debug"); err == nil && debug {

		log.SetLevel(log.DebugLevel)

		log.Debug("Debug logging enabled")

	}

	sendLenStr, _ := arguments["--sendlen"].(string)

	recvLenStr, _ := arguments["--recvlen"].(string)

	sendLen := 0

	if sendLenStr != "" {

		sendLen, _ = strconv.Atoi(sendLenStr)

	}

	recvLen := 0

	if recvLenStr != "" {

		recvLen, _ = strconv.Atoi(recvLenStr)

	}

	// Set default for source IP. If we're using IPv6 as indicated by ipAddress


====================
		port = arguments["<port>"].(string)

		sourcePort = arguments["--source-port"].(string)

	}

	sourceIpAddress := arguments["--source-ip"].(string)

	if debug, err := arguments.Bool("--debug"); err == nil && debug {

		log.SetLevel(log.DebugLevel)

		log.Debug("Debug logging enabled")

	}

	sendLenStr, _ := arguments["--sendlen"].(string)

	recvLenStr, _ := arguments["--recvlen"].(string)

	sendLen := 0

	if sendLenStr != "" {

		sendLen, _ = strconv.Atoi(sendLenStr)

	}

	recvLen := 0

	if recvLenStr != "" {

		recvLen, _ = strconv.Atoi(recvLenStr)

	}

	// Set default for source IP. If we're using IPv6 as indicated by ipAddress

	// and no --source-ip option was provided, set the source IP to the default


====================
	if recvLenStr != "" {

		recvLen, _ = strconv.Atoi(recvLenStr)

	}

	// Set default for source IP. If we're using IPv6 as indicated by ipAddress

	// and no --source-ip option was provided, set the source IP to the default

	// IPv6 address.

	if strings.Contains(ipAddress, ":") && sourceIpAddress == defaultIPv4SourceIP {

		sourceIpAddress = defaultIPv6SourceIP

	}

	duration := arguments["--duration"].(string)

	seconds, err := strconv.Atoi(duration)

	if err != nil {

		// panic on error

		log.WithField("duration", duration).Fatal("Invalid duration argument")

	}

	loopFile := ""

	if arg, ok := arguments["--loop-with-file"]; ok && arg != nil {

		loopFile = arg.(string)

	}

	logPongs, err := arguments.Bool("--log-pongs")


====================
		sourceIpAddress = defaultIPv6SourceIP

	}

	duration := arguments["--duration"].(string)

	seconds, err := strconv.Atoi(duration)

	if err != nil {

		// panic on error

		log.WithField("duration", duration).Fatal("Invalid duration argument")

	}

	loopFile := ""

	if arg, ok := arguments["--loop-with-file"]; ok && arg != nil {

		loopFile = arg.(string)

	}

	logPongs, err := arguments.Bool("--log-pongs")

	if err != nil {

		log.WithError(err).Fatal("Invalid --log-pongs")

	}

	stdin, err := arguments.Bool("--stdin")

	if err != nil {

		log.WithError(err).Fatal("Invalid --stdin")

	}


====================
	seconds, err := strconv.Atoi(duration)

	if err != nil {

		// panic on error

		log.WithField("duration", duration).Fatal("Invalid duration argument")

	}

	loopFile := ""

	if arg, ok := arguments["--loop-with-file"]; ok && arg != nil {

		loopFile = arg.(string)

	}

	logPongs, err := arguments.Bool("--log-pongs")

	if err != nil {

		log.WithError(err).Fatal("Invalid --log-pongs")

	}

	stdin, err := arguments.Bool("--stdin")

	if err != nil {

		log.WithError(err).Fatal("Invalid --stdin")

	}

	var timeout time.Duration

	if toval := arguments["--timeout"]; toval != nil {

		timeoutSecs, err := strconv.ParseFloat(toval.(string), 64)


====================
	}

	loopFile := ""

	if arg, ok := arguments["--loop-with-file"]; ok && arg != nil {

		loopFile = arg.(string)

	}

	logPongs, err := arguments.Bool("--log-pongs")

	if err != nil {

		log.WithError(err).Fatal("Invalid --log-pongs")

	}

	stdin, err := arguments.Bool("--stdin")

	if err != nil {

		log.WithError(err).Fatal("Invalid --stdin")

	}

	var timeout time.Duration

	if toval := arguments["--timeout"]; toval != nil {

		timeoutSecs, err := strconv.ParseFloat(toval.(string), 64)

		if err != nil {

			// panic on error

			log.WithField("timeout", timeout).Fatal("Invalid --timeout argument")

		}


====================
	logPongs, err := arguments.Bool("--log-pongs")

	if err != nil {

		log.WithError(err).Fatal("Invalid --log-pongs")

	}

	stdin, err := arguments.Bool("--stdin")

	if err != nil {

		log.WithError(err).Fatal("Invalid --stdin")

	}

	var timeout time.Duration

	if toval := arguments["--timeout"]; toval != nil {

		timeoutSecs, err := strconv.ParseFloat(toval.(string), 64)

		if err != nil {

			// panic on error

			log.WithField("timeout", timeout).Fatal("Invalid --timeout argument")

		}

		timeout = time.Duration(timeoutSecs * float64(time.Second))

	}

	log.Infof("Test connection from namespace %v IP %v port %v to IP %v port %v proto %v "+

		"max duration %d seconds, timeout %v logging pongs (%v), stdin %v",

		namespacePath, sourceIpAddress, sourcePort, ipAddress, port, protocol, seconds, timeout, logPongs, stdin)


====================
	if loopFile == "" {

		// I found that configuring the timeouts on all the network calls was a bit fiddly.  Since

		// it leaves the process hung if one of them is missed, use a global timeout instead.

		go func() {

			timeout := time.Duration(seconds + 2)

			time.Sleep(timeout * time.Second)

			log.Fatal("Timed out")

		}()

	}

	if namespacePath == "-" {

		// Add the source IP (if set) to eth0.

		err = maybeAddAddr(sourceIpAddress)

		// Test connection from wherever we are already running.

		if err == nil {

			err = tryConnect(ipAddress, port, sourceIpAddress, sourcePort, protocol,

				seconds, loopFile, sendLen, recvLen, logPongs, stdin, timeout)

		}

	} else {

		// Get the specified network namespace (representing a workload).

		var namespace ns.NetNS


====================
	w = New(c, name, profile, ip, ports, protocol, opts...)

	return w, w.Start()

}

func (w *Workload) Start() error {

	var err error

	// Start the workload.

	log.WithField("workload", w).Info("About to run workload")

	var protoArg string

	if w.Protocol != "" {

		protoArg = "--protocol=" + w.Protocol

	}

	command := fmt.Sprintf("echo $$ > /tmp/%v; exec test-workload %v '%v' '%v' '%v'",

		w.Name,

		protoArg,

		w.InterfaceName,

		w.IP,

		w.Ports,

	)

	if w.MTU != 0 {

		command += fmt.Sprintf(" --mtu=%d", w.MTU)


====================
		w.IP,

		w.Ports,

	)

	if w.MTU != 0 {

		command += fmt.Sprintf(" --mtu=%d", w.MTU)

	}

	if w.listenAnyIP {

		command += " --listen-any-ip"

	}

	w.runCmd = utils.Command("docker", "exec", w.C.Name, "sh", "-c", command)

	w.outPipe, err = w.runCmd.StdoutPipe()

	if err != nil {

		return fmt.Errorf("Getting StdoutPipe failed: %v", err)

	}

	w.errPipe, err = w.runCmd.StderrPipe()

	if err != nil {

		return fmt.Errorf("Getting StderrPipe failed: %v", err)

	}

	err = w.runCmd.Start()

	if err != nil {


====================
	w.C.Exec("ip", "link", "set", "spoof0", "netns", w.netns())

	// In the workload netns, bring up the new interface and then move the IP to the loopback.

	w.Exec("ip", "link", "set", "up", "spoof0")

	w.Exec("ip", "addr", "del", w.IP, "dev", "eth0")

	w.Exec("ip", "addr", "add", w.IP, "dev", "lo")

	// Recreate the routes, which get removed when we remove the address.

	w.Exec("ip", "route", "add", "169.254.169.254/32", "dev", "eth0")

	w.Exec("ip", "route", "add", "default", "via", "169.254.169.254")

	// Add static ARP entry, otherwise connections fail at the ARP stage because the host won't respond.

	w.Exec("arp", "-i", "spoof0", "-s", "169.254.169.254", "ee:ee:ee:ee:ee:ee")

	w.isSpoofing = true

}

func (w *Workload) UseSpoofInterface(spoof bool) {

	var iface string

	if spoof {

		iface = "spoof0"

	} else {

		iface = "eth0"

	}

	w.Exec("ip", "route", "replace", "169.254.169.254/32", "dev", iface)


====================
	return w.C.ExecCombinedOutput(args...)

}

var (

	rttRegexp = regexp.MustCompile(`rtt=(.*) ms`)

)

func (w *Workload) LatencyTo(ip, port string) (time.Duration, string) {

	if strings.Contains(ip, ":") {

		ip = fmt.Sprintf("[%s]", ip)

	}

	out, err := w.ExecOutput("hping3", "-p", port, "-c", "20", "--fast", "-S", "-n", ip)

	stderr := ""

	if err, ok := err.(*exec.ExitError); ok {

		stderr = string(err.Stderr)

	}

	Expect(err).NotTo(HaveOccurred(), stderr)

	lines := strings.Split(out, "\n")[1:] // Skip header line

	var rttSum time.Duration

	var numBuggyRTTs int

	for _, line := range lines {

		if len(line) == 0 {


====================
	}

	Expect(numBuggyRTTs).To(BeNumerically("<", len(lines)/2),

		"hping reported a large number of >1s RTTs; full output:\n"+out)

	meanRtt := rttSum / time.Duration(len(lines))

	return meanRtt, out

}

func (w *Workload) SendPacketsTo(ip string, count int, size int) (error, string) {

	c := fmt.Sprintf("%d", count)

	s := fmt.Sprintf("%d", size)

	_, err := w.ExecOutput("ping", "-c", c, "-W", "1", "-s", s, ip)

	stderr := ""

	if err, ok := err.(*exec.ExitError); ok {

		stderr = string(err.Stderr)

	}

	return err, stderr

}

type SideService struct {

	W       *Workload

	Name    string

	RunCmd  *exec.Cmd


====================
		"127.0.0.1",

		"15001",

	)

	pidCmd := fmt.Sprintf("echo $$ >'%s'", pidFile)

	testWorkloadCmd := strings.Join(testWorkloadShArgs, " ")

	dockerWorkloadArgs := []string{

		"docker",

		"exec",

		w.C.Name,

		"sh", "-c",

		fmt.Sprintf("%s; exec %s", pidCmd, testWorkloadCmd),

	}

	runCmd := utils.Command(dockerWorkloadArgs[0], dockerWorkloadArgs[1:]...)

	logName := fmt.Sprintf("side service %s", n)

	if err := utils.LogOutput(runCmd, logName); err != nil {

		return nil, fmt.Errorf("failed to start output logging for %s", logName)

	}

	if err := runCmd.Start(); err != nil {

		return nil, fmt.Errorf("starting /test-workload as a side service failed: %v", err)

	}


====================
func canConnectTo(w *Workload, ip, port, protocol, logSuffix string, opts ...connectivity.CheckOption) *connectivity.Result {

	if protocol == "udp" || protocol == "sctp" {

		// If this is a retry then we may have stale conntrack entries and we don't want those

		// to influence the connectivity check.  UDP lacks a sequence number, so conntrack operates

		// on a simple timer. In the case of SCTP, conntrack appears to match packets even when

		// the conntrack entry is in the CLOSED state.

		if os.Getenv("FELIX_FV_ENABLE_BPF") == "true" {

			w.C.Exec("calico-bpf", "conntrack", "remove", "udp", w.IP, ip)

		} else {

			_ = w.C.ExecMayFail("conntrack", "-D", "-p", protocol, "-s", w.IP, "-d", ip)

		}

	}

	logMsg := "Connection test"

	// enforce the name space as we want to execute it in the workload

	opts = append(opts, connectivity.WithNamespacePath(w.namespacePath))

	logMsg += " " + logSuffix

	return connectivity.Check(w.C.Name, logMsg, ip, port, protocol, opts...)

}

// ToMatcher implements the connectionTarget interface, allowing this port to be used as

// target.


====================
	case <-done:

		return

	case <-time.After(t):

		logCxt.Panic("Timeout!")

	}

}

func (c *Container) execDockerStop() {

	logCxt := log.WithField("container", c.Name)

	logCxt.Info("Executing 'docker stop'")

	cmd := exec.Command("docker", "stop", "-t0", c.Name)

	err := cmd.Run()

	if err != nil {

		logCxt.WithError(err).WithField("cmd", cmd).Error("docker stop command failed")

		return

	}

	logCxt.Info("'docker stop' returned success")

}

func (c *Container) signalDockerRun(sig os.Signal) {

	logCxt := log.WithFields(log.Fields{

		"container": c.Name,


====================
	return name

}

func RunWithFixedName(name string, opts RunOpts, args ...string) (c *Container) {

	c = &Container{

		Name:             name,

		ignoreEmptyLines: opts.IgnoreEmptyLines,

	}

	// Prep command to run the container.

	log.WithField("container", c).Info("About to run container")

	runArgs := []string{"run", "--init", "--cgroupns", "host", "--name", c.Name, "--stop-timeout", fmt.Sprint(opts.StopTimeoutSecs)}

	if opts.StopSignal != "" {

		runArgs = append(runArgs, "--stop-signal", opts.StopSignal)

	}

	if opts.AutoRemove {

		runArgs = append(runArgs, "--rm")

	}

	if opts.SameNamespace != nil {

		runArgs = append(runArgs, "--network=container:"+opts.SameNamespace.Name)

	} else {

		runArgs = append(runArgs, "--hostname", c.Name)


====================
func RunWithFixedName(name string, opts RunOpts, args ...string) (c *Container) {

	c = &Container{

		Name:             name,

		ignoreEmptyLines: opts.IgnoreEmptyLines,

	}

	// Prep command to run the container.

	log.WithField("container", c).Info("About to run container")

	runArgs := []string{"run", "--init", "--cgroupns", "host", "--name", c.Name, "--stop-timeout", fmt.Sprint(opts.StopTimeoutSecs)}

	if opts.StopSignal != "" {

		runArgs = append(runArgs, "--stop-signal", opts.StopSignal)

	}

	if opts.AutoRemove {

		runArgs = append(runArgs, "--rm")

	}

	if opts.SameNamespace != nil {

		runArgs = append(runArgs, "--network=container:"+opts.SameNamespace.Name)

	} else {

		runArgs = append(runArgs, "--hostname", c.Name)

	}

	// Add remaining args


====================
		ignoreEmptyLines: opts.IgnoreEmptyLines,

	}

	// Prep command to run the container.

	log.WithField("container", c).Info("About to run container")

	runArgs := []string{"run", "--init", "--cgroupns", "host", "--name", c.Name, "--stop-timeout", fmt.Sprint(opts.StopTimeoutSecs)}

	if opts.StopSignal != "" {

		runArgs = append(runArgs, "--stop-signal", opts.StopSignal)

	}

	if opts.AutoRemove {

		runArgs = append(runArgs, "--rm")

	}

	if opts.SameNamespace != nil {

		runArgs = append(runArgs, "--network=container:"+opts.SameNamespace.Name)

	} else {

		runArgs = append(runArgs, "--hostname", c.Name)

	}

	// Add remaining args

	runArgs = append(runArgs, args...)

	c.runCmd = utils.Command("docker", runArgs...)

	if opts.WithStdinPipe {


====================
	log.WithField("container", c).Info("About to run container")

	runArgs := []string{"run", "--init", "--cgroupns", "host", "--name", c.Name, "--stop-timeout", fmt.Sprint(opts.StopTimeoutSecs)}

	if opts.StopSignal != "" {

		runArgs = append(runArgs, "--stop-signal", opts.StopSignal)

	}

	if opts.AutoRemove {

		runArgs = append(runArgs, "--rm")

	}

	if opts.SameNamespace != nil {

		runArgs = append(runArgs, "--network=container:"+opts.SameNamespace.Name)

	} else {

		runArgs = append(runArgs, "--hostname", c.Name)

	}

	// Add remaining args

	runArgs = append(runArgs, args...)

	c.runCmd = utils.Command("docker", runArgs...)

	if opts.WithStdinPipe {

		var err error

		c.Stdin, err = c.runCmd.StdinPipe()

		Expect(err).NotTo(HaveOccurred())


====================
	if opts.StopSignal != "" {

		runArgs = append(runArgs, "--stop-signal", opts.StopSignal)

	}

	if opts.AutoRemove {

		runArgs = append(runArgs, "--rm")

	}

	if opts.SameNamespace != nil {

		runArgs = append(runArgs, "--network=container:"+opts.SameNamespace.Name)

	} else {

		runArgs = append(runArgs, "--hostname", c.Name)

	}

	// Add remaining args

	runArgs = append(runArgs, args...)

	c.runCmd = utils.Command("docker", runArgs...)

	if opts.WithStdinPipe {

		var err error

		c.Stdin, err = c.runCmd.StdinPipe()

		Expect(err).NotTo(HaveOccurred())

	}

	// Get the command's output pipes, so we can merge those into the test's own logging.


====================
	c.stdoutWatches = append(c.stdoutWatches, &watch{

		regexp: re,

		c:      ch,

	})

	return ch

}

// Start executes "docker start" on a container. Useful when used after Stop()

// to restart a container.

func (c *Container) Start() {

	c.runCmd = utils.Command("docker", "start", "--attach", c.Name)

	stdout, err := c.runCmd.StdoutPipe()

	Expect(err).NotTo(HaveOccurred())

	stderr, err := c.runCmd.StderrPipe()

	Expect(err).NotTo(HaveOccurred())

	// Start the container running.

	err = c.runCmd.Start()

	Expect(err).NotTo(HaveOccurred())

	// Merge container's output into our own logging.

	c.logFinished.Add(2)

	go c.copyOutputToLog("stdout", stdout, &c.logFinished, &c.stdoutWatches)


====================
	c.logFinished.Add(2)

	go c.copyOutputToLog("stdout", stdout, &c.logFinished, &c.stdoutWatches)

	go c.copyOutputToLog("stderr", stderr, &c.logFinished, nil)

	c.WaitUntilRunning()

	log.WithField("container", c).Info("Container now running")

}

// Remove deletes a container. Should be manually called after a non-auto-removed container

// is stopped.

func (c *Container) Remove() {

	c.runCmd = utils.Command("docker", "rm", "-f", c.Name)

	err := c.runCmd.Start()

	Expect(err).NotTo(HaveOccurred())

	log.WithField("container", c).Info("Removed container.")

}

func (c *Container) copyOutputToLog(streamName string, stream io.Reader, done *sync.WaitGroup, watches *[]*watch) {

	defer done.Done()

	scanner := bufio.NewScanner(stream)

	scanner.Buffer(nil, 10*1024*1024) // Increase maximum buffer size (but don't pre-alloc).

	// Felix is configured with the race detector enabled. When the race detector fires, we get output like this:

	//


====================
	logCxt.Info("Stream finished")

}

func (c *Container) DataRaces() []string {

	c.mutex.Lock()

	defer c.mutex.Unlock()

	return c.dataRaces

}

func (c *Container) DockerInspect(format string) string {

	inspectCmd := utils.Command("docker", "inspect",

		"--format="+format,

		c.Name,

	)

	outputBytes, err := inspectCmd.CombinedOutput()

	Expect(err).NotTo(HaveOccurred())

	return string(outputBytes)

}

func (c *Container) GetID() string {

	output := c.DockerInspect("{{.Id}}")

	return strings.TrimSpace(output)

}


====================
func (c *Container) GetIPv6Prefix() string {

	output := c.DockerInspect("{{range .NetworkSettings.Networks}}{{.GlobalIPv6PrefixLen}}{{end}}")

	return strings.TrimSpace(output)

}

func (c *Container) GetHostname() string {

	output := c.DockerInspect("{{.Config.Hostname}}")

	return strings.TrimSpace(output)

}

func (c *Container) GetPIDs(processName string) []int {

	out, err := c.ExecOutput("pgrep", "-f", fmt.Sprintf("^%s$", processName))

	if err != nil {

		log.WithError(err).Warn("pgrep failed, assuming no PIDs")

		return nil

	}

	var pids []int

	for _, line := range strings.Split(out, "\n") {

		if line == "" {

			continue

		}

		pid, err := strconv.Atoi(line)


====================
		}

		time.Sleep(1000 * time.Millisecond)

	}

}

func (c *Container) CopyFileIntoContainer(hostPath, containerPath string) error {

	cmd := utils.Command("docker", "cp", hostPath, c.Name+":"+containerPath)

	return cmd.Run()

}

func (c *Container) FileExists(path string) bool {

	err := c.ExecMayFail("test", "-e", path)

	return err == nil

}

func (c *Container) Exec(cmd ...string) {

	log.WithField("container", c.Name).WithField("command", cmd).Info("Running command")

	arg := []string{"exec", c.Name}

	arg = append(arg, cmd...)

	utils.Run("docker", arg...)

}

func (c *Container) ExecWithInput(input []byte, cmd ...string) {

	log.WithField("container", c.Name).WithField("command", cmd).Info("Running command")


====================
}

func (c *Container) Exec(cmd ...string) {

	log.WithField("container", c.Name).WithField("command", cmd).Info("Running command")

	arg := []string{"exec", c.Name}

	arg = append(arg, cmd...)

	utils.Run("docker", arg...)

}

func (c *Container) ExecWithInput(input []byte, cmd ...string) {

	log.WithField("container", c.Name).WithField("command", cmd).Info("Running command")

	arg := []string{"exec", "-i", c.Name}

	arg = append(arg, cmd...)

	utils.RunWithInput(input, "docker", arg...)

}

func (c *Container) ExecMayFail(cmd ...string) error {

	arg := []string{"exec", c.Name}

	arg = append(arg, cmd...)

	return utils.RunMayFail("docker", arg...)

}

func (c *Container) ExecOutput(args ...string) (string, error) {

	arg := []string{"exec", c.Name}


====================
	cgroup.MaybeMoveToFelixCgroupv2()

	arguments, err := docopt.ParseArgs(usage, nil, "v0.1")

	if err != nil {

		println(usage)

		log.WithError(err).Fatal("Failed to parse usage")

	}

	interfaceName := arguments["<interface-name>"].(string)

	ipAddress := arguments["<ip-address>"].(string)

	portsStr := arguments["<ports>"].(string)

	protocol := arguments["--protocol"].(string)

	nsPath := ""

	if arg, ok := arguments["--namespace-path"]; ok && arg != nil {

		nsPath = arg.(string)

	}

	sidecarIptables := arguments["--sidecar-iptables"].(bool)

	upLo := arguments["--up-lo"].(bool)

	mtu := 1450

	if arg, ok := arguments["--mtu"]; ok && arg != nil {

		mtu, err = strconv.Atoi(arg.(string))

		panicIfError(err)


====================
	if err != nil {

		println(usage)

		log.WithError(err).Fatal("Failed to parse usage")

	}

	interfaceName := arguments["<interface-name>"].(string)

	ipAddress := arguments["<ip-address>"].(string)

	portsStr := arguments["<ports>"].(string)

	protocol := arguments["--protocol"].(string)

	nsPath := ""

	if arg, ok := arguments["--namespace-path"]; ok && arg != nil {

		nsPath = arg.(string)

	}

	sidecarIptables := arguments["--sidecar-iptables"].(bool)

	upLo := arguments["--up-lo"].(bool)

	mtu := 1450

	if arg, ok := arguments["--mtu"]; ok && arg != nil {

		mtu, err = strconv.Atoi(arg.(string))

		panicIfError(err)

	}

	panicIfError(err)


====================
	}

	interfaceName := arguments["<interface-name>"].(string)

	ipAddress := arguments["<ip-address>"].(string)

	portsStr := arguments["<ports>"].(string)

	protocol := arguments["--protocol"].(string)

	nsPath := ""

	if arg, ok := arguments["--namespace-path"]; ok && arg != nil {

		nsPath = arg.(string)

	}

	sidecarIptables := arguments["--sidecar-iptables"].(bool)

	upLo := arguments["--up-lo"].(bool)

	mtu := 1450

	if arg, ok := arguments["--mtu"]; ok && arg != nil {

		mtu, err = strconv.Atoi(arg.(string))

		panicIfError(err)

	}

	panicIfError(err)

	listenAnyIP := false

	if _, ok := arguments["--listen-any-ip"]; ok {

		listenAnyIP = true


====================
	interfaceName := arguments["<interface-name>"].(string)

	ipAddress := arguments["<ip-address>"].(string)

	portsStr := arguments["<ports>"].(string)

	protocol := arguments["--protocol"].(string)

	nsPath := ""

	if arg, ok := arguments["--namespace-path"]; ok && arg != nil {

		nsPath = arg.(string)

	}

	sidecarIptables := arguments["--sidecar-iptables"].(bool)

	upLo := arguments["--up-lo"].(bool)

	mtu := 1450

	if arg, ok := arguments["--mtu"]; ok && arg != nil {

		mtu, err = strconv.Atoi(arg.(string))

		panicIfError(err)

	}

	panicIfError(err)

	listenAnyIP := false

	if _, ok := arguments["--listen-any-ip"]; ok {

		listenAnyIP = true

	}


====================
	portsStr := arguments["<ports>"].(string)

	protocol := arguments["--protocol"].(string)

	nsPath := ""

	if arg, ok := arguments["--namespace-path"]; ok && arg != nil {

		nsPath = arg.(string)

	}

	sidecarIptables := arguments["--sidecar-iptables"].(bool)

	upLo := arguments["--up-lo"].(bool)

	mtu := 1450

	if arg, ok := arguments["--mtu"]; ok && arg != nil {

		mtu, err = strconv.Atoi(arg.(string))

		panicIfError(err)

	}

	panicIfError(err)

	listenAnyIP := false

	if _, ok := arguments["--listen-any-ip"]; ok {

		listenAnyIP = true

	}

	ports := strings.Split(portsStr, ",")

	var namespace ns.NetNS


====================
	sidecarIptables := arguments["--sidecar-iptables"].(bool)

	upLo := arguments["--up-lo"].(bool)

	mtu := 1450

	if arg, ok := arguments["--mtu"]; ok && arg != nil {

		mtu, err = strconv.Atoi(arg.(string))

		panicIfError(err)

	}

	panicIfError(err)

	listenAnyIP := false

	if _, ok := arguments["--listen-any-ip"]; ok {

		listenAnyIP = true

	}

	ports := strings.Split(portsStr, ",")

	var namespace ns.NetNS

	if nsPath != "" {

		namespace, err = ns.GetNS(nsPath)

		if err != nil {

			log.WithError(err).WithField("namespace path", nsPath).Fatal("Failed to get netns from path")

		}

	} else if interfaceName != "" {


====================
				}

				if err = writeProcSys("/proc/sys/net/ipv6/conf/default/disable_ipv6", "0"); err != nil {

					log.WithError(err).Error("Failed to enable IPv6 by default.")

					return

				}

				if err = writeProcSys("/proc/sys/net/ipv6/conf/lo/disable_ipv6", "0"); err != nil {

					log.WithError(err).Error("Failed to enable IPv6 on the loopback interface.")

					return

				}

				err = utils.RunCommand("ip", "-6", "addr", "add", ipAddress+"/128", "dev", "eth0")

				if err != nil {

					log.WithField("ipAddress", ipAddress+"/128").WithError(err).Error("Failed to add IPv6 addr to eth0.")

					return

				}

				err = utils.RunCommand("ip", "-6", "route", "add", "default", "via", hostIPv6Addr.String(), "dev", "eth0")

				if err != nil {

					log.WithField("hostIP", hostIPv6Addr.String()).WithError(err).Info("Failed to add IPv6 route to eth0.")

					return

				}

				// Output the routing table to the log for diagnostic purposes.


====================
				if err = writeProcSys("/proc/sys/net/ipv6/conf/lo/disable_ipv6", "0"); err != nil {

					log.WithError(err).Error("Failed to enable IPv6 on the loopback interface.")

					return

				}

				err = utils.RunCommand("ip", "-6", "addr", "add", ipAddress+"/128", "dev", "eth0")

				if err != nil {

					log.WithField("ipAddress", ipAddress+"/128").WithError(err).Error("Failed to add IPv6 addr to eth0.")

					return

				}

				err = utils.RunCommand("ip", "-6", "route", "add", "default", "via", hostIPv6Addr.String(), "dev", "eth0")

				if err != nil {

					log.WithField("hostIP", hostIPv6Addr.String()).WithError(err).Info("Failed to add IPv6 route to eth0.")

					return

				}

				// Output the routing table to the log for diagnostic purposes.

				err = utils.RunCommand("ip", "-6", "route")

				if err != nil {

					log.WithError(err).Info("Failed to output IPv6 routes.")

				}

				err = utils.RunCommand("ip", "-6", "addr")


====================
					log.WithField("ipAddress", ipAddress+"/128").WithError(err).Error("Failed to add IPv6 addr to eth0.")

					return

				}

				err = utils.RunCommand("ip", "-6", "route", "add", "default", "via", hostIPv6Addr.String(), "dev", "eth0")

				if err != nil {

					log.WithField("hostIP", hostIPv6Addr.String()).WithError(err).Info("Failed to add IPv6 route to eth0.")

					return

				}

				// Output the routing table to the log for diagnostic purposes.

				err = utils.RunCommand("ip", "-6", "route")

				if err != nil {

					log.WithError(err).Info("Failed to output IPv6 routes.")

				}

				err = utils.RunCommand("ip", "-6", "addr")

				if err != nil {

					log.WithError(err).Info("Failed to output IPv6 addresses.")

				}

			} else {

				err = utils.RunCommand("ip", "addr", "add", ipAddress+"/32", "dev", "eth0")

				if err != nil {


====================
				if err != nil {

					log.WithField("hostIP", hostIPv6Addr.String()).WithError(err).Info("Failed to add IPv6 route to eth0.")

					return

				}

				// Output the routing table to the log for diagnostic purposes.

				err = utils.RunCommand("ip", "-6", "route")

				if err != nil {

					log.WithError(err).Info("Failed to output IPv6 routes.")

				}

				err = utils.RunCommand("ip", "-6", "addr")

				if err != nil {

					log.WithError(err).Info("Failed to output IPv6 addresses.")

				}

			} else {

				err = utils.RunCommand("ip", "addr", "add", ipAddress+"/32", "dev", "eth0")

				if err != nil {

					log.WithField("ipAddress", ipAddress+"/32").WithError(err).Error("Failed to add IPv4 addr to eth0.")

					return

				}

				err = utils.RunCommand("ip", "route", "add", "169.254.169.254/32", "dev", "eth0")


====================
		}

		if sidecarIptables {

			if err := doSidecarIptablesSetup(); err != nil {

				return fmt.Errorf("failed to setup sidecar-like iptables: %v", err)

			}

		}

		if strings.Contains(ipAddress, ":") {

			attempts := 0

			for {

				out, err := exec.Command("ip", "-6", "addr").CombinedOutput()

				panicIfError(err)

				if strings.Contains(string(out), "tentative") {

					attempts++

					if attempts > 30 {

						log.Panic("IPv6 address still tentative after 30s")

					}

					time.Sleep(1 * time.Second)

					continue

				}

				break


====================
		logEnabled:       true,

		contName:         containerName,

		matchers:         map[string]*tcpDumpMatcher{},

		listeningStarted: make(chan struct{}),

	}

	t.args = []string{"exec", t.contName}

	if netns != "" {

		t.args = append(t.args, "ip", "netns", "exec", netns)

	}

	t.args = append(t.args, "tcpdump", "-nli", iface)

	t.logString = containerName

	if netns != "" {

		t.logString += ":" + netns

	}

	return t

}

// AttachUnavailable use if tcpdump is not available in the container

func AttachUnavailable(containerID, iface string) *TCPDump {

	containerName := "tcpdump-" + containerID + "-" + iface

	t := Attach(containerName, "", iface)


====================
	t.args = append(t.args, "tcpdump", "-nli", iface)

	t.logString = containerName

	if netns != "" {

		t.logString += ":" + netns

	}

	return t

}

// AttachUnavailable use if tcpdump is not available in the container

func AttachUnavailable(containerID, iface string) *TCPDump {

	containerName := "tcpdump-" + containerID + "-" + iface

	t := Attach(containerName, "", iface)

	t.args = []string{"run",

		"--rm",

		"--name", containerName,

		fmt.Sprintf("--network=container:%s", containerID),

		"corfr/tcpdump", "-nli", iface}

	return t

}

type stringMatcher interface {

	MatchString(string) bool


====================
		t.logString += ":" + netns

	}

	return t

}

// AttachUnavailable use if tcpdump is not available in the container

func AttachUnavailable(containerID, iface string) *TCPDump {

	containerName := "tcpdump-" + containerID + "-" + iface

	t := Attach(containerName, "", iface)

	t.args = []string{"run",

		"--rm",

		"--name", containerName,

		fmt.Sprintf("--network=container:%s", containerID),

		"corfr/tcpdump", "-nli", iface}

	return t

}

type stringMatcher interface {

	MatchString(string) bool

}

type tcpDumpMatcher struct {

	regex stringMatcher


====================
	}

	return t

}

// AttachUnavailable use if tcpdump is not available in the container

func AttachUnavailable(containerID, iface string) *TCPDump {

	containerName := "tcpdump-" + containerID + "-" + iface

	t := Attach(containerName, "", iface)

	t.args = []string{"run",

		"--rm",

		"--name", containerName,

		fmt.Sprintf("--network=container:%s", containerID),

		"corfr/tcpdump", "-nli", iface}

	return t

}

type stringMatcher interface {

	MatchString(string) bool

}

type tcpDumpMatcher struct {

	regex stringMatcher

	count int


====================
	return t

}

// AttachUnavailable use if tcpdump is not available in the container

func AttachUnavailable(containerID, iface string) *TCPDump {

	containerName := "tcpdump-" + containerID + "-" + iface

	t := Attach(containerName, "", iface)

	t.args = []string{"run",

		"--rm",

		"--name", containerName,

		fmt.Sprintf("--network=container:%s", containerID),

		"corfr/tcpdump", "-nli", iface}

	return t

}

type stringMatcher interface {

	MatchString(string) bool

}

type tcpDumpMatcher struct {

	regex stringMatcher

	count int

}


====================
}

// AttachUnavailable use if tcpdump is not available in the container

func AttachUnavailable(containerID, iface string) *TCPDump {

	containerName := "tcpdump-" + containerID + "-" + iface

	t := Attach(containerName, "", iface)

	t.args = []string{"run",

		"--rm",

		"--name", containerName,

		fmt.Sprintf("--network=container:%s", containerID),

		"corfr/tcpdump", "-nli", iface}

	return t

}

type stringMatcher interface {

	MatchString(string) bool

}

type tcpDumpMatcher struct {

	regex stringMatcher

	count int

}

type TCPDump struct {


====================
// BinaryName is the name of the binary that the connectivity Check() executes

const BinaryName = "test-connection"

// Run executes the check command

func (cmd *CheckCmd) run(cName string, logMsg string) *Result {

	// Ensure that the container has the 'test-connection' binary.

	logCxt := log.WithField("container", cName)

	logCxt.Debugf("Entering connectivity.Check(%v,%v,%v,%v,%v)",

		cmd.ip, cmd.port, cmd.protocol, cmd.sendLen, cmd.recvLen)

	args := []string{"exec", cName,

		"test-connection", "--protocol=" + cmd.protocol,

		fmt.Sprintf("--duration=%d", int(cmd.duration.Seconds())),

		fmt.Sprintf("--sendlen=%d", cmd.sendLen),

		fmt.Sprintf("--recvlen=%d", cmd.recvLen),

		fmt.Sprintf("--timeout=%f", cmd.timeout.Seconds()),

		cmd.nsPath, cmd.ip, cmd.port,

	}

	if cmd.ipSource != "" {

		args = append(args, fmt.Sprintf("--source-ip=%s", cmd.ipSource))

	}

	if cmd.portSource != "" {


====================
const BinaryName = "test-connection"

// Run executes the check command

func (cmd *CheckCmd) run(cName string, logMsg string) *Result {

	// Ensure that the container has the 'test-connection' binary.

	logCxt := log.WithField("container", cName)

	logCxt.Debugf("Entering connectivity.Check(%v,%v,%v,%v,%v)",

		cmd.ip, cmd.port, cmd.protocol, cmd.sendLen, cmd.recvLen)

	args := []string{"exec", cName,

		"test-connection", "--protocol=" + cmd.protocol,

		fmt.Sprintf("--duration=%d", int(cmd.duration.Seconds())),

		fmt.Sprintf("--sendlen=%d", cmd.sendLen),

		fmt.Sprintf("--recvlen=%d", cmd.recvLen),

		fmt.Sprintf("--timeout=%f", cmd.timeout.Seconds()),

		cmd.nsPath, cmd.ip, cmd.port,

	}

	if cmd.ipSource != "" {

		args = append(args, fmt.Sprintf("--source-ip=%s", cmd.ipSource))

	}

	if cmd.portSource != "" {

		args = append(args, fmt.Sprintf("--source-port=%s", cmd.portSource))


====================
// Run executes the check command

func (cmd *CheckCmd) run(cName string, logMsg string) *Result {

	// Ensure that the container has the 'test-connection' binary.

	logCxt := log.WithField("container", cName)

	logCxt.Debugf("Entering connectivity.Check(%v,%v,%v,%v,%v)",

		cmd.ip, cmd.port, cmd.protocol, cmd.sendLen, cmd.recvLen)

	args := []string{"exec", cName,

		"test-connection", "--protocol=" + cmd.protocol,

		fmt.Sprintf("--duration=%d", int(cmd.duration.Seconds())),

		fmt.Sprintf("--sendlen=%d", cmd.sendLen),

		fmt.Sprintf("--recvlen=%d", cmd.recvLen),

		fmt.Sprintf("--timeout=%f", cmd.timeout.Seconds()),

		cmd.nsPath, cmd.ip, cmd.port,

	}

	if cmd.ipSource != "" {

		args = append(args, fmt.Sprintf("--source-ip=%s", cmd.ipSource))

	}

	if cmd.portSource != "" {

		args = append(args, fmt.Sprintf("--source-port=%s", cmd.portSource))

	}


====================
func (cmd *CheckCmd) run(cName string, logMsg string) *Result {

	// Ensure that the container has the 'test-connection' binary.

	logCxt := log.WithField("container", cName)

	logCxt.Debugf("Entering connectivity.Check(%v,%v,%v,%v,%v)",

		cmd.ip, cmd.port, cmd.protocol, cmd.sendLen, cmd.recvLen)

	args := []string{"exec", cName,

		"test-connection", "--protocol=" + cmd.protocol,

		fmt.Sprintf("--duration=%d", int(cmd.duration.Seconds())),

		fmt.Sprintf("--sendlen=%d", cmd.sendLen),

		fmt.Sprintf("--recvlen=%d", cmd.recvLen),

		fmt.Sprintf("--timeout=%f", cmd.timeout.Seconds()),

		cmd.nsPath, cmd.ip, cmd.port,

	}

	if cmd.ipSource != "" {

		args = append(args, fmt.Sprintf("--source-ip=%s", cmd.ipSource))

	}

	if cmd.portSource != "" {

		args = append(args, fmt.Sprintf("--source-port=%s", cmd.portSource))

	}

	// Run 'test-connection' to the target.


====================
	// Ensure that the container has the 'test-connection' binary.

	logCxt := log.WithField("container", cName)

	logCxt.Debugf("Entering connectivity.Check(%v,%v,%v,%v,%v)",

		cmd.ip, cmd.port, cmd.protocol, cmd.sendLen, cmd.recvLen)

	args := []string{"exec", cName,

		"test-connection", "--protocol=" + cmd.protocol,

		fmt.Sprintf("--duration=%d", int(cmd.duration.Seconds())),

		fmt.Sprintf("--sendlen=%d", cmd.sendLen),

		fmt.Sprintf("--recvlen=%d", cmd.recvLen),

		fmt.Sprintf("--timeout=%f", cmd.timeout.Seconds()),

		cmd.nsPath, cmd.ip, cmd.port,

	}

	if cmd.ipSource != "" {

		args = append(args, fmt.Sprintf("--source-ip=%s", cmd.ipSource))

	}

	if cmd.portSource != "" {

		args = append(args, fmt.Sprintf("--source-port=%s", cmd.portSource))

	}

	// Run 'test-connection' to the target.

	connectionCmd := utils.Command("docker", args...)


====================
	args := []string{"exec", cName,

		"test-connection", "--protocol=" + cmd.protocol,

		fmt.Sprintf("--duration=%d", int(cmd.duration.Seconds())),

		fmt.Sprintf("--sendlen=%d", cmd.sendLen),

		fmt.Sprintf("--recvlen=%d", cmd.recvLen),

		fmt.Sprintf("--timeout=%f", cmd.timeout.Seconds()),

		cmd.nsPath, cmd.ip, cmd.port,

	}

	if cmd.ipSource != "" {

		args = append(args, fmt.Sprintf("--source-ip=%s", cmd.ipSource))

	}

	if cmd.portSource != "" {

		args = append(args, fmt.Sprintf("--source-port=%s", cmd.portSource))

	}

	// Run 'test-connection' to the target.

	connectionCmd := utils.Command("docker", args...)

	connectionCmd.Env = []string{"GODEBUG=netdns=1"}

	outPipe, err := connectionCmd.StdoutPipe()

	Expect(err).NotTo(HaveOccurred())

	errPipe, err := connectionCmd.StderrPipe()


====================
		fmt.Sprintf("--sendlen=%d", cmd.sendLen),

		fmt.Sprintf("--recvlen=%d", cmd.recvLen),

		fmt.Sprintf("--timeout=%f", cmd.timeout.Seconds()),

		cmd.nsPath, cmd.ip, cmd.port,

	}

	if cmd.ipSource != "" {

		args = append(args, fmt.Sprintf("--source-ip=%s", cmd.ipSource))

	}

	if cmd.portSource != "" {

		args = append(args, fmt.Sprintf("--source-port=%s", cmd.portSource))

	}

	// Run 'test-connection' to the target.

	connectionCmd := utils.Command("docker", args...)

	connectionCmd.Env = []string{"GODEBUG=netdns=1"}

	outPipe, err := connectionCmd.StdoutPipe()

	Expect(err).NotTo(HaveOccurred())

	errPipe, err := connectionCmd.StderrPipe()

	Expect(err).NotTo(HaveOccurred())

	err = connectionCmd.Start()

	Expect(err).NotTo(HaveOccurred())


====================
func WithTimeout(t time.Duration) CheckOption {

	return func(c *CheckCmd) {

		c.timeout = t

	}

}

// Check executes the connectivity check

func Check(cName, logMsg, ip, port, protocol string, opts ...CheckOption) *Result {

	const defaultPingTimeout = 2 * time.Second

	cmd := CheckCmd{

		nsPath:   "-",

		ip:       ip,

		port:     port,

		protocol: protocol,

		timeout:  defaultPingTimeout,

	}

	for _, opt := range opts {

		opt(&cmd)

	}

	return cmd.run(cName, logMsg)

}


====================
	runCmd   *exec.Cmd

	lastPongTime time.Time

	pongCount    int

}

func (pc *PersistentConnection) Stop() {

	Expect(pc.stop()).NotTo(HaveOccurred())

}

var permConnIdx = 0 // XXX perhaps should be atomic / locked

func (pc *PersistentConnection) stop() error {

	if err := pc.Runtime.ExecMayFail("sh", "-c", fmt.Sprintf("echo > %s", pc.loopFile)); err != nil {

		log.WithError(err).

			WithField("loopfile", pc.loopFile).

			Warn("Failed to create a loop file to stop the permanent connection")

		return err

	}

	if err := pc.runCmd.Wait(); err != nil {

		return err

	}

	return nil

}


====================
	}

	if err := pc.runCmd.Wait(); err != nil {

		return err

	}

	return nil

}

func (pc *PersistentConnection) Start() error {

	namespacePath := pc.NamespacePath

	if namespacePath == "" {

		namespacePath = "-"

	}

	permConnIdx++

	n := fmt.Sprintf("%s-pc%d", pc.RuntimeName, permConnIdx)

	loopFile := fmt.Sprintf("/tmp/%s-loop", n)

	err := pc.Runtime.ExecMayFail("sh", "-c", fmt.Sprintf("echo > %s", loopFile))

	if err != nil {

		return err

	}

	args := []string{

		"exec",


====================
}

func (pc *PersistentConnection) Start() error {

	namespacePath := pc.NamespacePath

	if namespacePath == "" {

		namespacePath = "-"

	}

	permConnIdx++

	n := fmt.Sprintf("%s-pc%d", pc.RuntimeName, permConnIdx)

	loopFile := fmt.Sprintf("/tmp/%s-loop", n)

	err := pc.Runtime.ExecMayFail("sh", "-c", fmt.Sprintf("echo > %s", loopFile))

	if err != nil {

		return err

	}

	args := []string{

		"exec",

		pc.RuntimeName,

		"test-connection",

		namespacePath,

		pc.IP,

		fmt.Sprintf("%d", pc.Port),


====================
		return err

	}

	args := []string{

		"exec",

		pc.RuntimeName,

		"test-connection",

		namespacePath,

		pc.IP,

		fmt.Sprintf("%d", pc.Port),

		fmt.Sprintf("--source-port=%d", pc.SourcePort),

		fmt.Sprintf("--protocol=%s", pc.Protocol),

		fmt.Sprintf("--loop-with-file=%s", loopFile),

	}

	if pc.MonitorConnectivity {

		args = append(args, "--log-pongs")

	}

	if pc.Timeout > 0 {

		args = append(args, fmt.Sprintf("--timeout=%d", pc.Timeout/time.Second))

	}

	runCmd := utils.Command(


====================
	}

	args := []string{

		"exec",

		pc.RuntimeName,

		"test-connection",

		namespacePath,

		pc.IP,

		fmt.Sprintf("%d", pc.Port),

		fmt.Sprintf("--source-port=%d", pc.SourcePort),

		fmt.Sprintf("--protocol=%s", pc.Protocol),

		fmt.Sprintf("--loop-with-file=%s", loopFile),

	}

	if pc.MonitorConnectivity {

		args = append(args, "--log-pongs")

	}

	if pc.Timeout > 0 {

		args = append(args, fmt.Sprintf("--timeout=%d", pc.Timeout/time.Second))

	}

	runCmd := utils.Command(

		"docker",


====================
	args := []string{

		"exec",

		pc.RuntimeName,

		"test-connection",

		namespacePath,

		pc.IP,

		fmt.Sprintf("%d", pc.Port),

		fmt.Sprintf("--source-port=%d", pc.SourcePort),

		fmt.Sprintf("--protocol=%s", pc.Protocol),

		fmt.Sprintf("--loop-with-file=%s", loopFile),

	}

	if pc.MonitorConnectivity {

		args = append(args, "--log-pongs")

	}

	if pc.Timeout > 0 {

		args = append(args, fmt.Sprintf("--timeout=%d", pc.Timeout/time.Second))

	}

	runCmd := utils.Command(

		"docker",

		args...,


====================
		"test-connection",

		namespacePath,

		pc.IP,

		fmt.Sprintf("%d", pc.Port),

		fmt.Sprintf("--source-port=%d", pc.SourcePort),

		fmt.Sprintf("--protocol=%s", pc.Protocol),

		fmt.Sprintf("--loop-with-file=%s", loopFile),

	}

	if pc.MonitorConnectivity {

		args = append(args, "--log-pongs")

	}

	if pc.Timeout > 0 {

		args = append(args, fmt.Sprintf("--timeout=%d", pc.Timeout/time.Second))

	}

	runCmd := utils.Command(

		"docker",

		args...,

	)

	logName := fmt.Sprintf("persistent connection %s", n)

	stdout, err := runCmd.StdoutPipe()


====================
		fmt.Sprintf("%d", pc.Port),

		fmt.Sprintf("--source-port=%d", pc.SourcePort),

		fmt.Sprintf("--protocol=%s", pc.Protocol),

		fmt.Sprintf("--loop-with-file=%s", loopFile),

	}

	if pc.MonitorConnectivity {

		args = append(args, "--log-pongs")

	}

	if pc.Timeout > 0 {

		args = append(args, fmt.Sprintf("--timeout=%d", pc.Timeout/time.Second))

	}

	runCmd := utils.Command(

		"docker",

		args...,

	)

	logName := fmt.Sprintf("persistent connection %s", n)

	stdout, err := runCmd.StdoutPipe()

	if err != nil {

		return fmt.Errorf("failed to start output logging for %s", logName)

	}


====================
					return

				}

				currentMembers.Add(newMember)

				logCxt.WithField("member", newMember).Info("Member added")

			}

		case "del":

			Expect(len(parts)).To(Equal(4))

			name := parts[1]

			newMember := parts[2]

			Expect(parts[3]).To(Equal("--exist"))

			logCxt := log.WithField("setName", name)

			if currentMembers, ok := c.Dataplane.IPSetMembers[name]; !ok {

				_, _ = c.Stderr.Write([]byte("set doesn't exist"))

				result = &exec.ExitError{}

				return

			} else {

				existing := currentMembers.Contains(newMember)

				if !existing {

					c.Dataplane.TriedToDeleteNonExistent = true

				}


====================
}

const (

	// mainIpsetToken is the character that we append to the versioned prefix "cali4" or "cali6" to

	// get the main IP set name prefix.   To minimise the length of the prefix (and hence preserve

	// as much entropy as possible in the IP set ID) we use this as a version number, and

	// increment it when making breaking changes to the IP set format.  In particular, this must

	// be changed if the type of the IP set is changed because the kernel doesn't support the

	// "ipset swap" operation unless the two IP sets to be swapped share a type.

	//

	// The first "version" used "-" for the token.

	mainIpsetToken = "0"

	// tempIpsetToken similarly, for the temporary copy of each IP set.  Typically, this doesn't

	// need to be changed because we delete and recreate the temporary IP set before using it.

	tempIpsetToken = "t"

)

func NewIPVersionConfig(

	family IPFamily,

	namePrefix string,

	allHistoricPrefixes []string,

	extraUnversionedIPSets []string,


====================
		logCxt := log.WithFields(log.Fields{

			"prefix":          prefix,

			"namesWithPrefix": ifaceNames,

		})

		logCxt.Debug("Considering prefix")

		if len(ifaceNames) > 1 {

			// More than one name, render a prefix match in the root chain...

			nextChar := prefix[len(commonPrefix):]

			ifaceMatch := prefix + "+"

			childChainName := chainName + "-" + nextChar

			logCxt := logCxt.WithFields(log.Fields{

				"childChainName": childChainName,

				"ifaceMatch":     ifaceMatch,

			})

			logCxt.Debug("Multiple interfaces with prefix, rendering child chain")

			rootRules = append(rootRules, Rule{

				Match: getMatchForEndpoint(ifaceMatch),

				// Note: we use a goto here, which means that packets will not

				// return to this chain.  This prevents packets from traversing the

				// rest of the root chain once we've found their prefix.


====================
		if err != nil {

			log.WithError(err).WithField("rule", rule).Panic("Failed to marshal rule")

		}

		_, err = s.Write(data)

		if err != nil {

			log.WithError(err).WithField("rule", rule).Panic("Failed to write marshalled rule")

		}

		hash = s.Sum(hash[0:0])

		// Encode the hash using a compact character set.  We use the URL-safe base64

		// variant because it uses '-' and '_', which are more shell-friendly.

		ruleID := base64.RawURLEncoding.EncodeToString(hash)[:RuleIDLength]

		if log.GetLevel() >= log.DebugLevel {

			log.WithFields(log.Fields{

				"rule":     rule,

				"action":   rule.Action,

				"position": ii,

				"seed":     ruleIDSeed,

				"ruleID":   ruleID,

			}).Debug("Calculated rule ID")

		}


====================
		}

		// We safely dereferenced the Id in OnServiceUpdate before adding it to the pending updates map, so

		// it is safe to do so here.

		buf.sentServices.Add(id)

	}

	buf.pendingServiceUpdates = make(map[serviceID]*proto.ServiceUpdate)

	log.Debug("Done flushing Services")

}

func cidrToIPPoolID(cidr ip.CIDR) string {

	return strings.Replace(cidr.String(), "/", "-", 1)

}

func addPolicyToTierInfo(pol *PolKV, tierInfo *proto.TierInfo, egressAllowed bool) {

	if pol.GovernsIngress() {

		tierInfo.IngressPolicies = append(tierInfo.IngressPolicies, pol.Key.Name)

	}

	if egressAllowed && pol.GovernsEgress() {

		tierInfo.EgressPolicies = append(tierInfo.EgressPolicies, pol.Key.Name)

	}

}

func tierInfoToProtoTierInfo(filteredTiers []tierInfo) (normalTiers, untrackedTiers, preDNATTiers, forwardTiers []*proto.TierInfo) {


====================
// The returned address matches the address assigned to the VXLAN device on that node.

func (c *VXLANResolver) vtepMACForHost(nodename string, ipVersion int) string {

	logCtx := logrus.WithFields(logrus.Fields{"node": nodename, "ipVersion": ipVersion})

	var mac string

	switch ipVersion {

	case 4:

		mac = c.nodeNameToVXLANMac[nodename]

	case 6:

		mac = c.nodeNameToVXLANMacV6[nodename]

		nodename += "-v6"

	default:

		logCtx.Panic("Invalid IP version")

	}

	// Return stored MAC address if present

	if mac != "" {

		return mac

	}

	// Otherwise generate a MAC address

	hasher := sha1.New()

	_, err := hasher.Write([]byte(nodename))


====================
// NATted).

//

// When we delete conntrack entries by IP address, we need to specify which element of the tuple

// to look in.  This slice holds the flags corresponding to the fields we care about.  Since we're

// deleting entries for local workload endpoints, either the endpoint originated the traffic, or it

// received the traffic and replied to it.  In the originating case, the "original source" will be

// set to the endpoint's IP; in the other case, the "reply source". Hence, it's sufficient to only

// look in those two fields.

var deleteDirections = []string{

	"--orig-src",

	"--reply-src",

}

const numRetries = 3

type Conntrack struct {

	newCmd newCmd

}

func New() *Conntrack {

	return NewWithCmdShim(func(name string, arg ...string) CmdIface {

		return (*cmdAdapter)(exec.Command(name, arg...))

	})


====================
//

// When we delete conntrack entries by IP address, we need to specify which element of the tuple

// to look in.  This slice holds the flags corresponding to the fields we care about.  Since we're

// deleting entries for local workload endpoints, either the endpoint originated the traffic, or it

// received the traffic and replied to it.  In the originating case, the "original source" will be

// set to the endpoint's IP; in the other case, the "reply source". Hence, it's sufficient to only

// look in those two fields.

var deleteDirections = []string{

	"--orig-src",

	"--reply-src",

}

const numRetries = 3

type Conntrack struct {

	newCmd newCmd

}

func New() *Conntrack {

	return NewWithCmdShim(func(name string, arg ...string) CmdIface {

		return (*cmdAdapter)(exec.Command(name, arg...))

	})

}


====================
	default:

		log.WithField("version", ipVersion).Panic("Unknown IP version")

	}

	log.WithField("ip", ipAddr).Info("Removing conntrack flows")

	for _, direction := range deleteDirections {

		logCxt := log.WithFields(log.Fields{"ip": ipAddr, "direction": direction})

		// Retry a few times because the conntrack command seems to fail at random.

		for retry := 0; retry <= numRetries; retry += 1 {

			cmd := c.newCmd("conntrack",

				"--family", family,

				"--delete", direction,

				ipAddr.String())

			// The conntrack tool generates quite a lot of output on stdout (one line per flow) so we

			// only capture stderr (which is where it logs its errors).

			var stderrBuf bytes.Buffer

			cmd.SetStderr(&stderrBuf)

			err := cmd.Run()

			if err == nil {

				logCxt.Debug("Successfully removed conntrack flows.")

				break


====================
		log.WithField("version", ipVersion).Panic("Unknown IP version")

	}

	log.WithField("ip", ipAddr).Info("Removing conntrack flows")

	for _, direction := range deleteDirections {

		logCxt := log.WithFields(log.Fields{"ip": ipAddr, "direction": direction})

		// Retry a few times because the conntrack command seems to fail at random.

		for retry := 0; retry <= numRetries; retry += 1 {

			cmd := c.newCmd("conntrack",

				"--family", family,

				"--delete", direction,

				ipAddr.String())

			// The conntrack tool generates quite a lot of output on stdout (one line per flow) so we

			// only capture stderr (which is where it logs its errors).

			var stderrBuf bytes.Buffer

			cmd.SetStderr(&stderrBuf)

			err := cmd.Run()

			if err == nil {

				logCxt.Debug("Successfully removed conntrack flows.")

				break

			}


====================
	var conntrack *Conntrack

	var cmdRec *cmdRecorder

	BeforeEach(func() {

		cmdRec = &cmdRecorder{}

		conntrack = NewWithCmdShim(cmdRec.newCmd)

	})

	It("IPv4: Should remove all directions", func() {

		conntrack.RemoveConntrackFlows(4, net.ParseIP("10.0.0.1"))

		Expect(cmdRec.cmdArgs).To(Equal([][]string{

			[]string{"--family", "ipv4", "--delete", "--orig-src", "10.0.0.1"},

			[]string{"--family", "ipv4", "--delete", "--reply-src", "10.0.0.1"},

		}))

	})

	It("IPv6: Should remove all directions", func() {

		conntrack.RemoveConntrackFlows(6, net.ParseIP("fe80::beef"))

		Expect(cmdRec.cmdArgs).To(Equal([][]string{

			[]string{"--family", "ipv6", "--delete", "--orig-src", "fe80::beef"},

			[]string{"--family", "ipv6", "--delete", "--reply-src", "fe80::beef"},

		}))

	})


====================
	var cmdRec *cmdRecorder

	BeforeEach(func() {

		cmdRec = &cmdRecorder{}

		conntrack = NewWithCmdShim(cmdRec.newCmd)

	})

	It("IPv4: Should remove all directions", func() {

		conntrack.RemoveConntrackFlows(4, net.ParseIP("10.0.0.1"))

		Expect(cmdRec.cmdArgs).To(Equal([][]string{

			[]string{"--family", "ipv4", "--delete", "--orig-src", "10.0.0.1"},

			[]string{"--family", "ipv4", "--delete", "--reply-src", "10.0.0.1"},

		}))

	})

	It("IPv6: Should remove all directions", func() {

		conntrack.RemoveConntrackFlows(6, net.ParseIP("fe80::beef"))

		Expect(cmdRec.cmdArgs).To(Equal([][]string{

			[]string{"--family", "ipv6", "--delete", "--orig-src", "fe80::beef"},

			[]string{"--family", "ipv6", "--delete", "--reply-src", "fe80::beef"},

		}))

	})

	It("should panic on unknown IP version", func() {


====================
		conntrack.RemoveConntrackFlows(4, net.ParseIP("10.0.0.1"))

		Expect(cmdRec.cmdArgs).To(Equal([][]string{

			[]string{"--family", "ipv4", "--delete", "--orig-src", "10.0.0.1"},

			[]string{"--family", "ipv4", "--delete", "--reply-src", "10.0.0.1"},

		}))

	})

	It("IPv6: Should remove all directions", func() {

		conntrack.RemoveConntrackFlows(6, net.ParseIP("fe80::beef"))

		Expect(cmdRec.cmdArgs).To(Equal([][]string{

			[]string{"--family", "ipv6", "--delete", "--orig-src", "fe80::beef"},

			[]string{"--family", "ipv6", "--delete", "--reply-src", "fe80::beef"},

		}))

	})

	It("should panic on unknown IP version", func() {

		Expect(func() { conntrack.RemoveConntrackFlows(9, nil) }).To(Panic())

	})

	Describe("with no flows to delete", func() {

		BeforeEach(func() {

			cmdRec.nextError = errors.New("0 flow entries")

		})


====================
		Expect(cmdRec.cmdArgs).To(Equal([][]string{

			[]string{"--family", "ipv4", "--delete", "--orig-src", "10.0.0.1"},

			[]string{"--family", "ipv4", "--delete", "--reply-src", "10.0.0.1"},

		}))

	})

	It("IPv6: Should remove all directions", func() {

		conntrack.RemoveConntrackFlows(6, net.ParseIP("fe80::beef"))

		Expect(cmdRec.cmdArgs).To(Equal([][]string{

			[]string{"--family", "ipv6", "--delete", "--orig-src", "fe80::beef"},

			[]string{"--family", "ipv6", "--delete", "--reply-src", "fe80::beef"},

		}))

	})

	It("should panic on unknown IP version", func() {

		Expect(func() { conntrack.RemoveConntrackFlows(9, nil) }).To(Panic())

	})

	Describe("with no flows to delete", func() {

		BeforeEach(func() {

			cmdRec.nextError = errors.New("0 flow entries")

		})

		It("Should remove all directions and not retry", func() {


====================
		Expect(func() { conntrack.RemoveConntrackFlows(9, nil) }).To(Panic())

	})

	Describe("with no flows to delete", func() {

		BeforeEach(func() {

			cmdRec.nextError = errors.New("0 flow entries")

		})

		It("Should remove all directions and not retry", func() {

			conntrack.RemoveConntrackFlows(4, net.ParseIP("10.0.0.1"))

			Expect(cmdRec.cmdArgs).To(Equal([][]string{

				[]string{"--family", "ipv4", "--delete", "--orig-src", "10.0.0.1"},

				[]string{"--family", "ipv4", "--delete", "--reply-src", "10.0.0.1"},

			}))

		})

	})

	Describe("with a transient error", func() {

		BeforeEach(func() {

			cmdRec.nextError = errors.New("who knows")

		})

		It("Should remove all directions and retry", func() {

			conntrack.RemoveConntrackFlows(4, net.ParseIP("10.0.0.1"))


====================
	})

	Describe("with no flows to delete", func() {

		BeforeEach(func() {

			cmdRec.nextError = errors.New("0 flow entries")

		})

		It("Should remove all directions and not retry", func() {

			conntrack.RemoveConntrackFlows(4, net.ParseIP("10.0.0.1"))

			Expect(cmdRec.cmdArgs).To(Equal([][]string{

				[]string{"--family", "ipv4", "--delete", "--orig-src", "10.0.0.1"},

				[]string{"--family", "ipv4", "--delete", "--reply-src", "10.0.0.1"},

			}))

		})

	})

	Describe("with a transient error", func() {

		BeforeEach(func() {

			cmdRec.nextError = errors.New("who knows")

		})

		It("Should remove all directions and retry", func() {

			conntrack.RemoveConntrackFlows(4, net.ParseIP("10.0.0.1"))

			Expect(cmdRec.cmdArgs).To(Equal([][]string{


====================
		})

	})

	Describe("with a transient error", func() {

		BeforeEach(func() {

			cmdRec.nextError = errors.New("who knows")

		})

		It("Should remove all directions and retry", func() {

			conntrack.RemoveConntrackFlows(4, net.ParseIP("10.0.0.1"))

			Expect(cmdRec.cmdArgs).To(Equal([][]string{

				[]string{"--family", "ipv4", "--delete", "--orig-src", "10.0.0.1"},

				[]string{"--family", "ipv4", "--delete", "--orig-src", "10.0.0.1"},

				[]string{"--family", "ipv4", "--delete", "--reply-src", "10.0.0.1"},

			}))

		})

	})

	Describe("with a persistent error", func() {

		BeforeEach(func() {

			cmdRec.persistentError = errors.New("who knows")

		})

		It("Should remove all directions and retry", func() {


====================
	})

	Describe("with a transient error", func() {

		BeforeEach(func() {

			cmdRec.nextError = errors.New("who knows")

		})

		It("Should remove all directions and retry", func() {

			conntrack.RemoveConntrackFlows(4, net.ParseIP("10.0.0.1"))

			Expect(cmdRec.cmdArgs).To(Equal([][]string{

				[]string{"--family", "ipv4", "--delete", "--orig-src", "10.0.0.1"},

				[]string{"--family", "ipv4", "--delete", "--orig-src", "10.0.0.1"},

				[]string{"--family", "ipv4", "--delete", "--reply-src", "10.0.0.1"},

			}))

		})

	})

	Describe("with a persistent error", func() {

		BeforeEach(func() {

			cmdRec.persistentError = errors.New("who knows")

		})

		It("Should remove all directions and retry", func() {

			conntrack.RemoveConntrackFlows(4, net.ParseIP("10.0.0.1"))


====================
	Describe("with a transient error", func() {

		BeforeEach(func() {

			cmdRec.nextError = errors.New("who knows")

		})

		It("Should remove all directions and retry", func() {

			conntrack.RemoveConntrackFlows(4, net.ParseIP("10.0.0.1"))

			Expect(cmdRec.cmdArgs).To(Equal([][]string{

				[]string{"--family", "ipv4", "--delete", "--orig-src", "10.0.0.1"},

				[]string{"--family", "ipv4", "--delete", "--orig-src", "10.0.0.1"},

				[]string{"--family", "ipv4", "--delete", "--reply-src", "10.0.0.1"},

			}))

		})

	})

	Describe("with a persistent error", func() {

		BeforeEach(func() {

			cmdRec.persistentError = errors.New("who knows")

		})

		It("Should remove all directions and retry", func() {

			conntrack.RemoveConntrackFlows(4, net.ParseIP("10.0.0.1"))

			Expect(cmdRec.cmdArgs).To(Equal([][]string{


====================
		})

	})

	Describe("with a persistent error", func() {

		BeforeEach(func() {

			cmdRec.persistentError = errors.New("who knows")

		})

		It("Should remove all directions and retry", func() {

			conntrack.RemoveConntrackFlows(4, net.ParseIP("10.0.0.1"))

			Expect(cmdRec.cmdArgs).To(Equal([][]string{

				[]string{"--family", "ipv4", "--delete", "--orig-src", "10.0.0.1"},

				[]string{"--family", "ipv4", "--delete", "--orig-src", "10.0.0.1"},

				[]string{"--family", "ipv4", "--delete", "--orig-src", "10.0.0.1"},

				[]string{"--family", "ipv4", "--delete", "--orig-src", "10.0.0.1"},

				[]string{"--family", "ipv4", "--delete", "--reply-src", "10.0.0.1"},

				[]string{"--family", "ipv4", "--delete", "--reply-src", "10.0.0.1"},

				[]string{"--family", "ipv4", "--delete", "--reply-src", "10.0.0.1"},

				[]string{"--family", "ipv4", "--delete", "--reply-src", "10.0.0.1"},

			}))

		})

	})


====================
	})

	Describe("with a persistent error", func() {

		BeforeEach(func() {

			cmdRec.persistentError = errors.New("who knows")

		})

		It("Should remove all directions and retry", func() {

			conntrack.RemoveConntrackFlows(4, net.ParseIP("10.0.0.1"))

			Expect(cmdRec.cmdArgs).To(Equal([][]string{

				[]string{"--family", "ipv4", "--delete", "--orig-src", "10.0.0.1"},

				[]string{"--family", "ipv4", "--delete", "--orig-src", "10.0.0.1"},

				[]string{"--family", "ipv4", "--delete", "--orig-src", "10.0.0.1"},

				[]string{"--family", "ipv4", "--delete", "--orig-src", "10.0.0.1"},

				[]string{"--family", "ipv4", "--delete", "--reply-src", "10.0.0.1"},

				[]string{"--family", "ipv4", "--delete", "--reply-src", "10.0.0.1"},

				[]string{"--family", "ipv4", "--delete", "--reply-src", "10.0.0.1"},

				[]string{"--family", "ipv4", "--delete", "--reply-src", "10.0.0.1"},

			}))

		})

	})

})


====================
	Describe("with a persistent error", func() {

		BeforeEach(func() {

			cmdRec.persistentError = errors.New("who knows")

		})

		It("Should remove all directions and retry", func() {

			conntrack.RemoveConntrackFlows(4, net.ParseIP("10.0.0.1"))

			Expect(cmdRec.cmdArgs).To(Equal([][]string{

				[]string{"--family", "ipv4", "--delete", "--orig-src", "10.0.0.1"},

				[]string{"--family", "ipv4", "--delete", "--orig-src", "10.0.0.1"},

				[]string{"--family", "ipv4", "--delete", "--orig-src", "10.0.0.1"},

				[]string{"--family", "ipv4", "--delete", "--orig-src", "10.0.0.1"},

				[]string{"--family", "ipv4", "--delete", "--reply-src", "10.0.0.1"},

				[]string{"--family", "ipv4", "--delete", "--reply-src", "10.0.0.1"},

				[]string{"--family", "ipv4", "--delete", "--reply-src", "10.0.0.1"},

				[]string{"--family", "ipv4", "--delete", "--reply-src", "10.0.0.1"},

			}))

		})

	})

})

type cmdRecorder struct {


====================
		BeforeEach(func() {

			cmdRec.persistentError = errors.New("who knows")

		})

		It("Should remove all directions and retry", func() {

			conntrack.RemoveConntrackFlows(4, net.ParseIP("10.0.0.1"))

			Expect(cmdRec.cmdArgs).To(Equal([][]string{

				[]string{"--family", "ipv4", "--delete", "--orig-src", "10.0.0.1"},

				[]string{"--family", "ipv4", "--delete", "--orig-src", "10.0.0.1"},

				[]string{"--family", "ipv4", "--delete", "--orig-src", "10.0.0.1"},

				[]string{"--family", "ipv4", "--delete", "--orig-src", "10.0.0.1"},

				[]string{"--family", "ipv4", "--delete", "--reply-src", "10.0.0.1"},

				[]string{"--family", "ipv4", "--delete", "--reply-src", "10.0.0.1"},

				[]string{"--family", "ipv4", "--delete", "--reply-src", "10.0.0.1"},

				[]string{"--family", "ipv4", "--delete", "--reply-src", "10.0.0.1"},

			}))

		})

	})

})

type cmdRecorder struct {

	commands        []*mockCmd


====================
			cmdRec.persistentError = errors.New("who knows")

		})

		It("Should remove all directions and retry", func() {

			conntrack.RemoveConntrackFlows(4, net.ParseIP("10.0.0.1"))

			Expect(cmdRec.cmdArgs).To(Equal([][]string{

				[]string{"--family", "ipv4", "--delete", "--orig-src", "10.0.0.1"},

				[]string{"--family", "ipv4", "--delete", "--orig-src", "10.0.0.1"},

				[]string{"--family", "ipv4", "--delete", "--orig-src", "10.0.0.1"},

				[]string{"--family", "ipv4", "--delete", "--orig-src", "10.0.0.1"},

				[]string{"--family", "ipv4", "--delete", "--reply-src", "10.0.0.1"},

				[]string{"--family", "ipv4", "--delete", "--reply-src", "10.0.0.1"},

				[]string{"--family", "ipv4", "--delete", "--reply-src", "10.0.0.1"},

				[]string{"--family", "ipv4", "--delete", "--reply-src", "10.0.0.1"},

			}))

		})

	})

})

type cmdRecorder struct {

	commands        []*mockCmd

	cmdArgs         [][]string


====================
		})

		It("Should remove all directions and retry", func() {

			conntrack.RemoveConntrackFlows(4, net.ParseIP("10.0.0.1"))

			Expect(cmdRec.cmdArgs).To(Equal([][]string{

				[]string{"--family", "ipv4", "--delete", "--orig-src", "10.0.0.1"},

				[]string{"--family", "ipv4", "--delete", "--orig-src", "10.0.0.1"},

				[]string{"--family", "ipv4", "--delete", "--orig-src", "10.0.0.1"},

				[]string{"--family", "ipv4", "--delete", "--orig-src", "10.0.0.1"},

				[]string{"--family", "ipv4", "--delete", "--reply-src", "10.0.0.1"},

				[]string{"--family", "ipv4", "--delete", "--reply-src", "10.0.0.1"},

				[]string{"--family", "ipv4", "--delete", "--reply-src", "10.0.0.1"},

				[]string{"--family", "ipv4", "--delete", "--reply-src", "10.0.0.1"},

			}))

		})

	})

})

type cmdRecorder struct {

	commands        []*mockCmd

	cmdArgs         [][]string

	nextError       error


====================
		It("Should remove all directions and retry", func() {

			conntrack.RemoveConntrackFlows(4, net.ParseIP("10.0.0.1"))

			Expect(cmdRec.cmdArgs).To(Equal([][]string{

				[]string{"--family", "ipv4", "--delete", "--orig-src", "10.0.0.1"},

				[]string{"--family", "ipv4", "--delete", "--orig-src", "10.0.0.1"},

				[]string{"--family", "ipv4", "--delete", "--orig-src", "10.0.0.1"},

				[]string{"--family", "ipv4", "--delete", "--orig-src", "10.0.0.1"},

				[]string{"--family", "ipv4", "--delete", "--reply-src", "10.0.0.1"},

				[]string{"--family", "ipv4", "--delete", "--reply-src", "10.0.0.1"},

				[]string{"--family", "ipv4", "--delete", "--reply-src", "10.0.0.1"},

				[]string{"--family", "ipv4", "--delete", "--reply-src", "10.0.0.1"},

			}))

		})

	})

})

type cmdRecorder struct {

	commands        []*mockCmd

	cmdArgs         [][]string

	nextError       error

	persistentError error


====================
			conntrack.RemoveConntrackFlows(4, net.ParseIP("10.0.0.1"))

			Expect(cmdRec.cmdArgs).To(Equal([][]string{

				[]string{"--family", "ipv4", "--delete", "--orig-src", "10.0.0.1"},

				[]string{"--family", "ipv4", "--delete", "--orig-src", "10.0.0.1"},

				[]string{"--family", "ipv4", "--delete", "--orig-src", "10.0.0.1"},

				[]string{"--family", "ipv4", "--delete", "--orig-src", "10.0.0.1"},

				[]string{"--family", "ipv4", "--delete", "--reply-src", "10.0.0.1"},

				[]string{"--family", "ipv4", "--delete", "--reply-src", "10.0.0.1"},

				[]string{"--family", "ipv4", "--delete", "--reply-src", "10.0.0.1"},

				[]string{"--family", "ipv4", "--delete", "--reply-src", "10.0.0.1"},

			}))

		})

	})

})

type cmdRecorder struct {

	commands        []*mockCmd

	cmdArgs         [][]string

	nextError       error

	persistentError error

}


====================
			state, err := getFelixIntMetric("felix_resync_state")

			if err != nil {

				log.WithError(err).Error("Failed to get felix stat.")

			}

			return state

		}, "10s").Should(

		BeNumerically("==", 3), "Felix never reported in-sync with datastore")

}

func triggerFelixGCAndMemoryDump() {

	err := exec.Command("pkill", "-USR1", "calico-felix").Run()

	Expect(err).ToNot(HaveOccurred())

	time.Sleep(2 * time.Second)

}

// Copyright (c) 2017-2020 Tigera, Inc. All rights reserved.

//

// Licensed under the Apache License, Version 2.0 (the "License");

// you may not use this file except in compliance with the License.

// You may obtain a copy of the License at

//

//     http://www.apache.org/licenses/LICENSE-2.0


====================
	v1 "k8s.io/apimachinery/pkg/apis/meta/v1"

	"k8s.io/client-go/kubernetes"

)

func rotateLabels(clientset *kubernetes.Clientset, nsPrefix string) error {

	nsMaturity := map[string]string{}

	maturities := []string{"production", "test", "staging", "experimental"}

	// Create namespaces.

	for _, area := range []string{"1", "2", "3", "4", "5"} {

		for _, maturity := range maturities {

			name := nsPrefix + area + "-" + maturity

			createNamespace(

				clientset,

				name,

				map[string]string{

					"area":     "area" + area,

					"maturity": maturity,

				},

			)

			nsMaturity[name] = maturity

		}




